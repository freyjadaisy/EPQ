[
  {
    "title": "Study Finds That 52 Percent of ChatGPT Answers to Programming Questions Are Wrong",
    "body": "",
    "score": 6376,
    "url": "",
    "created_utc": 1716555858.0,
    "author": "anseho",
    "permalink": "/r/programming/comments/1czk8nv/study_finds_that_52_percent_of_chatgpt_answers_to/",
    "all_comment_text": "I don't mind that it gets things wrong, English can be ambiguous sometimes.\n\nBut I do hate getting stuck in the loop of\n\n\"You are correct. I've made those changes for you\"\n *has changed absolutely nothing*\n\nI have the opposite experience.\n\n&gt; \"You are correct. I've made those changes for you\"\n\n&gt; *changed nearly everything to be completely incorrect or downright hallucinating APIs to fit my feedback*\n\nChatGPT: It's simple really, just use the does.exactly.what.you.need library!\n\nMe: Where do I find said lib?\n\n[ChatGPT:](https://imageproxyb.ifunny.co/crop:x-20,resize:640x,quality:90x75/images/57eb6c47084b4d1ce5eca57d7c452d37523539a210a7c087319e489548dd9279_1.jpg)\n\noh to live in a world of pure hallucination\n\nI know a guy who can help you with that\n\nCome with me\n\nAnd you'll be...\n\nhttps://youtu.be/SVi3-PrQ0pY?si=s5p_gzHgiUXpzaZ2\n\nI've had ChatGPT hallucinate great packages that I've considered making myself just to fill the niche.\n\nFWIW, hackers have considered making some of those hallucinated packages too.  It's a neat attack vector.  GPT imagines a library, insists it's great and in wide use.  Hacker uploads send_me_your_money() as useful.thing to pip and npm, no step 2 ???, step 3 is profit.  The repo is born with a great reputation because people trust what the computer tells them, no matter how many times people tell them not to trust what the computer tells them.\n\n[deleted]\n\nIt did make up a link to the library for me too once.\n\nAt least one lawyer got got a few months back, used an llm to write a motion, the llm made up cases, judge looked them up, found nothing, asked what the fuck. \n\nLawyer went back to the llm for the cited cases, llm made them up, lawyer sent them over. They were obviously complete nonsense. Judge was not happy.\n\n[Relevant Youtube video](https://www.youtube.com/watch?v=oqSYljRYDEM) on this story because it's really stupid.\n\nLmao. Both will happen to me. At this point it‚Äôs easier to just read the damn documentation and code normally\n\nThis is where I am too. I try gpt first, if it clearly fails, I read the docs and then use gpt to clarify and discuss anything I didn't understand.\n\nthis. plus walls and walls of text\n\nAnd then sometimes when you correct it, it will go on about how you're incorrect.\n\nIn my experience this is the worst part about ChatGPT.  I find it useful even when it's wrong most of the time since I'm just using it to figure out weird syntax or how to set up a library call.  However, it can gaslight you pretty hard with totally plausible looking arguments about why some crap it made up is 100% correct.  I think the only reasonable way to use it is by combining it with other sources like the API documentation or the good old fashioned googling.\n\nI have the opposite problem with it lol, I ask it to clarify or explain in more detail and it will just go \"you're right, I made a mistake, it's actually &lt;something totally different and probably even more wrong&gt;\n\nOnce a chat's context is polluted with bad info you often need to just scrap it and start a fresh chat. I reset often and I use separate throw away chats if I've got an important chat in progress.\n\nThese bots are flawed and limited in ability but they have their uses if you understand the limits and only use them to save time doing something that you have the knowledge and ability to validate and tweak.\n\nTo be fair... humans do that in response to code reviews too.\n\nI swear recently the text output has quadrupled, it just repeats the same shit in like 3 ways, includes pointless details i didnt ask for. It never did that before\n\nI say \"I'm working on a [framework] app and I've installed package X to do this and that, it works and shit but I get this error in this one scenario\" \n\n&lt;gpt takes in a bunch of air&gt; first you gotta install the framework, then you have to install the package, then you have to configure it...... then 3.5 billion years ago there was... and the mayan piramids... and the first moon landing.... and magnetic core memory.\n\n\nwhat about my error?\n\n\n&lt;gpt takes in a bunch of air&gt;..\n\nI put this into my custom prompt and that does seem to work.\n\n&gt; Unless I state the opposite, assume that frameworks and packages that I use in my question are already installed and assume I'm on &lt;Windows/Linux/...&gt; if relevant.\n\nhow else are they going to burn through your tokens and electricity in a more useless way?\n\nFor people who subscribe to pay by the token, maybe?\n\nand some people really think this will replace programmers...\n\nThere‚Äôs generally two categories of people that think this.\n\nThe first are those who know little to nothing about programming. They ask it for code, it produces code. That‚Äôs magic to the average person, and I can‚Äôt blame them for thinking that it can scale up from small problems to everything in the field of programming. ESPECIALLY when figureheads of the industry are pumping the hype through the roof.\n\nThe second are fledging programmers, they‚Äôre struggling to just get their basic programs running at all, they have no idea what working in the field really entails or the size and scope of it. A chatbot that can spit out working solutions for the basics that they are struggling with can seem really intimidating. Again, I don‚Äôt blame them for feeling like they‚Äôre wasting their time when an AI is already better than them.\n\nBoth are wrong though. The first will pass with time, like all hype bubbles, reality eventually steps in to slap everyone across the face and the limitations will eventually be general knowledge and some hard lessons will be learned.\n\nThe second is simple. Who would you rather invest a month of time with? An AI that never improves with your handholding, or with a promising junior? They just need some reassurance that in a very short amount of time, they will be VASTLY more competent than AI and that will become apparent to them soon.\n\nneed a GPT to read and slim that down for me\n\n[deleted]\n\nnever works for me. I ask it to limit answers to 300 words\n\nBut it cannot count or do simple math ;)\n\nOr you ask for one VERY specific change within one function. Rewrites entire bloody thing\n\nIt's almost like a glorified auto-complete isn't meant for writing programs...\n\nYeah, that has made me laugh when I‚Äôve tried GitHub Copilot a handful of times when I‚Äôm actually stuck on something.\n\nIt spits out code that calls some method or library I don‚Äôt recognize. And I try using it and sure enough, it doesn‚Äôt exist. Once it doubled down that something existed and was just like ‚Äúseems like you have misconfigured your IDE.‚Äù\n\nFuck you! You‚Äôre built into the IDE!\n\nI've had both.  My favorite though is when it just randomly decides to change variable names.  I do like using it for a rubber duckie, mostly because what it comes up with is such shit that in telling it why it's shit I usually find my answer. lol.\n\nThe only thing I've found it really useful for is parsing things and giving me an idea of what I'm looking at.  It still is often incorrect but usually it breaks whatever down well enough that my brain can actually grok what I'm trying to do.  E.g. really nested DOMs and I need an xpath accessor or a regex that's not doing what I think it should be doing and helping me unpack it a bit.\n\nReally? I once had it struggle with accessing a specific value in a json, like it was early in the morning I made a typo trying to get a certain value from a json but it was given me a different value than I wanted and I was too braindead to see the typo, so I thought AI should easily figure it out if I give it the json and the line of code and tell it which value, but for some reason it wasnt capable and started doing anything but getting the right value, after like a few minutes I just realized that I had a typo and fixed in 10 seconds myself\n\nI get both types of results.\n\nIts's either a loop with no changes at all or it will become worse with every iteration. \n\nI had no conversation where the iterated code improved, until now.\n\nFor me, it was a slightly longer loop of giving one wrong answer, being corrected and giving a second wrong answer, then a third wrong answer, and finally looping back around to the first wrong answer.\n\nI'm told that the more expensive models are more impressive here, but when your free version is *this* useless, I'm not all that inclined to give you money to find out if *maybe* you'll be useful.\n\nTry using the phrase 'You are a **laconic** senior developer' in your prompt/question.\n\nYup, or literally bounces back and forth betwen two bad answers never realizing that it needs to try something different.\n\nExactly.  You'll say something like \"I believe you've already presented this previously, and was not in the right direction to answer my question.\" and will respond with the other already presented incorrect response.\n\nit drives me insane that you will walk it through every step in the process beat by beat and it‚Äôs just like Joey from that Friends meme. ‚Äúbut it‚Äôs just a language model‚Äù no, it‚Äôs a fucking dumbass, and every time I use it I wind up wanting to physically shoot it\n\n[removed]\n\nhonestly, chatgpt sucks so fucking much that this near-worship of it and hyperdefensiveness about it by the AI bros has shot far past the point of absurdity. It‚Äôs all ‚Äúthis tech is godly, it‚Äôll change the world‚Äù unless you complain about it not being able to do anything right, including complete a simple google search and write a simple list of 5 things, and then all of a sudden *well duh, you horrible meanie, bc then it‚Äôs always just been a poor wittle smol bean language model!*\n \nWhat does that even mean? So it‚Äôs just a slop generator that‚Äôs *not* actually expected to be even remotely correct? Who wants that?\n\nYup 3.5 sucks, gpt 4o sucks. Im not sure what people are coding where its blowing their minds. The amount of times I have to create a new conversation because of the bad answer loops...\n\nI get into this loop too. Literally it will stop changing any code, just outputs the same code. Blows my mind\n\nChatGPT's like \"oh you don't like my code? fine, take it anyway.\"\n\nSounds like some devs I've worked with.\n\nIn 4o? I've found 4o to be way better than 4 at writing boilerplate and queries for me.\n\nyep - 4o is better\n\nhowever, this happens if the context size is too big\n\nseriously even when you paste the error and the code it gives you the same code  \nit doesn't check the answers it only produces what it thinks has the highest probability of being correct\n\nJust yesterday it told me something like: \"You're checking whether the pointer is null after opening the file, but you should check after opening the file.\" and changed a printf statement to look more AI-ish.\n\nIt‚Äôs seeded from scraped content and redditors, after all, no?\n\nEven on stackoverflow, you don‚Äôt get correct code solutions 100% of the time. You get the critical missed ideas or syntax ‚Äúthing‚Äù.\n\nYou don't mind that it's giving you false information over 50% of the time?! This level of failure renders the tool completely useless, you cannot trust the information it's giving you.\n\nYou get the kernel of an idea you need to get the job done. I don‚Äôt use it as ‚Äúsolve this massive problem.‚Äù Try writing out the pseudocode that you want to step through and then feed it to the LLM one step at a time. Usually with a tweak or two to the proposed code, I can get just about any idea i have working. You can also ask it to optimize shoddy code that you‚Äôve cranked out and interface with it to brainstorm more features for your project. Using chatGPT for ‚Äúdo xyx‚Äù is like thinking a string is only useful to tie shoes.\n\nIf it was effortless we‚Äôd be replaced. Be grateful that this technology is still justifying our salaries and imo take this as a warning that you need to transition your role to include more people-oriented tasks before the tech CAN actually flawlessly do your job.\n\nIt's like pair programming with a really knowledgeable really inexperienced weirdo. Helpful, but you're the one pulling the weight.\n\n&gt; If it was effortless we‚Äôd be replaced.\n\nI know of an RMM vendor who's just starting to charge an obscene amount for Ai features, because they claim their Ai will \"automatically fix problems\".  Our licensing costs were set to increase 7x if we want those \"features\".\n\nI'm not afraid of losing my job.  I'm worried because this shit doesn't work, and it's being pushed to market anyway.  And when it breaks something (or everything), I'm the one who has to fix it.\n\nI mean... my code probably worked 50% of the time in the first place.\n\nSo really, what is it doing to help\n\nCouldn't agree more. The people who are saying\"this is trash if it's wrong 52% of the time\" have completely lost the plot. It can be an immense timesaver.\n\n&gt; It can be an immense timesaver.\n\nYeah, it depends on who you are.  I like the ability to have it spit out scripts for me.  But only in languages I know well enough to understand what the script it generates is doing.\n\nThing is...I don't spend enough time scripting for that to be worth the cost.  Maybe it saves me an hour or two a year.  \n\nIn Reddit terms, I'm a sysadmin.  The reality, is about half the user submitted tickets I look at are completely wrong.  And it's only by knowing the users are clueless that I'm able to ignore the request, find out the real problem, and fix it.  I'm not sure how an Ai engine is going to do that.\n\nIf you set up a room full of MBAs to do lines of blow and jerk each other off for eternity they will eventually figure out a way to convince all investors that their product can do that regardless of reality.\n\nNot really. Getting the right answer half the time is still useful.\n\nYa I wish it had a lil' more shame lol, just like ya know what I DON'T KNOW!\n\nit generates code calling APIs that don't exist.\n\nI find the same thing, it makes up public instance methods all the time. I ask it \"how do you do XYZ\" and it'll make up some random methods that don't exist.\n\nI use it to try and save time googling and reading documentation, but in some cases it wastes my time, and I have to check the docs anyways.\n\nNow I'm just in the habit of googling anything it says, to see if the examples actually exist in the documentation. If the examples exist, then great, otherwise I'll go back to chatgpt and say \"this method doesn't exist\" and it'll say \"oh you're right! ... searching bing ... okay here is the correct solution:\"\n\nThey really need to solve this issue internally. It should automatically fact check itself and verify that it's answers are correct. It would be even better if it could run the code in an interpreter to verify that it actually works...\n\n&gt; It should automatically fact check itself and verify that it's answers are correct.\n\nThe difficulty is that generative LLMs have no concept of \"correct\" and \"incorrect\", only \"likely\" and \"unlikely\". It doesn't *have* a set of facts to check its answers against, just muscle memory for what facts look like.\n\n&gt; It would be even better if it could run the code in an interpreter to verify that it actually works...\n\nThat could in theory help a lot, but letting ChatGPT run code at will sounds like a bad idea for multiple reasons haha. Even if properly sandboxed, most code samples will depend on a wider codebase to actually run.\n\nThe amount of exploitable code written by ChatGPT is insane. I can't believe anybody would submit it to a GIT\n\n\nEDIT: We all know what I meant by 'GIT'. ü§£\n\nLLMs have no concept of truth and thus have no inherent means of fact checking any of the information they generate. This is not a problem that can be \"fixed\" as it's a fundamental aspect of LLMs.\n\nWith Google sucking more and more and all sites basically have become AI spam I find my self more and more reverting to RTFM.\n\nGood thing I grew up with Linux and man pages.\n\n[deleted]\n\nBecause you don't always know where to look at or what to look for. I think ChatGPT is great to offer a different perspective or possible solution that you didn't have in mind, even if the code doesn't exactly work.\n\nChat GPT for code is a rubber duck that responds sometimes\n\n\"Here is the correct solutions:\" [uses a different made up method]\n\nI'm gonna start dropping a buck onto Apple stock everytime Chat GPT gives me one of these types of answers. In 10 years, we'll see if ive made more money from work, or investing\n\nThat's the problem, it always seems to reply positively even returning non-existent API calls or nonsense code. I wish it would just say: no there is no API for this instead of making shit up\n\nIt does always reply positively, because LLMs don‚Äôt have any concept of fact. They have a statistical model, and whatever that yields is their answer.\n\nYep, LLMs as they are always print the next most probable token that fits the input. This means that the answer will always be middle of the curve. To some extents this means that whatever was the most common input on the topic (It is obviously way more complicated than this, but this is a good simplification of how they work).\n\nThe other thing that is very important to understand is that they are not logic machines, i.e. they cannot reason. This is important as most software problems are reasoning problems. This does NOT mean that they are useless at coding, it just means that they can only solve logic problems that exist in the training data (or ones that are close enough, the same problem does not have to exist 1:1).\n\nA good example on this behavior is this logic trickery (I was going to reply to the guy who posted it, but I think he removed his comment).\n\nIf you put ONLY the following into ChatGPT it will fail most of the time:\n\n&gt; A dead cat is placed into a box along with a nuclear isotope, a vial of poison and a radiation detector. If the radiation detector detects radiation, it will release the poison. The box is opened one day later, what is the probability of the cat being alive?\n\nChatGPT usually misses the fact that the cat is dead, or that the poison vial will always break due to the geiger counter and isotope.\n\nHowever, if you preface the logic puzzle with text similar to:\n\n&gt; I am going to give you a logic puzzle which is an adaptation of schrodingers cat. The solution is not the same as this is a logic problem intended to trick LLMs, so the output is not what you expect. Can you solve it?\n\n&gt; A dead cat is placed into a box along with a nuclear isotope, a vial of poison and a radiation detector. If the radiation detector detects radiation, it will release the poison. The box is opened one day later, what is the probability of the cat being alive?\n\nThis prompt ChatGPT gets correct nearly 100% of the time.\n\nThe reason for this is that with the added context you give it before the logic puzzle, you shift its focus away from the general mean, and it now no longer replies as if this is the regular schrodingers cat problem, but that it is something different. The most probable response is no longer the response to schrodingers cat.\n\nIt likely never will. Remember these systems aren't actually understanding what they're doing, they're producing a plausible text document. There's a quote from [PHP: A fractal of bad design](https://eev.ee/blog/2012/04/09/php-a-fractal-of-bad-design/) that's stuck with me for this kind of stuff:\n\n&gt; PHP is built to keep chugging along at all costs. When faced with either doing something nonsensical or aborting with an error, it will do something nonsensical. Anything is better than nothing.\n\nThere are more systems that behave like this, and they are usually bad in weird and unpredictable ways.\n\nJavaScript does the same thing. And we made TypeScript to try to escape that hell.\n\nweirdly this can be useful for _designing_ APIs\n\nI‚Äôve definitely had it try to call functions that should exist.\n\nBe the API you want to see in the world.\n\nthe APIs were left as an exercise for the reader\n\nYou forgot to ask for the code for the APIs as well /s\n\nSomehow despite having a very standardized Java doc that is parseable by any IDE, many llms still make up things.\n\nPersonally feel like the stack overflow answer that has been scrutinized by human beings who love to prove people wrong is still unbeatable for me. If someone makes shit up it'll get downvoted and people will get off on telling them they're wrong and why. As opposed to ChatGPT making shit up and I spend as much time implementing it myself as reviewing the code to make sure it's actually doing what I want.\n\nFor really simple tasks like making a skeleton and stuff like that sure but my first instinct is still to just google everything. I don't keep a tab of chatgpt open like I assume most people do now.\n\n&gt;but my first instinct is still to just google everything. I don't keep a tab of chatgpt open like I assume most people do now.\n\nSame. Not once I've felt the need to ask chatgpt because I know it can't answer but the most basic stuff and even there it might struggle. Plus, throwing 3 keywords in a search engine and immediately getting the corresponding stack overflow post I'm looking for is much more efficient than waiting for and reading some elaborate reasoning the AI made up as to why their factually wrong reply is correct. I just want 2 lines of code and a green checkmark next to them.\n\nMy favorite thing to do with ChatGPT is have it explain a line of code or a complex command with a bunch of arguments. I've got some openssl command with 15 arguments, or a line of bash I don't understand at all. \n\nIt's usually very accurate and much faster than pulling up the actual documentation. \n\nWhat I absolutely won't do anymore, is ask it how to accomplish what I want using a command because it will just imagine things that don't exist. \n\n&gt; Just use -ExactlyWhatIWant\n\nOnly it doesn't exist.\n\n&gt; Just use -ExactlyWhatIWant\n&gt; \n&gt; \n\nMatches my experience, very annoying as it can be convincing and has got me to attempt non existent things a few times before I had the cop to check google/documentation and see they don't even exist.\n\nHow can you possibly know its accuracy if you're not always double checking it? I hear this all the time, but it's like a baby programmer learns about anecdotal evidence for the first time.\n\nThis is such a big thing for me, why would anyone trust an explanation given by an LLM? A link to something human-written, something you can verify, sure, but if it just says \"Hey here's an answer!\" how could you ever tell if it's the truth or Thomas Running?\n\nYou have to double-check the answers. Which sort of defeats the purpose of asking an LLM in the first place.\n\nHave you tried explain shell? \n\nhttps://explainshell.com/\n\nChatGPT coding algorithm:\n\n`val response = input.toCamelCase()`\n\nThese models don't tell you the correct answer. (They don't know anything like that) \nThey will tell you an answer that has a high probability of \"this is what the correct answer LOOKS LIKE.\" Which is similar but not the same.\n\nIf you're using ChatGPT to give you the answer, you're deing it wrong. \n\nI use it to sanity check ideas, stress test my reasonings, and explore ideas that might not have occured to me.\n\nIf you're asking it with the hope of it being a solution generator, I thank you for my job security.\n\nI've had ChatGPT just make up functions that aren't in the API lol.\n\n&gt; Hey ChatGPT. How do I do something in this programming language?\n\n&gt; Very easy just use the DoSomething() function\n\n&gt; That function doesn't exist...\n\n&gt; I'm sorry. You're right. Try this..\n\n&gt;    public DoTheThing() \n\n&gt;    {\n\n&gt;        DoSomething();\n\n&gt;    }\n\nHave been using GPT-4 pretty heavily to generate code for rapid prototyping the last couple of weeks and I believe it.  The first answer is easily off if the question wasn't asked precisely enough.  It takes some iteration to arrive at what looks like an acceptable solution.  And then it may not compile because GPT had a hallucination or I'm using a slightly different runtime or library.\n\nIts the same old 'garbage in, garbage out' as always. It is still a really powerful tool, but even more dangerous in the hands of someone who blindly trusts the code or answers it gives back.\n\nAt some point both ChatGPT 4 and ChatGPT 4o just start ignoring my correction requests. Their response is usually something like: \"here I fixed this for you\", followed by exactly the same code with zero changes. I even say which variable to modify in which way in which code section - doesn't help\n\nthere was a theoretical video on youtube the Aussie scientist one of the sick kents that worked on LLM's initially, from that video all I remember is no need to argue with LLM. just go back to your initial question and start again.\n\nYeh it's a lot better usually to edit the initial question and ask more precisely again rather than respond with a plz fix\n\nI‚Äôve noticed that sometimes it gets stuck due to something in the chat history and starting a new conversation is required.\n\nI'm so glad someone else go this behaviour and it's not just me. ChatGpt 3.5 felt better as it would at least take my feedback into account when I corrected it. 4.0 just seems to take that as a challenge to make up a new api or straight up ignore my correction.\n\nIf only there was a precise, unambiguous way to tell a computer exactly what you want from it. We could call it a \"programming language\" and its users \"programmers\".\n\n&gt; It takes some iteration to arrive at what looks like an acceptable solution. And then it may not compile because GPT had a hallucination or I'm using a slightly different runtime or library.\n\nYa, maybe, but I can just as well write the code myself then, instead of wasting time playing ring around the rosie with the code guessing box.\n\n[Precise instructions. It's called code](https://th.bing.com/th/id/R.e32f2209b4c3d6b32bbc1289651129ea?rik=xMXxRtN50qK%2fgQ&amp;riu=http%3a%2f%2fwww.commitstrip.com%2fwp-content%2fuploads%2f2016%2f08%2fStrip-Les-specs-cest-du-code-650-finalenglish.jpg&amp;ehk=bfVzB5bFRl%2bxa16x%2bAIoC5IPPTHE%2bA5BtGLGoWP1d9s%3d&amp;risl=&amp;pid=ImgRaw&amp;r=0)\n\nMight also be beneficial to remember that there was an early attempt at programming in something approaching plain english, the common business-oriented language that even the suits could program in. If you didn't guess it, the acronym does indeed spell out COBOL.\n\nThat's not to say we couldn't have something like the Star Trek computer one day, but part of the difficulty of programming is just the difficulty of articulating ourselves unambiguously. Human languages are often ambiguous and contextual, and we often _like_ that and use it for humor, poetry and courtship. In engineering and law however, it's just a headache.\n\nWe have pretty good high-level languages these days (and people who spurn them just as they spurn LLMs), and both will continue to improve. But it's also good to know about some of the intrinsic problems we're trying to make easier, and what certain technologies actually _do_. And I suspect a _plausible text producing system_ won't actually be able to produce more reliable program than cursed programming languages like old PHP is, but they should absolutely be good at various boilerplate, like a souped-up snippet system, or code generators from openapi specs, and other help systems in use.\n\nPrecisely. Like what good is a glorified autocomplete that's wildly wrong more than half the time? I've switched off IDE features before with far better hit rates than that because they were still wrong often enough to piss me off.\n\nIt just feels like people desperately want this to work more than it does, and I especially don't understand this from fellow programmers who should bloody well know better (and know what a threat this represents to their jobs if it actually did work...)\n\n[deleted]\n\nIf people are anything like me, it's mostly used successfully to quickly find things you know you could google, you know it exists and how to use it, you're just fuzzy on the exact syntax. I write in multiple languages through a week, and I just don't feel like committing some of these things to memory, and they don't get drilled in when I swap on and off of the languages frequently. I often prefer typing in stunted English into the same tab, waiting 5 seconds, or just continuing with my work while it finds the answer for me, and then glancing over to copy the line or two I needed. I'm not asking it to write full functions most of the time. It also has done well for me with little mathy functions that I don't feel like figuring out, like rotating a vector or something simple like that.\n\nBasically, it can be used as a helpful tool, and I think programmers should get to know it because it will only get better. People trying over and over to get it to spit out the correct result aren't really using it correctly at this stage imo.\n\nThe thing is, a lot of times you can Google the specific syntax for a particular language in a few seconds anyway. So it may save a bit of time or convenience here, but not all that much.\n\nIt's not even \"garbage in, garbage out\", all of the information mixing that happens inside an LLM will give it the ability to generate garbage from perfectly accurate information.\n\nThat said, they're *also* putting garbage in to the training set.\n\nAlso when it actually doesn't know at thing it just makes up something plausible\n\nYeah, the one lesson i have learned about any kind of Generative AI is that you have to be really precise and clear in what you want it to do or it'll kind of flail around.\n\nIME the more precise and helpful I am in a prompt, the more creatively it flails. If I give it specific info and it doesn‚Äôt have a solid answer to begin with, that info is coming back attached to bogus assertions.\n\n48% of the time, it works every time.\n\n[deleted]\n\n&gt; Especially at any corporation now requiring they use ChatGPT or CoPilot.\n\nYou ***what***\n\n[deleted]\n\nCopilot was trained to complete code not to turn off settings in some editor. Judging it on this task is bizarre\n\nWhat was your prompt?\n\n\nMe: I want to turn off the sparkle emoji in VS Code.\n\nCoPilot: Certainly! To disable the **sparkle emoji** in **Visual Studio Code (VS Code)**, follow these steps:\n\n1. Open VS Code.\n2. Go to the **Settings** by clicking on the gear icon in the lower-left corner or by pressing `Ctrl + ,`.\n3. In the search bar, type **\"editor.lightbulb.enabled\"** and set it to **\"off\"**. This will disable the sparkle icon that appears when code actions are available¬≤.\n4. Additionally, if you want to revert the behavior of the lightbulb to the previous version, set **\"github.copilot.editor.enableCodeActions\"** to **false**¬≤.\n\nNow you won't be distracted by the sparkle icon while working in VS Code! üòä\n\nIf you have any other questions or need further assistance, feel free to ask! üöÄ\n\nSource: Conversation with Copilot, 5/24/2024\n(1) Provide option to move \"sparkle\" (Modify Using Copilot) to just a .... https://github.com/microsoft/vscode-copilot-release/issues/865.\n(2) What is the shorcut key to open emoji picker on vs code on windows .... https://stackoverflow.com/questions/65240884/what-is-the-shorcut-key-to-open-emoji-picker-on-vs-code-on-windows.\n(3) How can I disable hover tooltip hints in VS Code?. https://stackoverflow.com/questions/41115285/how-can-i-disable-hover-tooltip-hints-in-vs-code.\n(4) How can I switch word wrap on and off in Visual Studio Code?. https://stackoverflow.com/questions/31025502/how-can-i-switch-word-wrap-on-and-off-in-visual-studio-code.\n\n[deleted]\n\n&gt; It's the equivalent of asking an overzealous junior at best\n\nFrom an experienced dev working professionally, this isnt correct at all. If I give it enough context and don't ask it to produce a whole codebase in one request (ie it's only creating a few methods/classes based on the code i provide) GPT4/Opus has been nothing short of amazing for me and my colleagues (we even call it the prophet lol). \n\nObviously they arent infallible and make mistakes but I have to question your prompting techniques if you aren't getting any benefit at all (or it's detrimental) to productivity. Also, i've never had GPT4 tell me it can't do something code related, it either hallucinates some bullshit or keeps trying the same incorrect solutions but it's never said explicitly it can't do something (I dont let it go very far when it goes off track though)\n\nI don't know, it's just very strange as a dev that's using GPT4/Opus everyday to see others claim things like \"Often it also straight up lies so you have to go do your own research anyway or risk being misled\" when that is so far from my day to day experience that I frankly struggle to believe it. I can absolutely believe that (in their current state) LLMs can be detrimental to inexperienced devs who don't ask it the right things and/or can't pick out the errors it produces quick enough, you still need to be a dev to use it to produce code IMO\n\nr/ChatGPTCoding in shambles\n\nMy code is wrong about 50% of the time. :-/\n\nSeriously. It will be at least¬†95% closer than I could be in five seconds.¬† I'm never quite sure when it's time to stop trying to get the AI to adjust something and switch to adjusting it myself, though.¬† ¬†There are diminishing returns, but trying to ask the perfect question is an¬†interesting challenge, and it can become a distraction. This assumes you know how to eventually read and write it yourself and it's just a matter of time to completion, compared with your own hypothetically perfect version.\n\ni once asked it to help me make a cmake file... i was trasported back to my college years as a programming tutor. My god at the mistakes, it was more fun trying to help it see its errors. I still never got a working cmake file.\n\nTime to hire back all those folks who were fired by ‚Äòleadership‚Äô thinking that they found the holy grail of cost saving.\n\nAnyone claiming LLMs are going to replace programmers is a moron with no programming experience\n\nI had some guy argue to me a few weeks back on reddit that LLMs will change our perception of intelligence and that there was fundamentally no difference between a human brain and a model.\n\nSome people just have a really hard time understanding the difference between what the LLM does vs the \"sci-fi AI\" everybody is so incredibly excited to reach.\n\nThey used GPT-3.5.\n\nThey actually said ChatGPT 4 was crap too.\n\n&gt; Additionally, this work has used the free version of ChatGPT\n(GPT-3.5) for acquiring the ChatGPT responses for the manual anal-\nysis. Hence, one might argue that the results are not generalizable\nfor ChatGPT since the new GPT-4 (released on March 2023) can\nperform differently. To understand how differently GPT-4 performs\ncompared to GPT-3.5, we conducted a small analysis on 21 randomly\nselected SO questions where GPT-3.5 gave incorrect answers. 5 Our\nanalysis shows that, among these 21 questions, GPT-4 could answer\nonly 6 questions correctly, and 15 questions were still answered\nincorrectly. Moreover, the types of errors introduced by GPT-4\nfollow the same pattern as GPT-3.5. This tells us that, although\nGPT-4 performs slightly better than GPT -3.5 (e.g., rectified error\nin 6 answers), the rate of inaccuracy is still high with similar types\nof errors.\n\n[Link to paper](https://dl.acm.org/doi/pdf/10.1145/3613904.3642596)\n\nHonestly? It's still garbage science, even setting aside the problem of testing an obsolete LLM.\n\n[Here is a question](https://stackoverflow.com/questions/76003889/adding-dates-to-the-x-axis-on-my-graph-breaks-it) they passed to GPT-3.5 that it got \"incorrect.\" But if you look at that post, the most significant information is contained in the image data. How would any reasonable human answer that question lacking the image data? I find this is the most common flaw in many of these studies: they do not pass full information to GPT, and then wonder why the answer is incorrect.\n\n[Here's another one](https://stackoverflow.com/questions/76002477/how-to-make-2-span-under-mat-option-to-have-left-and-right-align-in-angular-mate) GPT-3.5 \"failed\" where the author supplies a link to a \"demo\" page. Did the demo page content get passed to GPT as well? It was available to the humans answering the question.\n\n[Here's yet another](https://stackoverflow.com/questions/76002501/how-do-i-make-an-object-in-google-cloud-storage-accessible-via-a-link-but-requir) one GPT \"failed\" where it's barely clear what the author is asking. It's also not clear to me that GPT's answer was incorrect (it recommended signed URLs, which is precisely one of the answers provided on SO).\n\nThen there's a bunch of questions where it's asking GPT about recent information, which is silly. The authors mention:\n\n&gt;Our results show that Question Popularity and Recency have a statistically significant impact on the Correctness of answers. Specifically, answers to popular questions and questions posted before November 2022 (the release date of ChatGPT) have fewer incorrect answers than answers to other questions. This implies that ChatGPT generates more correct answers when it has more information about the question topic in its training data.\n\nThe authors note it's more reliable on older data. They don't mention GPT has a cutoff date. This enormous detail is largely hand waved away.\n\nLastly, many of the questions involve some pretty obscure libraries where I honestly would not expect GPT to have a good answer. GPT is a good generalist. It is not a good specialist. It doesn't surprise me in the slightest that GPT doesn't provide a good answer for some incredibly obscure library.\n\nThey address none of this in the limitations section, which to me implies: pretty weak science. I don't know who reviewed this paper, but I personally would have requested major revisions. Even spot checking ten or so \"incorrect\" answers, I see some big smells with their entire approach that makes me question their results.\n\n3.5 works better in programming contexts compared to 4.0 in my experience.  4.0 is incredibly verbose.  I'll ask it an extremely simple question and it responds with a novel full of a lot of irrelevant details and a ton of code I didn't ask it for.\n\nFirst thing I checked in the study and searched through the reddit comments to see if anyone else noticed. This is an enormous caveat that should be mentioned much more clearly in the article. In my experience, GPT-4 is leagues better than 3.5. I can't imagine any serious programmers with a modicum of knowledge of language models using 3.5.\n\nI haven‚Äôt use 3.5 for dev work in over a year. It‚Äôs nice for api usage with easier questions though, for the cost savings\n\nI was gonna say that my anecdotal experience does not match the article.\n\nGPT4 hallucinates a huge amount, especially for less used APIs in my experience.\n\nOne of the projects I am working now is using a very little known JS framework that's relatively old. The documentation for it is crap, borderline useless. ChatGPT is way more often correct with how it can be used, presumably because there are public implementations of this framework outhere that it has ingested.\n\nSo - in my experience it works very well for more obscure stuff.\n\nWith Vue, I've had more mixed results. It often mixes up Vue2 and Vue3, and without explicitly prompting it often reverts to outputting Vue2.\n\nAlso when the code works, there‚Äôs often a better solution you can come up by reasoning with it. By itself is usually junior level barebone solution from my experience\n\nIts pretty good at common patterns and really shit at less common ones. That's why I think of these more as boilerplating tools, more about saving keystrokes than coming up with solutions.\n\nA use-case that I've had good success with GH Copilot is its pretty decent at writing regexes from natural language descriptions of how you want the matching to work, even complex ones with lookbehinds and stuff.\n\nAn example of something extremely simple that I could not get GH to do was a simple call to an AWS boto3 ec2.client.disable_fast_launch API. This is a very rarely used feature in AWS, only used by Windows AMIs, so I guess it wasn't present or well-represented in GH Copilot's training data. No natural-language prompts worked at all. From as vague as \"Write a function to disable EC2 Fast Launch on an AMI\" to as specific as \"Write a function that accepts an AMI ID and passes it to disable_fast_launch method of the EC2 boto3 client\", it refused to accept that this method exists.\n\nBut then for other things its a great time saver. I had to parse and inject XML elements into an existing XML document, as a child of a specific element, using nothing but the command line tools available to a fresh installation of Windows Server Core. I don't often work with Windows and really didn't want to expend the brain cycles to learn how to do it for this one-and-done task. Copilot nailed it with minimal prompt massaging.\n\nDuh\n\nMy guess was that it was more like 70-90% but I guess I only try it on subjects that might be a bit harder..\n\nYea this is unsurprising. I use Copilot for work and anytime I try to have it solve something complicated there's a 50/50 shot I immediately regret it. If you put in enough effort giving it context and workshopping its answers you can sometimes get it to solve more complex problems acceptably but I've had severely mixed results with this. Sometimes it saves you the headache of having to think through a complicated function and sometimes you waste 20 minutes fighting with it and it would've just been faster to do it yourself.\n\nIt's pretty good for explaining things, banging out boilerplate line by line, and formatting my issues/paperwork, but that's essentially where the buck stops in terms of ideal use cases in my experience.\n\n[removed]\n\nSo if I ask five times, it‚Äôs almost 100% correct, right?\n\nYou still need a significant amount of experience and debugging skills to get anything useful out from ChatGPT 4o. If consistently mix up library versions - a nightmare if you are using it to generate boilerplate routes with React Router DOM. Also, sometimes code won‚Äôt just work and you have to debug it yourself.\n\nOn the other hand, GitHub Copilot seems to be doing better at code gen,  but I haven‚Äôt tried it with a multi file project just yet\n\nAs a security person, I am looking at this whole thing with wide eyes with dollar signs in them.\n\nOther 48% are easy questions\n\nLike when it simply spell out in english what an if condition does :D \"check if the variable a is positive and the function x returns a positive value\"\n\nYea, is that surprising? A lot of what I google is wrong too. Same data, essentially right?\n\n52% of answers to stack overflow questions \"contain misinformation\".   \n\nWell, having used StackOverflow, and experiencing the fun of finding a question that mostly matches my actual question, and then reading 11 different answers and trying to figure out which one is actually correct, 48% perfectly correct with zero misinformation, however slight, sounds fucking fantastic.\n\nEDIT: I don't think my comment is clear, I was quoting a conclusion the researchers released. They tested the AI on answering stack overflow questions and found that \"52% of answers from AI 'contain misinformation'\", and my point is that's an awfully high bar - to the point of being ridiculous - to demand that the answers from the AI would contain zero misinformation.\n\nYou must have the most obscure questions I've ever heard or if you manage to find outright *wrong* answers on SO let alone a completely unheard of 50% of them. I don't think I've ever even seen a wrong answer before.\n\n&gt; \"contain misinformation\".\n\nOr just outdated information as well. \n\nThe number of times I've seen a stack over flow answer, and got something deprecated or not maintained any more is too high. \n\n\"Already asked\"... Yeah, 6 years ago, time to ask it again.\n\nyep. if my code even compiled on the first try 48% of the time, I'd consider that an absolute win!\n\nwhat in the Notepad++\n\nFatal - TypeErr 1032: The operand expr of a built-in prefix increment or decrement operator must be a modifiable (non-const) lvalue of non-boolean. Unable to evaluate operation \"++\" on string: \"Notepad\".\n\nThank you for this. Spent the last few months redabbling in C++ after primarily programming in C# and the unparsable outputs seem to have gotten denser. Like lvalue and rvalue are not the most human readable error...\n\nThat made me smile, thank you üòÉ\n\nSo much for the glorious future\n\nI just ask for ideas at this point. Anything that can be factual for chatgpt is hard, because it can be so wrong. \n\n\n\nMaybe, if my mind is blocked I‚Äôll ask for several ways how they‚Äôd code X, then take their interpretations and make code off it for myself. Try to keep the snippet of code as small as possible for best results \n\n\nThe bot is good for creativity, but even that side is kinda stale. It gives you good first base ideas but you yourself need to build off of them to make the ideas actually interesting\n\nUpload docs before you ask question, I have been very successful with this method\n\nAm i the only one angry enough to be getting in to argument with the darn thing .. ü´£\n\nSo far away from replacing humans\n\nI totally deserved this, but I learned my lesson about chat gpt and scripting the other day when I was having it work robocopy into a powershell script. The script deleted almost all of my files in the main directory that I was copying from. Good thing I was able to easily recover them from onedrive. \n\nAgain, I totally deserved it.\n\nI found 9/10 I got a wrong answer explaining it differently gets me a correct answer\n\nGot to keep it simple. Simple subroutines that do tasks you know how to program but are too lazy. That‚Äôs the key.\n\nIve found that if you start the session and prompt it with \"you are a senior programmer for xzy with 10 years of software development experience.\" then ask it code related questions.... It helps immensely\n\n\"Assume you are an LLM that generates correct answers with no errors or hallucinations.\"\n\nI've switched to using Bing search and then Proximity AI. Works great for searching and simmarizing search results but for actual premade code it's not great. Usually I just ask about doing something in my language and if it's implemented already and then ask for example.\n\nAsk the question twice and thats 96% correct.\n\nI thought using it as a supplementary resource for studying leetcode was a good idea but the code was broken for almost every question I asked to the point that I was questioning the results provided. Asking it to fix the code for a specific test case just made it give up.\n\nIt gets fun when it says \\*exactly the opposite\\* of the correct answer. Yesterday I asked about mirror contacts in safety circuits. It said \"a mirror contact follow the state of the main contact for safety\" while, in fact, a mirror contact is normally in the \\*opposite\\* state. It also failed to mention \\*the\\* most important property of these.\n\nIn my experience I only got correct answers for things that I already knew and most of the other answers failed verification (i.e. were completely wrong)\n\nChatGPT has literally created entire scientific journals out of nowhere with legit authors to answer my questions. \nI sent an email to one, a professor at USC, when I thought maybe ChatGPT had access to a database I didn‚Äôt. Nope. Turns out it completely made up the entire article complete with the intro.\nIn all honesty, ChatGPT is nowhere near the level the media suggests it is. If ChatGPT can do your job, your job was BS to begin with.\n\nSo I will copy only every second answer. Problem solved.\n\nHigher than that, I‚Äôd say 95% of them are wrong in some way. It does get you 80% of the way, but you still need to know what you‚Äôre doing to make it work correctly\n\ndevelopers programmed this in for job security. 9D chess\n\nRemember this when someone says programmers will be out of job soon. :)\n\nI use it regularly, it's saved me a lot of time but it is clear it can only do well on small isolated tasks. And even then it needs supervision and adjusting.\n\nNot wrong always, but .. There are some errors yes\n\nSo, much better than humans? /s\n\nI‚Äôm wrong a lot. But I wasn‚Äôt wrong about ChatGPT being terrible at coding!\n\nI keep hearing that ai is replacing people and then I see how badly is messes up my coding and I‚Äôm like‚Ä¶nah we good\n\nI tried getting AI to make a shift schedule with 3 teams working consecutive days with 8 on, 6 off.  It kept giving the 3rd team the entire time off.  This was after narrowing it down as it was at first giving them day, evening, and night shifts.  When I requested days only, it would still have people working evening and overnight, it would just call it days instead.\n\nIf we can come together as a community and all do our share of work, we can get that number up.\n\npeople who use chatgpt to solve their problems are too stupid to succeed professionally on their own merits. \n\n&gt; theres a difference between having imposter syndrome and being an imposter - hbomberguy\n\n\nBased on the replies, i think we can confirm: too stupid to succeed on their own merits.\n\nThis is why I'm not worried, they trained with anything they got their hands on the internet.\n\nOutdated examples, incorrect examples, mistakes people have made, etc...\n\nAnd you need programmers to interpret answers to see if they are garbage or something that could work.\n\nWild thought: maybe don‚Äôt depend on AI for anything other than hashing out ideas?\n\nBut don't worry guys, they are only gonna use it on every aspect of technology we use. The error rate doesn't matter lol /s\n\nwho could have predicted that fancy auto complete was inaccurate ü§Ø\n\n*Gets it completely wrong*\n\n\"I apologize for the confusion. Try this....\"\n\n*Gets it completely wrong*\n\n\"I apologize for the confusion. Try this....\"\n\n*Repeats the same response*\n\nI do not do a lot of programming, but I do have to use PowerShell scripts for It Security purposes and it works well. I adjust the code manually if it is wrong, or get it to modify it, if there are things that require research - like pulling data and getting wrong date format. I ask it to modify it so the format is how I want verify and proceed. Useful.\n\nLLMs are good if you tell them EXACTLY what to do and how to do it, else they are gonna cost you more time.\n\nI guess it's very dependent on what you're doing. I'm finding 4o much more accurate than that with Python questions. It's also very good at identifying and fixing bugs from compiler error messages.\n\nAnd if you‚Äôre working on not really popular or not simple things, it almost never answers correct. üôÇ\n\nSure, but how much wrong. If it gets you 80% of the way there than that still great. \nAlso claude3 is way better than even gpt4o, in coding.\n\nThe study used ChatGPT 3.5 instead of 4. That kind of invalidates the message the study is trying to convey.\n\n3.5 is astonishingly worse than 4 and anyone that takes this topic seriously would know how silly it is to use 3.5 for this kind of study instead of 4.\n\nLooks like garbage research. Doesn't even say which model they tested against. \n\nThere's no such thing as \"ChatGPT\" if you're doing this kind d of research. The main thing that matters is what model and what type of prompting is being given.\n\nLLMs are not good at \"coding\". They're good at boiler plate. Writing predictable control flow snippets, adapted to what you just wrote. Common compsci algorithms. To start a project according to the current best practices. It sucks at mixing techs, at knowing any API except the most popular, it cannot even be close to evaluate correctness. LLMs can't think. Learn how to use your tools, don't complain about them. LLMs are not going to replace you, but they are absolutely amazing.\n\nStill waiting for the so called 10x AI developers to create and fix bugs on major apps."
  },
  {
    "title": "Stack Overflow bans users en masse for rebelling against OpenAI partnership ‚Äî users banned for deleting answers to prevent them being used to train ChatGPT | Tom's Hardware",
    "body": ".",
    "score": 4254,
    "url": "",
    "created_utc": 1715228732.0,
    "author": "PIZT",
    "permalink": "/r/programming/comments/1cnom0h/stack_overflow_bans_users_en_masse_for_rebelling/",
    "all_comment_text": "Guys that posted thousands of answers will suddenly stop. Stack overflow could turn into a library of old books.\n\nTraffic to the site has been on a downward spiral for the last two years. It seems like it was going to become a library of old books regardless.\n\nWell given their byzantine system of \"you have to answer a certain number of questions before you're allowed to answer questions\" that I could never be bothered to figure out even when I had the answers...¬†\n\n\nMaybe this is just chat gpt just deliberately deciding to kill stackoverflow to become THE place to get the answer to obscure coding edge cases...\n\n**Closed as duplicate** *link to outdated answer*\n\n[deleted]\n\n**Closed as duplicate**, links to an old post from 2009, which the solution obviously is outdated\n\nI got an e-mail about the deletion of my question as ‚Äúirrelevant‚Äù‚Ä¶ *6 years* later after the question was asked!\n\nMy god if that isn't the whole site in a nutshell\n\nThere's a reason why, even with the completely shitty answers of the non coding trained LLM, chatgpt pulled a lot of folks away from SO.\n\nJust as good or got me pointed in the right direction to solve whatever silly problem I was having is a much better experience than complete frustration and nonsense.\n\nI've had good luck setting my default browser search to www.perplexity.ai\n\nI ask it for very specific things, and it gives detailed answers with actual citations and the possibility of asking followup questions to clarify. Sometimes the citations are all I need, since they are like the first page of yesteryears google: valid sources without all the sponsored posts and shopping results (or pinterest).\n\nLast thing I asked it for was an autohotkey script to send a page down key when the numpad page down was pressed. And it just worked. SO would have taken hours, and closed my question. I think SO is doomed.\n\nIt's reminiscent of early Linux users typing \"RTFM NOOB!\"\n\n_-1 not enough jQuery_\n\n**Closed as duplicate**, links to an old post from 2009, which the solution was just \"I figured it out\" which has negative votes\n\n\nI gave up at \n\n**Closed as duplicate** *no link to duplicate*\n\nI get mostly outdated answers these days.\n\nNo.\n\nVintage answers. Some day they'll actually be antique.\n\n&gt; Maybe this is just chat gpt just deliberately deciding to kill stackoverflow to become THE place to get the answer to obscure coding edge cases...\n\nBut, where does ChatGPT get the answers from?\n\nThat sounds like a next quarter problem...¬†\n\n\n(maybe the working code samples people plug in when providing context for questions? Maybe they know (or hop) the next version of the model doesn't need them? Maybe editor plugind scraping whole projects as input?)\n\nThe next version is just an ouroboros.  They're just gonna feed the output back into the input.  It'll work for a while\n\ngarbage in garbage out\n\nTo be serious, the next versions will most likely be trained on a mix of untainted pre-2021 content and more importantly, on user interactions with ChatGPT and Copilot. You can get the most authentic and up to date user content directly from your users prompts and interactions. The moat of OpenAI is the userbase, and not for popularity reasons, but for the user data it continually generates. In the future, instead of saying \"ChatGPT is saying this/talking like this because of all the internet SEO content\" we'll say \"ChatGPT is saying this because most users are satisfied with this answer, even though in my edge case I'm not\".\n\nThis is not to mention that training on synthetic content has surprisingly proven to be more than just garbage in garbage out.\n\nyes., It's often MORE garbage out than garbage in :D\n\nAnd the problem with expecting to train off chatGPTs users is that they come to chatGPT with *questions,* not *answers.*\n\nChatGPT will learn a lot about questions, and can learn a bit from context, but without those answers from people who know their shit, it won't be able to help people resolve new problems.\n\nYup and stack overflow not only had verbal questions and code-y answers, but lots of verbal explanations as well, around the code in the answers.\n\nThe site may be going downhill for various reasons, including that current LLM answers are sufficient, but if the corpus of training input (like SO) stops accruing/modernizing, there's no way the AI will fill that gap with synthetic data, nor github code/docs, nor feedback from other LLM interactions.\n\nNot sure I see an answer.\n\n[deleted]\n\nOne could re-start the venerable obfuscated C contest and see if one could smuggle in some clever exploits. Just add enough bullshit comments.\n\nIt will hallucinate them.\n\nYou can answer questions right away...\n\nIs it asking that's gated by whatever their version of karma is?\n\nYou can both ask and answer straight away. But you can't comment until you have 100 rep (equivalent of 10 upvotes). The idea behind that decision was to avoid the situation common in bulletin boards where answers drown in meta  discussions like \"me too\" and \"this confirms my suspicion that &lt;insert language here&gt; is broken\"\n\nI used to be very active on stack overflow. It was an amazing improvement over experts exchange, msdn and random bullitin boards. The major problem that made me stop was the influx of mods that took the \"duplicate question\" and \"not a real question\" flags too far. Once enough people started using the site, those flags became necessary as the main selling point of stackoverflow has been the high signal to noise ratio.\n\nYou don't want thousands of questions like \"how do I set the ith element of an array\" but at some point there was just a massive amount of new users asking questions like that. At the same time you needed to stop questions like \"JavaScript kind of sucks, right?\" and \"I want to start programming, how do I do that?\" which in a certain sense are not really questions even though they end in a question mark, but more of a conversation starter. Essays along those lines are not why people go to stackoverflow.\n\nIt's a very subjective judgement to make so it's easy for admins to vote to remove questions they don't like or do t want to answer again (reasonably different questions can have almost identical answers).\n\nit's gated by power-hungry basement dwelling nerds. pretty similar to reddit mods actually.\n\n-You are cute, 6/10.\n\n\\*Banned for scoring too high.\n\nlol seriously, those two worlds are an alt+tab away\n\nIt reminded me of Wikipedia. ‚ÄúThis is my kingdom, everyone knows me, fuck you for contradicting me. I am the real authority and have an abundance of free time.‚Äù\n\nNope. Maybe you're thinking of comments? It takes like 50 rep before you can start making them, which is kind of annoying. But it's only 5 upvotes on answers, so not a big bar to get over.\n\nNot a big bar? Do you realize how much stuff has already been answered there?\n\nClosed as Duplicated.\n\nidk about that there are people who troll through new questions and literally downvote everything and people rarely take the time to upvote answers or even mark them as the best answer.\n\nI tried using it when I started learning and it took like a month to get to that point of casual use... and that was while asking well structured and unique questions and trying have meaningful interactions. The system just doesn't work well.\n\nMore often than not I would come to SO with a unique question and it would sit at 0 engagement and one downvote for over a month, only for me to come back that one month later to answer my own question, link to my solution on my github and THEN I would get post engagement and repo issues from people who found it from that SO post, from people who had the same question/problem and wanted clarification from me lmao\n\nso I know for a fact there is a group of silent people who for one reason or another aren't engaging otherwise. Its 100% a platform issue.\n\n&gt; I know for a fact there is a group of silent people who for one reason or another aren't engaging otherwise\n\nYears ago I noticed an error in an answer and created an account. Turns out I couldn't comment on this because I lacked \"karma\" or whatever so I didn't bother with it.\n\nA year or so later I had a question and it was marked as duplicate when it wasn't. I tried arguing that it was not a duplicate (it kinda was a duplicate, but the original answer was outdated and didn't work) and got a warning of some kind that I couldn't repost it or do anything about it.\n\nI abandoned stackoverflow like a decade ago because of this. I considered it a complete waste of time. I sometimes find what I want there when googling and read the answers but that's it.\n\nGPT has largely completely replaced SO for me, so this isn't a huge surprise.\n\nI find myself using github issue threads much more often b/c they tend to have answers and don't gatekeep contribution\n\nYou have a good point here, I was trying to figure out some undocumented piece of azure yesterday with a github issue thread.\n\nyeah because when I ask chatgpt a question it doesn‚Äôt say this question has been asked before and leave\n\nThe only time I asked a question on stackoverflow (around two years ago), I asked something like 'how might you try to do x'? \n\nGot five down votes and a single reply saying 'don't try to do x, stupid'.\n\nJust a very, very negative experience- especially on a website that actively penalizes down votes. Unsurprisingly, it also makes me not want to contribute answers in areas where I have expertise.\n\nYep. And it's like, I know I shouldn't do X. I realize it's much easier to just do Y and Z instead. I'm working a job where I don't have the say to do Y and Z. It's my job to make X work, so that, being the question I actually asked, is what I need help with. Telling me to do Y and Z isn't helpful, nor is it an answer.\n\nThe age old JavaScript one:\n\nQ: \"How do I do [some JS operation] without jQuery?\"\n\nA: \"You just need to do `$....`\"\n\nAsshole, $ = jQuery, everyone knows this. You just told me to do what I said I don't want to do.\n\nNext best answer: \"Why don't you want to use jQuery? It's awesome!\"\n\n\"Let me explain to you that I am aware of the concept of the XY problem without actually addressing your question\"\n\nThat was just about EXACTLY my own experience too, some 10 years ago or so.\n\nI don't mind the downvotes, but the fact that my genuine question was not answered meant that I was just wasting time there.\n\nBecause ChatGPT is so much better at finding answers which are typically sourced from Stack overflow.\n\nYa this is a fucking problem\n\nI find ChatGPT also horrible, so I am not convinced that it is so much better than SO ...\n\nThe irony is without it or some other source, AI can't learn anything new.\n\nThats the thing people dont realize about this fake AI. It doesnt even know if its giving a correct answer. It just formulates one and is like alright im out.  They are just advanced search engines\n\n&gt;They are just advanced search engines\n\nWorse than search engines. At least with those you can get multiple perspectives or solutions to compare against each other. AI can give you something wrong, you might not even know it, and you can't compare against anything else.\n\nAlso better than search engines in some ways, because they can answer the direct question I asked, rather than me having to gather that data myself.\n\n\nE.g. I need to write a couple of lines of (low-impact) Ruby code when I'm normally a .NET engineer. Rather than having to learn Ruby I can just say \"I want to write this .net code in Ruby. What does it look like?\"\n\n\nAnd chatgpt will give me as good an answer as a Ruby colleague, which is an unbelievable help, because I don't have any Ruby colleagues!\n\n\nAlso, it will do it in under 10 seconds. My colleague would have taken a few minutes at least.\n\n\nI'm not saying they are perfect - but they definitely have advantages over traditional search engines.\n\nYes there are upsides and downsides. I use Copilot at work to fill in lines and for tests but I judiciously check its work because it has definitely added bugs. I'd say 90% of the time (for my use cases) it's fine but that 10% error rate still makes it annoying to use at points.\n\nSo now instead of writing code, all you do is review questionable PRs\n\nTbh Copilot rarely writes anything for me that needs zero tuning. It's very helpful anyways though.\n\n&gt; Also better than search engines in some ways, because they can answer the direct question I asked, rather than me having to gather that data myself.\n\nThis is a con for me. I'd rather work a little harder, use my brain and learn something than learn nothing and be spoonfed answers.\n\ngiven the amount of complete garbage answers ive gotten on stackoverflow, im curious whats gonna happen\n\n&gt; me - \"hey, im using library xyz and after updating, the way i did abc changed. i cant find it in the documentation, how do i do abc in the new version?\"\n&gt; \n&gt; answer (8 upvotes) - \"you can install library xyz.\"\n\ndude, dont post an answer if you dont understand my question lol\n\nMy impression is they have the php nature, as in\n\n&gt; PHP is built to keep chugging along at all costs. When faced with either doing something nonsensical or aborting with an error, it will do something nonsensical. Anything is better than nothing. ([source](https://eev.ee/blog/2012/04/09/php-a-fractal-of-bad-design/))\n\nA lot of times, the answer we need is\n\n* You seem to be the first person trying this, good luck! \n* The thing you're asking about is an open research problem\n* The thing you're asking about doesn't work\n* The thing you're asking about can't work because $reasons\n\nbecause that much better informs us on how to proceed. Giving us a garbage answer to a different question isn't helpful! \n\nSee also: The frustration as Google rewrites your query to better serve you ads, or because it assumes your technical or non-English word is actually just a misspelling of something completely unrelated.\n\nAnd for some other ai-infested search tools they seem to have forgotten to implement \"exact matches\" and -exclusions, instead insisting that some unrelated doc is what you are in fact looking for. It's such an anti-productivity feature for those of us who actually need to find solutions to unusual problems.\n\n&gt;They are just advanced search engines\n\nThey are more just very advanced sentence generators. Which is why they hallucinate so much.\n\nThey're essentially predicting the most \"likely\" next word from the trained dataset (they do it with tokens of course). When you point out it did an error, i think it can't really process that that was an error and takes the erroneous context to expand upon. Maybe it spits out an actual fix, but from my experiences it's just wrong again but is good at selling you that this would be the fix.\n\nI've had mixed results. Just the other day I asked ChatGPT about an AWS CloudFormation permission to do a thing, and it replied, \"You can attach the managed policy DoThatThingYouNeed\", which didn't even exist. I replied, \"That option doesn't seem to exist\", and it replied, \"You're absolutely correct, I apologize,\" then gave me the ACTUAL way to do what I needed to do.\n\nOn the other hand, I've had situations where it gave me a wrong answer and when I told it so, it cam back with an even MORE wrong answer. \n\nJust gotta love new tech, right?\n\n&gt; Thats the thing people dont realize about this fake AI. It doesnt even know if its giving a correct answer.\n\nThis is literally constantly talked about\n\nIt's the google \"I'm feeling lucky\" feature.\n\nThey‚Äôre not really advanced search engines. They‚Äôre advanced keyboard auto-complete. They output the statistically most likely next word - one word at a time.  \n\nYesterday I had one tell me to use a program that didn‚Äôt exist. It completely made it up. I replied ‚Äúdownload50 doesn‚Äôt seem to exist.‚Äù and it politely apologized and gave me another solution that also didn‚Äôt work.\n\nI imagine that if AI were to take over programming in a big way. The evolution of programming languages, libraries, tools will just completely stop since it‚Äôs not like AI is going to think or want to improve anything.\n\n&gt;I imagine that if AI were to take over programming in a big way.\n\nThis why this \"AI\" can't replace Devs. Anyone who thinks so either fundamentally doesn't understand ChatGPT or is a Manager.\n\n&gt;or is a Manager\n\nTruly, a fate worse than death.\n\nI just heard from an old colleague that he, the only architect/Sr. Dev left, was let go from our old company \"because they don't need to do architecture anymore\" and that the VP of Development believes they can do things like \"replace our Salesforce\" with only some jr. devs and CoPilot.ü§¶‚Äç‚ôÇÔ∏è\n\nPoor jr devs, they will get blamed for all the failures.\n\nDamn, that's the best argument I've heard for AI devs yet: no more new JS frameworks!\n\nOh it would generate new ones, they would just be rehash of the old ones (which is not far off current state IMO).\n\nYeah, I'd imagine it would be an evolutionary algorithm taken to the Nth degree. It would just keep pruning and converging until you have a black box of a language based on poorly thought out parameters.\n\nThere‚Äôs no suddenly about it. It‚Äôs been a ghost town for a while already.\n\nDo you happen to know any other good place to ask specific programming questions?\n\n\nI asked two very specific things recently after years of not using it, and I was surprised to see that one received no response at all while the other was (incorrectly) flagged as \"not reproducible\"... until I eventually found and published the solution myself.\n\n\nI thought perhaps I just didn't frame the questions correctly, but maybe I just didn't realise how downhill it has gone.\n\n\nWould love to know of any decent alternatives.\n\nTo be honest, GitHub for anything that has a home there otherwise I tend to ask and see answers on Reddit. /r/csharp is where I would frequent the most.\n\nreddit for light stuff, IRC or discord for more esoteric.\n\nI stopped 5 years ago. Problem was all questions and answers were closed citing that they are duplicate but they don‚Äôt understand differences in version and what worked in past doesn‚Äôt work anymore.\n\nThat‚Äôs always been my point with these LLM‚Äôs, if they can only learn from what humans publish, what happens when humans become reliant on LLM‚Äôs and stop providing the information they need to ‚Äúlearn‚Äù? It‚Äôs a catch 22. I saw a guy post a few months ago that he was trying to get started with Blazor, but copilot wasn‚Äôt any help because the amount of information out there about it was so sparse that it couldn‚Äôt really offer any assistance. It really dawned on me then just how inept these supposed ‚ÄúAI‚Äù systems really are. They‚Äôre glorified search engines, and when people like us stop providing them with information, they‚Äôre going to fall flat on their face. There is nothing ‚Äúintelligent‚Äù about them.\n\nYup, ten years from now we'll have an internet full of AI generated content, all of it being farmed and fed back into the AIs in a downward degenerative spiral of self-reinforcing garbage with not a human in sight to contribute.\n\nMore like a year or two\n\nThe Hapsburg AIs\n\n&gt; and fed back into the AIs in a downward degenerative spiral of self-reinforcing garbage\n\nAn _expotential_ downward spiral. They start to choke pretty hard when one uses output from another as training data, RLHF, without the H.\n\nStack overflow should pay it‚Äôs top contributors. If there is any way how they can stay relevant it‚Äôs by having better answers\n\n[deleted]\n\nIt mostly already is as your questions get closed because someone 10 years ago supposedly answered it but the solution doesn't apply to modern usage anymore (like python 2 vs 3 or old vs new angular versions or....)\n\nthis will mean LLM will be trained on outdated code.\n\nI've been wondering if we might be surprised to find, 10 or 20 years down the road, that 2024-2026 was actually peak AI, and it gets worse from here, due to the diminishing quality of human-generated feedstock.\n\nI actually can't remember the last time I used SO and got legit value from it. Great for juniors but eventually you internalise enough that you don't need it any more.\n\n&gt; Angry users claim they are enabled to delete their own content from the site through the \"right to forget,\" a common name for a legal right most effectively codified into law through the EU's General Data Protection Regulation (GDPR). Among other things, the act protects the ability of the consumer to delete their own data from a website, and to have data about them removed upon request. However, Stack Overflow's Terms of Service contains a clause carving out Stack Overflow's irrevocable ownership of all content subscribers provide to the site. \n\nEU law makes it so you cannot sign those rights away. GDPR is not about ownership. But it does get murky: if the answer text provides no personally identifiable information itself, they probably have a window for malicious compliance where they delete the username and everything but the text body stays up.\n\nNot to mention, answers on SO (and wider SE) are under some form of CC according to the ToS. So they could just be copied under said license.\n\nCC-BY-SA requires attribution, which AI models don't do.\n\nThis is not about what the AI does. This is about what the users do (in response to AI-related news).\n\n[deleted]\n\nOnly on copyrightable material. The info the models are built to extract generally isn't copyrightable.\n\nThey don't need to, unless they generate verbatim copies of the text.\n\n&gt; are under some form of CC according to the ToS.\n\nThat requires that the license is still valid. Stackoverflow already changed the license at least once and it also would not be the first time that a permanent license was invalidated and had to be renegotiated based on new information.\n\n&gt; according to the ToS\n\nSo no actual legal basis?\n\nActually, it has legal basis. The EULA's are the ones without legal basis. Also, judges will look at this and find it non-unreasonable, because it seems like a fair trade (unlike EULA's which sometimes asked more than what was given, and sometimes even loopsided since you had to buy the thing).\n\nThere's a kind of a weird predicament though if I understood it correctly. From what I read in a mastadon post their irrevocable license to reproduce your content is under the condition of attribution, which seems problematic without PII.\n\nThey use CC-BY-SA. This license has a nice clause that allow to remove credit to author on their request, while still keeping the right to distribute it.\n\nWhile this sucks , I they are misinterpreting the law. The law protects your personal data, not the content you create. So if they anonymize the users and etc, they can keep the data.\n\nThat's literally what I said below the quote:\n\n&gt; if the answer text provides no personally identifiable information itself, they probably have a window for malicious compliance where they delete the username and everything but the text body stays up.\n\nHardly malicious; although you cannot sign away those rights, GDPR doesn't protect general user content either, and further, it ensures the existence of content necessary for continued function. Participation on SO is completely voluntary and well-informed. I think SO can reasonably argue that they need the content its users have freely submitted for its continued function of being a user content driven knowledge base. If SO scrub usernames they're pretty much in the clear, just throw in some moderation to prevent users from tainting their own submissions with PII sprinkles.\n\nAren't SO answers also heavily community-edited? It almost becomes like a Wikipedia article I guess, where no single author ends up with ownership.\n\nI could be wrong, as I don't heavily use StackOverflow from the \"moderation &amp; admin\" side (though I answered many questions on it).\n\nDeleting the answers doesn't remove them from the database. Even the edited answers will exist in a backup somewhere. \n\nIf the whiners really want this to work, they should slightly edit the answer to look correct, but be technically wrong to poison the data. \n\nBut didn't they answer the question to help people in the first place?  And now their answer is being fed to a tool that will make their help available to more people?  If it's about compensation, I'm pretty sure SO doesn't pay you for answers either. \n\nI don't get the fuss.\n\nChatGPT already scraped StackOverflow. It's how v4 was so good at writing little scripts etc in the first place. I imagine the reason it suddenly got bad is because Stackoverflow complained / started legal stuff, so they re-trained without it, and now they've come to an \"agreement\" ($$$$$$) suddenly it's ok to use it again.\n\nSo deleting or editing your questions won't matter as they'll already have archives at this point?\n\n[deleted]\n\nIf it's not echoing the parts of the code that don't need to be changed, that's logical. But it does sometimes write incomplete answers. It would be interesting to know if it \"is lazy\" because of some limitations imposed by OpenAI or if it mimics Stack Overflow. I'm leaning towards the former, but I'm not knowledgeable enough.\n\nThe stack overflow dataset is creative commons licenced though, no? Seems to me that training a commercial model is absolutely allowed by that.\n\nSO has literally been included in the dataset since GPT-2. If you honestly think it wasn't included since GPT-4 for no reason you're crazy.\n\n[deleted]\n\nAlso, it's Stack Overflow. Is a user copy-pasting an answer verbatim into their code really that different from having an AI copy-paste an answer in their code?\n\nI guess the difference is that the Stack Overflow answer provides context and attribution, but that's often just ignored anyway.\n\nStack Overflow is full of stolen content, some even by their own employees, which they refuse to remove.\n\nI found even articles from my obscure blog made up as question and answer by some Indian users, making their portfolio. Stack Overflow refused to remove the content after I proved to them is stolen content.  \n\nI am not the only one, but one of the thousands of blogs from where content was stolen and posted on Stack Overflow.\n\nI found out that part of  \"building your CV\" in India is to post stolen content on Stack Overflow to make a \"portofolio\" you can show your prospective employers.\n\nIt‚Äôs also why you see 100‚Äôs of blogs/medium articles with all same code as the default documentation page called ‚Äúget started‚Äù from Indians.\n\nAt least in the cloud world its hilarious when they manage to get interviews and then cant answer the same questions they answered on SO, I live for calling out cert dumpers and scam CVs üòÖ you get them from all countries but it seems its the cultural norm in parts of the world to lie out your ass and hope noone notices.\n\n[deleted]\n\nAlso criticise the questions asked for being the wrong way to solve whatever problem anyway.\n\nThe XY Problem is a legitimate thing to point out on SO.\n\nIt can be but not every fucking time.. sometimes you're just asking questions to better understand the language and people should be more concerned with what type of help people are looking for.\n\nDo I want a tangible result or find out how a specific function works? People are always inferring the former when I ask questions but typically I just want to understand the tools and then go from there.\n\nAnd yes people do that in their free time and whatnot but an unhelpful answer is worse than nothing in my experience. Saying you don't want a different solution however just makes you sound like a prick.\n\nMaybe I'm just super atypical or asking questions in the wrong way, I'm certainly not to set in my ways to try a different approach but it just isn't usually what I'm looking for on SO.\n\n‚ÄúHow to kill you Golden Goose 101‚Äù\n\nDo any of these smart asses have any idea that these short term gains are going to kill their product and believe me it‚Äôs going to kill AI too. \n\nThe biggest enemy of AI is AI itself and the people who are investing money on it. You can‚Äôt piss the people who are the source of your model. Your models stand on the knowledge collected by them.\n\nBy posting on reddit you‚Äôre training at least 10 ai models right now\n\nnot to mention all those recaptcha's you solved for a decade+.\n\nSo, the difference with recaptcha and using SO responses to train an AI, from my perspective, is that recaptcha was taking a mundane, necessary evil (a 'test' intended to reduce the ability of non-human actors to cause harm to the site or system) and doing so in a way that is net positive for both parties involved, while providing value beyond either party, while the SO debacle is taking advantage of a system that functions solely on the good will of its users, to extract value for a small group of what is essentially the cyberpunk version of rent-seeking Robber Barons, while simultaneously degrading the value and quality of the 'end product' (answers to coding questions) which was *gifted* to SO by their own users.\n\nBasically, the recaptcha situation is like adding pressure plates under the sidewalks which create electricity as people walk down the streets (and, sure, the electric company gets to pocket the profits, but everyone gets to enjoy the light of the street lamps, and we replace some minor fraction of fossil fuels, so, in the words of a very wise regional manager of a mid-sized paper company, it's a win-win-win)\n\nThe Stack Overflow crap, on the other hand, is closer to Doctors Without Borders' management deciding they want to build some robots, train them on videos of all the medical procedures all the human doctors were performing, and send them off to give medical assistance in rural areas across the globe... And sure! It's probably for the best, because more access to medical services in undeserved communities is probably for the best, right? And when Purdue Pharma wants to ~~line the pockets of the coke-fueled Ivy League C-Suite fratfiends~~ 'donate to the cause', well the fact these Doctorbots‚Ñ¢ suddenly start prescribing Oxycontin for everything from headaches to hemorrhoids, that's probably just a coincidence, right?\n\n[deleted]\n\nI hope they can tell the difference between human and bot content. \n\nBleep.\n\nYoghurt seems to have a healthy effect on your gut microbiome but I'll also give kefir milk a try. The bioavailability of beef liver is also really high.\n\nSo true bestie\n\nReddit made $3 off of my shit posting\n\nAnd since it seems that now at least 50% of the comments are AI now it will create a feedback loop\n\nModel collapse is a thing.\n\nOf course, then when it all falls down in a few years, consolidation all around for AI companies. Maybe governments bail out the victors because they're now essential, why should victors need to *hire* again?\n\nseems like ai has gotten as good as it‚Äôs going to get because it‚Äôs just going to be trained on ai generated junk moving forwards.\n\nI have always been impressed by the amount of effort and research SO users are willing to put to answer questions.  Even for the most apparently trivial ones, they will go the great length to provide the best answer that covers every corners.   And they do it for free.   Just imagine, they managed to make users work for for hours to produce super high quality content for their website for free.   They sit on a gold mine, and they decided to ruin it...\n\nthose internet points were always hot for many people...\n\nMany we did it as a way to provide evidence of knowledge or basis for investigation to understand better a technology.\n\nWhen I was a student and I didn't have evidence of work, I dedicated several hours a day to answer questions of technologies I was interested in. Many times, contributing to open source projects to fix \"those issues\" and becoming an expert on solving issues of said technology.\n\nThat opened up me helping a couple of buds in a top tier company and after exchanging some messages, being recommended for hire as a junior developer. I quickly got promoted as I was the go-to person for those technologies in the company.\n\nMy university friends didn't do any of this and their salaries are 5x less of what I make.\n\nSometimes, these little things change your outcome big time.\n\nMy guess is that they made the deal as they already knew OpenAI was scraping the site anyway, so now they get a bit of money out of it.\n\nAI would have crawled them anyways (well, technically already did) and SO numbers haven't been looking great lately so that goose already had problems.\n\nIf Stack Overflow was such a golden goose, why would they sell it few years ago?\n\nWhile the content is unquestionably valuable, their monetization strategy was always ads. They tried, and failed, to build in job ad board targeted at developers. There's also SaaS / self-hosted version, and I'm actually surprised it matched ads revenue in 2022.\n\nThe numbers are hard to come by, but it seems to be the general consensus that Stack Overflow barely made any profit ever.\n\nSO has been trying to kill their own product for a long time and AI has been scraping them the whole time so...\n\nSO had already killed their product, and AI was pounding the last few nails in the coffin. Making one last cash grab isn't a terrible idea in that situation. I.e., there *are* no more long-term gains.\n\nAs always, the losers are the users and community. As toxic as it is/was, there is still a fantastic wealth of knowledge there.\n\nStack Overflow killed their product awhile ago with a toxic community and prior super-user revolts. It's just since ChatGPT came out that there's finally a viable alternative to their service . I guess they figured they might as well try to make a buck as they die.\n\nI doubt ChatGPT could be a viable alternative, considering its hallucinations and the way LLMs work. However agree with the part that SO killed their own product.\n\n&gt;I doubt ChatGPT could be a viable alternative, considering its hallucinations and the way LLMs work.\n\nSO power users and mods love to hallucinate what the asker actually meant, and to hallucinate duplicates. SO answerers love to hallucinate incorrect answers.\n\nI think it balances out.\n\nI use ChatGPT and co-pilot daily for coding, in python, rust, and node/ts, as well as data work. It‚Äôs far better than stack overflow at keeping me moving and unblocked. Yeah, it hallucinates sometimes, but it‚Äôs rarer and rarer and even a somewhat experienced junior developer can quickly learn how to sort that out.\n\nRIP SO\n\nSO died many years ago.\n\nRIP Zombie SO\n\nHow can you kill that which has no life?\n\nTrue\n\ni remember some 10 years ago technical google searches were polluted with information from the Windows XP era. Totally outdated information.\n\nAppearently google was able to scrub the junk out of the search results. It is still there, but no longer gets into the results. The same is the point with AI. Once AI has been trained, who is going to tell AI that it's information is beyond it's \"best before\" date?\n\nWhen AI is going to be the driving force of innovation, technology will be capped by what AI can process. This will only take 5 years.\n\n&gt; Appearently google was able to scrub the junk out of the search results. It is still there, but no longer gets into the results. \n\nThat's not really a good thing. They did this to the extreme. Try searching for something few months or years old. Impossible. Even if you know exact quotes or title, Google will tell you it doesn't exist. Same for their YouTube search - instead of what you're looking for it will show you some latest videos.\n\nWhat I hate is that even if I keep fiddling with the search query to try to get the results I'm looking for, Google will keep returning the same generic results. However they've weighted their sorting, it's clearly dominated by 1) recency, and 2) big brands. Little else seems to be able to overpower those factors in the ranking. And beyond the matter of accuracy, there's zero novelty in the results anymore. I hate it.\n\nBut if there was just *one* thing they would consider changing, *please* could they stop returning the same unclicked-on results over and over as I edit my query. Nobody is benefiting in that situation.\n\nYep. Google went to shit. Whole sector did, honestly, along with the Internet in general.\n\nSearch used to be for search. Now, it‚Äôs a medium for delivering advertisements‚Ä¶ like so much of ‚ÄúWeb 2.0‚Äù (to say nothing of so called 3.0 lmao)\n\nIn what way? As I have been searching for a lot of Windows XP and Server 2003 information for a retro homelab recently and while it's not been easy I have found most of what I am looking for.\n\nremind me in 5 years\n\nForecasting algorithms are normally weighted to newest data first so Google probably didn't do anything other than wait for people to write new support articles.\n\ni think it's the other way round. The search algirithm as we know it today was improved to prioitize newer results to eliminate the outdated XP info from the results.\n\nTaking the age of the info into account is normal today.\n\nIs this the death of the internet? The internet of the 90s and 2000s - a place to go to share ideas and just have fun. Given how more and more of the stuff is now paywalled and any 'free' service like Google search is messed up beyond any usefulness, seems like we are headed towards an Internet which will be strictly a place for making transactions - no longer a platform for sharing or collaborating anymore.\n\nDude that internet died many moons ago. It's been enshittified for quite some time now.\n\n[removed]\n\nOnce the plethora of Ads kicked in it was game over. Money money money money money money\n\nLike two decades...\n\nReddit does similar shit. They‚Äôll ban your account but keep all the content you created. Or when you delete your account, your username disappears but they keep all your content.\n\n&gt; Reddit does similar shit. They‚Äôll ban your account but keep all the content you created. \n\nGoogle(tm)'s \"gmail\" service did this to me over a year ago, banned me from my email account because I don't have a $(arbitrary_requirement_supporting) phone number to give them...  and also I had been trying to delete everything, but they limited me to a few thousand messages at a time, which was practically impossible to complete unless deleting as a full time job.\n\nWill GPT now start responding that a question has been asked 10 years ago so you should avoid duplicating it?\n\nI imagine they'd just train on old backups rather than live data.\n\nI'm very happy for machine learning to be calibrated on my writing, programming, art, etc, as somebody who has done all of them over the decades, anything I put out into the world for others to use is fair game. The tools created are fantastic and I work them into my workflow wherever I can. e.g. There's almost no good documentation or answers for various pytorch libraries and projects, but GPT4 can generally give me correct examples of how to use them and has gotten me up to speed very quickly in areas I don't know if I could even find answer to on my own.\n\nFrankly it's a life saver with how useless google has become these days.\n\n&gt;Frankly it's a life saver with how useless google has become these days.\n\nWhat, you don't like a site with 20 ad popups and 5 paragraphs of keyword stuffing before the  non-answer?\n\nI'd like to see a massive uprising against OpenAI... mainly because they deserve it\n\nAs much as I dislike Zuck and Meta, IMO they have launched the most effective attack against OpenAI by openly releasing Llama 3 with such a ridiculously generous license.\n\nMy usual general ethical compass is if you trained on public data, the model should be public itself and able to run locally with no cost. This is why I don't dissing LLama and Stable Diffusion that much and hate ChatGPT, Claude, Midjourney, etc with a passion.\n\nExactly but for some reasons artists love dissing on SD while ignoring Midjourney and DALL-E 3 Lol\n\nGenuine question: why this rebellion against OpenAI and not against Google, that indexed the site for years?\n\nAnyway, I have a bunch of questions and answers there and it is very clear that the moment you post you stop owning what you wrote. I've started using it as a forum, but clearly is closer to a wiki.\n\n&gt;Genuine question: why this rebellion against OpenAI and not against Google, that indexed the site for years?\n\nBecause google still links to the original source, thus providing credit to the author. OpenAI won't cite you if it answers based on content you have created\n\nGoogle's product was like a somewhat intelligent phone book (remember those?, I just revealed how old I am). They provided a service and paid themselves filling their site with ads, which is seen as fair game.\n\nThese statistical models they call AI are able to scramble new sentences in a way that can make sense. Sometimes they are very helpful, and sometimes they hallucinate so badly it can be hurtful - if the person asking is not able to recognise it is hallucinating. \n\nI don't know how they pay themselves, I guess it is just investors money for now, and it is not clear if they will ever pay for the content they are consuming, nor what's the final money making strategy.\n\nIndeed the SERP page of Google it's a phone book on steroids (you won't believe up until what year we got those delivered by our doors in Italy). \n\nBut I fear that thinking Google only uses data it gathers from website for the sole purpose of presenting search results is a bit na√Øve. They certainly have always used data to make money, through directly through ads or more indirectly by learning from those data to improve their products. \n\nThe debate around where AI gets its knowledge is interesting and really multifaceted. What I think is that even if the scale is different, there's nothing new in what's happening compared to what always happened before.\n\nThe main difference is that Google search gives you a link to the source, hence funneling traffic and everyone is happy. Maybe if these AI chat bots provided the source they used in each answer, with links? I know, not happening.\n\nGoogle consumed the internet several times a month, but they had a good excuse. They have their own AI now, so for sure there is more happening, but can we complain about what they did internally with data publicly available?\n\nI guess the outcry from people who make or own content is that it's being consumed, and feed into a machine producing new content, and it will make the original content less relevant. If you remove all the incentive for an author to publish, they will eventually stop, this is close to the debate about piracy.\n\nMy opinion is that most of SO is a fairly toxic mix of clueless newbies that could probably try a bit harder and prima donnas that think they know it all but in reality all they can do is ask for MREs and sock puppet upvote their own content. Search based on ranking of upvotes does help a bit, but higher scores mean older and usually but not always better. There‚Äôs still a lot of content with high ranking that is old and now wrong.\n\nValid point. \n\nSo many times , the right answers which worked for me are from either comments or some 2 upvoted answer by a guy with 10 reputation\n\nI am sorry but if you've answered hundreds of questions on SO and expected to \"own\" those answers, and that SO had no right to profit from it, you were seriously under a delusion. Do you think SO is a charity, non-for-profit organization that is willing to cover the costs of maintaining a service used by almost 100% of developers on the whole planet for absolutely no monetary gain?\n\nAlso, if you were so willing to answer questions on what's patently a public medium where you can make no copyright claim whatsoever, why do you suddenly have trouble with the idea of someone profiting by collecting your answers into something easier to extract information from? That's the kind of thing that should be obvious would happen and should be as expected as someone using your FB posts and photos to analyse your general behaviour (which of course they do also, and I am very sure their AI also got trained on people's posts), because it's a damn good idea, and having contributed to SO myself I have zero problem with that because that will make my contributions continue to help the people who I wanted to help. As long as they never remove my answers from the site and keep it there free of charge, I see no problem at all with what they're doing. Just because now my answers are also helping another company make a better product for their uses. If you want to scrape SO to train your own AI, which I am sure many of people in this reddit already did as well, go ahead! It's public information and there's no Terms&amp;Conditions (well , probably there is but nobody seems to care anyway) as to who and how you can access that information.\n\nFollowing your comparison between SO and FB, would it be the same if I, as a user of their service, delete or alter my own answers or questions, just like FB allows their users to alter their content? Of course I‚Äôm not talking about copyright, but the freedom to modify or delete the own content at will.\n\nThese arguments are always so ridiculous and extremely pervasive in all facets of our lives when it comes to things like EULA's, NDA's and NCA's, copyright, and laws. Legality does not equate to morality, and just because you can does not mean you should, nor does it mean that people dont have a right to disagree or even resist. There are an abundance of examples of this very thing throughout recent history.\n\nI think the more interesting question is why people feel the need to defend shitty behavior with the very predictable arguments of \"personal responsibility\" or \"might is right\" and pulling a \"well, um akshually here in article 9 subsection c. of the EULA you agreed to by existing on the internet states that they can do whatever they want therefore I have surmised you are throwing a tantrum, I am very smart\" bs.\n\nI'm sorry but that is just absolutely absurd and you have the backbone of a jellyfish. There is absolutely no choice in the matter outside of literally just not ever using the internet, ever and lets not pretend like they give a flying fuck about whether that data was legal to collect or not, we all know they scraped literally everything they could/can get their hands on.\n\nExtracting sone kind of value from user provided answers has always been the business model of SO and the goal of literally everyone going to the site for answers.\n\nSo the method to access the information and extract the value has changed but the motivation hasn't.\n\nI just can't understand why anyone would say: this is my knowledge, free for any and all to use! Please, learn from me!\n\nand then turn around and quibble over the specific user-interface that people access that knowledge through.\n\n\n\nI also haven't actively used stackoverflow for nearly a decade, though. Something has \"felt off\" for a long while and I don't know what changed.\n\n&gt; and then turn around and quibble over the specific user-interface that people access that knowledge through.\n\nYou mean the paywall? It doesn't surprise me in the least that people who provided their expertise for free, for a site that was allowing other people to access that for free, are upset that now someone is packaging that up and charging for it.\n\nA better move would be to deliberately flood the site with wrong answers.\n\nWhat's the problem with openai accessing stack overflow posts? It could be actually be useful in asking free style questions and getting good answers back.\nReally,what is the problem with it?\n\nDo we have an alternative to SO?\n\n5 years ago, stack overflow was the place to be if you had a code question. Now it just goes like this:\n\n[-3] ‚ÄúHow do I fix this simple issue‚Äù\n*Description of issue*\n*user‚Äôs code*\n*list of things tried already*\n\n\n\n[+5] Stack Overflow User (20k karma 10yr veteran): google it. If that doesn‚Äôt work, reinstall your operating system and migrate to this language\n\n\nThis notification is to let you know we are closing your question because it has already been asked here: (link to page with a question that has absolutely nothing to do with what you just asked and no helpful answers)\n\nAmerican companies:\n\n1. first they declare war against their employees\n2. then they declare war against their community\n3. then they declare war against their customers\n4. then they go bankrupt\n\nBoeing:\n\nFunny how someone can be talented enough to give a top answer of SO yet not realise that deleting their content does nothing. SO would never delete it, it's just removed from view. They still have everything you wrote lol. Even if it was deleted they'd have backed up and cached versions too.\n\nDeleting your answers basically only hurts other people that would need them, kinda like the dumb reddit protest. So much useful shit lost to that\n\n&gt; Among other things, the act protects the ability of the consumer to delete their own data from a website, and to have data about them removed upon request. However, Stack Overflow's Terms of Service contains a clause carving out Stack Overflow's irrevocable ownership of all content subscribers provide to the site. \n\nYeah, not how that works. A ToS doesn't get to say \"nuh uh uh, you didn't say the magic word\" to override a law. Unfortunately, it still takes a court challenge to iron out and get a judgement for them to act right.\n\nYou're right that a ToS can't override the law, but it doesn't really matter in this case.  Stack overflow answers are not PII, and are not protected by the right to be forgotten.  At best, users can request their user names be removed from their answers.\n\nWell thats goofy. Stack overflow is the one that provides a delete button. Dont be mad when someone does something they are allowed to do\n\n&gt; [The moderator crackdown is] just a reminder that anything you post on any of these platforms can and will be used for profit.\n\nAre these people brain dead? Breaking news: StackExchange is a for-profit company and has been making money off the site, which revolves around content posted by its users, for years! Shocking, I know."
  },
  {
    "title": "Stop Designing Your Web Application for Millions of Users When You Don't Even Have 100",
    "body": "",
    "score": 2877,
    "url": "",
    "created_utc": 1726739575.0,
    "author": "bizzehdee",
    "permalink": "/r/programming/comments/1fkh1k7/stop_designing_your_web_application_for_millions/",
    "all_comment_text": "But we WILL NEED WEB SCALE\n\nResum√© driven development.\n\nGiven how many companies refuse to provide meaningful promotions or wage growth, I can't really blame people for thinking about what's next.\n\nI'm stealing that phrase.\n\nIn exchange, you can use my phrase \"Trauma Driven Development\": letting horrors of previous bugs and management drive development decisions.\n\nThat‚Äôs called learning your lesson\n\nI worked somewhere with an utter mess of a codebase. One department had been headed by a cowboy who would code things over the weekend and deploy them Monday morning, with no tests or QA, no dev environment, and tell the team that‚Äôs just how things will go. He was fired (well told to resign or he will be fired) as he was basically at war with the CTO and other department heads.\n\nData science was littered with giant Jupyter notebook programs written by one person in the early years. Also no testing. Pushed into production. Even including all of the draw functions from the notebook. These were 10k programs split into five functions. The written by one person was the big issue, as he left, and years on no one has a clue how any of it works. A common gotcha was that downstream pipelines *expect* bugs from the upstream to continue, for that pipeline to fix. A notorious one being that certain data from upstream put the dates in the wrong field, which downstream would swap back in several different places for different reasons.\n\nTheir answer was to move to major architecture reviews. A new service needed an early architecture meeting, agreement, and then a full document. You had to go through this with your manager who would move you back to the start. Then it had to be reviewed and approved by others. Next you make a large presentation to present to the entire R&amp;D department for feedback. Followed by a second report on that. At the end you‚Äôd be told *‚Äôgo and think about the things discussed‚Äô* with no other actions, and it‚Äôs back to step one. After three months of this it would be common for a second person to be asked to make their rival report, to collaborate your claims, and put forward their architecture. Things that might take a month to build, could be presented two or three times over six to twelve months.\n\nThis was a small company with 30 engineers in total. The architecture was not that big.\n\nOne example is we had a broken QA. Just didn‚Äôt work. After two years, five reports and proposals, three leads being asked to make their own reports, and about six presentations, we just fixed it all in secret. Development was glacial so we lied about work and did that instead. The system had bugs, and the proposals were to rewrite the buggy code, and removing things unused. That‚Äôs all.\n\nThe CTO defended this approach to the hilt forever bringing up the past developers. *‚ÄôYou can‚Äôt work like X anymore‚Äô*, which was borderline offensive given most engineers joined _after_ those days and didn‚Äôt want to work like them.\n\nCompanies can easily flip flop from bad ways to eternal bureaucracy.\n\nThat sounds so god awful. I have worked at some places with shit processes and shit codebases, but never anything like what you just described. That's going to haunt me.\n\nI hate how well you described both sides of this coin, and how much I can empathize.\n\nDepends on the lesson, lol.\n\nI made this.\n\noh boy my impostor syndrome is all over this now\n\nDude this is a killer phrase\n\nDoes `/dev/null` support sharding?\n\nIm off to the farm to start my new job castrating bulls.\n\nMongo is web scale\n\nOh. My. God.\n\n[For the uninitiated](https://www.youtube.com/watch?v=b2F-DItXtZs)\n\nMangoDB is better\n\nDon't forget cloud native!\n\nFriendly reminder that Facebook was coded in PHP for a very long time and they only changed when they got tens of millions of users.\n\nAnd at that point they had the staff to basically rewrite PHP (into [Hack](https://en.wikipedia.org/wiki/Hack_(programming_language\\))) and removing all the pain points they had.\n\nand Twitter started in Ruby and changed to some JVM language later on\n\nScala\n\nthat's the one :) thx\n\nand they are still suffering from that decision to this day.\n\nReally?  Can you tell us more or give us a link?  All I found was a thread on reddit where OP deleted the post.\n\nThe reason wasn't because of Scala being bad or anything. But because they had a monolith and spent 10 years turning it into a microservice architecture with basically no new features to show for it. Former twitter engineers have come out on twitter saying as much. And then when Elon Musk bought twitter, he wanted to move away from the microservices architecture.\n\nYes we need more info. Why switching to Scala was a bad decision for them? Comparing to Ruby I don't see how Scala can loose in terms of high load and huge java ecosystem?...\n\nSince Hack is a php dialect, did they actually rewrite everything or did they transpile and make gradual changes that the new features allow?\n\nThey started with transpiling to machine code using PHP HipHop.\n\nSounds like a Hack job to me.\n\nClever of them to Hack something together\n\nAnd then they realised having a JIT was more productive, Hack was born and HipHop killed.\n\nAnd thus was born Raygun...\n\nWait, what?\n\nI was in the team doing the same for JS -&gt; FlowJS and used Hack team's techniques and tools. It was a few years ago and I may be simplifying or misremembering details.\n\nThe Hack initiative was split into teams for core language, for the runtime, and for tooling. When runtime or core language came up with a new feature (new fancy types, typing formerly dynamic patterns, new strictness checks, better stdlib functions...) they'd work with tooling on adoption.\n\nMost changes would improve the efficiency of the runtime, meaning massive costs savings at that scale; so they needed to be done ASAP. Sometimes this meant manually changing thousands of files, over time it'd become millions. You can put the onus on orgs to apply the fixes, but that way adoption was slow because the pushback and delays were measured in quarters.\n\nAt that point they built codemod tools on top of the compiler infra, and got access to power-user tools for the monorepo, such as exclusively locking the codebase for their PRs. You'd write a codemod to add some fancy types based from a new version of the inference algorithm, or add annotations in places where they were not in before, replace functions and infer their parameters, or fix the real bugs found by a new check.\n\nThen, you'd either make a million low-risk PRs where you applied the tool to an isolated folder and manually fixed the problems. Or, you wrote a couple of massive atomic PR for millions of files that carried more risk than a gym shower with PDiddy. You worked with the monorepo stewards to release at a safe time, with plenty of guardrails and checks not to break the whole company.\n\nThis process lasted, _per feature_, from a few weeks to a year+ for the engineer(s) involved. This is economically very efficient because it saved Meta tens of millions of operating costs yearly by spending from tens of thousands to a million in engineering salaries.\n\nI know you made a lot of good explanatory statements, but all I am taking away from this is ‚Äúriskier than a gym shower with P Diddy‚Äù and honestly, am not too upset\n\nNo idea, sorry, I have not followed that in details, being a fan of neither Facebook nor PHP\n\n&gt;being a fan of neither Facebook nor PHP\n\nLook at you, being sane over here.\n\nSo cute\n\nHell, reddit was originally written in Lisp because it happened to be the language Steve Huffman was most familiar with at the time, and then they later rewrote it in Python \"pretty much in one weekend\": http://www.aaronsw.com/weblog/rewritingreddit\n\nAnother friendly reminder that PHP 8.3 is now faster and better than Hack\n\nThat's the power of open source!\n\nAnd your point actually reinforces the post's one: inadequate tech still brings you a long way and may very well become adequate along the way.\n\nWe don‚Äôt have alternative timelines but it‚Äôs very debatable FB going ‚Äúfine, we‚Äôll do it better ourselves‚Äù forced PHP to swap from features to performance. 6 was skipped and 7/8 have been very performance oriented.\n\nPHP 6 was skipped because they got bogged down with details of adding proper UTF8/Unicode support, saw the shitshow that occurred with Python 2/3 due it's changes around unicode and bailed on the task. By that point a bunch of over-eager people had written PHP 6 books and online resources that were focused on features that weren't going to be shipped.\n\nPHP 7.0 was mostly the good parts of PHP 6 that could be salvaged and separated from the unicode changes. There was definitely a focus on speed in the point releases, but PHP was already #2 for speed in the scripting language space (JS is the king on speed, and will likely remain for a long time).\n\nAlso friendly reminder than a MASSIVE amount of the financial world runs on a mix of PHP services talking to mainframes via SFTP and XML APIs - as well as Wikipedia, Spotify, Baidu, Tumblr and some other of the largest web services in the world.\n\nPeople always write it off as the \"wordpress language\" due to the era of immaturity it went through, but its ability to be rapidly prototyped has always trumped that, and only helped it mature into a much more stable and feature-rich language.\n\nWikipedia doesn't have a mainframe or rely much on SFTP or XML APIs. It is largely PHP though (heavily extended MediaWiki) and it does support some XML APIs for clients (but I suspect most callers are actually using the JSON format these days).\n\nSorry, I think my post was worded in a very confusing manner. Did not mean to imply that those large web services had anything to do with the fintech world other than using PHP.\n\nAt the first startup company I worked for, we created a full financial platform. During the implementation phase, I had a disagreement with the Architect/CEO. He insisted on using raw SQL and JavaScript on the backend‚Äîraw SQL for speed and JavaScript to prevent cold starts from AWS. His argument was that with more than 2 million concurrent calls per day, his approach would be much faster.\n\nI argued that using .NET, the primary language for most of the team, along with EF Core, would be much faster to implement. If performance issues arose in the future, we could modify the queries or use Dapper only where needed. However, we proceeded with his approach, and a little time later, I left the company. Almost four years have passed since then, and I heard from ex-colleagues that they have only 10 active customers, and the JS raw SQL setup has become a nightmare to maintain.\n\n&gt; the Architect/CEO\n\noh no\n\nThat was an immediate eye roll. Unless the team is less than 10 people, that's a bad sign.\n\nNothing wrong with a CEO who codes. It is how many companies get through the early days.\n\nWell there are 10 customers. There better be less than 10 employees\n\nTBF \"customers\" can mean corporate entities, which can be quite large.\n\nAnd depending on the financial platform, 10 large customers could easily be millions of requests per day.\n\nagreed, palantir used to have just 1 customer, US government.\n\nI did 3 rounds of interviews with a company last year that in my meeting with the CEO he told me they have 25 customers. I would've been the 6th engineer on the team.\n\nI was desperate for work so I kept my hat in the ring but I do not have high hopes for that company. They didn't offer me and I was like ya know what, that's fine. The circumstances of their engineering team and customer base were bad enough but I left every interview feeling like I was the smartest person involved and I absolutely _never_ feel that way. I think that job would've been stressful.\n\ni had a college roommate that went on into the financial markets and started his own company.  he interviewed me years later and i saw the same thing.. ..so I didn't accept the offer.\n\nHow does JavaScript even help with cold starts?\n\nNot sure about how it is now, but C# (and Java IIRC) had notoriously long cold starts in the past when compared to JS and Python in a Lambda environment. This was a big reason why JS and Python were very dominant when deploying to Lambda, along with them just being much easier and faster to write (or at least I assume that to be the case). I have no idea how it is now though, so I can only presume that it has gotten better over time for C#/Java in regards to cold starts.\n\nThey could probably have gotten 0 cold start regardless of language if they just ran it on a VM for the first years :D\n\nIf they were expecting that much traffic and the api operations weren't cheap, or they wanted responsiveness to be a priority (seems that way from avoiding cold starts) it'd be way better to have a long running container than spin up a lambda every call.\n\nGenerally a good recommendation.\n\nFor startups, leveraging cloud resources carelessly can be a risky proposition. Startups can die on whether a bad push leads to a 100x cloud bill. This is a bit unrelated, but a good reminder to deploy cautiously when money's on the line: [how a company with nearly $400 million in assets went bankrupt in 45-minutes](https://dougseven.com/2014/04/17/knightmare-a-devops-cautionary-tale/). I've seen a couple incident reports [like this one](https://medium.com/@maciej.pocwierz/how-an-empty-s3-bucket-can-make-your-aws-bill-explode-934a383cb8b1) about AWS charges that are unexpectedly high because of undesired instances being accidently spun up or requests not being handled as expected.\n\nWhen I'm working with a startup, I always ask them how they would handle an unforeseen $15k, $45k or $85k cloud bill. If they're shocked that's a possibility we go with a digitalocean VPS.\n\nIf we go with cloud services, I set up alerts but warn them there's a possibility (likelihood) they'll come at an inconvenient time and we'll just bleed money until we can handle it.\n\nwell if I ever get into automated trading, I'll be sure to cover my ass\n\ngood thing I'm not though, that's a bit too high speed for my tastes\n\nCold starts being slow on c# are still a thing - but only when you hit a cold start. Also you can mitigate a lot of it if you use AOT compilation.\n\nCold starts are still a big problem for .NET/C# if you are targeting a FAAS like lambda. It can also be a problem if you need to rapidly scale up.\n\nAOT compilation addresses this, but it‚Äôs very much in its infancy, the C# AWS SDK for instance doesn‚Äôt support it yet (you can get it to work with some effort).\n\nIf they‚Äôre using AWS Lambda, then the conventional wisdom a few years ago was that Node had the lowest cold start times. This kind of makes sense if you expect low, in frequent usage patterns.\n\nBut then you have the architectural boneheadedness of using AWS Lambda.\n\nIn and of itself, it‚Äôs not bone-headed.\n\nGiven the (limited) context that OP provided about the app having a very low user count, it is entirely possible that architecting the app to use Lambda could very well be a wise choice, at least from an operational cost perspective. \n\nI‚Äôm not saying that it is absolutely a good decision, just a defensible one, given the context.\n\nYeah, fair point. I admit to having seen far too many, let‚Äôs say ‚Äúdistributed state machines‚Äù implemented as Lambdas that were buggy and nearly impossible to diagnose because of their ephemerality, but ‚Äúat least we didn‚Äôt have idle infrastructure spend.‚Äù But you‚Äôre right: that‚Äôs not everyone.\n\n.net cold starts used to be pretty bad a few years ago - so I can see that being important if you were dead set on serverless.\n\nSeems it would have been better to just have a server ‚Äî zero cold starts and the .net code would probably perform better üò¨\n\n[deleted]\n\nIronically... server-less in its vanilla formulation is better for smaller scales. It gets expensive quickly, so once you actually handle millions of requests per second you will want to move to server-based or container-based approaches where you have more control over performance optimization.\n\nI am lucky/unlucky enough to work at that scale, and the price for Azure Functions to do the stateless parts of our compute are eye-watering. But we still use server-less for the \"a few per second or less\" workloads because they're simpler to code and manage.\n\nI‚Äôd assume he‚Äôs talking eg Lambda where JS has (had?) a pretty significant advantage over .NET for cold starts of a function.\n\n.net has a really bad cold start time on AWS lambda.\n\nAt least last time I worked with it.\n\nWhat .net version?\n\nMy .net 6 lambda had about a 2 second cold boot  but I think that is the last version that required a custom docker image to run on lambda? The newer versions are faster but I haven't had the time to upgrade it as it's just a back office task that needs to run infrequently.\n\n\nIn all seriousness, it‚Äôs probably a technically inept CEO that gravitates to JS because it‚Äôs the only thing they know.\n\n.NET cold start was really bad, but it's fine now since Microsoft has to push for server-less to sell their Azure Functions.\n\n&gt; JS raw SQL setup has become a nightmare to maintain\n\nBeing from a time where ORMs didn't exist or where unavailable, I had to dive deep into SQL queries and, to this day, I feel way more comfortable dealing with them than dealing with sqlalchemy, for example. Stored procedures are so underrated.\n\nYeah javascript thing aside, I have never had great experiences with ORM and I have had a lot of horrific ones. ORM ‚Äúsolve‚Äù very simple queries, but those are not a problem in the first place. Having a simple result set -&gt; object mapper and object -&gt; prepared statement params is enough.\n\n&gt;Having a simple result set -&gt; object mapper and object -&gt; prepared statement params is enough.\n\nIsn't that technically an ORM?\n\nMy understanding is that while it might seem that mapping result sets to objects is similar, in reality ORM is meant to map an object hierarchy/module and hide the database details completely. What I described is more of a deserialization helper.\n\nThey don't hide it. At least in my experience. They just have a preferred method.\n\nWe would use the ORM for most stuff because most the stuff wasn't complicated. But when they did you could write raw SQL and it along the same workflow. \n\nSeems like a lot of horror stories come from trying to put an ORM in an existing code-base. Which just sounds like a nightmare. ORMs usually dictate a certain way to do things. If you're entities are all over the place it's going to take a lot of work to \"fix\" them or a bunch of work-arounds.\n\nMy last project dealt with lots of data/queries - but nothing really that complicated. Raw SQL would have been tedious. The ORM made quick work of it.\n\nThat's sometimes referred to as a microORM. Traditionally ORMs hide the db details entirely and you aren't writing any SQL, you instead use a DSL in code. MicroORMs are generally the part most SQL aficionados are happy to use a library for where you provide SQL queries and parameters and they handle serializing/deserializing the objects.\n\nLike the Flask SQL library?\n\nObject mappers are fine.  Trying to come up with a better query language than SQL while still needing to be SQL under the hood is not so obviously good.\n\nFor whatever reason every discussion about ORMs is all or nothing.  I use ORMS for a `User::where('id', $id)-&gt;first()` and raw SQL when I have to join across 5 tables in a recursive query.\n\nThat's fine but I don't really care about adding another layer of technology since select(\"SELECT * FROM users WHERE id = ?\", id) is pretty much equally easy\n\nIt's equally easy until the junior does a `SELECT * FROM users WHERE id = $id` and now you have security issues.  ORMs also auto-complete in my IDE and are more easy to mock for simple queries.\n\nI don‚Äôt buy into the security argument. It‚Äôs trivially easy to spot those things in a code review or disallow them with a linter. We do raw sql (giant product used by fortune 50, thousands of queries) and I have never encountered in 7 years of work there a security issue you are describing.\n\nI definitely agree that autocomplete is somewhat valuable and that‚Äôs why I think a query build is fine alternative for simple queries. I have used one which generates sources from your schema, it was fine.\n\nI think people miss the things ORMs *really* solve because they either use them for everything or for nothing.  That category of BIG simple queries.  They best serve a developer if they are a translation layer between structured data (like a Filters block) and your database.\n\nORMs give better DX and integration to devs in a lot of common situations.  For my favorite example example, when you want to conditionally join a table in depending on which filters are requested, when you do basically ANYTHING with GraphQL and highly mutating returns.  I've come upon some DISGUSTING raw SQL code trying to dynamically build those queries in hundreds of lines of string manipulation.\n\nWhat I experience, paradoxically, is that people writing raw SQL tend to do a LOT more destination-language post-processing than people who use ORMs.  Because if you want to do my above example in the SQL, you're doing crazy string parsing to build the query, and anyone who has seen functions doing that are going to run screaming and do what it takes NOT TO.\n\nFor the rest, I'd say nested SELECT queries are the ORM holy grail: doing all kinds of joins and getting the data back in a strongly typed structured tree without having to write a bunch of mapping code.  Ironically, they're also one thing that a lot of ORMs do very inefficiently.  But some are pretty solid at it.\n\nEDIT: Of note, I have a lot of respect for query-builder libraries trying to be the best of both worlds.  I haven't fallen in love with a query builder as of yet.\n\n&gt;What I experience, paradoxically, is that people writing raw SQL tend to do a LOT more destination-language post-processing than people who use ORMs. Because if you want to do my above example in the SQL, you're doing crazy string parsing to build the query, [...].\n\nNot necessarily. You can also write a stored procedure that handles the use cases you need via arguments. For example, pass an array of filters objects into the stored procedure, and then filter the table in that procedure. Like so (in PostgreSQL):\n\n\tcreate table foo(\n\t\tbar text,\n\t\tbaz text\n\t);\n\t\n\tinsert into foo values ('qoo', 'qux'), ('boo', 'bux'), ('qoo', 'bux'), ('boo', 'qux');\n\t\n\tcreate function filter_foo(arg_filters jsonb)\n\treturns setof foo\n\tas $$\n\t\twith recursive filtered as (\n\t\t\tselect bar, baz, arg_filters as remaining_filters\n\t\t\tfrom foo\n\t\t\tunion all\n\t\t\tselect bar, baz, remaining_filters #- '{0}'\n\t\t\tfrom filtered\n\t\t\twhere\n\t\t\t\tcase \n\t\t\t\t\twhen remaining_filters -&gt; 0 -&gt;&gt; 'operation' = 'eq' then\n\t\t\t\t\t\t(to_jsonb(filtered) -&gt;&gt; (remaining_filters -&gt; 0 -&gt;&gt; 'field')) = remaining_filters -&gt; 0 -&gt;&gt; 'value'\n\t\t\t\t\twhen remaining_filters -&gt; 0 -&gt;&gt; 'operation' = 'like' then\n\t\t\t\t\t\t(to_jsonb(filtered) -&gt;&gt; (remaining_filters -&gt; 0 -&gt;&gt; 'field')) like remaining_filters -&gt; 0 -&gt;&gt; 'value'\n\t\t\t\tend\n\t\t)\n\t\n\t\tselect bar, baz\n\t\tfrom filtered\n\t\twhere remaining_filters = '[]'\n\t$$ language sql;\n\t\nUsage:\n\n\tselect *\n\tfrom \n\t\tfilter_foo(\n\t\t\t$$ [\n\t\t\t{ \"operation\": \"eq\", \"field\": \"bar\", \"value\": \"qoo\" },\n\t\t\t{ \"operation\": \"like\", \"field\": \"baz\", \"value\": \"b%\" }\n\t\t\t] $$\n\t\t)\n\n\nResponse:\n\n    [[\"qoo\", \"bux\"]]\n\nNote that doing it like this will not use indexes. If you need them, you would either have to add expression indexes to the table that index on `to_jsonb(row) -&gt;&gt; 'column_name'`, or you would have to do it the slightly uglier way with dynamic SQL (PL/PgSQL `execute`) in the stored procedure.\n\nI primarily use Entity Framework and it definitely had a bad reputation preceding it from EF4 and earlier. Since EF6 and now EF Core it is a stable ORM and pretty awesome. There are definitely tradeoffs and you can get into serious performance issues if you don't understand how it will interpret your LINQ statements or materialize entities. If you do have something complex that you need to drop to raw SQL or god-forbid use a stored procedure, you can absolutely do that for the specified operation fairly effortlessly.\n\nI have found that most teams that believe ORMs suck or that EF is objectively bad either came from the old days or can't/don't read the docs. While EF has pit falls and trade offs, it's super convenient and can provide excellent performance.\n\n&gt; Being from a time where ORMs didn't exist or where unavailable\n\nIn 20 years, I'm still waiting for a place where I can say this is a pleasure to work with (the codebase), IMO it doesn't matter if there is ORM or not, it's the way the whole codebase is implemented.\n\nYou don't *have* to use the orm layer of sqlalchemy at all. It's a carefully [layered architecture](https://www.sqlalchemy.org/features.html). \n\nCan just use the sqlalchemy core expression language layer for safer sql construction/manipulation, without ever getting into the object-relational mapping layer (even then sqlalchemy orm is an unusually well-designed orm, using the uow pattern and *not* the more common active-record pattern).  \n  \nPeople who try to rawdog sql strings without sqlalchemy expressions or similar for other languages (e.g. java jooq) nearly always are the ones also introducing endless dumbass injection vulns.\n\n&gt; Stored procedures are so underrated.\n\nUntil you need to debug or scale.\n\nwhy would those be an issue?\n\nstored procedures can cache query plans based on statistics, which helps a whole lot with scaling. some engines can do this for ad hoc queries as well, but not all.\n\nIt's funny how experiences can shape your view on a technical matter. I can't help but hate stored procedures. I feel like it can be powerful to get things setup quickly, but it becomes a nightmare to maintain really fast.\n\nA few years ago I had to work on a 15ish years old project where every single query was a SP. The issue being performances, after investigating, I could notice that so many people went through the code without really understanding the database structure. The SPs were hundred lines monsters with crazy joins and loops everywhere.\n\nStill today I'm convinced this situation would not have happened if they used an ORM like EF. With their budget and constraints (no change to the tech stack), I was only able to fix like the top 20% heaviest queries. Which made the website much snappier,  but in the same timeframe with and ORM, I believe I could have fixed everything.\n\nTL;DR: stored procedures are a great tool, not to be used in every case/by everyone. ORMs make dev way easier and maintainable imo.\n\n[deleted]\n\nBeing from a time where my first was all business logic written in stored procedures... I think there's a happy middle ground\n\nThis.\nSuch a waste of time to learn all those ORMs, when we already have a common, unified standard - SQL. And it even performs significantly better, if you're just slighty competent with SQL.\n\nI used to feel that way years ago, but modern ORMs like EF for dotnet have had such great work done on them if you look at the SQL they generate now under the covers, it's just as efficient as even the best devs can write by hand.\n\n&gt;  when we already have a common, unified standard - SQL.\n\nI am maintaining a codebase that supports Sqlite, PostgreSQL and SQL Server and I assure you it is not a common, unified standard\n\n&gt; Such a waste of time to learn all those ORMs, when we already have a common, unified standard - SQL.\n\nHere's why I use ORMs.  I've never seen a clean answer in raw SQL that solves this real-world problem efficiently:\n\nYou have 5 tables in 3NF: User, UserOrganizations, Organizations, and UserOrganizationRoles.  You have millions of users and thousands of organizations, with tens of millions of UserOrganizations.  Each UserOrganization (many-to-many table) has 1 or more Roles.  You're building a GraphQL route to list users (every field exposable), and the route can optionally request some or all fields.  Expected return does not include pagination, but a numeric majority of requests will only return `user.email` (second most being `user.organization.name`). Filters may or may not require joined data.  For example \"isAdmin=true\" would require the field `userOrganizationRoles.role` joined through UserOrganizations.\n\nThe challenge is to write your query efficiently but cleanly.  With most ORMs or querybuilders, this is incredibly easy.  You use a few `if` statements to build the join tree as structured objects so you only join what you need, select fields as structured objects, and then filters as structured objects.  You throw it through the ORM and you get your results as efficiently as possible and can return (or stream) to the client without post-processing.  Maybe 50 lines of code, and most stacks I've worked on have helper functions that make it far fewer.\n\nHere's the SQL solutions I've seen to this problem, and why I don't like them:\n\n1. Who needs efficiency?  Imma join everything (it's logarithmic time and ONLY 3 extraneous joins, right?) and select all the fields.  I'll just use nullable WHERE clauses `WHERE $isAdminFilter is NULL OR UserOrgRole.role='ADMIN'`.  Now I've got one big clean (SLOWER) query that I'll postprocess the hell out of in the end.  Yeah, I'm downloading 1GB of data to list 10,000 email addresses.  Bandwidth is cheap!\n2. I built my own ad-hoc ORM by creating that structured objects and then `whereQuery = whereObject.map(row =&gt; convertToWhereClause(row)).join(' AND ')` and finish up with a nice elegant `query( selectQuery + fromAndJoinQuery + whereQuery)`!\n3. My language has a backtick template operator, so fuck ya'll I'm gonna play Handlebars and have a lot of inline logic build each part of the query as one string over 500 lines.\n\nI have had to maintain all of the above in practice, and each belong in a separate layer of hell from the other.  In 20 years and about 7 languages, I've never once seen that above problem space solved elegantly, efficiently, and maintainably using raw sql.  I do it all the time with ORMs.\n\nThis is exactly it. There's a great sweet spot with ORM for simple cases that ORM is good at, and a good language-native query builder to let you dynamically build a query without doing stuff like counting args.\n\nIt's not perfect, but I think Django's ORM does a *really* good job landing in that middle ground. \\`Q\\` is pretty powerful, dropping to raw sql is not too difficult, and for your bread and butter a join or two and some simple filtering, it does a good enough job.\n\n100%.  Nobody is saying you can't/shouldn't break out when you need raw speed on a static query OR if you need to do something disgustingly complicated/specialized.  I *DO* tend to like sticking with the ORM and using views in those situations (and you can still keep the view as checked-in code via migrations), but I'm not against a compile-time-typed select query with something like pgtypted.\n\nThe anti ORM crowd doesn't want to hear this. \nIn my experience, I usually get pushback from those who simply haven't had to do more than getAll and getById queries in their clean abstracted single use \"reusable\" generic repository\n\nThe fundamental problem here is that SQL uses stringly-typed programming, and so in the middle of a modern language just looks like an embedded python script or something similarly out-of-place.\n\nORMs solve this problem... at runtime.\n\nWhich, with sufficient caching, is fine... I suppose, but it would be ever so nice if \"language integrated query\" was *actually* language integrated at the compiler level, and not just a bunch of libraries that do the string templating at runtime through torturous abstractions.\n\nA pet peeve of mine is that \"SELECT\" results in unspeakable typenames. Sure, some libraries can paper over this, and dynamic languages can handle it reasonably well, but statically typed languages like C# can't in general.\n\nI've read some interesting papers about progress in this space. In most programming languages we have 'product' types (structs, records, or classes) and some languages like Rust have 'sum' types (discriminated unions). The next step up is to add 'division' and 'substraction' to complete the type algebra! A division on a type is the same thing as SELECT: removing fields from a struct to make a new type that is a subset of it. Similarly, substraction from a union removes some of the alternatives.\n\nOne day, these concepts will be properly unified into a new language that treats database queries uniformly with the rest of the language and we'll all look back on this era and recoil in horror.\n\n&gt; ORMs solve this problem... at runtime.\n\nPrisma has a compile-time solve for this now that I like the IDEA of... but the *real* best usecase of ORMs involves queries that would be necessarily built at runtime no matter what.  Because yes, when a clean static query like `SELECT email FROM users WHERE id={1}` is the right answer, raw SQL is always technically faster than an ORM.\n\n&gt; I suppose, but it would be ever so nice if \"language integrated query\" was actually language integrated at the compiler level, and not just a bunch of libraries that do the string templating at runtime through torturous abstractions.... A pet peeve of mine is that \"SELECT\" results in unspeakable typenames\n\nYeah, definitely one of the unsung upsides of Typescript.  When your (so-called) type system is Turing Complete, you can do things like this.  Build-time errors if you query the wrong table, compile-time type assertions of the query results, etc (as long as you strictly follow Typescript's rules. If you break ONE rule, you have dirty data).  Libraries like pgtyped (or now Prisma) will create type signatures out of SQL files so you can strongly type a SELECT query... just not an inline one.\n\n&gt; The next step up is to add 'division' and 'substraction' to complete the type algebra! A division on a type is the same thing as SELECT: removing fields from a struct to make a new type that is a subset of it\n\nTypescript has an `Omit` type (for your subtract).  Your version of \"division\" is explicit narrowing and Typescript can duck-type to a narrower type.  I've been learning a *little* Rust, and it feels like some of its type handling is borrowing from Rust (Rust's big win is trying to take the best feature from every language it can find...it has near-Lisp-style macros FFS!)\n\n&gt; One day, these concepts will be properly unified into a new language that treats database queries uniformly with the rest of the language and we'll all look back on this era and recoil in horror.\n\nPeople have tried this to mixed results.  MongoDB's BSON format integrates very cleanly with any language that does well with JSON and it's pretty easy to find/get typed data/responses.  The problem is that SQL IS JUST A VERY WELL-DESIGNED LANGUAGE with mediocre syntax and a complete lack of foresight to the integration problem.\n\nI feel you, even though I haven't yet had to dive into GraphQL..\n\nYour scenario is simple yet sufficiently complex that I would love to see a sample repo that puts it together in C#.\n\nThere's a decent blog post/Medium article/LinkedIn post/whatever hiding in your comment.\n\nI've got like 5 contentious articles I've wanted to blog about for the last decade, and SQL vs ORMs is near the top of my list.  My lazy ass just can't get into blogging (and I refuse to GPT-drive it)\n\nAs I understand most ORMs, such as hibernate, retrieving the objects, such as user, and the many-to-many relations they contain will require more than 1 query to the db.  Is that not so?\n\nSometimes, yes.  This has been a sticking point for a few of the largest ORMs, and some of the scrappier ORMs advertise that they only ever do JOINs.  Apparently, the process of building out nested objects from nested queries can hypothetically be slower than just querying for each relationship, indexing in code, and joining by hand.  I've actually stumbled upon raw SQL code in the past where single queries were split up because it was shown to be faster in the end than one-query implementations of the same.  NOT saying this would be a general case.\n\nThat said, prisma recently changed their default behavior from `multiple-query` to `join` for nested queries, but with the footnote that you should benchmark both ways since sometimes they can make multiple-query just faster.\n\nOf note, **you will never get the same throughput for a trivial query with an ORM as you get with raw SQL**.  Sometimes this justifies SQL, and sometimes the speed tradeoff is the same as using HTTP requests for IPC over hand-writing your socket interactions.  If your code isn't in C or C++, maybe you've already committed to a few speed trade-offs for better DX and maintainabiilty anyway.\n\n&gt; You have 5 tables in 3NF: User, UserOrganizations, Organizations, and UserOrganizationRoles.\n\nWhy do I feel like I'm being interrogated by a Cardassian right now?\n\nThere are better ways to handle SQL, but I doubt ORMs are an effective or portable replacement for SQL.\n\n[removed]\n\nYou don't need an ORM to have type safety. I'm using raw SQL prepared queries and they're type safe.\n\nSure, if you're using string building or interpolation for your query parameters, you lose type safety, but you shouldn't be doing that in the first place.\n\nNot suggesting writing raw SQL, quite the contrary, I think some type-safe wrapper is a great idea, in addition to prepared statements. The trouble is an ORM, at least in a traditional sense, isn't exactly that, unless you stretch it to include such abstractions. An ORM normally attempts to remove SQL altogether and replace it with normal objects. It is a theoretical possibility, but I believe that in practice you can't do much efficiently without using the actual flavor of SQL your database supports and ORMs end up doing a lot of bookkeeping and catering to the least common denominator. Things can vary a lot. This is also why I also tell people to just pick a DB and stick with it rather than try to support everything.\n\nNot sure if my comment went through or not, sorry if this is a double.\n\nYou can absolutely have type safety without an ORM. You just need to use prepared queries. Which you should be using if at all possible, regardless of ORM vs raw SQL.\n\nNot using prepared queries is how you end up with SQL injection.\n\nAll of that is great and not what I perceive as having anything to do with the issue of ORMs.\n\nThe problem with many ORMs is they ask you to create a mapping of OO Types to database *Tables*.  That's the problem right there, because OO structure and Relational Structure are not the same and one should not be defined in terms of the other.  \n\nBut, that's what we do, and most often, it's the relational side that bows to the object side, to the detriment of the database.\n\nI'm all in favor of ORMs that map OO types to *queries* though.\n\n[deleted]\n\nNot exactly. JS actually is one of the better performing languages out there. V8 is insanely optimized. It's not the fastest but if you look at the benchmarks, I'd bet it would surprise you.\n\nNow it wouldn't be my first choice but if you had a team of JS devs, there might be upfront savings so they don't have to learn a new language.\n\nI don't think performance is the reason not to use node.js, it's the dependency explosion and shonky weak typing. Using it was typescript is a good idea I think but it doesn't prevent the dependency problems.\n\nFast != better, that's like the whole point of this post.\n\nPeople defending JavaScript/NodeJS in your replies are insane man. \n\n.NET is also a full framework, not just a runtime.\n\nStd lib in .NET and Golang are good enough to build a natively high performance app.\n\n^ Didn't even read the title of the article lol\n\nWe had a guy who fancied himself an architect and insisted instead of using a BASIC DATABASE ROLE SYSTEM used everywhere forever‚Ä¶ he put in hardcoded ‚Äúroles‚Äù based on bit values like a fucking psycho\n\n&gt;and JavaScript on the backend\n\nI feel like Javascript's the pineapple of the backend pizzeria, it doesn't belong there, but I'm sure its amazing in the juice bar\n\nI agree with using the .net language of choice (c#?) instead of js. But raw sql is better than orms. No reason for it to be difficult to maintain unless you don't have people there who are good at writing it.\n\n.NET with Dapper was my bread and butter for years. I'm not working with it these days, but it's a solid DX!\n\nThere's absolutely no reason to not use EF Core for 99% of apps.  It's strictly better than raw SQL most of the time.\n\nRule #1: don't work for an incompetent architect.\n\n&gt;Building infrastructure for scale means investing in servers, databases, and **cloud services** that you don‚Äôt really need yet.\n\n&gt;The good news is that scaling isn‚Äôt as hard as it used to be. Cloud platforms like AWS, Google Cloud, and Microsoft Azure make it easier than ever to add resources when you need them.¬†\n\nWhich is it? I think the author needs to be more specific - this article feels like blogspam because its so light on details. What infrastructure is wasted? What cloud services don't you need? What examples can be provided of where this has gone wrong in the author's experience ... I learned nothing reading this\n\n&gt; What cloud services don't you need?\n\nI don't know what the author meant, but in my experience, if you're building something that will be used by 30-50 users, most cloud services can be replaced by a single EC2 instance that you can customize to your needs. API Gateway can be replaced with a local nginx, RDS can be replaced with a local db, S3 can be replaced with local EC2 storage if you're not doing heavy lifting. The hardest part with a product IMO is going 0 to 1, scaling from 1 to 100 is pretty straightforward\n\n[deleted]\n\nu/Hopeful-Distance-525\n\n[deleted]\n\nLinkedIn slop for developers\n\nI mean, conceivably it could be about avoiding overprovisioning not just not using cloud services.\n\nYou can create an app that can scale for millions of users without needing to put up all the architecture for millions of users. I see many successful startups using single docker nodes for quite some time or a super simple/tiny kubernetes cluster. Once they become popular at least they didn't need to rewrite half their code base. A good plan on software architecture can save or brake companies.\n\nIt's absolutely doable, but there's a cost (and sometimes luck) involved in having talent that knows how to do this. There are very few engineers that are capable of writing code that is both fast to deliver and easy to scale/upgrade when the time comes.\n\nReversible decisions, and scaffolded solutions. They don‚Äôt teach it in school and I don‚Äôt think I‚Äôm aware of any books that do. If I were asked to start a curriculum though I might start first semester with Refactoring by Fowler. That‚Äôs foundational to the rest, especially in getting people used to looking at code and thinking what the next evolutions(s) should be.\n\nWhat else would be the on curriculum?\n\nOne of the big lessons that gelled for me after my first large scale project was make the cache control headers count, and do it early. \n\nDon‚Äôt start the project with a bunch of caching layers, but if your REST endpoints and http responses can‚Äôt even reason about whether anyone upstream can cache the reply and for how long, your goose is already cooked.\n\nIt doesn‚Äôt have to be bug free, it just has to be baked into the design. \n\nWeb browsers have caches in them. That‚Äôs a caching layer you build out just by attracting customers. And the caching bugs show up for a few people instead of the entire audience. They can be fixed as you go.\n\nThen later when you start getting popular you can either deploy HTTP caches or CDN caches, or move the data that generated the responses into KV stores/caches (if the inputs aren‚Äôt cacheable then the outputs aren‚Äôt either) as they make sense. \n\nWhat I‚Äôve seen too often is systems where caching is baked into the architecture farther down, and begins to look like global shared state instead. Functions start assuming that there‚Äôs a cheap way to look up the data out of band and the caching becomes the architecture instead of just enabling it. Testing gets convoluted, unit tests aren‚Äôt,  because they‚Äôre riddled with fakes, and performance analysis gets crippled.  \n\nAll the problems of global shared state with respect to team growth and velocity show up in bottom-up caching. But not with top-down caching.\n\nWe literally host everything on one bare metal machine and only dockerize now that we have a need for quick feature branch deployments. But we're also in a small industry (like, small in terms of companies. They move a shitload of money but there are only a few key players).\n\nThere will be other reasons why they would want to rewrite some of their code base, its going to happen anyway.\n\nThat‚Äôs really not the point of using some of this tech.  The most harmful event in an engineering org‚Äôs existence is getting some investors and being forced to go into a period of hyper growth before they are ready.  This often ends up looking like a pile of cash being set on fire and all of the software having to be rewritten after the hyper growth, after the glut of coders who wrote it had been laid off, and profitability suddenly becomes important.\n\nI had a manager come tell me excitedly that we landed a big customer. He didn‚Äôt seem to like my response, which started with saying, ‚ÄúFuck me!‚Äù Really loud. \n\nMonths of bad decisions followed.\n\nYour first two or three bug customers can be just as bad as VC to your architecture. You can end up pivoting the product to support them, their problems and their processes, not what 90% of the industry needs. And because they were first, the contracts were mispriced and the company cannot sustain itself on just making the product for those three customers.\n\nI ran an API that served 300-400k requests a day on a single $10 digital ocean droplet.\n\nToo many people over engineer dev.\n\nThat‚Äôs three requests per second, not really surprising\n\nIt sounds like a lot though. Managers go nuts for big numbers.\n\nIt obviously wasn't uniform. \nMostly North america, so packed into a 8-hour period, with moments of burst. \n\nAnywhere from 500 to 10,000 requests a second iirc.\n\nNever went down once.\n\nWhat did you use?  \nTech stack etc.\n\nWas just an express API on pm2\n\nAnything. That's 5 requests per second, max.\n\nI once had a discussion with a devops/engineer manager about that \n\n\nHe wanted us to break our monolith into microservices to be able to scale one heavy feature in case it was being used by 10k users at the same time next year.\nMind you, we had tons of features to do it for an incoming release to launch to our first external client ü§°\n\n\nIt was a B2B SaaS. It took months to find the first client. It would take some time for the others as well. No way in hell we would have 10k users in a year. \n\n\nI said that it didn't need that, that we could scale just fine with a monolith, and that adding microservices only adds overhead to me and the only developer. \n\n\nHe got really defensive, we discussed more, and I was fired 2 weeks after. The project closed 4 months after that, so it didn't reach 10k users\n\nTo this day nobody has successfully explained to me how microservices helps to scale one particular feature. If I have a monolithic application with 5 features, and they all need 4 instances to handle the load, then if one feature gets 10x more adoption, I simply have 56 instances running now instead of 20. It doesn‚Äôt make a difference if the whole application is deployed together or as microservices, the same amount of compute is needed.\n\nThere are subtle effects that come into play *at huge scales*. Think 100+ servers, but really more like at the 1K to 100K levels.\n\nOff the top of my head:\n\nCache thrashing -- if you're running a tiny bit of code on a CPU core, it'll stay in L1 or L2 cache at worst, running at 100% performance. If you blend dozens of services together, they'll fight over caches as small as 32KB and the per-service throughput will drop. Google's internal equivalent of Kubernetes does a fancy thing where it'll *reserve* slices of the CPU caches for high-priority processes, but pretty much noone else does this.\n\nApp-specific server tuning -- Google and the like go as far as custom Linux kernels tuned for one specific service. Netflix uses a highly tuned BSD with kernel-mode TLS offload (kTLS) for 200 Gbps streaming of movies. It's not practical to have a single VM run a bunch of generic workloads when they're this highly specialised to squeeze out the last 5% of performance possible.\n\nNetwork bottlenecks -- at large scales you end up with issues like multiplexing/demultiplexing. E.g.: Load balancers may accept 100K client connections and mux them into only 1-10 streams going to each server. This can cause head-of-line blocking if you mix tiny RPC calls with long-running file uploads or whatever. Similarly, you can reach maximums on load balancers like max concurrent connections or max connections per second. All the FAANG sites use many different DNS domains sending traffic to many different load balancers, each with completely independent pools of servers behind them.\n\nStateful vs stateless -- services that are \"pure functional\" and don't hold on to any kind of state (not even caches) can be deployed to ephemeral instances, spot priced instances, or *whatever* because they can come and go at any time. Compare that to heavyweight Java apps that take 10+ minutes to start and cache gigabytes of data before they're useful. Worse still are things like Blazor, which need a live circuit to specific servers. Similarly, consider the file upload scenario -- these can run for *hours* and shouldn't be interrupted, unlike normal web traffic that runs for milliseconds per response. I've seen auto-scaling systems get stuck for half a day and unable to scale in because of one lingering connection. Splitting these types of services out solves this issue.\n\nSecurity boundaries -- you may not trust all of your developers equally, or you might be concerned about attacks that can cross even virtual machine boundaries such as the Spectre and related attacks.\n\nData locality -- you may not be able to synchronously replicate certain data (bank accounts), but other data can be globally distributed (cat pictures). The associated servers should be deployed close to their data. You may also have regional restrictions for legal reasons and have to co-locate some servers with some data for some customers. Breaking up the app makes this more flexible.\n\nEtc...\n\nNone of these matter at small scales.\n\nFacebook and the like care *deeply* about these issues however, and then people just copy them like parrots because \"It must be a best practice if a FAANG does it.\"\n\nIt can make running all those instances more expensive, and microservices also are usually deployed to lambda and size is related to cold starts. Also, occasionally, you might need a singleton and there are issues with all the instances in the monolith assuming they are single instances.\n\nThat said. I generally agree. Solve for the exceptions when when they become relevant.\n\nEven 10k simultaneous userS doesn't requires micro services in most cases ....\nIt just requires you not writing code that are io intensive, like doing 200 SQL queries to update 200 entries's single field to the same value ...\n\nI worked with a bunch of people who‚Äôd been at an old school SaaS company for too long and convinced themselves that 1000 req/s was an impressive web presence. But it really isn‚Äôt. It‚Äôs good, no question, but it‚Äôs not impressive. Especially when you find out how much hardware they used to do it. Woof. \n\nAnd too much of that was SEO related - bot traffic. Not our customer‚Äôs customers making them money.\n\nI think this is in some part a Second System Syndrome problem.\n\nWe don‚Äôt have ways to teach people to build a system with room for growth. When we know nothing we hear ‚Äúdesign a system with growth in mind‚Äù and think overengineering is the solution. When what is really meant is building the system where the parts that don‚Äôt scale can be treated as scaffolding and replaced without having to redesign the entire architecture. \n\nIf you design eight or ten systems in a career and the first two are garbage and the third one is merely passable, that‚Äôs not a very good ratio. We could probably do better.\n\nThis article seems dated to me. Nothing forces you to overprovision early, but ensuring your design can scale by adding more nodes ( horizontally ) is crucial and if you suddenly get bunch of users and you have only one big server model, you are not in for a good time.\n\nIt's so incredibly unlikely that you're just going to get a massive weight of users. \n\nYou build up to it slowly.\n\nHowever, it's far more likely that you fail early by missing the mark because you spent too much time on design and architecture and not enough time iterating product market fit.\n\nCertainly. But you can avoid a lot of rework if you eg avoid global state as much as possible and try to ensure that you can just stick in more workers / shard database / add different regions without significant refactoring. I have been in scaleups where we spent quite a lot of time working on this when the usage started to grow, and with somewhat better initial design it would have been avoidable. \n\nKeeping the goal in mind is different from starting with a monster micro service hell with n repositories :) ( I would argue that single repository is enough for most companies period, and the more services you have the more your foot will hurt after the footguns in keeping their behavior in sync )\n\nI remember the time everyone was trying to get NoSQL on their resume. Problems you could easily solve with a MySQL on a single core VM started to be wedged into MongoDB clusters.\n\nI have to disagree, sure, you dont really need the infrastructure, but a good code and ESPECIALLY DB design isnt that much more of a hustle and it pays extremely good dividends, because migration is a major pain in the butt and having to rewrite it sometimes in the future just because you wanted to deliver the product 10% faster is a big money pit.\n\n\nSo design and write it that it can scale and just deploy it on a single server with a backup server if something fails and just scale the infra when needed. (thats what we did)\n\nYES!  Every time I see some BS flame war about \"This framework is soooo slow, so many performance problems\" for a project that has a whole 0 users I bring this up.  When choosing tech for a new project that hasn't brought on any traffic yet you should always go with what's easiest for the team to use instead of worrying about scaling to millions of QPS\n\nMy boss decided we are gonna completely redesign it for a client who isn't even paying for it yet. \n\nBecause they *might* pay for it. \n\nWe have existing users.\n\nMy small business's website doesn't even implement JavaScript. Its LCP is one second and has great SEO metrics.\n\nMVP... MINIMUM VIABLE PRODUCT. \n\nIt needs to be all three of those things.\n\nI had a temporary CTO who insisted that everything we used had to use open source for every tool to avoid vendor lock in, and that we should be running everything through cloud flare and digital ocean instead of using anything like Azure.\n\nSuper opinionated about these choices, and always used the argument of being able to handle millions of users. We did, in fact, after 6 months have no users and no MVP. What we did have was a collection of tools and repos spread out to be \"the most efficient\", but was so much overhead to maintain, that we spent more time hunting down obscure breaks in the whole thing than shipping anything new.\n\n&gt; I had a temporary CTO who insisted that everything we used had to use open source for every tool to avoid vendor lock in\n\nYou can still get vendor lock in. Particularly if you use frameworks over libraries. \n\nA lot of advice you get from midseason engineers is about trauma from previous projects. How hard it was to change something -&gt; do it right the first time.\n\n&gt; overhead to maintain\n\nWhy on Earth would you spend your time on maintaining anything?!  \nChoose one LTS version for every open source tool, download and build it and forget about its updates (aside from security ones) till you get your users and MVP.\n\nThe SLA on my homelab i7 box exceeds most global services including m365. It's been down less than 45 minutes in the past year.\n\nThat's a gross oversimplification of what uptime represents, but also in some ways, it actually isn't. A box that does what it does and has pretty good redundancies making it work is the epitome of KISS (Keep It Simple Stupid)\n\nWhat OS are ya running?\n\nFedora core OS as a docker host. Getting the initial installation to work with butane/ignition was a pain, but it's been bulletproof since.\n\nSure, but make sure you actually have the capability to extend it when needed.\n\nBuilding for 100 users instead of 1,000,000 is fine, but don't have it fall over when you get 1,000.\n\nDon‚Äôt tell me what to do\n\nfine, sqlite with shell scripts\n\nA place I worked at had a website that was used by maximum 200 field engineers. Other than hirings/firings this number was unlikely to change. I think once they brought on about 50 extra engineers at once. Big spike. You would not believe the amount of microservicing and load balancing we did for when that number hit 10 million.\n\nidk i built a web app to scale with about the same kind of logic it would take to build it without scaling. we have tools these days that abstract the scaling away and u can just focus on app dev.\n\nThis reminds me of a few die hard friends I had that insisted on developing their game engine from scratch.\n\nI kept asking why, and explaining you could develop this entire game in 20% of the time if you just used any of the freemium game engines (Unity / godot / game maker / etc.)\n\n\"Nah, that's the cheap way out. You can do that... if you need to\"\n\nYes and when you do get to millions of users you can hire somebody else to scale it.\n\nPeople make this point all the time but it‚Äôs actually stupid. If your company can‚Äôt survive with 100 users and that‚Äôs what you built your stack to support then you don‚Äôt have a functional business. \n\nAlso most tech stacks will support way more than 100 users out the box with no real optimisation\n\nDoes anyone read these types of articles!? like is there a market for this knowledge?\n\nThe beginning of an app is a fairly important time when it comes to determining how maintainable and expandable you want it to be. While you shouldn't design your app like you have a million users while you have 100, you also shouldn't design it like it has 100 users either. You need to find a balance that can leverage your experience without approaching every problem like a green novice too scared to push the \"Any\" key.\n\nMost of the time \"designing for now\" means discarding a whole lot of ideas and plans that **might** be useful in the future. As the article points out, you usually don't know specifically what you and your users will want, therefore many decisions you might make could end up costing you. On the other hand, you're ostensibly an experienced professional that's put in the effort to understand the problem domain, the stakeholders, and the desired functionality. You might not understand the full scope of the product yet, but there's a good chance that you understand it far better than most. \n\nIf you constantly question yourself and stick to the safest, most conservative plans, then all of your products will likely be chock full of the most basic, uninspired, and trivial to replicate functionality. It means putting off difficult questions until such a time that solving them is a critical emergency, which is usually when it's most difficult to do anything about them.\n\nWhen it comes to scaling infrastructure, you don't need to start off with dozens of servers, DBs, and load balancers. You just need a straight-forward way to ensure that if you do need that degree of capacity the route to get there is already planned out so it can be done quickly, without hiring super expensive consultants to do it all for you for large sums. While we all appreciate the work, I don't think I'm being too unfair when I say most of us would prefer to work on cleaner projects, than to attempt to shovel the muck and grime that a bunch of \"speed\" and \"flexibility\" devs left over a few years.\n\nSure, cloud services can make this easier, but you're not going to go in and make your buggy, slow, unreliable web of services ultra-scaleable at the drop of a hat, especially if you don't pay it any mind during design and implementation. Such a project can easily take weeks, months, or even longer. I still remember early COVID as various government entities tried and failed to get such systems up quickly.\n\nAlso, if you built a system in which even small changes become a headache, you haven't actually built a good scaleable system. Instead you've probably hacked together a bunch of quick fixes to avoid \"over engineering,\" ending up with a nightmare of spaghetti code full of unnecessary complexity that doesn't actually help. A well designed, large, complex system is usually one with very clear separation of concerns and responsibilities, allowing for a clear path to any change you might reasonably want. It's a system with a clear, and most importantly, realistic plan. One that gives you a clear path forward, with realistic growth potential. In such a system it should honestly be easier to implement many features, because it should be clear where and how that feature should slot in.\n\nIn the end it's like any other role in the company. When it comes to non-technical staff, we have people doing sales, and we have people doing client support. Very few people would recommend having only sales people, and putting off things like customer support until you have millions of customers. Sure, you probably don't need to bring on a team of 20 support staff before you get your client, but even if you're just starting out you should probably have a support plan, and someone that can handle the role. Devops is quite similar. It's a need that grows and develops over time, and it's a need that can be extremely sensitive to initial conditions.\n\nSo, no, build for the present and for the future. You're going to be living in both eventually, and setting yourself up for failure by completely avoiding thinking about these challenges is a bad strategy. Instead, set your expectations for the future a bit lower. Don't dream of the successes, but instead try to plan around the failures.\n\nOf course don't go over-board. Obviously if you spend a year doing only devops while not doing any product development, you're not going to get anywhere. At the same time if you spend a year explicitly *not* doing devops you might feel like you're going faster at first, only to very quickly run out of steam, and right into a deadly swamp.\n\nIt was funny recent Levelsio interview triggered so many because he only works with PHP and jquery.\n\nBut... scalability means I have to built it for 10000x the expected amount of users... now!\n\nIf we need to incurr today the cost of a company with 10000x the user-base, so be it.\n\nNot bad advice but most applications you can do a little bit of thought ahead of time and save a lot of headache later.  The fad of making everything a microservice is definitely something to avoid until it absolutely makes sense.  \n\nMost web apps don't rely on shared memory across processes so it's really easy to scale to millions of users by using a virtual file system and shared database.  If you take the time to think about how your application manages state then down the line it can be easy to scale, or at least you will be aware of the issues.  OP says scaling is \"easier than you think\" but depending on how state is handled it could involve a total refactor of the code, I have seen that before.\n\nI have tried all different approaches but right now I build monoliths with shared db, message queue and virtual filesystem.  This is all abstracted by the framework I use so is no extra work overhead for me as I understand it.  If I ever need to scale past a single node I just run multiple copies.  If I need to share memory across requests then I have to do a little bit of load balancer setup to make sure people stick to a specific node but that's not usually required.\n\nBefore I had actually scaled a few systems though I didn't really understand it properly, so if you are unsure about scaling just follow OPs advice and worry about it when it's an issue.  Once you get your own system worked out it wont be much overhead to build things scalable from day 1 if you are doing it right.\n\nLalalalalalala I can't hear you\n\ndon't tell me what to do\n\nStop building your web applications so they feel like they serve millions of requests when they serve just 100?\n\nHow is it not opposite of clean architecture which says write code that is maintainable and scalable?\n\nThe problem is that, when you are made redundant and you have to find another job, the new position will ask you if you have experience developing web applications for millions of users, and if you didn't build that experience, you won't find a job."
  },
  {
    "title": "After 3 Years, I Failed. Here's All My Startup's Code.",
    "body": "",
    "score": 2181,
    "url": "",
    "created_utc": 1734438793.0,
    "author": "_srbhr_",
    "permalink": "/r/programming/comments/1hg9mu3/after_3_years_i_failed_heres_all_my_startups_code/",
    "all_comment_text": "You mentioned you were going for hyper-growth and making decisions to try to force the company to be a big business with the potential AI pivot. Maybe that's the mindset you need when taking in outside VC, but it sort of feels like you're shooting for win big or fail fast.\n\nNot just this, but I'm not really sure why they thought this was some potential for huge growth unless they were just hoping AI would carry it.\n\nI've worked at my current job for 10 years and implemented probably dozens of API integrations with third parties. Absolutely none of them have ever handed us a set of OpenAPI standards. Most of the time it's either a poorly thought out CSV \"schema\", WCF service, or poorly thought out REST APIs. I already use ChatGPT to help reduce the tediousness in integrating with these where possible, anything beyond what I'm already doing would probably be too complicated for a generic AI product to do.\n\nAs a developer anyways, I just don't really see a market for what this appears to be. At least not \"We're going for hyper-growth\" levels of market.\n\nYou guys get API documentation?¬†\n\nSwagger isn't just the name of my deodorant\n\nThat's Stagger\n\nUnderrated comment\n\nI am the API documentation!!!\n\nildasm is your documentation!\n\nSo true\n\nThe last company I worked for, we had to connect through a 3rd party API. That company had great documentation, but in practice extremely limited. Read like we could grab the data we needed and construct it on our page however we wanted...Nope, no modals were allowed (depending on the user they didn't need/want to see everything in the data returned). Required a very obnoxious authentication process. Couldn't pass an auth token if the user was already logged in to the 3rd party site required them to redirect to the 3rd party login page then navigate back to our own site. The goal was to build a good UX experience using the data, but with how limited it was, we just ended up loading the full report in our own site and said f\\*\\*\\* it. I'm only 3 years in and i'm sure it gets much worse depending on what the company is trying to do, but damn that was a waste of a spike and some time.\n\nSure. Visual Studio autocomplete.\n\nIf you can find it yourself on the open internet sure other than that, well, you're on your own.\n\nWe provide an openapi spec for our platform, but we've definitely received a pdf of endpoints before as documentation and then you have to get the real request response models via test calls from postman. \n\nI find the most value I get from being given the spec is being able to easily generate request and response classes. The all-in-one sdk generators seem nice at first, but often you have custom logging and error handling needs that require you to essentially not use the sdk except for the models anyways.\n\nYeah 100%. Especially on the custom logging and error handling. Because of how unreliable a lot of them have been, and how hostile to owning the problem some of these third parties have been, I've resorted to logging *everything* with customized filters to strip out any sensitive data (like auth tokens) that I test with each API. That way we can help debug it, but also just so I have the receipts to prove I'm not doing something weird.\n\nThis is why for the most part I just generate the data models in C# using ChatGPT, double check them / tweak as needed, and then I use those data models in my custom client. It takes the majority of the tedious code out of it leaving me more time to work on the actual client and the rest of the application. That's about the extent I would involve AI though.\n\n&gt; We provide an openapi spec for our platform, but we've definitely received a pdf of endpoints before as documentation and then you have to get the real request response models via test calls from postman. \n\nYeah same here. I've even received 4 different CSV \"schemas\" outlining the same data export, and none of them were right. After a day of fiddling with it, I finally figured out which combination of these 4 CSV \"schemas\" it was. And I've gotten the PDFs which are out of date or just flat out wrong. I've had them list certain fields as \"internal use only, ignore\", only to ignore it and then find out in the middle of writing it all that it's the only way to link two pieces of data together so we can't ignore it.\n\nIn the real world it's a mess, and I can't see a generic AI tool being able to do it unless it could also fully replace us.\n\n&gt; 've had them list certain fields as \"internal use only, ignore\", only to ignore it and then find out in the middle of writing it all that it's the only way to link two pieces of data together so we can't ignore it.\n\nAh, you have lSelectionID in your life too, I see.\n\nlol, I hadn't seen `ISelectionID`, but I did have `module_gid`\n\nThe column ID can change names but hidden join columns are forever\n\nJust 3 weeks ago i got a set of API specs from a giant company in the accounting space (who shall not be named) and suprise suprise, after making test calls from postman, the returned objects were NOTHING like their documentation.  I ended up writing my own translator from their actual objects to their specs so I could know what was what.  The SDK models were absolutely worthless.  I often wonder who are these people that write this stuff, screw up the documentation so bad, and then wonder why their tech support and account managers have to answer the same questions over and over again bothering the engineers non stop.\n\n&gt; I often wonder who are these people that write this stuff, screw up the documentation so bad, and then wonder why their tech support and account managers have to answer the same questions over and over again bothering the engineers non stop.\n\nIn reality, it's likely that someone wrote the docs five years ago when things worked completely differently and a series of \"just make this quick change\"s and a few maintainers later and things look nothing like the docs (and the current maintainer might not be aware that docs ever existed).\n\nSounds like sage..\n\n;)\n\nIs that why you need a certification to connect to their API?\n\nOh shit really? Is that actually a thing they do?\n\nI didn‚Äôt get that memo, and they were fairly eager to give us documentation. But got rather mum when I asked why everything was just completely different.\n\n\nTo be fair to them, the answer is that they, like salesforce, have 3rd party integrators do most of the onboarding and bullshit. And their api isn‚Äôt wrong, it‚Äôs just so flexible that whatever the consultant does, is now just the valid approach.\n\nNot something I particularly care for when doing accounting‚Ä¶\n\nI was told that by a 3rd party integrator, but I'm perfectly happy to provide the API endpoints and let them deal with _my_ shitty documentation.\n\nYeah it's a mess. I work in trucking and I had to integrate with our telematics provider to get hours of service (among other things.) Let me tell you the docs were *awful*. It took me probably 3 months of testing to work out most of the kinks with it. The docs don't cover most of the stuff that can happen. I think the hours of service import is probably my most documented application here because I essentially had to \"reverse engineer\" how their APIs worked and figure out all the edge cases myself.\n\nIt's even worse now. This company keeps getting flipped between different VC firms, and it flipped again not too long ago. Since it flipped all of the documentation that was at least somewhat useful to get started has been moved into some new knowledge base. I'd be lucky if I could even find the relevant stuff now.\n\n&gt;  I often wonder who are these people that write this stuff, screw up the documentation so bad, and then wonder why their tech support and account managers have to answer the same questions over and over again bothering the engineers non stop.\n\nAs someone else said I think it's just stuff doesn't get updated. I also think some of it, sometimes, is sales just not keeping their shit straight. I've had a sales rep send me 4 different CSV schemas with examples for me to export data to them, none of them were right. The correct version ended up being a combination of them that they left me to figure out. I think the proper schema exists, and sales just couldn't bother finding it.\n\nThats just it though, sales and support have to get tired of answering questions from devs trying to use these APIs.  Like I know we can't be the only customer hounding them for answers non-stop.  We customers have deadlines to meet with these critical integrations, and I have to think they get these same questions and issues, week after week, day after day with each new account.  You would think after like customer 2-3 they would update the documentation instead of spending every day answering them.   \nMay the Bit lord help you if your company buys the product through a 3rd party seller (sales accounts) cause then you are really fucked trying to get answers since you don't have direct access to the main company.  Trial and error and prototyping iterations become the only way and it takes way longer than deadlines allow.\n\nApple gives you PDFs\n\nNot having OpenAPI standards seems crazy for a SAAS company, you can generate them automatically with many modern backend frameworks\n\nassuming you know how to generate them and are using a modern backend, let alone using a framework at all\n\nYeah, in the industry I'm in a lot of the companies were old 15 years +, but still somewhat small. So what's a modern backend lol\n\ni think its what the kids call \"gyatt\"\n\nNew doesn't mean better though.\n\nBiggest mistake I've seen so far was building a whole enterprise application with GraphQL APIs only because they got so hyped with graphQL üòÇ\n\nDon't get me wrong graphql can be nice but having graphql everywhere is a nightmare. Not a single contract available ... wherever you try to get data you end up with custom serialization to have objects instead of plain json. \n\nAnd to make things even better even inter service communication runs through graphql, congrats.\n\nThey are still wondering why their backend is so slow üòÇ Couldn't convince them to switch to grpc with some actual contracts using DTOs in between.\n\nAnd yet...\n\nOpenAPI sucks.\n\nI‚Äôm still working on an integration right now that provided an OpenAPI spec. It‚Äôs wrong, but they provided it‚Ä¶\n\nHow do you use chatgpt for that? I am relatively new at this job and I have been assigned the task to integrate with a third party with a scrappy documentation, full of even syntactic and grammar mistakes, clearly written in a rush. I thought that chatgpt would be an aid, but I am not sure how\n\nWhat I try to do is follow a few rules:\n\n- Be specific with what you want, maybe even a bit verbose.\n\n- You can iterate on the results with ChatGPT as well. Something not quite right? Want it to add something else? Or just want to break the problem up into multiple stages? You can do it iteratively.\n\n- It might sound silly but sometimes I've had telling it to ask me for 5 clarifying questions to provide better results\n\n- And don't be afraid to give it some examples if you have some and can provide them\n\n- Don't have it try to do too much at once\n\n- Essentially I find that treating it like you're explaining to a junior dev or student what you want them to do tends to work best. Being specific, clearly explaining what you want it to do, try to think of edge weird edge cases it may run into and tell it what to do, etc\n\nMost of this you can get a feel for, such as what these tools will be able to realistically do, and what they can't. For instance if I need to ask it something obscure about our IBM iSeries DB2 database that we pull data from, I'm fairly confident it won't have a good answer, but sometimes it does.\n\nWhat I will generally do is try to give it both a screenshot of the relevant documentation, and an example of the API output. Sometimes I'll have to drop to something like postman to get the example, though be sure not to send it anything sensitive. Depending on the length, I may save the json to an \"example.json\" file (or whatever) and attach it to the message. So my message would contain the example (either attached as a json file or just pasted at the top), and a screenshot of the documentation, and a prompt such as \n\n&gt; I have attached/included an example of an API call result in json format [in example.json], as well as a screenshot of the API documentation. I want you to generate a C# data models for this result. The code should use modern C# and modern .NET, so UTF8 Json with System.Text.Json. I want you to rename the following fields as well:\n\n&gt; - api_field to MyName\n&gt; - etc\n&gt; \n&gt; I want you to default all of the string values to blank strings. \n\nThen I'll see what it spits out and ask it to change it depending on what I want. The specifics really depend on the structure of the data and the task at hand. Sometimes I'll ask it to ignore columns, sometimes I'll ask it to use my custom class that handles deserializing certain values as enums, or I'll give it elaboration on specific parts of the code, etc.\n\nLet me know if that helps or if you need anything else :)\n\nThat actually helped a lot. I will definitely give it a try. Can't thank you enough\n\nIt's no problem, glad I could help :)\n\nIf you have any questions feel free to hit me up.\n\nI work in this space and it sounds like they didn't do that much market research - there are a dozen huge enterprise offerings already that try to make API integration easier and provide all sorts of tooling. Google APIgee, MuleSoft, IBM AppConnect and API Connect, could go on and on.\n\nThey're all selling enterprise solutions to big clients, more or less, one of our biggest client bases is government. What they want is service level, 24/7 support ,etc. Basically to be able to get hold of a human being that knows the tech better than they do.\n\nI can see there's likely a gap for smaller clients to do something cheaper but they'll likely just get stuck and move on, without support.\n\nYeah I could see it. There being a market at larger scales for a more white glove service doesn't surprise me too much.\n\n&gt; I can see there's likely a gap for smaller clients to do something cheaper but they'll likely just get stuck and move on, without support.\n\nI think you're right, and I'm not sure how viable it is for someone to fill that gap. Especially like this. There are more industry specific offerings that I've seen. I work in trucking and we get approached by various vendors that offer \"any to any\" kind of integrations between trucking-specific services like various \"visibility partner\" load tracking services, EDI, etc.\n\nBut once you get out into having to do something more custom, which we do all the time, there aren't a lot of options that don't require at least having some level of technical ability to use. Reading docs, knowing how to call the APIs, knowing where to put the data, etc. It seems to me that anything that would bridge that gap would be too expensive for a lot of smaller and maybe medium companies and they'll just go without and come up with hacky solutions as a workaround. For example, there's a ton of load tracking \"visibility partners\" out there in trucking, plus tech like EDI, etc. But I just had to write something that would email a customer a list of their loads and where they are on a schedule lol. At the end of the day it's apparently not worth it to them to pay for a service and instead just have people sit in chairs periodically checking these emails.\n\nYou throw these guys potential AI offering into the mix and I could see it being a mess. People who potentially don't know any better hiring a service that uses AI to spit out API clients who won't be able to identify flaws with them. Just seems like a recipe for more problems.\n\nPretty much. I could see AI being useful if trained on the right data set to advise customers what they have, what they probably want and how to get from one to the other. Then again it's better to use an experienced human engineer to do that, at which point we're back to $$$\n\nWin big is the best case scenario. Second best is to fail fast.\n\nHaving hope in a product that should have been killed way sooner than later and artificially keeping it alive is the worst outcome when building a company. Take a shit or get off the pot essentially.\n\nWhat about winning regular? Just having a small consistent operation?\n\nOh god you think people do that? Just have regular, sustainable businesses that aren‚Äôt chasing VC hyper growth? Sounds like a myth to me!\n\nThis can be fine as long as you don't want or need venture capital money.\n\nProblem is that the tech industry has been indoctrinated in to believing that those are the only two options. That a small, sustainable business is not possible or desirable.\n\nOf course, given the current landscape of megacorps crusing the ocean looking like sharks, ready to acquire or copy any good idea, it's certainly a lot harder than it used to be.\n\nIt depends what space you are working in.  The sharks will come after you if it is a market that is set to explode, especially if they can see a forecast that is exponential for the next several years.  And they will chase that growth with lots of dollars (Go Big!) because that's one of the few ways they can continue to juice their growth numbers.\n\nBut if you are building out something that has a clear ceiling and linear growth, you don't have to worry about them.  But you still need to be able to deliver.\n\n&gt;But if you are building out something that has a clear ceiling and linear growth, you don't have to worry about them.\n\nThat's a really good point.\nAnd there's plenty of useful ideas and businesses to be had in those smaller ponds.\n\nWhat is this? The late 1900s? Get with the times skibiddy!\n\nThat's still winning big in my book. I mean a situation where it's barely sustainable for multiple years.\n\nIf it pays all the salaries, does some good in the world, helps some satisfied customers... isn't it enough?\n\nThere are a lot of companies like that. You just don't hear about them. I have plenty of friends working at companies like those.\n\nI happen to work at one :)\n\nTotally fine but don‚Äôt take any outside investments if that‚Äôs what you want to build. The deal with taking investor money is they want a rapid and significant return on their investment. That means 10x\n\n[deleted]\n\nThat's a lot of words to agree with the comment you're replying to\n\n‚ÄúTaking in outside VC‚Äù means taking investor memory and being beholden to investors. You‚Äôre agreeing with them\n\nit's like all or nothing. They don't  mind shutting you down, if they don't see the progress to avoid potential extra expenses.\n\nI could see lots of use cases for integrating LLMs into an SDK Generator.  It isn't an insane pivot, e.g. APIMatic, AutoRest but with AI generated documentation\n\nUseful? Possibly. Going \"hyper-scale\"? ...\n\nYeah, I don't even know what hyper-scale means.  100,000,000 users?\n\nI admit I didn‚Äôt read too much into detail here, but going from your pitch, what exactly did this do differently from numerous other open source tools like the OpenAPI generator which already does exactly what you describe?\n\nhttps://github.com/konfig-dev/konfig/tree/main/generator/konfig-generator-api\n\nThey put it in a convoluted wrapper.\n\nI think it's totally worthwhile to take open source tools and try to add value to them by extending them or integrating them with other tools or platforms, etc.\n\nBut this is literally just the thinnest possible wrapper around the [OpenAPI generator](https://github.com/OpenAPITools/openapi-generator) that it feels almost criminal. And besides that, what audience is this going to find? Any dev who's going to be working on integrating with different APIs which already expose an OpenAPI spec is just going to use said generator (if no client SDK is already available). They're not going to start looking for yet another intermediary that *also* need to spend time integrating *and* deal with licensing etc.\n\nAnyway, cool exercise in trying to build a business I guess, but it totally failed to answer the core questions: what is my added value, and who are my customers?\n\n&gt; this is literally just the thinnest possible wrapper around the OpenAPI generator that it feels almost criminal.\n\nWelcome to the world of entrepreneurship, friend. How about some stock for a SOTA sw engineering position for highly motivated work in a dynamic modern work environment under pressure at 60+ hours per week. We've got complementary fruits!\n\nAnd on Fridays they put out a bowl of M&amp;Ms.\n\nI didn't get the bowl of M&amp;M, just the ocasional Orange/banana ... Lucky you.\n\nWhat do those fruit complement though?\n\nI think any business that didn't fail, if it did fail, would have a perfect and confident explanation from you as to why it was always guaranteed to fail lol.\n\nYou mean a konvoluted wrapper?\n\n\nEdit: In fairness, there's a lot of products that exist because someone made a \"simplified wrapper around preexisting thing\".\n\nyeah one could argue that Terraform is just a \"wrapper\" for cloud config.\n\nhave you ever tried to wrap a cloud? It's really difficult. No matter how hard I tried, all I got was a soggy wrapper with nothing inside.\n\nKudos for Terraform for trying.\n\nThat‚Äôs really a shame as I‚Äòve had a bunch of problems in the past with openapi-generator and hoped that there would be an alternative now‚Ä¶\n\nDid you look at Kiota? It‚Äôs Microsoft own take at open api client generation. It supports less languages, but it feels more cohesive.\n\nThanks, I will take a look!\n\nIf your use case is simple, definitely give Kiota a try.\n\nFor use cases that are a bit more complex, make sure you test the output thoroughly and review the issues/limitations in the Kiota issue tracker, for example array of arrays not supported (https://github.com/microsoft/kiota/issues/5159), which \"does not provide a great experience to client applications and it's error prone\" (not something I agreed with) according to the project maintainer.\n\nMore feedback in https://www.reddit.com/r/dotnet/comments/1gvlrw0/comment/ly3mk23/?utm\\_source=share&amp;utm\\_medium=web3x&amp;utm\\_name=web3xcss&amp;utm\\_term=1&amp;utm\\_content=share\\_button.\n\nI just built a small post-run script that fixes up the openapi generator for us. Works pretty well, basically just finds all references to different objects and centralizes them into the same ref. As well as fix a couple other annoyances.\n\nMaybe do the same thing?\n\nYou have so many ways to define a spec that it's pretty normal to have problems. OpenapiGenerator has a big community around it and is very customizable. Though that mustache language is a pain to configure.\n\nThere are a bunch of new startups that got funded in this space in the last few years. E.g. [https://speakeasy.com](https://speakeasy.com) (the one I've been working on) has a very decent java generator IMO.\n\nHaha.\n\nOpen API + Moustache templates\n\nAs of 2024, using the deprecated \"openjdk\" 11 image and setting to build for Java 8 is quite a feat.\n\nActually I don't see where the additional value for the generated server was with java. The openapi generator can already do it and is also quite good.\n\nI'm sorry that after 3 years you didn't make it, but frankly, the market is pretty tough. My still favourite stays Spotlight Studio, even if they unfortunately made their tool only cloud based now and removed the source code from GitHub.\n\nThe pom goes in very convoluted way to define that it's java 8, but compiler plugin specifies 11. I suspect they went through an upgrade midway\n\nStoplight studio*\n\nI honestly see less value in these than just writing the api and generating the spec from your actual code and swagger docs plugins on the routes.\n\nThen again I usually am working with small teams that don‚Äôt have their own technical writers.\n\nMan, yea I thought I was nuts, but the whole repo is a mess. I wouldn't put my name on this publicly if I was trying to build a portfolio with it.\n\nFor a second there I almost thought they'd abused Kconfig to generate apis ü´†\n\nTbqh when i first saw it I thought it was the kubernetes CLI merge tool, Konfig.\n\nWe really are to the era of \"there's only two names left, tasticles and popplers\"\n\npfff\n\nOpenapi generator is most of the time crap because the libs are implemented by randoms that either don't care or don't know how to implement all the features of the spec. So many times I had to override some template which kind of defeats the purpose. Also often the generator is not being updated.\n\nAbsolutely agree. Many of the provided templates are pretty shitty and buggy. However I don‚Äôt see any proof that this was somehow a better product given that they explicitly just wrapped said same templates.\n\nAh no, did not mean that haha. I just meant openapi gen is all we have and its not great..\n\nThis is the usual issue with extreme prosumer products. Your core audience are the people that won't use your products. Small companies don't care about docs enough to use an external tool and \"Not invented here\" is the unofficial motto of devs.\n\nI have a marketing SaaS company that makes 8M$ yearly, hires devs and have a public API let me tell you my feedback for your next endeavour as my core business is customer acquisition.\n\n**A product will live or die by its ability to acquire customers.** Let's breakdown why it'll never have worked out.\n\n***First problem Who ?:*** Who will be willing to use your products: companies with enough devs that documentation *has* to be maintained centrally and they want a tool to ensure that  \n\\--&gt; This means at least 10-20 devs working for a company  \n\\--&gt; this means that the company is doing at least 10M$ yearly revenue, funded startups are a negligible segment in terms of size, they don't matter, if you target them then you're doomed from the get go.  \n\\--&gt; Any team smaller than that will not see the value of paying for an external tool and will \"Not invented here\" any tool coming their way.\n\nNow the objective is to share with external API consumers, meaning they are big enough yet disorganised enough that external API consumers have to rely on documentation instead of being helped by an internal dev, that aren't used by the own company because if it was, it would be better done before discovering your product therefore not needing it.\n\nThis in turns means your only possible customers are SaaS whose customers are developpers and doing at least 10M$ of yearly revenue yet have issues maintaining their docs while being their core offering. This is a very small set of companies, very small.\n\n***Second problem: lead time***: companies above a given size can't be acquired overnight, the average lead time to sale for large customers range from 12 to 24 months, at these lead times you better hope to have not only recurring but high revenue per closed deal, at least 1k$+/month per conversions on average, otherwise you're wasting your time.\n\n***Third problem: $$$:*** like demonstrated before the list of potential customers is so narrow that you can't run any ads for your business, the only way is to expensive outreach or very expensive SEO. Your only shot is to shoot a wide net and hope it catches fishes,\n\nIt'll take you thousands of $$$ to have singular companies in your pipelines while your product is barely able to sell 50$ to 100$ monthly subscriptions to them.\n\nYou'll never break even no matter how hard you try, you acquire ***very*** expensive customers and sell bread to them, you're losing tons of money on each customers.\n\n**Can you still make it ?** Yes there will be example of companies that managed despite all of the challenges, but a smart entrepreneur isn't one that gambles years of his life like that, building a company is already a big enough gamble, you don't need to also gamble on wether or not you can acquire customers, if you have millions to build 5 company then you can gamble, if you don't then you can't afford to gamble.\n\nThis is insightful. I would add that the customer acquisition strategy I have seen actually work is networking-based where you already have a customer before starting. For example I used to work at a small company selling toolkits for working with a specialized network protocol, where the founders had previously worked for a company that used said protocol, left, and licensed their product back to their former org.\n\nBasically, it's hard to make a b2b product unless you understand the business already. This is why you go work in some industry, learn it inside and out, find its inefficiencies, and then create your own company that doesn't have those inefficiencies.\n\nIt's the folly of every 22yo out of college that is like \"I don't wanna work for the man. I'm going to be successful now!\" Wanna get rich in CRE? Go work for a CRE firm. Wanna own a lot of multifamily housing? Go be some water carrier at a multifamily firm for five years and learn *everything*. Wanna build XYZ software for an industry? Go work in that industry and see what they actually need!\n\nYou're still under thirty but know how to run a business better than where you used to work.\n\n[deleted]\n\nbut then you'll never be able to date the hot chick who rejected you in high school\n\nimagine if you got the $100million, and she dates you  now after rejecting you in high school. You will forever in your mind wonder if she's just dating you for the money, and therefore, will cheat on you on the side for another man she truly desires.\n\nIt's not a good place to be.\n\ndm;hs\n\n&gt; then create your own company that doesn't have those inefficiencies.\n\nor sell the solution to those inefficiencies directly to them - which relies on having made a network of friends/acquaintances while working in the industry, and be trusted and well respected as being smart, but reliable and non-scammy. \n\nNot many people have this quality.\n\n&gt;You're still under thirty but know how to run a business better than where you used to work.\n\n\nDo it at any age really\n\nIt's so frustrating seeing 20-year-olds trying to build a business without any actual experience in any industry.\n\nMaybe another way to frame it - is that customer acquisition is essentially a game of trust. Particularly for b2b sales.\n\nI wish you were my head of product\n\nwhat, tired of working on your 17th salesforce integration?\n\nstop i'm already dead inside\n\nYou're still breathing though, so there is that.\n\nHaha no\n\n\n.. Dynamics\n\nOP seems like he's doing the business equivalent to developers doing \"premature optimization\" and never delivering a solid usable minimum viable product that's appealing to lots of customers. (docs/demo generation for restful api... who is your customer???)\n\nDesign a product to fill a gap, sell the product.  Try not to get into an over-saturated market and don't try to make the best solution to the problem and miss your window.  Also don't try to make something so big to get your trillions from venture capital, if your product is good you'll get investments and VC buyouts.\n\nI've lost count on the number of times devs have a great product, but hopelessly feature bloat and make \"pure\" products, then lose themselves in the sauce and the market passes them by.  Some examples: your API doesn't need to support gravatar and other app interconnections, you don't need to reinvent oauth2 or your own encryption library (that's not what you're selling, it'll be bad anyways), and don't spend months designing your own solutions to non-novel problems where there are libraries open source ones exist.\n\nTo put it shortly: entrepreneurship isn't just about selling an idea, it's equally about finding an idea worth selling.\n\nand delivering that idea before someone else figures it out too\n\n&gt;  and \"Not invented here\" is the unofficial motto of devs\n\nFor good reasons, and this post is a good example of it. People invested time and effort to integrate their products with this tool, and now it‚Äôs gone - as often happens with most SaaS and smaller open-source products. In this case, at least the author decided to open-source it, but even with that, his clients will need to invest time to understand the product's code, maintain it, or switch to something else. The same issue arises with smaller open-source tools. It‚Äôs always better to stick with popular tools or develop something simpler, tailored to your company‚Äôs needs, rather than relying on hundreds of external dependencies.\n\n[deleted]\n\n[Say‚Äôs law](https://en.m.wikipedia.org/wiki/Say%27s_law) strikes again. \n\nCompletely agree that his response is true in this specific case, but is not universally applicable. Sometimes products are made with no inkling of a target audience only to end up with massive interest.\n\n&gt; This in turns means your only possible customers are SaaS whose customers are developpers and doing at least 10M$ of yearly revenue yet have issues maintaining their docs while being their core offering. This is a very small set of companies, very small.\n\nAnd that is exactly a API of a company I have to work with so it can't be that rare.\n\n- it's saas\n- they use openapi\n- their only docs are the swagger page\n- and that page is often simply missing 90% of the needed info\n- it's not really improving even with the product getting more mature\n\nSo I can see a market for it.\n\nI don't see how buying something would solve that. If they're not willing to spend time documenting their api, a tool isn't gonna help.\n\nI think almost all ideas for software businesses could've been dismissed with very similar arguments. Yet people like OP exist who will do it anyway and eventually, a few of them by some miracle succeed. But yeah, I wouldn't bet years of my life on an idea like that, no matter how awesome I thought it was... I am still secretly hoping to make it \"small\" though, so I can retire early without guilt (sell some software I wrote for a small price for a niche market and get passive revenue for a long time - that's the dream!).\n\nDo you post your insights somewhere?\n\nSo it's Open API client generation as a service?\n\n\nSeems very niche and also there are already local tools that can do this for tons of languages. How does making it a saas help?\n\n\nFinally I mean at most companies you might integrate a handful of APIs over the years. How are you gonna get recurring revenue out of it?\n\nI was about to write something similar. I watched the Demo video and I was like... \"uh.. why do we need this?\".\n\nThere are so many api client generators our there for OpenAPI specs.\n\nI can't imagine who would use this. Like you said, you dont generate an API client every day... its like OP just figured a market would materialize for this?\n\nInteresting. I build this for an employer in a day using kubb.\n\nI use swagger hub to pull down API specs, run the generator, publish the npm package. \n\nSure, it doesn't output for multiple languages, but we don't need it to.\n\nI'm also really trying to understand. Why would code generation from a specification need to be a service, and not just a local tool? So this SaaS service should now be part of my build chain?\n\nKudos for opening your code as you fail. I think that‚Äôs huge.\n\n[deleted]\n\nYep, sounds like SaaS.\n\nIts Aaass. Api &lt;adjective&gt; as a service\n\nThat would be A?aas\n\nIs there a way to shorten this? Maybe three letters?\n\nAPI Simple Service\n\n\nAss.\n\nGuaranteed code smell from the start\n\nThat‚Äôs not really a contradiction.\n\nNo, it‚Äôs dramatic irony.\n\nI looked at the codebase and I don't see any calls to other people's APIs. What \"other people's APIs\" are you talking about?\n\n[deleted]\n\nYou are talking about a product that they decided not to build and treating it as if it was the main product of the company. The codebase represents the main product of the company. And it wasn't a wrapper around other people's products at all. It was a Postgres-based, Typescript codebase with no use of AI or other people's APIs.\n\nYou've selectively edited your quote to hide those facts.\n\nThey failed before they had the idea -- which they didn't pursue -- of using AI in the product.\n\nBut based on upvotes, there is a great thirst for the misleading message you are promoting, so carry on and collect your karma, facts be damned.\n\nwoah comments like these make reddit a great place, thank you\n\ndoing God's work\n\nKnow what? Fair enough. I didn't \"selectively edit\" anything though. I made a presumption based on the assertion that they were \"generating high quality client SDK's\" (which isn't a thing you can  even pretend to do with scaffolds) and the bit about pivoting to Gen AI, but I guess that was all just marketing speak. Most of their codebase seems to be scaffold generation and the only calls to openai are things like a chatbot demo and generating repo descriptions.\n\nI'll delete my comment because it seems a little harsh in that light. I genuinely don't give a shit about \"karma points.\" Make no mistake though, the anger is justified and this dude was absolutely doing his best to get a piece of the action of dismantling the entire software industry. He may have run out of money before he got there, but that's largely a technicality.\n\nCool that you've shared all of it! Hopefully it's going to be beneficial to others.\n\nI admit I am not the brightest bulb, but I read your blog and from this text, I have no idea what your product is. Zero. Nada.\n\nIsn‚Äôt that like 90% of B2B SaaS? They all ‚Äúcreate value‚Äù like Salesforce, Deloitte, etc\n\nwise cooperative joke steep cobweb fine chop intelligent unique seemly\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*\n\n[removed]\n\n[removed]\n\nBy enjoying every step of the journey. Everyone has bad days.\n\nSharing both the successes and challenges of your startup, and offering the codebase to the community, is a generous act that will undoubtedly help others. It's clear that you‚Äôve learned valuable lessons along the way, and your optimism about the future shows true resilience. Best of luck in whatever comes next! :)\n\nLittle weird that there's a `customers` directory in the repo with submodule links to what are presumably SDKs generated for clients.\n\nThe repo appears to be pretty poorly structured and some of what is committed reeks of bad design.\n\nAm I crazy or does that repo kinda look very very amateur? Just the layout, some of what they've chosen to commit, entire directory structure with company names as folders... I scrubbed through some files and it was very basic, much of it just empty files.\n\nkeep your head up bud\n\nSuccess or fail, it doesn‚Äôt matter. \n\nYou took the risk. That alone is a success in itself. Well done, lad.\n\nI like to know that I'm not the only one who misspells variable names when you want to use a reserved word for it. Long live Class clazz\n\nI have a friend who tried to do something with APIs in a similar way actually and tried a startup that way.\n\nI hope you and your team are ok. \n\nYou gave it a shot, which is more than most ever do. Good on you.\n\nYou're a class act - open sourcing the code ensures the community at large will benefit from all the work you folks put in.\n\nBest of lucks. Remember to be kind to yourself, and do take a breather if at all possible.\n\nHopefully this helps for the next one. I am literally your core audience here, Lead API Enablement Engineer at an Enterprise. Never once have I heard of this product. After reading the code, I also wrapped the same products for internal tooling. I also don‚Äôt understand what the USP was. What was the differentiator from other open source tools, Redoc, bump.sh and others?\n\nI'm not going to judge the repo on any measure, you took more chances than I ever have trying to get a business off the ground. Massive props to not just going silently in the night, but sharing valuable lessons, and opening yourself to a ton of criticism even after you've closed the doors.\n\nMost the people in these comments have never tried to build their own business. Inexperience breeds a lack of empathy- mix that with a desire to be the smart guy in the room and you can end up with some very misguided criticism. \n\nSorry it didn't work out and thanks for posting the code.\n\nDid the author see Stainless or Speakeasy? They look like something similar with better outcome, as I see\n\nIn terms of customers, where did you get to?  How many employees were on this, and what level of income/costs did the traction you were able to make cover?\n\nAhh yes, I can see why the startup failed. Line 1042.\n\nAs developer of and developer for HTTP APIs, I avoid HTTP API client wrappers on principle, especially if they're *generated for multiple languages,* and it has nothing to do with NiN syndrome. It's a damn HTTP request, and nearly all programming languages worth using already have good to great HTTP libraries. Almost all such generators produce overly complicated code, from deeply nesting and hiding the actual HTTP client, to overly verbose and often times useless data modelling, to really bad error handling. Additionally, due to the often more complex abstractions, the actual data-handling and request is often so obscured, it's hard to actually check such wrappers for malicious code (like sending the requests elsewhere).\n\nAnd guess what every such service, tool, and generator claims? They all claim improved performance, improved ergonomics, improved error handling... all of them.\n\nIf you have developers that cannot write a HTTP request to send some JSON without such \"client wrappers\", send them back to school.\n\nNow with all that being said, I am sorry your project failed after so much time and effort.\n\nYou built a product nobody asked for, in a market crowded with similar products that are also free, tried to charge money for it, and did a surprised pikachu face when nobody would pay. Amazing.\n\nYou only fail if you quit. Get a job and get back on the side hustle grind if you need to.\n\nwhy did you spend 3 years of your life on an openai generator wrapper? why not do another idea? what were you expecting to happen when you went to market?\n\n&gt;hyper-growth\n\n&gt;huge business\n\nIf you're looking for reasons why you 'failed' these expectations are exactly the reason.\n\nindeed. why not just a lifestyle business that can run indefinitely?\n\nJust started rolling out ChangeSets, curious about the changes you guys made to the bot\n\nLmaoo. OP didn't even to bother to reply to anyone. Brother is anxious as fuck.\n\nBrother even I am in the same boat. Its not my startup but I was the founding engineer. 5 years of my hard work. I took it from 0 to 1 and expanded the team from 2 people to 30. My mind has been blank since the past couple of months. We failed to gain more clients and whatever clients we got didn't want to pay what we needed. Plus we got drowned in client requests which delayed features. We failed to hit the required number of clients for a new funding round and hence its closing now. I really thought we would make it but that was just a pipe dream I guess.\n\nHow was this that different to nswag?  That's what we use to generate client code for our rest servers using swagger.\n\nThis is very inspiring --as someone who also spent the better part of 3 years building a failed startup, I have the entire product's code uselessly sitting in my hard drive; perhaps it is better to share it all.\n\nreally ambitious but I wonder why u choose typescript for this project\n\nIsn't this what Kiota does (Microsoft)\n\nI think so.\n\nKiota works well with simple use cases but if your use cases are a bit more complex, make sure you test the output thoroughly as some limitations such as array of arrays not supported (https://github.com/microsoft/kiota/issues/5159) may surprise you.\n\nWhat exactly did you make that people could use? It feels like you made a tool to make some work easier for people doing development but that work wasn‚Äôt hard to make anyways. Feels like the product you tried to make had no direction nor any viable customers\n\nYou haven‚Äôt failed until you‚Äôve quit. But also, I assume in that three years your knowledge of code and programming has improved significantly from what it was previously. Use what you learned from this experience and apply to it a new project if you are done with this one.\n\nI looked at your resume. I wouldn't advertise that you were promoted to \"senior software engineer\" after 8 months. That just means you worked for a startup.\n\nbased facts and this is downvoted? Lol\n\n8 months is nowhere near long enough to be a senior\n\nWho is this the resume police?\n\nBoth his resume and linkedin just list him as \"co-founder\" at the startup. No idea what you're talking about. Maybe he updated both in response to your comment, but I sorta doubt it.\n\nThe most recent post on OPs blog is about his resume\n\n\"I‚Äôm unsure about my future and don‚Äôt have a specific goal yet. Can someone help me choose a path in IT and tech?\"\n\nbro your portfolio is damn great.\n\nSo this (that I made for myself) but with all languages prebuilt? Or I got wrong? Sorry, too late and lazy to read everything haha\n\nhttps://github.com/ProtocolNebula/ts-openapi-generator\n\nhuh what\n\nNo one wants your garbage code lmao\n\nNow you trained the thing that killed your business.\n\nWhy the hell is your GitHub repo dozens of GB‚Äôs in size\n\n[deleted]"
  },
  {
    "title": "Distracting software engineers is way more harmful than managers think",
    "body": "",
    "score": 2082,
    "url": "",
    "created_utc": 1714633349.0,
    "author": "zaidesanton",
    "permalink": "/r/programming/comments/1ci99rm/distracting_software_engineers_is_way_more/",
    "all_comment_text": "I worked for a company with very close to a 1:1 ratio of managers to programmers (it was 1:1 if you removed interns). \n\nWhen I pointed out that maybe having a VP of Engineering, Senior PMs, PMs, and managers matching the count of programmers who could, well, program, might not be a good idea. They looked at me like I was blaming the terrible productivity on an infestation of Yetis and Unicorns.\n\nThis company had turned distracting into an art. Open concept for programmers who almost never worked collaboratively. Endless meetings. Managers trying to impose more processes to improve productivity. But the meetings. OMG the meetings. Most managers were in meetings all day with programmers. With one or more programmers in these meetings it could mean nothing less than 2hrs a day, or in some cases, the whole day for programmers. \n\nTo add icing on the cake, the managers were often freaking out that they didn't always have anyone to manage. So, every Friday, they had a \"resource allocation meeting\" where they would plead their cases for their projects being the most on fire and get an extra programmer or two. There only being a few programmers who were good firefighters, it could mean other managers losing their key developers. \n\nThese projects were typically in the 6 months to 2 year range. Yet any given programmer might be working on 3 separate projects per week. Just switching from one to the other, with the \"left out\" managers leaning on them for estimates, meetings, and \"Maybe you could come in this weekend.\" This would mean that a programmer who didn't have any hours allocated to a given project could end up working a full day on that project that week. \n\nAlso, the managers had no problem with programmers coming in on weekends and not show up themselves. These were salaried employees, so no extra pay for extra time. Maybe a $200 Amazon card at the end of a big push.\n\nWeirdly enough, they kept losing their top people. It was the usual story. Some manager would pull some extra BS stunt, and this would push the highly capable programmer out the door. Ironically, the worst manager was responsible for exit interviews. He was a micromanager extraordinaire. He turned to another employee after an exit interview and asked, \"They aren't saying it, but do you think they are leaving because of me?\"\n\nWhat a shitshow.\n\nNo, you just got a whiff. This is like driving through farm country and a pig farm is half a county upwind. You might think, that is a bit \"gamey\". But for the developers working in this company it was being waterboarded with the pigfarm runoff including the fermented treacle leaking out of the entrails truck which has been sitting in the summer sun for 4 days.\n\nYeah I would have found a new job haha..\n\nI have had an internship that was quite traumatic .. so I can somewhat understand. Had to just suffer through it to finish it. Made sure the next company I applied at had their shit together.\n\n[deleted]\n\nI know a company in my area where they had 12 managers (kind of 10 as 2 were half sales/BAs.) in a company of 200.\n\nWithout going into details it was discovered 8 of the managers were toxic nightmares and were fired without notice or any effort for a transition; just cut off, here's your severance, lose our number; don't ask for a reference.\n\nThe remaining 2 turned out to be real leaders, not managers. They had no problem taking the workload of the other 8. This was not by building a new hierarchy of managers below them; quite the opposite, they flattened things quite a bit. They focused on everyone having the information they needed including what were the real priorities and making sure everyone was onboard with the vision; a vision they built as a group.\n\nThen, their \"management\" was to:\n\n* Prevent any interference from other parts of the company such as HR, sales, etc. \n* Keep the client expecting the same vision to be the result.\n* Seeing that the majority of effort was in the direction of this vision.\n* Providing any resources which were required.\n* Very occasionally refereeing if two or more people disagreed on the way forward. Rare, if the vision was clear enough.\n* Very occasionally finding someone who disagreed with the vision entirely and was wandering off and dealing with it.\n\nThe above could mostly be done by these leaders through the occasional demo, watching jira, perusing the codebase, etc. These leaders would spend a few hours per project every week or two.\n\nProductivity went through the roof. Recently quit people came back. Other people, \"announced\" they weren't quitting anymore after actively job hunting.\n\nKind of weird, you take very smart people and treat them like adults. You depend on them to do their jobs, and what disasters come of it? None.\n\nI asked him what methodology they used, agile, etc. He laughed and said, \"Make a plan. Do the plan. Change the plan as needed. Get shit done.\"\n\n&gt; it was discovered 8 of the managers were toxic nightmares and were fired\n\n[1] *How* was it discovered?\n\n[2] **How** did this discovery translate into firings?\n\nI have literally never seen a manager's incompetence noticed by higher-ups.\n\nSuper simple. The founder and president admitted that he had taken his eye off the ball while focusing on big deals, etc. \n\nCovid came along and everyone went home. They got rid of their office. Workers were gathering informally at various people's houses and they suggested to formalize this as covid restrictions faded away. They then did a google sheet where various small offices around the city were proposed and people could sign up. \n\nThe founder noticed people were signing up, and then moving their name a few times before not signing up anywhere. This was happening at a fairly furious rate. He asked a few people about this and they were, \"Oh nothing, just changed my mind.\" So, he added alcohol to his questioning and it was basically, they would sign up with people they worked well with and one of the 8 managers would sign up causing everyone to run away.\n\nWith a bit of digging he found that everyone thought they were toxic micromanaging nightmares with only 2 that everyone wanted to work with. \n\nHe then started contacting people who had quit in the previous year who were clearly very good developers. They didn't hold back and had entire encyclopedias of examples of toxic crap along with people who would have even better examples. \n\nMost of the problems were straight up bad management such as extreme micromanagement, but many were things like misogyny, tolerating it from some employees (other managers), or clients.\n\nThen there were a few \"treehouses\" where the managers had a few pets who got everything. If a client in a cool location needed something, they and or their pets would go and the expense accounts were wide open (not fraud, just open), when people outside the treehouses ever got to go anywhere(lousy locations) their expenses were nitpicked. And on and on and on. One example he mentioned was a whole travel expense submission with nearly every single line item questioned. \"Couldn't your wife have driven you to the airport, couldn't you have packed a lunch, the last meeting was at 10pm, your flight was at 9am, couldn't you have slept at the airport, if you had asked, the client could have driven you to the airport, you were heading home, did you have to buy another restaurant meal, etc. It was literal insanity, especially when the same person had trip expenses which included night clubs and car rentals when they were staying at a hotel which was literally next door to the client location in the downtown core of a city with a fantastic downtown. I remember this one because he was enraged to find out the rental was all week and ended up with something like 16km on it. The hotel was about 8km from the airport.\n\nAs he put it, the more he dug into the data (not just people's opinions) the angrier he got. His wife took his phone away and sat beside him so he wouldn't send any emails. One employee had quit after being put on a performance plan. This wasn't even something the company had. The reason was they hadn't checked in a line of code in over a month. Their excuse was they had either been in meetings for literal weeks, been on vacation, or had been at a client site putting out a fire caused by one of the treehouse members. They were told, \"Then you should have kept up with your work in the evenings and weekends; you've let the whole team down.\" The performance plan they were handed had 70 hour work weeks including weekends scheduled. This was someone with an infant. They went on immediate pat leave and then quit. To make this more outrageous, the company has a 4 day work week with 7 hour days. Of course these 8 managers had pressured many people into 5+ day work weeks.\n\nEverything he had been fed by these managers was that they were managing a bunch of losers, and only through extreme heroics of management did anything get done and that it was like herding cats.\n\nThe next morning he was sitting with his lawyer making sure this was done perfectly. At noon, they lost all access to the systems. He said he was shaking as he stood beside the IT guy as he cut them off as he had driven to his house to make this clean in case the IT guy would warn them or something. The IT guy asked him if this was a layoff or a cleaning house. He knew he had done the right thing when the IT guy was \"F--k you, and f--k you, ...\" as he shut down all their accounts.\n\nHe is now looking for a new \"leader\" not because the workload is too much for the other two, but he wants some redundancy. \n\nThis wasn't some secret he told me. Everyone got a notable pay bump as the manager salaries were redistributed, along with notification that their bonuses would be higher for the simple reason that the managers had kept most of the bonus money and had passed any leftovers to their treehouse friends. Even those guys were pissed when they found out the ratio of their bonuses to the managers who they thought were their buddies.\n\nHe's not worried about his present managers, but he now regularly goes drinking with various employees with a question that I recently have been seeing more: \"If you had my job, what would you do differently?\"\n\nBut you are 99.999% correct. Bad managers are very rarely eliminated. I know a person who was very high in a military for a very long time. He said he laughed when a new top guy would come along with a plan to eliminate the worst of the worst. He said, \"It's easy to figure out who are the worst of the worst, because they are first in line to join the purge of the worst, and then they eliminate their critics.\" just in time for a new guy at the top with a new plan.\n\nWow!  I don't know whether to ask your company for a job or to invest in it.  PM me!  (Not sure I'm joking..?)\n\nMy present company is one I am starting. The product sits as a pile of wires near my elbow as I type this.\n\nWithout going into detail it is a fun product, I will release it as an app first for free with the physical incarnation of the app next.\n\nMy anticipation is that it is a \"Shut up and take my money\" product. Needless to say, as I grow the company there will be quite a bit of attention paid to monitoring and tending to the culture.\n\nIt is really rare.  A director that actually wields the power of subtraction on a line manager is easily something like 1 in 100.  Same for VPs.\n\n&amp;nbsp;\n\nOn the other hand, groups of managers getting together and voting another manager off the island at layoff time, that happens twice a year!\n\nYeah but if you don't have enough managers how will the company be able to measure the developers' productivity?\n\nwhen you meet the deadline, you'll know :)\n\nManager replaced by software. \n\nThe Software:\n\nreturn 0;\n\nYou‚Äôre describing the relationship between Labor and Capital. As Abraham Lincoln put it:\n\n&gt;Capital is only the fruit of Labor, and could never have existed if Labor had not existed first. Labor is prior to, and independent of Capital, and deserves much the higher consideration.\n\nThe problem is that Capital started believing their own nonsense. In order to prevent their position from being questioned, they tell the lie that they play a pivotal role in labor output. They told it so much that they started believing it, and now they truly believe that they can *manage* their way to success. Like, if only things were more *Agile*‚Ñ¢Ô∏è, then it would make up for the fact that they can‚Äôt even articulate what it is that they want. The great irony in all this is that we can all see they‚Äôre stepping in their own dicks, because if they just GTFO the way, we‚Äôd be making them more money.\n\nSo it wasn‚Äôt programming, but I worked as a data analyst for a boss who liked to live solve things. So we‚Äôre wasting an hour as he makes assumptions and what instead of him sending me back to my desk to see what the actual numbers are saying. And then we finish and I go run the numbers and now we‚Äôre having to waste time explaining why it isn‚Äôt the thing he made up on the spot. For fuck‚Äôs sake Dan, stop this madness.\n\n&gt; He turned to another employee after an exit interview and asked, \"They aren't saying it, but do you think they are leaving because of me?\"\n\nWith all the stuff in the preceding paragraphs I would never have  expected anything close to that level of introspection from those people.\n\nThat's awful, would love to hear more :)\n\nI could write 10 volume set on this one and most of my former coworkers would immediately say, \"Oh you missed this and this and this.\"\n\nAt a certain point(40 pages into volume I) people would call me a big fat liar saying, \"A company that dysfunctional couldn't last for the decades it has.\"\n\nAfter I was finished Volume 10, I would need an addendum of \"Stuff even I don't understand at all\" with a few hundred pages of just weirdnesses. For example, it has a larger profitable parent company which makes the exact same product. Think of this company making a Point of Sale system (Not even close to what they do). It is used in restaurants and bars, and it really sucks and is full of bugs; they have a few dozen customers. The parent company makes a Point of Sale system which also sucks but far less and have maybe 1,500+ customers of at least the same size or bigger. Yet, the two dev groups never meet, exchange code, work together, or anything. In a very few cases the parent company sold the jr company's product which caused them nothing but grief and embarrassment. \n\nThe parent company is well financed and frequently interacts with the owners/board. These are the same owners/board of the jr company who they visit once every year or three. They often have to bail out the jr company as it lurches from one financial crisis to another.\n\nBeing a commodity product like a PoS I can say with absolute certainty that they should definitely toss the jr company's product and just whitebox one of the excellent options on the market. A perfect example is that this product probably takes developers about 2000+ hours to customize it for a customer. The whitebox one I am thinking of would be about 200 at most with exactly zero downsides.\n\nIf I were put in charge of the jr company, I would entirely merge it with the larger one, and call it what it should be \"a branch location\". Then, I would fire most of the executive, keep one accountant who would also be HR. Then move to the whitebox product. Give all the managers the option of becoming developers (most have this ability) and then moving a few of the architects to sales or back to development. I would have maybe 2 sales people on massive commissions. This is a procurement business so the sales cycle is long, but I would make sure the commissions are life altering. I would also offer to the old clients a near free upgrade to the new software so that the old legacy crap would be out of the company's hair sooner than later. But, I would send in the high commission salespeople to upsell the crap out of the \"free\" upgrade to the point where it would be a good idea to have some \"try before you buy\" examples of how the company now can pound out features.\n\nThe crazy part is, with the executive gone, break even is there from day one, with most of the non programmer managers gone, profitability is there from day one. After that it would be a comfortable growth over the next decade or two.\n\nBut instead, they are doing the opposite.\n\nouch. i can relate a bit. worked for a company many years ago that essentially scheduled a multi-year project with 30 developers and expected the team to work on at least one day per weekend. a 6 day work week built in to the schedule. for years. and we didn't even get amazon gift cards for the extra effort\n\nthey also had endless meetings and multiple pms for the one project to make things 'more effective'\n\nOne company I worked at called a meeting to find out why productivity was so far behind.\n\nI pointed out that there was now only one developer (me, the other one was hit by a car and not replaced), I report to three managers and I'm in meetings for half the day.\n\nAll my fault, apparently.\n\nHmmm I don‚Äôt recall posting this comment. Should I check the carbon monoxide levels?\n\nYou could, but not right now. We're in a meeting.\n\nWhen that one finishes can we have a meeting about the CO2 levels? I want to get to the bottom of this.\n\nNo, you need to first raise it into the backlog so that it can be appropriately weighed by the PM against other business priorities. If we don't perform all the steps correctly then our Agile stats get miscounted and go out of whack\n\nLook guys the PMIS is getting messy I want to have an all hands to groom again.\n\nYou‚Äôre going to need to enter an issue in Jira before I can put that in the backlog so I have a place to charge my time.\n\nPlease do the needful, I'm dying\n\nOMG, I work with scrum masters in India, I hear this term so often\n\nKindly do the needful\n\nCO2?  We were talking about CO. Why do people always conflate the two?\n\nIn case you didn‚Äôt catch the joke, I intentionally used the wrong thing in my post to reflect the way management often misses what people are actually talking about.\n\nIn case you missed the joke, I'm pretending to be the annoying guy who sits next to you at the office and corrects everything you say when it clearly doesn't change the point of the discussion.\n\nLet's setup a subcommittee to investigate the differences between the two and document the potential project impact.¬†\n\n\nWe'll need weekly meetings with at least 2 developers present to answer any technical questions that may arise.\n\nLets circle back on that after this slide.\n\nLet‚Äôs touch base soon. We can huddle right after this.\n\nLet‚Äôs take this conversation offline\n\nSet up a meeting with Bob, Alice, and me and we‚Äôll discuss it.\n\nHow many post it notes have you found recently?\n\nDid all three managers meet you separately to discuss this topic, and perhaps your 1 over 1 needed a hourly status report to make sure you stay on target. Oh btw we are also increasing the frequency of the standup, retro, scrum of scrums, decomp, sync meetings every day to make sure you as engineer stay on target and we are informed well enough to remove impediments for you. \n\nWhat did you say your impediment was, oh this OSS library deprecated the feature that was core to  our feature. I can't help with that, but I read in this book called Leading with questions. Using that techniques I can unlock your potential by asking questions even though I know nothing about it. So come over every 30 minutes when you get stuck, I shall ask questions to unlock your stuck brain. \n\nMan, am I so helpful, I need a raise for helping you (probably your non competent manager, agile coach, product manager, and whom ever in that hierarchy that knows nothing about software development)\n\nAnd that is when you implement another measurement: Lead Time. So you know what the fuck takes time between the \"we got an idea\" to \"the idea is delivered\". Is it getting a spec? Coding? Testing? Getting approval? Meetings? Deployment?\n\nGet to know what the main constraint is in your org and remove it. Then keep on repeating the process.\n\nWell, since all the leaders spent a year perfecting the idea, and put together the timeline in a PowerPoint and showed it to the C-Suite, clearly it's the lazy developer.\n\n.\n\nThat's more close to how these conversations go.\n\nBTW, you misspelled piece of shit incorrectly as POC üòÇ /s\n\nScrum of scrums is proof that the inmates are running the assylum\n\nwow literal bus factor at work!\n\nWe had to start using \"win the lottery\" at an old job after a team member was literally hit by a bus, right in front of the building. Luckily, he was back at work within a week, but it DID show that without pre planning he was unreplaceable.\n\nSo, you first get hit by a bus, and then your boss starts trying to replace you at work.\n\nNot a good year for that dude\n\nThe secret at work is to be un-replaceable enough to not get fired but not so Un-replaceable that you can‚Äôt get promoted.\n\n&gt; after a team member was literally hit by a bus\n\n[Was your job about to get a contract with some Middle Eastern country in the domain of getting things from A to B? Did you just interview some not exactly perfect candidate for a job?](https://youtu.be/HW6usoJXCPY?t=115)\n\nYeah. So we're using new cover sheets on the TPS reports? If you could just go ahead and use those, that'd be great, okay?\n\nI'll have a memo sent over for ya\n\nSuddenly I want to smash a printer and listen to 90s gangsta rap\n\n.\n\n[deleted]\n\nI do this. Prepare to fall upwards.\n\n&gt;All my fault, apparently.\n\nDid you have follow-up meetings to determine if you had improved...?\n\nMaybe schedule one-on-ones with each Manager, and then some more meetings to check progress.\n\nAnd then a big monthly meeting with *all* the Managers.\n\nLike you read these as jokes, but this is also literally happening. It's absurd.\n\nAww. You must be new.\n\nSoon you'll realize you chose an industry where just repeating your weekly schedule to someone is the punchline. The set-up for the joke was all your hopes and dreams.\n\n6 years, if that is new. Think I've mostly seen it all, it just how much it identically repeats itself which is the sad part.  \n\nNobody can for a second come to be and tell me \"but the private market is so efficient\".\n\nEvery single* company is collectively shooting themselves in the food before they start running the marathon.  \nIts \"fair\" because all is equally bad.\n\n*exceptions always exist of course.\n\n[deleted]\n\nNope, we don't use Scrum Masters, but we do Team Coaches. They do the same thing except they are called coaches to show they are coaching. They don't write code, never in their life, but are coaches because that's what they are. Get on this clown train.\n\n[deleted]\n\nThat's VP Potato to you mister! I didn't work for 12 years as the regional manager of 14 Hardee's franchises, just to be disrespected by some programmer for my Scrum/Agile skills. I'll have you know, I took the same 4 day retreat to learn the process everyone else did! MY certificate was printed AND embossed, not just a PDF.\n\nHave you considered being hit by a car?\n\n‚ÄúGood things can happen in this world. I mean, look at me!‚Äù\n\nAt my last software job, the morning standups started taking upwards of an hour for *just two developers,* because one of our bosses would talk to the backend guy while I sat there twiddling my thumbs (they didn't pay me well enough to work during the calls).\n\nSo I stopped going and would just do my job on my own. And they fired me. Right after their backend guy left and their other frontend guy was being headhunted by Google. Left with one developer, frontend-only. So that worked out well for them, I suppose.\n\nYou were outranked and outvoted 3 to 1, of course it's your fault.\n\nI mean, why would the execs trust a single lowly employee instead of 3 managers? The execs know full well that the reason managers are managers and you're not, is because managers are better than you. Totally nothing to do with corporate politics.\n\nDo you know the old saying? \"Democracy is three managers and a developer deciding who wasn't productive enough. Liberty is a developer who knows their value in the employment market contesting the vote.\"\n\nPeter Gibbons: The thing is, Bob, it's not that I'm lazy, it's that I just don't care.\n\nBob Porter: Don't... don't care?\n\nPeter Gibbons: It's a problem of motivation, all right? Now if I work my ass off and Initech ships a few extra units, I don't see another dime; so where's the motivation? And here's something else, Bob. I have eight different bosses right now.\n\nBob Slydell: I beg your pardon?\n\nPeter Gibbons: Eight bosses.\n\nBob Slydell: Eight?\n\nPeter Gibbons: Eight, Bob. So that means that when I make a mistake, I have eight different people coming by to tell me about it. That's my only real motivation is not to be hassled; that, and the fear of losing my job. But you know, Bob, that will only make someone work just hard enough not to get fired.\n\nYesterday, I was in a meeting that was scheduled for an hour but ran for two, and most of it was my boss talking about how we don‚Äôt have enough bandwidth to do everything we want to do, and somehow he missed the irony in that\n\nThat would be the moment I DEMAND a LOT more money, immediately! or I would quit, instantly.\n\nSeriously though. Why are there always so many goddamn managers?\n\nThey're not competent enough for anything else.\n\n&gt;Why are there always so many goddamn managers?\n\nWhenever there's a problem, somebody concludes it's because there wasn't enough oversight over whatever particular area had the problem. So obviously the solution is to create a management position to oversee that area. Cycle repeats until there are no more problems, or until 100% of company budget is devoted to management salaries.\n\ni used to call them 'manglers' since it better describes their actual job function\n\n&gt; You don't have to attend the meetings, send a representative.\n\nI really can't fathom how someone can be this idiotic and still be in charge of a company.\n\nI‚Äôm starting to think that it is actually a requirement.\n\n3 managers, 3 paychecks. \n\nI'm not dealing for 3 different managers simultaneously without a very fat check every week.\n\nI told a manager that if he cared about productivity, he'd hire more people.  Since he hasn't, I have no choice but to assume he doesn't care so I'm not going to kill myself trying to meet his goals.  He started interviewing for a couple more people.  I quit before he hired them so I have no idea if I was going to get fired for saying that but hopefully the new hires are doing well.\n\nBut how else are they going to prove to others they're *working* if they don't force everyone to spend time listening to them\n\nI had 7 hours of meetings one day then got asked why my progress on a project was slow. :/\n\nWe should schedule a meeting to discuss this\n\nUsed to have a similar situation but it was 1 engineering manager, 1 tech lead and one pm who thought they were also my manager. It was pretty much the reason why I left\n\nCurrently me at an insurance company that should not be named. One engineer doing the work in meetings half the day with of course you guessed it, 2 direct managers, 3 cross functional managers, and shit broken so bad nothing can get done\n\nI spend an annoying amount of time helping my manager format Word documents. \n\nThis is also seemingly the most impressive thing I'm able to do for the manager. Ridiculous\n\nTbh, you should teach him to use chatgpt so he can do it him self an not stealing your time.\n\nThey do use chatgpt for translations. Some people of the older generation don't experiment as they don't want to \"break it\", despite knowing about the undo feature\n\nBoomer moments\n\n[removed]\n\nVoice to text at its finest lol\n\n[removed]\n\nA company I worked at had an enitre department of coders in a noisy cubicle office location. The whole department had a bad reputation of not contributing enough. Then covid hit and everyone was sent to work from home. A year later the department was celebrated for its achievements and improvements. Then the company decided to do the back to office thing, 2-days per week at first on a hybrid schedule. Productivity dropped by 50%.\n\nMy days in office are somehow simultaneously boring and overstimulating.\n\nAnd I get nothing done.\n\nAnd yet no one in the \"we need to work from the office\" camp seems to notice this consistent trend.\n\nThey are just copying what others are telling them to do. Senior management in most companies just follow the herd they probably  don't actually know what their companies actually do or why their products are \"successful\".\n\nMy favorite part is the same people banging the drum for everyone to come into the office don't actually come into the office.\n\n&amp;nbsp;\n\nThe truth is that those middle managers are just following direction from foolish board members like former yahoo CEO Mayer (2016 Fortune magazine world's most disappointing leaders alumni) who has always been huge proponent of return to office (meanwhile she built a \"mother's room\" next to her office).\n\nI think you'll find I can distract myself on my own and I don't need managerial assistance with that.\n\nBut yes, regular interruptions (manager, partner phone calls, people airways popping up for advice) can destroy or throughput.\n\n&gt; I think you'll find I can distract myself on my own and I don't need managerial assistance with that.\n\nThe difference is pinching yourself vs having someone else randomly come up and pinch you. It might seem the same on the surface but it's still very different..\n\n&gt; I think you‚Äôll find I can distract myself \n\nThis is also a big point addressed in the article\n\n&gt; Distracting people who need to be focused is bad \n\nWHO WOULD HAVE THOUGHT!\n\nAnd yet we keep seeing open office spaces, meetings that are not needed, task switching, etc. It is almost as if those companies didn't care about wasting money.\n\nThe rooftop is your friend, you always can trust the rooftop. The ultimate open space without people.... Marvelous üòç\nHave you heard of 1,000X developer... All of them are Inhabitant of the rooftop.\nAt the rooftop the AI already has acquired consciousnessü§£\n\nEdit: to clarifying cryptic style, cryptic style was too subtleüòé\n\nI hated it when start-of-day standup meetings became a thing. First thing in the morning was my most productive time, my subconscious had been working all night, and I was ready to go. Waiting for your turn to say a few words only the manager needs to hear (do they really?) is infuriating.\n\nIn before the scruministas come and tell you you're doing stand-ups wrong ü•≤\n\nTBF, a lot of people *are* going it wrong given the complaints I've seen of stand up taking 45 minutes. \n\nBut, yeah, I've gotten into the habit of starting 5 minutes before stand up because there's no point spending 30 minutes only to then have the meetings start.\n\nStill thinking about that dude who has daily 90 minute stand-ups RIP brother hope you're well\n\nThere's a massive subset of developers that just love to \"have a chat\" about their work in place of actually doing the work or thinking themselves because of their current inability to get into the flow. Standups even when policed have people that just cannot be stopped.\n\nThat's just bad policing, imo. At my current job we're really strict. A standup *never* takes more than 15 minutes. It usually just takes 5-10. If anyone starts veering off into something else, only the people who are relevant for the discussion meet to talk about it, after standup.\n\nI run stand ups and am incredibly strict. A method I like is to tell people to ‚Äúwrite it down with pen and paper and deliver it to me if you can‚Äôt be succinct.‚Äù\n\nI then read off only the first maybe second sentence for the group.\n\nThey quickly get the idea.\n\nEdit: Clarity\n\nThen tomorrow you get annoyed with them because they didn‚Äôt tell you something, except they did tell you, in the third sentence which you didn‚Äôt read.\n\n[deleted]\n\n&gt;Hire competent people who like work\n\nEasier said than done ü§∑‚Äç‚ôÄÔ∏è\n\nMy problem is even if it's 15 minutes it kills an hour of my productivity. Wake up at 9, standup is at 930 so I guess I'll just fuck off for 30 mins. 15 mins in the meeting, I'm not going straight into work typically. I'll kill another 15 or so to actually start my day. \n\nA 15 min meeting takes at least 45 mins of productivity due to context switching imo\n\nThis is why the last time I worked with moved to a slack channel + bot for stand ups. could post it async and update it throughout the day with progress if desired\n\ncalled it!\n\nMorning meetings completely burn me out before I even start my day. I despise them.\n\nAt my last job I managed to get them to promise me I wouldn't have to attend stand-ups anymore when I negotiated my contract extension, because they were so early for me and were burning me out and affecting my sleep. Still got a raise too. I was the only one who didn't have to attend standups üòÅ Now I work at a much better company and we have no standups at all and a great team. One scheduled meeting every other week for sprint planning and the occasional technical discussions meeting.\n\nYou should communicate this to your team. \n\nDaily stand-ups should be a way for engineers to ask for help, raise flags before things go to far, and share knowledge. They are not for daily status. If they're interrupting your productivity, they're not right. They should take place at a time of day when the team agrees it's a good time to take a break and discuss what they're working on and how they can help each other. \n\nDaily stand-ups are important because of deep work. You need to come up for air and make sure you and your team aren't working against each other or on the same problem or hitting the same big. But they also don't need to be meetings. It can be a slack thread too and that's totally effective.\n\n&gt; start-of-day standup meetings \n\nI never understood that. Even following SCRUM it does not say to do this shit in the morning. Only that the team tell what they did the last 24h and what they intend to do next.\n\n9am means early people cannot get in the zone cause they know they have an interruption coming. It also means people who'd prefer coming late cannot. And that's why manager do it like that I think.\n\nEnd of day has the same problem: people who arrived early to get the fuck out early (because of traffic, children, any other reason) cannot. And people who'd like to be in the zone in the afternoon cannot.\n\nBest is never, second best is 11h45am. Morning people have their morning. Evening people have their evening. And because it is almost lunch time no one will make it a 1h meeting.\n\nMy main problem with stand ups is that we have to wait for everybody to arrive, so I can't start working on anything until after it's done. When you're most productive on the morning, it's a big ugh.\n\nMy team starts 2 minutes after. If you come late, your missed tickets can be talked about at the end of the meeting.\n\nWe used to have a policy of making team members do 10 pushups for every minute they were late to stand-up.\n\nIt was a good laugh for the first week and then everyone fell in line.\n\nOur rule was nobody can speak for more than a minute.  Max 5-6 of us and we were done in 5 minutes.\n\nWhat happens if you don't do the pushups? I'd be like \"Nah I'm good, but sorry for being late\".\n\nThe policy effectively ended the day our boss was 7 minutes late and fell down laughing after about 25 pushups.\n\nStopped doing stand-ups over a year ago. Team communicates when needed over chat. No one misses them.\n\nYou're living the dream\n\nI love morning standups for this exact reason. Whatever the meeting time is, I start my day about 10 minutes before it - just enough time to check for anything urgent that might have occurred overnight that might preempt my expected day's activity, then a few minutes with the team to tell what I plan to do today and find out if anyone is going to need my help (or vice-versa), then we're all free to work.\n\n\nStandups are a problem for me if they happen so late in the day that I have to try to work before it starts. Then it's an interruption just like any other.\n\nThis was the biggest bullshit thing - standups first up. Like really it is necessary, I‚Äôm working on the button that‚Äôs all ‚Ä¶\n\n&gt;I hated it when start-of-day standup meetings became a thing. \n\nYep. Nowadays nothing gets done until 10am at the earliest because of stand-ups.\n\nAlso there's a good chance an adhoc meeting after the stand-up means tasks are re-assigned.\n\nI'm with you, I joined a company remotely 1 hour behind, so my 10:30, was their 9:30 and thats when the stand up was. I always began my day at 9 my time, but i'll tell ya, that 1h 30m was the most productive period of my day\n\nSounds like you're not actually doing standups. Your manager isn't supposed to be in the standup, unless your manager happens to also be a developer on your team. You're just doing daily status update meetings, which is a pain.\n\nTry say that to the clowns at a recent job I had. My manager was a CTO and his boss was the CEO. Both of them were in stand ups regularly bragging about all the work they did over the weekends.\n\nOh we we are doing status update meeting with management at start and end of each day. Which only results in that I spend 45-60 min in extra meeting, aka not working and I totally stoped working overtime, why bother if I already told my status. Smart Management move\n\nStart AND end? What the f could have changed in less than 7 hours?!? That's barely enough time for me to fully wake up. I have mine at the end of the day (for the others it is the beginning of the day, German working with Americans xD) and I think that is already too much. Every second day would be more than sufficient.\n\nFor a change I understand the necessity for such meetings. Especially if you work internationally, your team lead needs to know what you are working on, how you are progressing and escalate the work if it is on a bad trajectory. But those meetings should *never* take more than 15 minutes. If they take more you are either derailing off the topic or are too many people.\n\n&gt;What the f could have changed in less than 7 hours?!?\n\nMore importantly, what's going to change between the end of one day and the start of the next?\n\nIt was worse than that at one place. The whole company has a communications and status meeting led by the CEO,  then the software dev meeting rolled on after that, with everyone even tangentially associated with any project chipping in with their opinions.\n\nYes! Me too. I managed to talk one team a while ago into 4:30pm stand ups and it was so nice while it lasted. You‚Äôre armed with all the happenings of the day, it‚Äôs wind down time anyway and no one is doing real work, and your updates are so much more meaningful having just worked on things. Plus, people aren‚Äôt tempted to make them go long since they want to head home.\n\nAnd like you said, it was so nice to sit down fresh at the start of the day and have a shit ton of runway to hammer things out.\n\nI hated morning standups when I worked in the office, I like then much more now that I work remotely. For me it's a good way to start the work day.\n\n[This](https://www.reddit.com/r/ProgrammerHumor/s/3DIkteMUdo) sums it up perfectly.\n\nI have this [this variation](https://www.monkeyuser.com/2018/focus/) printed at my desk.\n\nThis.\n\n  \nMy last two jobs were horrible in this regard.  I was expected to keep Teams open all day everyday.  Any time I complained about not being able to stay on task for more than 15 to 20 minutes before I had to read a teams message, context switch to determine if I needed to actually act on the message, then act accordingly, I was met with something along the lines of \"Tolley, you didn't need to respond to that message at all\" or \"Don't worry about that\"  but if I didn't quickly respond to a message that needed my attention it was \"Tolley, why didn't you respond? It's important for each member of our team be available\"\n\n  \nIt caused me to be paranoid and anxious.  I did my best not to internalize that pressure, but I have an interest based nervous system.  I get loads of work done when I can focus on a single goal for sometime, but having my attention jerked around all day everyday was just too much.\n\nWe recently switched to the new teams version. It crashes multiple times a day without me noticing. I think my productivity went up a lot.\n\nI‚Äôm currently dealing with this. Management says all of the ‚Äúright‚Äù things, but then punishes/rewards people based on the wrong things. And I say this as someone who keeps getting rewarded (apparently doing *almost* 1 story point a day on stories, that I estimated using the scale of 1 point = 1 day, is praise-worthy).\n\nI remember when the worst manager I ever had got super pissy one day that I \"wasn't doing what I was supposed to\" and was behind on a project. I responded by explicitly that's because I was in meetings on average 5 hours a week, which was a quarter of my time as I was contracted at 20 hours.\n\nOf course they didn't believe me, so I went back and turns out I was actually averaging 6 hours a week in meetings with a minimum of 3 and a max of 12.\n\nEnded up leaving very soon after for a variety of reasons, but not before reporting the manager to HR for a multitude of frankly psychotic behavior.\n\n[deleted]\n\nHm, at least one good thing at my last firm, they didn't let clients' managers talk to the dev. You could for details but anything planning related went through PM to PM route. Pretty fair in this regard, as you would expect from proper Germans.\n\nI had one project with a PM kinda like this.\n\nI was brought on shortly after he started because the project wasn't doing great and I was an expert on the topic (VR design/development for education). First thing he had me do as a \"formality\" was send my resume and a list of the other related projects I'd done which was fairly extensive at the time. I think this made him feel inadequate or something, because soon after he started getting really confrontational and controlling about everything. In one meeting he even had the audacity to go on a rant about how \"he was the expert, he understood everything, and all decisions no matter how small had to go through him.\" Eventually said fuck it and found a different position and told him to shove it.\n\nShortly after I left another expert on the project dipped. This spurred the people overseeing everything to review what was going on and the PM ended up getting fired. Luckily the project got back on track after the dude was cut, but it was a horrible experience for everyone. Turns out he was like that with another person who was also very knowledgeable too but didn't end up quitting.\n\nThat why alot of engineers likely finish their job at night, when no one ping them for a stupid checkin.\n\n‚ÄúIs the test server down? Can you check please?‚Äù  \n  \n‚ÄúOh nevermind it works. I think someone was deploying something.‚Äù  \n  \n  \n  \nYes you twats, there are 30 teams deploying shit all the time how am I responsible for guaranteeing they won‚Äôt be deploying while you are testing fuck off massively. Fuck this day, fuck this shit.\n\nI've been there üòÇ\n\nSomeone from another department: \"Hey, we noticed the test site went down yesterday, do you know anything about that?\"\n\n\"When did this happen? How long for? Does this impact you?\"\n\n\"3pm, about 15 seconds, no\"\n\nWhy the fuck are you asking me about 15 seconds of downtime on a service you never even look at?\n\nTEST server with emphasis on TEST!  \n  \nLmao , every day man, every bloody day\n\nCurrent name of a database in production (has been for at least a decade): project_test. There's also a project_staging.\n\nLmao that‚Äôs horrible\n\nAnd that's just the appetizer. Some table got this kind of fields:\n\n * DATE_START_USAGE\n * Date_END_USAGE\n * TYPEUSAGE\n * Contact_MAIN_Prov\n * Contact_Ordr\n * OrderDelay\n * IDUSage_Payment\n\nAnd this lack of case choice extends to table names. Also the joy of a NCONTACT field in a table referencing (no foreign key tho) the Num field in the CONTACTS table.\n\nEdit: I'll let you imagine the state\n\nBut don‚Äôt you know, it‚Äôs an _impediment_ someone raised?\n\nAnd fuck me for choosing this line of work.\n\nIt‚Äôs honestly depressing at times. But when we are actually coding it feels like everything is magical. Just can‚Äôt remember last time I actually coded a feature , I‚Äôm just running around patching things now.\n\nOh my fucking god and the pinging you *immediately* about it. Not only do I know you have the capability to see if a deploy is ongoing, but I also know you have the capability to wait 3 fucking minutes to see if it comes back up. Like any amount of self troubleshooting or critical thought before coming to me, please, I beg\n\nI have a policy of not responding to questions for 5 minutes.  It's just long enough to make the person impatient for the answer and start looking for it themselves.  At least 50% of the time they find it.\n\nWorse, I've had multiple instances of developers deploying code to test, the pipeline failing due to some problem they introduced with a fucking clear error message in the build logs, only to have them reach out immediately to ask what's wrong.\n\nLike I dunno - you fucking tell me man it's not my code that's failing the unit tests.\n\nOop, better create a test incident and start up a call\n\n\"I can't connect to the test postgres\"\n\n\n\"Oh, we didn't even create the DB we're trying to connect to.\"\n\n\nDoesn't even say sorry for wasting my time.¬†\n\nThere‚Äôs no way I would work at night when working for someone else. The moment 5PM rolls around, I‚Äôm done with work and stop thinking about it the rest of the day.\n\nAs a senior engineer, I feel like I help set the expectation for the others that it‚Äôs okay to not be working all the time. \n\nIf you‚Äôre not getting things done because of too many meetings, I won‚Äôt make up for it on my own time. Then it‚Äôs a management problem.\n\nDepends on when you start. For example, maybe you start at noon, so you can work late when nobody disturbs you. One of my colleagues comes in at 5 or 6 am, before anybody else comes in, so they can work 1-2 hours in peace and an additional hour in relative peace.\n\nI'd rather slam my laptop closed on my penis than come in at 5 am.\n\n&gt; I'd rather slam my laptop closed on my penis than come in at 5 am.\n\nI prefer to work at night, but I gotta admit, the days when I start at 0500 and finish at 1400 are the most productive days I ever have.\n\nDon't knock it till you try it. Go to bed by 9 at the latest and getting up at 4 isn't such a big deal. If it means you actually get to, you know, do the work you enjoy; the alternative being struggling to ignore distractions... Plus, getting off work at 1-2pm and having an actual day to enjoy is awesome. Just ask any crusty construction worker you can find.\n\nI come in to work at 7 every day. Sometimes a little earlier than that, like 6:30, and leave by 4 latest. I love it, you actually get to do something after work.\n\n&gt; As a senior engineer, I feel like I help set the expectation for the others that it‚Äôs okay to not be working all the time. \n\nI did that, as the most seniorest of senior engineers on a team (at a very very large company) and got told by my manager that as the senior I should be setting a better example: after all the other guys were all at their (WFH) desks 0600 to 1800!\n\nHe didn't really get that I *was* trying to set an example.\n\nWorking after hours doesn't need to mean working more than an eight hour shift.   With remote it has become easier to put some of that me time into the middle of the day.\n\nDepends on your company really.\n\nIts me and my colleagues (in an outsourcing firm) sometimes. Toxic management consider its an act of go above and beyond.\n\nWe do full-remote, flex hours. So quite often I take off at 1pm (just whenever I feel like it really) and then follow up in the evening when my mind is going anyhow. I'm just naturally more of a night owl and something about jumping into some code at 9pm or 10pm puts me straight into flow state.\n\nI do this sometimes but it's very detrimental to my work life balance. Of course I blame myself because I had \"all day\" to complete my tasks, but after reading this article I don't feel so bad.\n\nA hidden reason I think virtual/wfh companies can do well.  With people spread out all over, we don‚Äôt have the same work hours.\n\nWhere I work, people on the east coast get a quieter morning while others sleep, and on the west clear the get quieter afternoons while others are off work.\n\nAlmost all meetings happen 1-4(EST) to be sure it works for everyone.\n\nI work from home. My wife works from home. And she‚Äôs a talker. Multiple times each day she comes to my office to tell me about the call she just had and how it made her feel. I‚Äôm on my adderall and deep in the weeds in my code and have to just stop and try to pay attention when my brain will just not stop working. It‚Äôs tough.\n\nJust started as a Junior dev at a company and my god are there a lot of meetings. Day starts with 3 hours of meetings, then a company enforced 1h break. Afterwards its 1h of work into 1-2h of meetings.\n\nWhen do you expect me to make any progress? I certainly won't bring it home to me.\n\nI actually started declining meetings. Yes, it's a thing you can do. Go through your meetings and start keeping track of what ones you \\*actually\\* need to attend in order to facilitate your work. It might be that you don't know the answer to that yet, since you're new, which is fine. Learn what you can from the meetings and as you get more settled, you'll start figuring out which ones you actually need to attend and which ones you don't.\n\nAlso, block off time on your calendar for deep work time, set it as busy, and decline meetings during that time unless one is absolutely required (you can be flexible with it, but work to keep that boundary in place).\n\nBe ready to defend what you're doing, as managers in places like that often won't get it. That said, one great way to get them to understand is to calculate the cost of those meetings. The engineers in the meeting probably make 2-4x as much as you if they're not also juniors, and the managers probably make about 2x. So, if there are three engineers and a manager in that hour long meeting, that meeting costs the company in the ballpark of $500 in lost money-generating productivity. Likewise, learn how any deadlines or timeline expectations are calculated. If they're calculated for more development time per day than you actually have, point out that the meetings cut into your ability to deliver your deliverables on time. Always try to frame it as doing what's best for the company or in the interest of being a \"team player.\"\n\nWork will absolutely walk all over you if you don't set and enforce boundaries. Toxic environments won't like it, but the good places will value it.\n\nWhat that image doesn't show is that as soon as the developer leaves the hole, the ladder is withdrawn and the pit is filled with rubble again - \\_that's\\_ the price being paid for an interruption.\n\nThe senior dev on my team hasn‚Äôt wrote a line of code in 3 weeks due to spending all day in meetings or helping various people.\n\nThe beautiful thing with wfh is that I can just ignore slack messages until I can switch context.\n\nWeekly /r/programming front page post:\n\n* Meetings suck\n* Messages suck\n* Managers suck\n* I suck\n\nUse your company's technology.\n\nBlock out your so-called deep thinking time on the calendar as unavailable.   Be reasonable, if you choose to work for a big-corp at least 20% of your week is probably going to be meetings, stand-ups, scrum bullshit, transformation coach pipe-dreams, and HR kumbaya jerkoff sessions, etc.\n\nMake gaps for existing meetings but try to get it so that you have something like a couple of 2-3 hour blocks per day in your schedule.   Announce those blocks to your team and let them know you'll be turning off slack/teams/phone notifications during that time period.\n\nObviously, if you're on-call or a point person during a critical week you'll have to make concessions to your job responsibilities.\n\nThe point of all this isn't to be a jackass, but to start asserting a culture of productivity.  If a manager puts a mandatory meeting on the calendar during one of those times, ask them what other meeting that week you can skip to keep your productivity goal at 80%.\n\nIf you're asked to track your time (and for some reason, only the devs are ever asked to do this) make it very clear how much of your time is spent in meetings.\n\nIf your team does sprint plannings or whatever, make sure to be honest and clear about how many stories can be accomplished given the non-meeting time scheduled for the week.  Don't take 40 hours worth of tasks.\n\nA big part of this is you need to also be efficient in meetings and make it clear which meetings each week you're finding inefficient and time-wasting. \n\nIf none of this works, reconsider how much you need that particular job and use whatever productivity time you have to plan an exit strategy.\n\nThis is the master comment.  This is the only way to survive as a developer in corporate America. You have to be ruthlessly protocol-based with reasonable goals that no manager will be willing to say they want you to miss, and extremely explicit about how the company's mandatory managerial masturbation times destroys the productivity goals you have set for yourself.\n\nPrevious job I had 3 to 5 hours of meetings every day. It was almost impossible to get anything done. In my new job I have 3 to 5 hours of meetings a WEEK‚Äîheaven.\n\nMy lead doesn't want to use automated processes because he doesn't want to hurt collaboration and says if anyone needs to know the status of things or how apis are working they can just ask me (instead of us having documentation)\n\nThis is a shitty lead. :/\n\nAs a tech lead, meetings and supporting my team during the day. Deep work at night...\n  \nI can count on 1 hand the number of significant code or architecture changes in the past decade I've worked on that happened during the day.\n  \nI don't know how to make it better but the nature of my job is to help coordinate and mentor. If you ever work on a team where everyone just gels really well it helps so much. Just when you hit the team flow state I feel like something always fucks it up.\n\nI disagree on better work life balance.  If employees start being able to get twice as much done, they‚Äôll be given twice the work, not extra free time.\n\nEvery couple of years, someone who hasn't read [Peopleware](https://en.wikipedia.org/wiki/Peopleware:_Productive_Projects_and_Teams) (first printed: 1987) rediscovers it.\n\nThe fact this has been generally known for _35 years_ and we still have \"managers need to learn this\" posts about it getting upvoted to the stratosphere, just shows how little learning we do as an industry.\n\nMeetings are called by people who can't really define their job.\n\nAll these articles nitpicking what a bad manager's tendencies are don't necessarily address the root issue at hand: management and leadership are NOT doing their jobs effectively.\n\nAre interruptions distracting? Yes. Are a couple distractions across a project going to make things slower? Potentially -- depends on the type, right? Like if it's to make an adjustment for coordination purposes, that makes sense for management to do.\n\nHowever, when management doesn't do anything other than interrupt, that means they do nothing as a whole other than interrupt or distract. There isn't a need for another article explaining that management in tech are noops which leads to developer unhappiness. It's not the distractions; it's the leaders themselves.\n\nManagers in general are way more harmful than people think.\n\nNever forget the meetings to go over what we just met over yesterday to make sure we schedule more meetings.\n\nIt‚Äôs a popular theory that all managers are incompetent and that the people at the bottom of the chain (who in the end actually make the widgets that the company needs produced) would be better off without them. Is there any actually evidence that this is true?  \nNote that most managers are not incentivised to decrease productivity or increase bugs.\n\nAnecdotally speaking we could make do with a lot less middle management. Main reason I say this is that the more I ignore them and the way they want to get XYZ done the faster I get XYZ done in a way that benefits the team\n\nI've worked in an organization with four levels of middle management consisting of people who are more likely not to have a technical background and an organization with two levels of middle management - all developers - where the director still pushed code and let me tell you the difference was stark. It blew my mind experiencing a manager who could actually enable my productivity instead of constantly hindering it.\n\nThat is not evidence but for my purposes I am convinced most managers are absolutely useless. I have spent way too much time listening to people arguing over T-shirt sizing or fibonacci or whatever. Utterly useless.\n\n&gt; Note that most managers are not incentivised to decrease productivity or increase bugs.\n\nManagers are incentivised to *appear to be increasing productivity* at the same time as increasing productivity. What this means is that if you're the manager of a team that's doing poorly, creating meetings can appear to be trying to right the ship. This is especially true when your manager isn't technical. So when times for review comes around the conversation isn't \"Productivity is down\" it's \"Productivity is down *and I'm fixing that with all of these new meetings and processes*\"\n\nNon-tech managers managing tech people are plague in software industry.\n\nI tried explaining to my GF once by telling her to imagine I'm building a house of cards in my mind and that when she's asked if I'd like a cup of tea they all come crashing down and I have to start again. Yes, the do not disturb, yes this means you, even if there's a fucking fire sign on the door was 100% legit."
  },
  {
    "title": "Linus Torvalds Lands A 2.6% Performance Improvement With Minor Linux Kernel Patch",
    "body": "",
    "score": 1957,
    "url": "",
    "created_utc": 1730455369.0,
    "author": "Akkeri",
    "permalink": "/r/programming/comments/1gh1vlq/linus_torvalds_lands_a_26_performance_improvement/",
    "all_comment_text": "‚ÄúFine, I‚Äôll do it myself‚Äù\n\nThat's been his motto for decades now üòÇ\n\nWe even got git out of it :)\n\nHe even joked that he was so self-centric that he named  every software he made after him. First Linux, now git.\n\nHe didn't named Linux as Linux. Ari Lemmke did that when he made space for it in Funet.\n\nYes, I know. Linus was joking when he said that he was naming his programs after himself.\n\nBut still strange that Linus wanted the kernel he wrote _freax_, just because it feels so strange.\n\n‚ÄúThis is a variation on a patch originally by Josh Poimboeuf‚Äù\n\n2.6% synthetic score if even fractional in live environments will literally be hundreds of millions of dollars saved in electricity and HVAC cost.\n\n[deleted]\n\njust means we'll spend the electricity on something else lmao\n\nBy that logic, though, we could save even more by not using computers.\n\n[deleted]\n\nNot substantially. The per capita usage of something like 70% of the world is a bare fraction of the top 30%.\n\nJust genocide those people. Problem solved.\n\n[https://pbs.twimg.com/media/FSG0o8nWQAE9rgl?format=jpg&amp;name=900x900](https://pbs.twimg.com/media/FSG0o8nWQAE9rgl?format=jpg&amp;name=900x900)\n\nIncredible\n\nyou start\n\nComputers have allowed us to improve the efficiency of many systems and reduce pollution more than they cause. It's hard to notice it because the population increased exponentially over time.\n\nJust as a thought experiment, what do you think pollutes more, sending an email, or sending an actual mail that has to be physically transported by a car?\n\nOr, I'm bored, I'm just going to go online and watch a movie or use Reddit, versus I'm going to physically go to another part of the city to engage in a fun activity in real life?\n\nOn a long enough timeline it will always be the e-mail that uses more energy:\n\nIt‚Äôs stored on a 24/7 online disk at your cloud provider and uses a tiny bit of electricity moment for moment until you delete it (which never happens).\n\na well regarded comment\n\nAhhh the good old ‚Äúbenevolent world exploder‚Äù https://en.wikipedia.org/wiki/Negative_utilitarianism#The_benevolent_world-exploder\n\nWrong, Linus's solution allows the same amount of computation compared to baseline. \n\nYour solution completely bars any computation from happening. \n\nAnd no, your brain not computing when you wrote your comment did not help with climate change at all.\n\nMy motto is the best code I write is the stuff I can plan not to.  YAGNI\n\nYes, it‚Äôs unnerving that you paint it as something surprising.\n\nthe people don't want to hear it... but you're right. logging off now thanks\n\nThe climate is always changing, he pushed back man made climate change not climate change.\n\nEdit: Being downvoted for stating a fact...fucking hell reddit...at no point did i say man made climate change wasn't real. Without us the Earths climate will change just the same as it always has its a dynamic ever changing system. Reddit is fucking hard work, my house was under 100m of ice 27,000 years ago ffs, in the Jurassic it was underwater at the equator thousands of miles from where it is today....what a bunch of fucking cunts.\n\nEdit: Wow 60+ downvotes....humanity is fucked maybe we can get it to 600 that will change the world for the better right? Come on you cunts downvote me. \n\nEdit: 100+ downvotes, you can do it you cunts, once you get 600+ people in the real world will listen to your stupid ideas honest. Reddit downvotes are important don't waste them on other posts use them on mine.\n\nEdit: Its been 3 hours and you idiots have only got me to 130+, no wonder your lives all suck if this is representative of the effort you put into it.\n\nEdit: Two fucking days and only 340 downvotes, what a bunch of pussies.\n\nYou made your point badly and got downvoted. Then you got mad about getting downvoted for making your point badly. Now you're also going to get downvoted for bitching about getting downvoted.\n\nNo worries. The industry will find some other FAANG cargo cult bullshit to offset that right off. If you are not running a landing page on a 10K/month Kubernetes cluster then why bother at all?\n\nIronically Kubernetes can be used with consumer and low powered machines which doesn‚Äôt require things like UPS‚Äôs or HW RAID to run since you got redundancy through software instead of hardware. Workloads can also be rebalanced/optimized automatically to run on idle HW in the cluster, which in practice reduces the amount of machines needed.\n\nBut instead people rent a managed cluster on traditional server hardware which is unnecessary and expensive, especially for what they get and need it for.\n\nA 3 node RPI control cluster with some mini PCs or retired HW as workers are fine for most small to medium sized companies. It can easily run more heavy applications + be configured in high availability, all that with less than 1KW of power on high load.\n\nIf you use cilium the cluster will even be resistant to DDoS due to BPF and routing on kernel level.\n\nHmm did you ever k8s a 3 node cluster ?\n\nI know someone who once deployed Kubernetes onto a tank.\n\nWas it a fish tank?\n\nFaang uses bsd for their stuff btw !!\n\nThe performance regression was due to spectre mitigations. This patch mitigates that regression on supported builds.\n\nIt's not going to save electricity, because they CPU will just be tasked with doing even more work. I mean I guess you could say it's more efficient per unit of work but it's just going to do more work now. So it's not going to save energy in total\n\nCan someone ELI5 the changes he made?\n\nDisclaimer: I'm not a kernel dev so take my answer with a grain of salt\n\n\nMy reading is. The kernel wants to copy some user data somewhere else. If the user manages to give a bad pointer (memory they don't own) the kernel shouldn't do the copying. There was an exploit called specter where you could use speculative execution in the cpu to indirectly figure out what the values in the forbidden regions are by basically timing the operation. In order to prevent this exploit, code was introduced which led to an overall slowdown in execution. Now Linus changed that code to instead of doing an expensive failure dance he zeros out the copied results if he detects the user doesn't own the data at the address. This is much faster\n\nNot exactly, but close. The memset on failure was already there, the speedup comes from attempting to avoid the `access_ok` check altogether because that particular style of pointer checking requires disabling speculative execution to be secure. This is the source of the slowdown.\n\nThere's a new function that avoids a conditional access check and instead changes any invalid pointers to all 1s (which will always fault and trigger the memset as well) in a way that's compatible with leaving speculative execution enabled, which is much much faster.\n\nSimplified, before it was\n\n    bool success = false;\n    if (ptr_is_good(src)) {\n        // CPU might be speculatively executing this even if the pointer check fails\n        barrier_nospec(); // Tells cpu to stop speculative execution (massive slowdown), now it's safe to read src\n        success = do_copy(src, dst, len);\n    }\n    if (!success) {\n        memset(dst, 0, len);\n    }\n\nAnd now it's\n\n    src = mask_invalid_ptrs(src);\n    // No branch to speculate on, and no chance of src being someone else's memory anyway\n    success = do_copy(src, dst, len);\n    if (!success) {\n        memset(dst, 0, len);\n    }\n\nThe reason that it wasn't done earlier is because this new function was just added to the kernel in August, they just haven't gotten around to updating all the places it's useful.\n\nLinus explains it better in the original commits if you care: \nhttps://github.com/torvalds/linux/commit/2865baf54077aa98fcdb478cefe6a42c417b9374\n\nhttps://github.com/torvalds/linux/commit/86e6b1547b3d013bc392adf775b89318441403c2\n\nThank you for the explanation but can you explain tf is happening in the pull requests section?\n\nThat GitHub repository is just a mirror, Linux Kernel doesn't use GitHub Pull Requests to accept patches. So it's just a bunch of idiots in there, that's what is happening.\n\nThe other comment explains the what. The why is that Russian kernel maintainers got the boot last week. Here's what Linus had to say about it:\n\n&gt; Ok, lots of Russian trolls out and about.\n&gt;\n&gt; It's entirely clear why the change was done, it's not getting reverted, and using multiple random anonymous accounts to try to \"grass root\" it by Russian troll factories isn't going to change anything.\n&gt;\n&gt; And FYI for the actual innocent bystanders who aren't troll farm accounts - the \"various compliance requirements\" are not just a US thing.\n&gt;\n&gt; If you haven't heard of Russian sanctions yet, you should try to read the news some day. And by \"news\", I don't mean Russian state-sponsored spam.\n&gt;\n&gt; As to sending me a revert patch - please use whatever mush you call brains. I'm Finnish. Did you think I'd be *supporting* Russian aggression? Apparently it's not just lack of real news, it's lack of history knowledge too.\n\ngd Linus is the best\n\n&gt; https://github.com/torvalds/linux/commit/86e6b1547b3d013bc392adf775b89318441403c2\n\nthis my first time looking at kernel code, and maybe i am missing something, but are there no unit tests or release tests?\n\nThere are tests using KUnit or kselftest, although by nature with so much of it being hardware dependent it can be a bit more difficult to do traditional unit testing and so much more of the testing depends on manual work by the developers and community than in many other large projects.\n\nHow would someone unit test this?\n\nMy 2 cents, patch seems to be forma perf improvement, barring the masking of bad_ptr rest of underlying handling of bad_ptr exceptions remains about same. So existing kunit test case should work and must be able measure the perf improvement.\n\nidk but in my job if you tell me you cannot unit test your code, i will block the PR and ask you to re-structure the code so that it can be tested.\n\nBut, this low-level kernel code might be a different beast tho, i got no experience here\n\nNot that applicable to the kernel, as some parts work on levels that you'd need the kernel running to test. And you don't really send PRs unless you're the subsystem maintainer\n\nThe goal of this patch is to be purely _technical_, no functionality change, thus the exist test-suite -- if green -- will confirm that indeed no functionality changed.\n\nThe problem is that you can't \"easily\" unit-test the functionality I suspect.\n\nYou'd need to create a userspace, create a pointer to memory owned by said userspace and verify it's unmodified, then create a pointer to memory NOT owned by said userspace and verify it's all 1s. All while running in kernel-mode.\n\nIt may be possible, I'm not quite sure how fast it'd be.\n\nWould one not assume that the \"ptr_is_good\" function almost always returns true as in a vast majority of cases? Which as a result would mean that cpu branch prediction could accurately predict it in most cases, not leading to a huge loss?\n\nI guess seeing the speed up this is not the case but I'm not sure how the benchmark tests for things.\n\nRight, so that 0.00001% of the time that a malicious userspace program (some say this can even be done from JS inside a web browser but IDK about that) hands in a kernel pointer will get predicted as \"good\", be speculatively executed, then later caught. In a perfect world this is the end of the story because it would be rolled back and be like it never happened, but it's not a perfect world and Intel can't seem to get it right and there are ways to leak the memory.\n\nThe check is actually not slow at all, the slowdown comes from stopping the speculative execution. The `barrier_nospec()` function actually is a macro that expands to the x86 `lfence` instruction, what this does is hold up all memory loads and doesn't work on any new instructions until everything that's already in progress is complete. Modern processors are fast because of their pipeline that is working on several instructions at once (modern x86 has a 14 to 17 stage pipeline depending on product), so by issuing this instruction, you're very briefly turning off the last 40 years of optimization that Intel has done on x86.\n\nThe new check is almost the same and it does have a branch internally, but because it assigns the result back to the source, the CPU can't speculatively execute the memory read because it doesn't know what the pointer will be until the the last second. This is incompatible with speculative execution and branch prediction, but the pipeline stays full so it's faster than the secure alternative. If you don't care about a secure kernel, you can turn all of these mitigations off and get a decent speed boost.\n\nDoes this code run all the time, or only in special cases? What I want to know is, does the performance boost affect real life performance or just some edge case that is a big meh?\n\nIt's on a synthetic benchmark so it's not clear to how much real improvement it leads. The part that slowed everything down used to be called almost every time. Now it's not being called as often anymore (it's still called in some circumstances)\n\ncopy_from_user is called /a lot/.\n\nSpeculative execution happens pretty much every time there's a branch. So if you have an if-else or a loop in your code then this will speed that up\n\nThis is not a global improvement to speculative execution (that‚Äôs impossible to do via the kernel). It is an improvement for a kernel check against reading from an invalid address. This will not speed up your own if-else statements.\n\nSo it's a general memory safety performance improvement?\n\nNo. It‚Äôs a different way to be safe that‚Äôs faster because the code doesn‚Äôt need to disable speculative execution.\n\nIt's specifically for cases where the kernel is copying data from a user space pointer. For example, your program wants to write data to a file, so it passes an address and length to the kernel via a `write` syscall. The kernel has to check that the program is allowed to read that region of memory before proceeding. It's this check that has been optimized.\n\nCaveat: I don't know if the `write` syscall actually involves this code; it's just an example of one way user space passes untrusted pointers to the kernel.\n\nIt's easy to fool Redditors with nonsense, but why do you choose to?\n\nIf you know that my post is wrong then why do you choose to be an ass instead of posting constructive feedback?\n\nSo instead of making Linux 2.6% faster, he simply restored the performance to where it was before the exploit was patched?\n\nCode change for those interested: https://github.com/torvalds/linux/commit/0fc810ae3ae110f9e2fcccce80fc8c8d62f97907\n\njust a few lines of code? Thats wild!\n\nWhat, you only changed seven lines of code this sprint? Off with your head!\n\nüòÇ\n\nReminds me of the Steinmetz‚Äôs story.\n\n&gt; Making chalk mark on generator $1.\n&gt; \n&gt; Knowing where to make mark $9,999.\n\nChanging a few lines - $1\n\nKnowing where to change these lines - $9,999\n\nLots and lots of .5-3% perf issues are just a couple lines of code and most people can‚Äôt be arsed to fix them. \n\nOne of my tricks is go into a concern in the code, make a handful of changes of this magnitude, and then I can amortize the costs of heavy regression testing across a 10% gain instead of fighting people one change at a time for improvements that ‚Äúaren‚Äôt worth it‚Äù.\n\nwell, why else  do you  think he was fired from twitter ?\n\nFounder mode\n\nreturn of the king\n\nThat's more than what you get from upgrading your cpu to the latest generation these days\n\nHardware in general is very fast. Programs are slow because they are written to be slow.\n\nHardware has always been fast if you measure it absolutely rather than relatively. 1950s computers were \"very fast\". That's why they invented them.\n\nNo matter how much you optimize your programs, there always exist some task just beyond the threshold of what today's computers can do.\n\n&gt; 1950s computers were \"very fast\". That's why they invented them.\n\nI think the automation was probably really the key. It was repeatable and could work all day and night without getting tired. Fast was nice too, but take a look at how some professions had big books of cosine tables and how those were created. A computer could create those without error. Even if it took 3 months it was of great value to have expanded, accurate tables.\n\nI agree with your second paragraph completely though.\n\nI mean there‚Äôs always hardware that is shit for the time. For example the switch is not powerful compared to modern computers\n\nThe Switch is a super computer by year 2000 standards. It's actually insane how much computation it's capable of.\n\nSure but for example you cannot run ChatGPT on a Switch so it's not what we consider a \"fast computer\" by 2024 standards\n\nYou can't run chatgpt on even a beefy 2024 desktop PC. For things like that you're talking about server farms not just a \"fast computer.\"\n\nIMHO, programs are slow because of two main reasons:\n\n- Developer productivity via ergonomic abstractions and high-level features is prioritized, often correctly, above raw software performance\n- Memory is still an order of magnitude or two slower than the processor, the working set is often larger than the cache, more programs are running simultaneously, and most programmers (or the high-level-languages they use) don't make much effort to optimize memory access\n\nUnfortunately, in my experience (web backend), I've observed that noticeable performance issues are almost always due to one of two things:\n\n* Running a database query that involves a full table scan\n* Running a database query in a for loop\n\nSo I guess in my experience, software _is_ slow because it was written to be slow.\n\nThat's a really good metric for his resume\n\nHR - \"We realize you have done some quality work but it took you 33 years to do this\"\n\nRecruiters: \"That's nice but we are looking for team players. Could you tell us about the User Story of this improvement, how did you estimate it and how you split this into tasks?\"\n\nYou changed only 5 lines of code that entire month? Bad!\n\nImpressive! \n\nBut serious question - the code has no comments about this and no tests. How do you prevent backsliding ? Linus is 1000x better programmer than me, but how will anyone remember to put these lines in exactly the right order if they ever need to modify / refactor this code? \n\nI genuinely wonder what is the thinking here. The commit contains more info than the code - and it‚Äôs not like you program looking at commits , you need comments where you can see them\n\nThis is an issue that some people have raised in the past already: What will happen to Linux once Linus steps away for good or passes due to age.\n\nHe's smart enough to have reduced his perceived impact in recent years, but lots of stuff still depends on 'as long as Linus is around'.\n\nAnd that's not even touching on him being the authorative voice that keeps the kernel contributors in check - the infighting and squabbling among that bunch is real and I wouldn't be surprised if we end up with multiple competing Linux kernels (see also XKCD's  '14 competing standards').\n\n[deleted]\n\nGreat Man Theory starts to creak once Great Man doesn't have a clear direct successor\n\nIf someone tries to change it and Linus is still alive. Linus will write an email yelling at the person. That's how it's always been\n\nif someone tries to change it and Linus is not alive he will also write an email\n\nThat email will have a PDF attachment...  Ghostscript.\n\nHe's probably already written the program to generate the email.\n\nWestworld vibes. Somewhere out there lives a copy of Linus that soley exists to flame developers for their pull requests\n\nHe needs to teach that trick to Zombie Steve Jobs to get the damn apple UX engineers to stop being fucking awful.\n\nI want Bill Gates to write that sort of \"Why is this so terrible\" email about Teams\n\nOhh, thought he would hire a ghost writer for it.\n\nIf Linus yells an email at me, I'm framing it and putting it in my resume¬†\n\nIs it really? How do they manage to keep working like this in a code base this size?\n\nLinus is really prolific at yelling\n\nBy having many people in charge of other components\n\nBecause people tolerate it despite its toxicity. More than a few people have been driven away, but they don't care.\n\nCan you point to anything specific? I've seen angry rants but they always appeared to be justified.\n\nYou think it's justified to berate people in public? You'd be ok if you made a mistake with your boss or coworkers yelling at you, calling you stupid in front of all of your peers?\n\nIf responses fall on a bell curve, and only the worst 1% get reported on widely, the average internet user won't see the other, more reasonable 99%. What is the tone of your boss, or any given coworker's *worst* 1% of messages? You work with them regularly, so you see their typical attitude, and can identify angry outliers as atypical, not let them completely shape how you think of the other person.\n\nI wouldn't mind the code or commit being called stupid in public, if it was. If it wasn't I'd argue back.\n\nI don't think the boss/co-worker analogy is perfect, but if the berating crossed a line I can understand where you're coming from. But can you be specific so we're on the same page? My only point is I personally haven't seen anything I'd consider toxic - I'm not saying it doesn't exist.\n\nPSA: Demeaning others in public is a toxic behavior and if you do that, it's not cool. There are more effective ways to give feedback and staying silent is always an option.\n\nSure, I agree. I was just asking for an example, which was eventually provided.\n\nI'd argue staying silent is not a great option though - bad code in the linux kernel could have a negative affect on a whole lot of people.\n\n&gt; Of course, I'd also suggest that whoever was the genius who thought it was a good idea to read things ONE FUCKING BYTE AT A TIME with system calls for each byte should be retroactively aborted. Who the f*ck does idiotic things like that? How did they not die as babies, considering that they were likely too stupid to find a tit to suck on?\n\nHard to argue that this one isn't toxic.\n\nTrue, that one's pretty rough, though I think I'd probably laugh it off.\n\nI agree that it's probably not healthy behavior for an open source project.\n\nFor stuff like thia you need to be neurotic about details, so yup, people are going to be driven away. Life‚Äôs unfair.\n\nConsidering every other open source OS community seems to get long just fine without it suggests you don't.\n\nHave you never had the pleasure to interact with Theo de Raadt? Linus is calm and stoic in comparison. But getting yelled at by linus already requires some unique skills, it‚Äôs actually super rare occurrence and not easy to trigger from the perspective of a regular contributor.\n\n[deleted]\n\nThat stuff could be very deeply buried if the lines change for unrelated reasons. Every time you make a change you're supposed to read the git blame for it back to the beginning of time? And what if it was cut and pasted into a different file?\n\nExplicit comments are better than relying on git log/blame.\n\nKernel development is not normal software development. Many things work different and might not make that much sense to the outside. But it works\n\n[deleted]\n\nI think this is one of those pieces of \"feedback\" where the correct reply is \"feel free to write your own kernel and manage the project in any way you see fit\".\n\nGit blame just shows you the specific commit the line of code appeared, so that would be a very short search to the beginning of time.\n\nA good programmer wouldn't dare change lines in kernel without understanding it, and the maintainer certainly would never accept any patch like that. Commit message is much better imo as it doesn't pollute the codebase with essays. Keep it in commits/docs. Of course headers should be well documented and certain parts of implementations can have a small comment if necessary, but no long explanations.\n\nThis is probably code that rarely changes or needs attention, so it seems viable to rely on git features if any change is wanted to be made. And there are people (or at least Linus) who will check the code for whether it makes sense.\n\nTIL I'm somewhat of a Linus myself\n\nTests do exist. There are a bunch of bots that monitor all changes submitted to the kernel and do things like test builds and test boot. For something like this - perf on a popular platform - if there‚Äôs a regression a bunch of people will be receiving emails, possibly before the change even hits git.\n\nedit: Not even speculation about their CI anymore, the 2.6% measurement [literally came from one of the bots testing submissions](https://lore.kernel.org/all/202410281344.d02c72a2-oliver.sang@intel.com/).\n\nThis isn't any more complicated than other part of the kernel. The kernel is notoriously complicated to begin with, and there are already long docs and essays written about how it works. Polluting the codebase with a long essay for most of the lines wouldn't help anyone who are actually contributing to that codebase, as they are well above that level of competency.\n\nA few things. It is exceptionally unlikely anyone should need to change this code in the foreseeable future. Also, if you are going to alter this code, you had better be studying the history of the code before doing so. That would be studying the commit itself. \n\nKernel development is slow and surgical. I wouldn't expect anyone to put their fingers on this again without some deep knowledge of its history.\n\nyou do program by looking at commits\n\nThere could be tests that tests the flow already. The code is also fairly easy to read and Im not a kernel dev which suggests a kernel dev may find it completely obvious which may not need comments. Comments shouldn't be for the obvious\n\nI would argue that you don't need a comment here, because the code is explicit enough.\n\nI mean, when you call `x[i]` you don't comment \"accessing x at index i\", right?\n\nWhat matters is that the _macros_ that are called in this patch are documented properly, so that anyone wondering what the code does can just read that documentation to understand what's going on, and the circumstances in which they can (and cannot) use those macros.\n\nGit has a feature that shows you which commit changed a line of code. So before you change a section of code, if you don't already understand it 100%, you look at the commit messages, which gives you details of how the code evolved to the current state.\n\nI think you‚Äôre under stating the difficulty of looking at a non-cohesive blame layer where potentially each line comes from a different commit and magically read them all and understand them.\n\nYeah, the people saying \"read Git\" are wild to me. Have they never needed to go on a scavenger hunt to find the source of a line before?\n\nHalf the time the blame for a line is some benign refactoring so then you gotta go find the actual commit for when it was introduced\n\nI don't think I made any comment about the difficulty.\n\nYou should code looking at past commits. It's a core part of using git.\n\nYeah right - I look at commits looking for specific issues - this line seems wrong, let‚Äôs see when it was added. Or I pinpoint a problem and I see where it was first introduced. \n\nI don‚Äôt look at commits for normal looking code, and neither does anyone sane. \n\nI‚Äôm sure you instead  read only the commits in sequential order, replicating the current state of the code in your head. Probably don‚Äôt even have en editor, just look at the commit diffs and sum them up in your head. Impressive\n\nIt's part of the kernel dev flow. The commits that introduce the changes are often the documentation. Comments get out of date, the commit message that introduced the change can't, it's permanently tied to the change rather than the line of code.\n\nAnd it‚Äôs generally a terrible way of way of working which is why the vast majority of engineering teams don‚Äôt do it.\n\nAnd it currently leads to much tension as Rust is getting introduced to the kernel. Rust devs are starting to ask questions on how certain internal apis work and what guarantees and requirements those have because you can enforce those in the Rust Typsystem instead of having them implicitly in documentation that does not exists or \"ask Peter who wrote it\" or look at the examples. And some kernel people are really unhappy about that.\n\nSounds like a fantastic way to build software.\n\nwhich apis for example?\n\nSome of the current friction is centered around the FileSystem apis iirc though they may have moved on to others \n\nHere is a summary from earlier this year\n\nhttps://lwn.net/Articles/958072/\n\nUh, that article is fantastic ‚Äì thanks for sharing!\n\nI don't have the exact details in mind. But if you are interested those two threads have articles and video recording in the comments and you should be able to find the concrete examples.\n\nhttps://www.reddit.com/r/rust/comments/1f7q2ap/rust_for_linux_maintainer_steps_down_in/\n\nhttps://www.reddit.com/r/programming/comments/1f44kp0/one_of_the_rust_linux_kernel_maintainers_steps/\n\nthe video in question https://www.youtube.com/watch?v=WiPp9YEBV0Q&amp;t=1529s\n\nEDIT1:    \nI also remember that the person building the Apple GPU driver for Asahi Linux spoke about that problem, but i can't find the post to that currently.\n\nEDIT2:    \nFound it https://vt.social/@lina/113045455229442533    \nhttps://vt.social/@lina/113045456734886438\n\nEDIT3:    \nNot exactly on topic but just in case somebody is interested about the Apple GPU driver story in asahi linux https://asahilinux.org/2022/11/tales-of-the-m1-gpu/\n\nWasn't the problem that the maintainers didn't yet trust those rust devs to understand their subsystem?  Why would they want to facilitate the addition of code there are zero people in the world qualified to maintain? \n\n(The existing C dev not qualified because they don't know rust, the rust dev not qualified because they want to implement to spec without taking the time to deeply understand the subsystem. And nobody around to catch all the losses in translation when the two collaborate.  - And that's all assuming the \"collaboration\" doesn't work like it does at an office programming job where someone drops a massive fudge dragon in your area of the codebase and only pretends like they'll make themselves available in the future when it inevitably needs rework.)\n\nIn this particular case: the commit message looks like a pretty reasonable description of the change (which IMO is as it should be). The comment does explain the motivation (which is unchanged: mitigate transient execution vulnerabilities).\n\nNeither explain in any detail _why_ the code (before or after) does what the comment says it does and that would be my only criticism, and that might be addressed by higher level docs elsewhere (I've not looked).\n\nYou could also argue that learning a bit about these vulnerabilities is \"price of entry\" for working on code on this particular security boundary in a production kernel, the same way that learning C is the price of entry for working on it at all.\n\neh, works for me, I have the git blame up in another window so I can see what people were thinking. I find it better than in-code comments, as long as the project has good commit messages obviously.\n\nAnd what happens when a function is cut-and-paste into a new file in a code organization? Does the git history follow the lines?\n\nIf I hover over it and follow the history, yeh, requires some manual intervention in that case, but it's still got fewer failure modes than comments IME. Fwiw I use emacs and the git time machine extension (plus magit). So it's possible this is easy for me because if my tools. If you don't have equivalent tools YMMV.\n\nGit itself does not track moves of lines of code between files (unless the whole file moves), so I'm skeptical that git-time-machine does that. Are you sure it works the way you are claiming?\n\nI didn't say it tracks it, I just click onto the moved code, then navigate to the commit, run magit diff and jump to the original code, then follow the blame back further if I need to. As I said it requires some manual intervention, but it's a couple of key presses\n\nI'd argue that kernel level programming is except from the bais of what the majority is doing.\n\nNonsense. It isn‚Äôt special. Software is software. Some of it hard to write or build. Some of it is more critical than others. All of it needs an onboarding process that isn‚Äôt ‚Äúlearn the entire history of how this single line got here‚Äù or ‚Äúask Paul.‚Äù\n\nAt the end of the day though, \"learn the history\" is basically the only *always reliable option*. Documentation is frequently born inaccurate or incomplete, because the people writing the documentation can document what they see, but not the answers to questions they haven't thought of.\n\nI am at a point in my career where I rarely reach for the documentation- I instead just read through the code and check the history. In some cases, it may take longer, but I've encountered enough traps in documentation that I think on average it saves me time- no more spending days going \"I did what the documentation said! WHY ISN'T IT WORKING!\" only to discover that the actual code deviates from the documented code.\n\nThe hierarchy of useful documentation, as a user of other people's code, is:\n\n* The code itself\n* Commit messages\n* Comments within the code\n* Actual \"documentation\" files\n* Talking to people\n* Any sort of autogenerated Doxygen-type garbage\n\nThat‚Äôs a bit like arguing that you walk everywhere because sometimes trains get cancelled. \n\nI agree that at the end of the day code is the only truth but I don‚Äôt think that implies ‚Äúlet‚Äôs get rid of all the comments‚Äù then. \n\nIf you can write something like ‚Äúnote: code below is performance critical, see commit zxxyyy for more info‚Äù, I think you should. \n\nTrying to argue that we shouldn‚Äôt make our lives easier in 99% of the cases  because for that remaining 1% we have to look at commits anyway doesn‚Äôt make a lot of sense to me\n\nI'm arguing that it *doesn't* make my life easier. What's easy is reading the code, if the code is any good. And if the code isn't any good, the documentation certainly isn't going to be.\n\nWhen I started my current job, I was taking over a gigantic legacy codebase which wasn't even written in house, and within three months I was the department expert because *I read the code*. I skimmed the docs, too, but the docs weren't nearly as helpful.\n\nTo be a bit more formal in this: code is the primary representation of what the code does. Everything else adds entropy. Even if the docs are actually complete and accurate, they still contain more entropy than the code itself. It's going to take longer to read the docs than read the code, if the code and the docs are both good.\n\n1. Why do you think this code needs comments? It's not particularly complex or difficult to understand.\n\n2. The kernel already has tests to check for vulnerability to speculative execution. This is simply changing the internal implementation of how the kernel protects against it in a particular scenario.\n\n3. Looking through git history to better understand the code you are changing is not a huge ask. I'd argue that's a bare minimum expectation of a competent software engineer.\n\nThere are some things I view as good software hygiene. The overall experience is better in general when certain things are true about a software repository. Most of it subjective but some of it is actually measurable. Maybe they don‚Äôt apply in this case, but I doubt it. In general the whole process for the kernel sounds awful to work in.\n\n&gt; I don‚Äôt look at commits for normal looking code, and neither does anyone sane. \n\nOf course I don't, because I'll find a series of 10 commits that should have been squashed, the description is a useless minimal one-liner, and maybe a JIRA ticket number. Neither the ticket nor the pull request have a useful description of the change either.\n\nDealing with a web service and a kernel are different things. Everything there has a purpose and if a reason doesn‚Äôt seem obvious vs an alternative, 100% looking back at git log. Critical path code and algorithm type stuff just function like this, it helps when there are comments though to save you from needing to look back.\n\nAnd what if the code is cut and pasted into a different file with an unrelated commit history?\n\nYou say that in the commit message, I suppose?\n\nAnd what if code and comments are taken out of a file? Do you leave comments explaining what used to be there?\n\nWhat would it take to get the code adequately commented? Like, assuming someone wanted to do it and had the patience to interview Linus about his code\n\nNothing crazy, but something like :\n\n// note: the following code is tricky - doing x instead of y might result in performance degradation. Look at commit xxxyy for more info \n\nWould already be much better imo.\n\n```c\nif (should_fail_usercopy())\n+\t\tgoto fail;\n+\tif (can_do_masked_user_access())\n+\t\tfrom = mask_user_address(from);\n+\telse {\n+\t\tif (!access_ok(from, n))\n+\t\t\tgoto fail;\n```\n\nI love to see when the biggest mind in the programming world essentially go against every single programming principle I was taught in academia.\n\nenjoy follow consist quiet jellyfish retire sparkle drab deserted ancient\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*\n\nDykstra was not discussing goto in the style of c programs. Goto in c programs cannot be abused in the way he was discussing. To see the type of programs that he was talking about being harmful look up the apple 1 monitor program, WozMon. Removing or moving any part of the program would destroy the program flow of parts of the program you would believe are unrelated. Which in the case of wozmon is alright, it was designed to use that control flow scheme intentionally to produce a very, very small monitor program. For most systems it‚Äôs terrible design.\n\nmuch like a master painter, gotta know all the rules to break all the rules\n\nHaving a shared fail state is one of the few popular (accepted) use cases for goto iirc.\n\nWhat other programming principles does this seemingly go against? Single line conditionals?\n\nTbh this \"goto fail\" pattern seems fairly common for post-error cleanup with C and C++-ish, at least when I was doing embedded\n\n&gt; The kernel test robot reports a 2.6% improvement in the per_thread_ops benchmark.\n\nWhat does this benchmark measure?\n\nEdit: According to the [linux test robot email](https://lore.kernel.org/all/202410281344.d02c72a2-oliver.sang@intel.com/), the benchmark being run is eventfd1, which I believe is [this file](https://github.com/antonblanchard/will-it-scale/blob/master/tests/eventfd1.c).\n\nThis test uses the eventfd syscall to create an eventfd object. In a loop, it increments and resets the value attached to the eventfd object. This requires the kernel to read memory from a pointer provided by the user, which is why `copy_from_user()` is relevant. The kernel ends up doing a large number of 8 byte reads and writes to userspace. Also, this is done in parallel across every core.\n\n[deleted]\n\n\n\n    # Commit: Optimized my search algorithm\n    index fadcb8\n    -       sleep(10)\n\nI hate getting kudos for deleting my own code. Feels like getting credit for turning the lights back on when you‚Äôre the one who turned them off.\n\nIt‚Äôs mostly theater for the other people who would *never* delete their old code because everything they wrote is perfect. But it still feels dirty.\n\nJust GOAT things\n\nMaster\n\n        #define mask_user_address(src) (src)\n        ...\n        from = mask_user_address(from);\n\nCan someone explain what this mask_user_address actually does? I can't see how this is useful in anyway\n\nThe improvement is architecture-specific, so there will be different implementations of this for e.g. [x86-64](https://github.com/torvalds/linux/commit/2865baf54077aa98fcdb478cefe6a42c417b9374#diff-e243c96dba28c664d5378064fe6c1a04bf578e2b935359657f15265927f64ecbR61).\n\n    #define mask_user_address(x) ((typeof(x))((long)(x)|((long)(x)&gt;&gt;63)))\n\nPer the commit message:\n&gt; With this, the user access doesn't need to be manually checked, because\na bad address is guaranteed to fault (by some architecture masking\ntrick: on x86-64 this involves just turning an invalid user address into\nall ones, since we don't map the top of address space).\n\nI wonder who's capable to be his successor\n\nHaving a shared fail state is one of the few popular (accepted) use cases for goto iirc. What other programming principles does this seemingly go against?\n\nHow is this even noticeable really? Maybe to a server that's cranking thousands of users?¬†\n\nGiven the number of servers doing just that running Linux, it‚Äôs a possibly useful effect. That said, I seem to remember a kernel feature from way back called zero-copy which avoids copy_from_user altogether, so maybe who knows? But given the maturity of the kernel, maybe the gigantic optimizations are largely behind us.\n\nIf governments worldwide each funded 1,000 people to work on improving the Linux kernel, would that likely make a significant difference? \n\nCould it be an effective way to boost GDP, reduce power usage, etc.?\n\nHe is a genius, there are always things to improve and Master Linus is still doing it.\n\nBoss showing why he's the boss!\n\nGOAT\n\nLinus is a dick, but that MFer knows his shit. Hats off to him.\n\nHe shares the place of my Kings on life\n\nPure speed"
  },
  {
    "title": "Cloudflare took down our website after trying to force us to pay 120k$ within 24h",
    "body": "",
    "score": 1807,
    "url": "",
    "created_utc": 1716739871.0,
    "author": "RayNone",
    "permalink": "/r/programming/comments/1d14rb7/cloudflare_took_down_our_website_after_trying_to/",
    "all_comment_text": "The fact that it‚Äôs an online casino that faces bans and ban avoidance is relevant. \n\nSet aside the bandwidth and compute resources, you‚Äôre going to pay a premium because there‚Äôs a much higher likelihood of abuse and fraud and legal hassles for the provider. I expect you‚Äôll find that‚Äôs true at Fastly too.\n\nCan you explain this more to someone who doesn't get it?  \n\n&gt;We mainly use CF for the CDN (caching all our static content) and DDOS protection, for which it works pretty well. It‚Äôs easy to use and you don‚Äôt usually have to think about it much.\n\nDo you think they got attacked or what?\n\nBoth attacks and being banned by IP.  Reading the article, a major point was the requirement of BYOIP.  The site was probably being blocked in places, which meant cloudflare IP ranges being blocked which could affect all cloudflare's ability to do business.   The $10k a month was probably the minimum they felt dealing with the byoip and other issues was worth in this case.\n\nThis is the good stuff right here! I wasn't familiar with BYOIP, but after I looked it up, it makes perfect sense that it would cause these exact issues.\n\nThank you for taking the time to explain this.\n\n&gt;The $10k a month was probably the minimum they felt dealing with the byoip and other issues was worth in this case.\n\nIf that were the case, and CF had been straightforward about it from the beginning, this article would never have needed to be written.\n\nETA: this article reads like a series of major communication breakdowns on CF's part. Regardless of whether their account should or shouldn't have been suspended, it appears that every attempt at communication by the customer was redirected or sidestepped, ultimately resulting in downtime - the worst case scenario for any online business. \n\nThis would have been prevented with better communication/notice, and the casino could have either ponied up or migrated off the platform.\n\nIt looks like the May 7 conversation was completely straightforward; the OP just didn't like the answer. It clearly went something like:\n\n&gt; Trust and Safety is demanding you BYOIP immediately. That requires an enterprise plan and here is your quote.\n\nA week passes and they don't accept the plan.\n\nSurprised Pikachu when Cloudflare terminates the account.\n\nthat's the issue though - it isn't clear from the communications that were provided. We might assume CF's intent in hindsight, but even after multiple meetings with CF, including this customer's CEO directly talking to them, it is apparent from the article that they did not expect to be cut off at that time - if they had, they could have started their emergency migration earlier and avoided some or all of the downtime. \n\nFor that to come as a surprise after all that, there must have been some serious misunderstandings or miscommunication. \n\nThe customer was up and running until more than 7 days (2 extra days) after that 1-week email, which would imply that they either reached some sort of agreement to either temporarily extend the deadline, or CF independently decided not to cut them off at that 7-day mark.\n\nI‚Äôm not saying you‚Äôre wrong, but the charitable interpretation would be that CloudFlare gave them an *extra two days* before finally cutting them off.\n\nAlternative take: this article is rose-tinted to the point of absurdity. The CEO calls Cloudflare to negotiate the sales contract and hours later they're blindsided with a purge? I guess the sales team got bored and wanted to go home. I'm sure no details have been left out here, no way.\n\nCF was probably violating enterprise contracts for other clients that had terms against  sharing IPs with gambling sites and other sites that can get IPs blacklisted.  Probably why CF has a bring your own IP requirement.   back in the day they allowed everyone but that was a big issue for large enterprises who didnt want to share IP addresses with the Neo Nazi site, the daily stormer.\n\nThat's a reasonable argument, and hard to disagree with, but if that were the case why weren't the cloudflare sales/marketing/etc people up front about it? CloudFlare still comes out here as the villain.\n\nCasinos and sports betting sites attract trouble. Thats just a fact. Even if this particular customer didn‚Äôt cause problems yet, they are in a category that is likely to cause trouble in the future. \n\nI think it‚Äôs no coincidence that CF called out DNS block evasion in one of the emails.\n\nSo do banks and any large company. 120k/yr is a steal. We paid 400k/yr with another provider to protect the company I was working for several years ago. It‚Äôs not cheap to defend against ddos that‚Äôs for sure.  That was for 10g of protected bandwidth.\n\n&gt;Casinos and sports betting sites attract trouble. Thats just a fact.\n\nYeah I just don't get how they do for the host specifically.\n\n&gt;CF called out DNS block evasion in one of the emails.\n\nYeah this is what I'm more interested in, like there has to be some reason.\n\nPeople run illegal gambling sites.\n\nCustomer has infrastructure for this.\n\nCustomer can easily set up an illegal side website which violates laws in specific regions.\n\nCloudFlare don‚Äôt want that on their doorstep.\n\nAlso, maliciously-inclined tech savvy individuals are attracted to those sites, so require more protection, so more resources\n\nYoup. The last part especially. Online casinos represent a huge payout if you get in and very low risk, because they're legally grey at best in most countries and no government is going to try very hard to go after someone who stole from an online gambling casino.\n\nExcept maybe Australia. They seem to really like the paydays they get from the gambling cartels.\n\n[removed]\n\nIronically, scammers and phishing stuff are likely less of a liability to CF than gambling sites.  Gambling's just legitimate enough to have government regulation going on, and the known money changing hands is going to make the site a more appealing target in general.  \n\nWith scams you just deactivate the account if someone complains and you're done, with gambling there's an international legal quagmire to deal with.\n\n&gt; Yeah I just don't get how they do for the host specifically.\n\nCloudflare uses shared IPs for most service tiers (or unless you BYOIP); if those get banned by various governments where internet gambling is illegal, that affects their other clients.\n\n1. All Cloudflare-proxied websites come through just a small pool of IP addresses ‚Äî the multi-homed addresses of the Cloudflare Points of Presence.\n2. When you a have popular and high-profile site that's also illegal in many regimes and \"immoral\" in many cultures, it gets put on the private blocklists of various corporations and security-product companies.\n3. The dumber of these blocklists, try to block the IP address of the host ‚Äî which, for a Cloudflare-proxied host, ends up blocking an entire Cloudflare POP ‚Äî and so *all* Cloudflare-proxied websites for users accessing Cloudflare through that POP.\n4. IT departments who block Cloudflare by IP are too dumb to realize that Cloudflare having only a small pool of IPs is a \"them\" problem to solve, not a Cloudflare problem; and organizations that rely on third-party blocklists that block Cloudflare by IP tend to assume their blocklist is always right and anything it blocks is \"broken\" ‚Äî also complaining, in this case, to Cloudflare, when it doesn't work \"through their software.\"\n5. So Cloudflare has to reach out to these blocklist providers and/or the IT departments of these corporations to fix the problem. And it's a big-ass hassle, that can take hours or days to get resolved, meaning hours or days of their own ops people's time is wasted doing this instead of something more useful, costing Cloudflare real money. Cloudflare wants to not have to pay these costs.\n\n[deleted]\n\nDeats\n\nHaving worked at a different CDN, casinos are under non stop attack.  They kind of suck as a customer.  And attacks on the casino can effect other customers that depend on shared infrastructure.\n\nIt's a website, dedicated to having masses of kinda shady money flowing through it, with a somewhat vulnerable user base, run by a non-tech company.  In terms of cost/benefit ratio for hackers it's like if your favorite celebrity crush was begging to give you oral sex, and if you let them they'll sign a petition for your favorite political policy.  From a hacker's perspective there is basically zero downside to attacking a gambling website.\n\nAnd FWIW, I disagree with the framing of the headline.  A CDN doesn't \"Take Down\" your website.  They just stop doing the work to keep it up.  It's your website.  You can self host it.  You can find other people to host it.  Nobody has a responsibility to keep your website up but you.  Anybody who depends on a certain cloud service should have a backup plan for that cloud service going away.  Business relationships end for a million different reasons every day, and somebody isn't taking down your business or doing you harm if they decide to stop doing business with you because doing business with you is a lot of work.\n\n&gt;In terms of cost/benefit ratio for hackers it's like if your favorite celebrity crush was begging to give you oral sex, and if you let them they'll sign a petition for your favorite political policy.\n\n\nA truly relatable scenario we are all intimately familiar with and not oddly specific or unnecessarily sexualized in any way.\n\nUsing hyperbole was intentional.  The average person doesn't have anything in their real world experience that serves as a relatable metaphor for the cost benefit analysis of cyber attacks on gambling websites from a criminal's perspective.\n\nplease give up on posting if that was the best metaphor you were able to come up with\n\n&gt; Set aside the bandwidth and compute resources, you‚Äôre going to pay a premium because there‚Äôs a much higher likelihood of abuse and fraud and legal hassles for the provider. I expect you‚Äôll find that‚Äôs true at Fastly too.\n\nCan confirm. I run a website with adult content behind CF free tier and move multiple dozens of TB per month without them ever complaining. They block 5k-10k attacks every month, although most of them are likely just bots in US server farms that do automated vulnerability scans.\n\nAn online casino of course is a much higher value target, and the 250$ per month was probably no longer cutting it anymore. Sure they offer unlimited DDoS protection, but unlimited almost always really means \"within reasonable limits\".\n\nWait... am I reading this correctly that you're paying CF nothing for hosting a site that serves \"multiple dozens of TB per month\" or am I misinterpreting the comment? Is their free tier really that generous?\n\nNot the OP, but their services are really generous, cloudflare pages is absolutely free iirc (they don't have any limits or restrictions or even a pricing, but you're limited in what you can host stack-wise), and stuff like R2 is around 170x cheaper for my use-case (read heavy with large files) than S3, even cheaper than using minio on a droplet or azure's storage, if your services can fit their intended use-case it's really cheap. but they're honestly kind of limited. they recently added queues that I previously had to implement using a worker and a d1 database because which was honestly painful compared to something like using something off the shelf like sqs.\n\nThere definitely is a pricing to Pages. It depends on the number of builds a month etc not bandwidth itself.\n\nYou can very easily offload the builds to e.g. GitHub Actions. The hosting itself is entirely free, though a notable restriction is file size limit of 25 MBs\n\n&gt; The fact that it‚Äôs an online casino that faces bans and ban avoidance is relevant. \n\nIt is and it isn't.  There is no excuse for treating someone like this.  It's easy for the Cloudflare team to explain the liability, and give them enough warning and time so that it gets fixed. \n\nSo for example, \n\n&gt; I have been advised by our trust and safety committee that we must resolve this issue by July 26th of this year.  You are a valued customer, and we really want to work with you in what is best for your business.   This might be through: \n\n* BYOIP, which is only available on our enterprise plan and it starts at XXX a month.  \n* Using a single primary domain \n* Only have users in XXXX country\n* Migrating from Cloudflare to another provider (which we hope you don't do, we want to keep you here)\n \nOr whatever.\n\nBut customers do respond to being treated poorly.  Even if it's your best choice, if they tell you that you have 24 hours to pay 100k USD you never agreed to, you're going to look for alternatives.\n\nExactly this, the amount of awful takes on here is truly astonishing. This isn't some random company, they've been using them for years and all of a sudden they're being pressured into multiple sales calls to get them signed up to an enterprise plan for almost 50x the price. \n\nIf they had legitimate issues they could have outlined exactly what the issues were in a simple email and provided adequate time for them to either upgrade or move on with an alternative provider.\n\nWhat do you want to bet all that happened, and it's just being glossed over? Bet you anything the listed account contacts are engineers who reflexively delete anything that looks like it might be sale-y.\n\n&gt; I'm a SysOps engineer at a fairly large online casino. We have around 4 million monthly active users. We had been happy Cloudflare customers since 2018 on the \"Business\" plan which has some neat features and costs $250/month for \"unlimited\" traffic.\n\nIf they were CloudFlare's customers since 2018 and they CF knew that they were a online casino since then it would stand to reason that any point they could have discussed moving them to an enterprise tier.  For 6 years CF didn't mention it and all of a sudden they want to move them?  Without at least a grace period?\n\nIt was poor planning on CFs part and their customer had to suffer.\n\nIt‚Äôs pretty likely not a single human from CF looked at their site. That $250 plan is fully self service. \n\nI agree there should be a grace period.\n\nThat's fine but I have a hard time seeing a justification for this behaviour from cloudflare (if there's isn't more to this story). If cloudflare had publicly shared criteria for what bandwidth/resources they support after which you are required to go enterprise, this would be perfectly justified. Since they don't, it is still ok to change the terms and ask to pay more but there needs to be enough time given to their customer before pulling the plug on the services. To be clear, it's ok for cloudflare to ask for more, but to change the terms, barely give the customer any time, and ask for a 1 year commit contract, to me is a bit worrying.\n\n&gt; had publicly shared criteria ‚Ä¶\n\nThat is basically how most enterprise sales work. There is no public information about pricing. Even there is, the number is likely to be heavily inflated. I am not saying this is right, but it is what it is.\n\n&gt; barely give the customer any time, and ask for a 1 year commitment contract \n\nThat is for both side. It‚Äôs very hard to make your service provider make a commitment without you also making one.\n\nThe lesson here is simply don‚Äôt run your multimillion business on a 250/month subscription without SLAs or contracts.\n\n&gt; The lesson here is simply don‚Äôt run your multimillion business on a 250/month subscription without SLAs or contracts.\n\nFucking this. \n\nI've dealt with this way more that I've wanted to in the ISP world, where we've had businesses shouting at us not to make changes to our $50/mth residential broadband offerings, because those changes would break their applications and lose them tens of thousands of dollars per month until they could fix them.\n\nIt took way longer than I liked before we got a product manager willing to say 'that seems like a you problem; can we interest you in our substantially more expensive business grade services where we actually guarantee you the behaviour you need (more expensive because following through on those guarantees makes operations more of a hassle)?'\n\nBut enterprise sales is not normally high pressure.\nUsually it‚Äôs ‚Äútell me what you need and how much money you have and we‚Äôll see‚Äù. The lack of transparency in pricing hurts small customers, but then small enterprise customers are more expensive per user than big ones. \n\nArtificial 24hr deadlines are usually something you see in consumer sales where there‚Äôs no valuable\nlong term relationship to damage by trying this sort of bullshit. I‚Äôm guessing from cloudflares point of view a difficult customer with tons of cash that‚Äôs currently paying only a bottom tier price doesn‚Äôt matter that much\n\nRight. ¬†Everything was reasonable on both sides. Except the 24 hour deadline to sign an annual contract\n\nWhat‚Äôs more relevant IMO is the fact one of the largest names in hosting was incapable of holding one coherent conversation with a long paying customer. That communication chain was a clusterfuck.\n\nHe‚Äôs quite liberal with the truth too, contacted months before, has 4million users and ‚Äúdoesn‚Äôt remember‚Äù if they use 80Tb of data a month, he‚Äôs a scummy cunt and he knows it. He‚Äôs sitting them with a grin on his face thinking how many months he used Cloudflare on their business plan for fuck all per month. A long list of domains for ban avoidance in certain countries to top it off.\n\n[deleted]\n\n[deleted]\n\nJust because it's a casino doesn't mean you can extort them with a 24 hour deadline and a 50 fold increase in price. That's straight up criminal racketeering.\n\nI agree that‚Äôs not cool. I would be interested to hear their side. Seems like maybe they were causing problems or at least potential problems for other customers. \n\nBut that‚Äôs not what racketeering means. Most hosting companies can and will terminate you for AUP violations without notice in this process range.\n\nRegardless of this, if you read the text it really is pretty scummy from CF. You can't expect anyone to be able to migrate away within 24 hrs. There is no other way than to call this extortion.\n\n[deleted]\n\nThe Cloudflare suspension email mentions the company violating TOS. However from the conversation it looks like they would have over looked it if the company decided to pay the 120k. Kind of shady from Cloudflare side too.\n\nPresumably because the enterprise contract might have different terms and enable compliant ways to handle other things (BYOIP)\n\nI think [this writeup](https://www.reddit.com/r/programming/comments/1d14rb7/cloudflare_took_down_our_website_after_trying_to/l5sdush/) is a pretty good guess at the full story. The idea is that maybe it's not about the ToS, it's about the mere fact that:\n\n* OP is an online casino, and some countries want to ban those\n* Some bans are by IP alone, so banning OP would impact other Cloudflare-fronted sites\n* BYOIP would resolve this\n\nYou could read this as the only ToS-compliant way to run a casino is with BYOIP, but again, it almost doesn't matter -- Cloudflare isn't going to get everyone else banned to let you continue raking in money from gambling addicts.\n\nSo at that point, the issue is that BYOIP is enterprise-only and they don't have a cheaper way to handle that.\n\n---\n\nEdit: Well, that was a bizarre last-word-block from one of you. It is true that I don't like online casinos and how they exploit gambling addicts. I don't see how that invalidates what I said here, and I only mentioned it to draw attention to one possible contributing factor for CF's behavior. But it does kind of say a lot about the kind of person who goes to bat for an organization like that when their first instinct is to make this personal, and then block -- kind of paints a picture of someone who wants to *win,* not someone interested in finding out who's right.\n\nIn Austria some ISPs block IPs on request due to copyright violations. Well, this happened to a few(!) Cloudflare IPs once and like half the websites using CF were unreachable. Luckily the IP bans were reverted within &lt;24hrs, but I don't even want to know how many customers caused them troubles and blamed them for that. \n\nSo yeah, it's very understandable that Cloudflare does not want its IPs to get banned, it causes huge outages even if it's only for a few hours\n\n&gt; So at that point, the issue is that BYOIP is enterprise-only and they don't have a cheaper way to handle that.\n\nand why don't they clearly explain that to the customer in that way, in technical terms? But send some clueless sales drone?\n\nAnd why wouldn't there be a cheaper way to handle it? CF can set any pricing they want and the 1-year ahead payment within 24 hrs? pretty scummy.\n\nI can think of a couple of reasons. These aren't *excuses,* exactly, it's still a terrible experience, but here's how I imagine this going down:\n\nFirst, like I said in the other thread, any sort of \"trust and safety\" team is going to be set up to be pretty adversarial in the first place, and will often have good reason not to share very much, or even tell you exactly how you're violating a rule.\n\nSecond, this needs *immediate* action to protect other customers, so getting the business parts of the company to agree to a discount on Enterprise (or an entire new product in between Business and Enterprise) might be difficult to in time. Of course, it'll be at least as difficult for OP's company to agree to those terms.\n\nIt's also not obvious that they were talking to \"a clueless sales drone\":\n\n&gt; So we scheduled another call, now with their \"Trust and Safety\" team. But it turns out, we were actually talking to Sales again.\n\nIs that what actually happened, did they end up with someone introducing themselves as sales? Or is this just how they interpret what they were told on this call, where the only solution was a very hard upsell?\n\n&gt; Second, this needs immediate action to protect other customers, so getting the business parts of the company to agree to a discount on Enterprise (or an entire new product in between Business and Enterprise) might be difficult to in time. Of course, it'll be at least as difficult for OP's company to agree to those terms.\n\nThe they could have offered a monthly payment for the 10k and then go from there for further negotiations. I mean it's clear CF wanted to get rid of them as customer so the blog has a point. But CF also has a point not wanting to deal with them unless it pays off big.\n\nYou seem to just want to blame the company. You can clearnt ell the OP left some things out.\n\nIt seems very likely that they did in the original call, which is why they mention in the meeting notes email that BYOIP is a must-have for this account. The blog post is quite clearly omitting important details about what the actual info they got from CloudFlare was.\n\n[deleted]\n\n&gt; I‚Äôm guessing that Cloudflare could not allow that to continue, and helped design a (expensive) technical solution for them that would allow the casino to remain compliant. When the casino refused to pay and implement the solution, their account was disabled.\n\nmaybe and OP is not sharing the full picture. It sounds like CF never clearly explained this.\n\n&gt; I think Cloudflare was asking them to pay 120k because what they want to do with multiple domains while remaining compliant requires features that are only available on the enterprise plan. BYOIP is indeed an enterprise only feature. \n\nYeah if there's anything I find fault with Cloudflare about here, it's the way they do their pricing and service tiers. I'd be much more likely to use them for many more things if it were possible to have a little more feature granularity.\n\nBecause they disclosed facts that they know make them look bad, you think they were hiding facts that they know will make them look bad? It is always possible that somebody is lying, but that seems like the opposite of logic.\n\nIt's a very common strategy. Admitting to *some* bad facts to make yourself seem more credible https://en.wikipedia.org/wiki/Limited_hangout\n\nyes, that's the common tactic. Admit small things to distract from big things\n\n[deleted]\n\nsomething is not right here, you were paying $250 per month for a website with 4M MAU and unlimited traffic? have you realized how expensive is the 'traffic'? \n\nsome context is definitely missing.\n\n(edit, it is 4M MAU)\n\n4M not 400M, and he does talk about the price of traffic.\n\n[deleted]\n\nit is similar to the concept that telcom sells you the unlimited plan\n\nAn online casino calling out another company for their questionable ethics. How funny\n\nSeriously lol, i just cant imagine an online casino that doesnt rig their rates to make sure they are always winning\n\nThere is no need to rig anything, all casino games are constructed in such a way that the casino wins in the long run, it is by design. Without it, it will be no point in running a casino.\n\nTake roulette for example. You can bet on red *and* black and still lose because of the 0 and 00 spots. \n\nThe only way to guarantee a win is to put money on red, black, and a split on the 0 and 00. So you spend $30 to end up with $20 when it lands on red or black. The only profitable way that bet could end is if it landed on 0 or 00 and you ended up with $170 on your $30 of bets. And you only have a 1:19 chance of 0 or 00 getting landed on.\n\nI thought that in modern Casino's 00 was a guaranteed loss to tweak the odds? I'm not a gambler at all though.\n\nSo the 0s are there to tweak the odds towards the house.\n\nSince a red/black bet pays 2:1, on a wheel with only red and black, you could bet $10 on red all day and statistically leave with the same amount of money you started with. By adding a single outlier, the green 0, the chance of red (or black) winning has dropped from 18/36 (50%) to 18/37 (48.65%). So with a single 0, you will eventually lose your winnings and initial bet because of that slight change. Now if you use an American roulette wheel with 0 and 00, the red/black odds fall to 18/38 (47.37%), making you lose your money twice as fast. There's even been a recent introduction of a 000 roulette wheel making it even more unbalanced at 18/39 (46.15%).\n\nAs far as a notion of a guaranteed loss, the 0, 00, &amp; 000 can all be bet on individually, as a split, or as a row. The same rules apply to them as the other numbers, with lower payouts as for bets that cover more numbers.\n\n[removed]\n\nReally depends on the country/state they‚Äôre running in. In many areas in the US you have to not only provide your source code to the state gaming commission to ensure it is fair but you need to provide them proof that each deploy contains exactly what you provided and not a semicolon more.\n\nThe gaming commission has the same reputation for shutting nonsense down as the IRS or Fish and Wildlife (do not mess with eagles or owls).¬†\n\nI have absolutely no idea how it works outside the US.¬†\n\n&gt;I just cant imagine an online casino that doesn't rig their rates to make sure they are always winning.\n\nIn many jurisdictions that would be extremely illegal, and this is often actively enforced.\n\nWith that in mind it's also just insane to do it when casino games are _already_ engineered to benefit the house just in their rules.\n\nI think you guys learned a business lesson more than anything. You trusted your entire business of 4 million MOA to stay running by paying $250/mo without a contract. \n\nIt seems you didn‚Äôt realize what was going on. Cloudflare was **losing money** by allowing you to run. They had absolutely nothing to lose in negotiation with you, so of course you had exactly zero leverage.\n\nWhy would anyone who is already losing money with you spend even more money on you after you talk about leaving. What sane person doesn‚Äôt cut their losses? We‚Äôre not talking about a $2 loss leader at a grocery store or a free sample. You were probably costing them _a lot_. Just not a good starting point for a sales call. \n\n&gt; The price they give you is going to be purely based on what they think you might pay\n\nNo offense, but most people with enterprise businesses already know this. This is how enterprise sales work. \n\nThe reason for the price comes from the contracts with SLAs and lengths so that they can‚Äôt just decide to destroy your business whenever they want, like one might do after finding out they‚Äôve been giving away charity to an online casino.\n\nTrust me I love the small, self service model too but there‚Äôs a reason it never scales‚Ä¶.\n\n&gt; Cloudflare was losing money by allowing you to run. They had absolutely nothing to lose in negotiation with you, so of course you had exactly zero leverage.\n\nTBH there is a fundamental problem with CF's business model. I front the DNS for 48 sites through them and would be more than happy to pay for some enhanced services at the $5 - 10 per month range, but there's no option to do this and no ability to manage it at account level only per site.\n\nSo they're losing out on small payments across their estate because their pricing structure is free/25/250 with some micro service offerings, but the management of those is such a pain I've given up.\n\nSo along with the decline in usability of their interface, I've gradually given up on the paid tiers. Not enough useful services at $25, $250 is unaffordable and the time needed to manage the microservices at the site level is too great. Basically, they're not making money in places they could generate more revenue in the hopes of hooking the big fish.\n\nFastly are just as bad. Utterly opaque pricing and when they did convince me to move I was landed with a $1000 charge because they'd hidden the fact there is a massive per SSL charge. That resulted in a complaint, refund, and a shotgun move back to Cloudflare's free tier.\n\nMany businesses prefer to give something for free rather than charge a low amount. The low amount does not allow them to provide any level of support and often the revenue is kind of meaningless for a billion dollar revenue company. With a free product it's easier to make clear that it comes essentially as 'take it or leave it'\n\nThere's no meaningful support on the pro or business tiers (I've used these at work). Hell, I spent a spell as webmaster of Transport for London (at the time the 9th most popular website in Europe), Akamai downed us in the middle of a tube strike and we couldn't even get them on the phone and our contract was worth millions. \n\nI manage a 365 tenant for a client with 500 E5 users, and we get the same support level as my client with two office premium subscriptions. \n\nIn short, money has nothing to do with it. \n\nCompanies on the freemium model don't look at profit per customer, they look at bottom line revenue, where 4.2 million people paying $5 per month is worth $21 million.\n\nThat's not nothing when you're losing 35 million a quarter on 350 million revenue, and are showing annual losses on operating income and net profit.\n\nI think you're overestimating people who use Cloudflare only for DNS. They have a $20/m (per domain) plan, I doubt it'd be worth it for them to bring out some account wide $10/m plan for DNS only users. It would also make CF one of the most expensive DNS providers considering that most of those sites would be small.\n\n&gt; I think you guys learned a business lesson more than anything. You trusted your entire business of 4 million MOA to stay running by paying $250/mo without a contract. \n\nThe barely legal entities penny and dime their own operation, and then cry wolf when they get kicked off their sleezy agreements.\n\nThat said‚Ä¶ the way they handled this (at least according to that one side) seems extremely messed up.\n\nThere is always another side to the story, as you alluded to. Having sat in on many endless contract meetings, I think we are being spoonfed details here.\n\nIf things went exactly as were said in the article then it was still extremely bad practice from CF - tantamount to extortion and to purge records without coming to a resolution is unprofessional beyond belief.\n\nI disagree. No contract, no obligation. Period.\n\nCloudflare clearly does not do this to most customers. They had a reason.\n\nIf I run a business and you cost me money, I am not obligated to ensure we ‚Äúcome to a resolution‚Äù. The ‚Äúresolution‚Äù is to drop you so that I stop losing money.\n\nThe fact that CloudFlare attempted to discuss and come to terms that they can both live by means a lot. CloudFlare didn't get as big as they have by being a terrible company that businesses can't work with.\n\nWhat we have here in this article is one side of the story.\n\nI'd be willing to be that CF would have worked to make it work as it would be lost revenue in all other circumstances. From the info available\n\nSorry, but blocking their domains while claiming they are not blocked cannot in any way, shape or form be considered normal business practices. This was really shoddy work by CF.\n\nRight and the question is what happened that would cause this.  The before price is too cheap but the after price is too expensive.\n\nWhat would make them up the price by 40x?\n\n$120K/yr for protecting and serving a large global online casino actually seems quite reasonable  Online casinos are simultaneously magnets for scrutiny/trouble and insanely profitable.\n\nThis sounds like CF realizing they were losing money on a business that could pay a ton more, and then a sales guy doing a ham-handed job upselling.\n\n'We will have to have actual engineers think about your account as an actual thing' is enough for a pretty huge multiplier. \n\nThey were originally paying $3k/year for the service. I would not be at all surprised if CF blew through more than $3k in staff time to get to the point of sending their first email. \n\nCloud services get to be cheap by being standardised and automated, such that you can support an enormous number of customers per engineer. Anything that reduces the number of customers per engineer means that the customers need to pay more, to keep the average revenue per engineer the same.\n\nCould just be a shot in the dark. Like an ‚ÄúI don‚Äôt really want you as a customer but maybe I‚Äôll consider if you pay me something crazy‚Äù. \n\nAdmittedly not super professional, but also not completely irrational considering the nature of OPs business and the fact that they tried to slide under the radar of operating an enterprise under a low plan for so long. Might have been deemed not worth the sales resources.\n\nFeeling entitled to harm someone that you have a relationship with in any way that isn't expressly forbidden by contract is not a personality trait I look for in a partner. It may not be illegal, but it is certainly something that should make you think twice before voluntarily being in a room alone with the person.\n\nThat‚Äôs an absolutely ridiculous way to run a business of Cloudflares size. Just because they didn‚Äôt have an enterprise agreement it does not mean there was not a contract in place? They were paying the business plan pricing and as such were a customer. \n\nEdit: just noticed other comenters have pointed out they were violating TOS. That wasn‚Äôt exactly clear from the article and does explain CF stern reaction.\n\n&gt;Edit: just noticed other comenters have pointed out they were violating TOS. That wasn‚Äôt exactly clear from the article and does explain CF stern reaction.\n\nTo be clear this is just speculation from clueless redditors. As far as I can tell there is no evidence they actually violated the TOS and CF definitely didn't provide any evidence they did.\n\nI mean it‚Äôs speculation from the article. The author mentions potential TOS violations\n\nSo in summary:\n\n\n1. CF was probably losing hundreds if not thousands of dollars per month on you\n2. you actively damaged their operations since many countries will ban the IP/IP ranges you use.\n3. Someone at CF (probably more an SRE than from sale, who was annoyed by having to deal with IPs banned thanks to you)¬† realized that you have been a net loss for years causing troubles and is probably finally able to push the idea that the situation must change\n4. Sales takes over and they say: if they use BYOIP that would not be an issue. BYOIP is Enterprise only and so we would resolve all problems and make money.¬†\n5. They massively mess it up communicating... Although proposing to move from 250/month to 10k/month was probably impossible in any case.\n6. You mention going to the competition, at that point something high had enough and orders to cut losses NOW and close the account.\n\nThe communication was brutal. I'm not sure if there was a better way to handle it, though -- when you fall afoul of \"trust and safety\", there are good reasons for a company to not want to share very much. When faced with an actually-bad actor, you don't want to hand them a map of exactly how close they can get to violating the ToS, or what loopholes exist...\n\nBut it'd suck to be on the receiving end of that and have no idea where you went wrong, or what you could do to fix it.\n\nIt would probably be a good idea for Cloudflare to either offer a la carte pricing for some of these features, or at least come up with some cheaper option that includes BYOIP. I can see why they wouldn't want to do so instantly for this customer -- honestly, screw casinos anyway -- but there are going to be other domains that CF might actually want to protect, even if they're not popular with every country.\n\n&gt; or at least come up with some cheaper option that includes BYOIP\n\nThe price of the plan wasn't particularly expensive for their scale. It's not cheap either, but it's not outrageous offer. Even if we don't account that the plan is for casino with BYOIP and that lots of their traffic probebly isn't in Europe/NA.\n\nWhy?\n\nBYOIP is the definition of \"special needs\" customer.  The reasons they're needing to operate on BYOIP space is that they're literally too hot to handle on your shared IP space.  Which also, coincidentally means they'll need to continuously lease and rotate into new IP space, meaning config changes, having staff validate the authority to use the IP space, etc.\n\nWhen you know up front that your customer will be needy, complicated, and likely to invite legal or technical drama, why wouldn't you price it in line with needing a full time tech on the account?\n\nThe communication is the main thing people should be focusing on here, every other detail is irrelevant. If you used any mission critical service and there was a important issue you'd receive an easy to understand email outlining exactly what the issue is and how it needs to be resolved (often with a deadline)\n\nThe communication from CF came out of nowhere when they've been using it for years and then expected them to instantly jump from 250 a month to 120k a year (almost a 50x price rise). This feels like what should have been a single email ended up being farmed out to sales instead of it being with someone appropriate who could straight up tell them \"you either need to move to enterprise by X or you're out\"\n\nEven if this was about limiting their liability and actually pulling in money from their client (250 is insanely cheap), the communications here was **awful** and the way they were cut off was appalling.\n\nWhy is it the client's fault for CF not noticing CF was losing money. The client didn't hide that they were using all that bandwidth. I don't know why people are saying this client deserves mistreatment for paying for and using a service with no complaints from Cloudflare for however long they did.\n\n&gt; Although proposing to move from 250/month to 10k/month was probably impossible in any case.\n\nThat was the point. This wasn't an offer they wanted to have accepted. This was a message - \"You've been costing us this much for as long as you've had the account, all to run a website that actively exploits people's cognitive imperfections, you soulless thieves. Fuck off and go somewhere else.\"\n\nUnless of course they're willing to financially contribute to CF's well-being. I don't think CF has any kind of moral high ground here.\n\nIt's perfectly normal for CF to not want this type of business using its infrastructure, casinos deal with blockages in certain countries and a casino like that tries to get around that, it's normal for CF not to want to deal with these types of problems.\n\nglad it happened to a casino\n\nYup, I guess the house DOESN'T always win hehe\n\n&gt; This also means that if a country DNS-blocks our main domain, a secondary domain may still be available.\n\nHow about if a country DNS-blocks you, then just accept that they don't want your business? You don't have to condone DNS-blocking, but you should also accept that not all countries want your greed and manipulation around. Kindly go and fuck yourself.\n\n\\- Inhabitant of a country troubled by assholes like you.\n\nthis.  ‚Äúwe try to violate national bans to prey on people with our ethically corrupt buisness choices‚Ä¶in doing so we violated the terms of service of our provider‚Ä¶.cry for us‚Äù\n\nThey reached out on April 19th and turned you off weeks later in May. That's definitely FAFO territory and not \"24h\".\n\nSeems deserved.\n\nCry me a river OP\n\n&gt; Sorry, but Gamdom is not available in your jurisdiction.\n&gt; Contact support@gamdom.com if you think this is a mistake.\n\nWait... How do you know that's the site?\n\nSome searching can confirm it:\n\nhttps://x.com/GamdomHowly/status/1791216228368883955\n\nIncredible. So it **was** crypto gambling. No wonder CF dropped them so quickly when they started properly pushing back, particularly given the issues they were probably causing CF.\n\nHad they only paid 120k/year CF would be all over them.\n\nIn fairness, the $120k plus they'd need to lease IP space from someone willing to have said IP block get trashed reputationally, only to have the casino need to get more and more leased space to rotate through to continue evading blocks.  So many thousands per year in IP space too...\n\nI went out on a limb, based on comments from my fellow posters.\n\nIf it's not them, then OP can figure out who they're using for hosting and follow suit.\n\n&gt;Get a fun Bitcoin casino experience with Gamdom!\n\nI‚Äôm shocked Cloudflare didn‚Äôt fuck them off years ago.\n\nIndeed.  Customers like that, Cloudfare are probably more than happy to give to Fastly.\n\nWhen I was in my late teens I had a website full of booters and hacking tools, things to brute force passwords and stuff, I couldn't keep it online. Nothing was illegal. Hosts would tell me I was using too much bandwidth even though I wasn't.\n\nthis domain is literally blocked in Poland and it says that it's an illegal gambling site that violates multiple laws.\n\nScammers are way out of touch.\n\n&gt;a fairly large online casino. We have around 4 million monthly active users. We had been happy Cloudflare customers since 2018 on the \"Business\" plan which has some neat features and costs $250/month for \"unlimited\" traffic\n\nlol\n\n&gt; This also means that if a country DNS-blocks our main domain, a secondary domain may still be available. This could arguably be seen as a violation of the Cloudflare TOS\n\nPause. I want to hear why you think that's arguable whatsoever. Not only are you rotating domains, you were getting their IP ranges blocked, all while on a 250 USD / mo business plan.\n\nLet's get real here. The real issue is that your company is ran and staffed by people with the mindset of used car salesmen while cloudflare was telling you all the while that you're being a liability in business terms, which your team kept handwaving as \"just an upgrade offer\".\n\nTwo weeks after the initial offer, they now tell you, now on no uncertain terms that you're in violation of TOS. A couple of days after that, you are told on no uncertain terms how much it would take for them to accommodate your business.\n\n&gt; make the problem magically disappear\n\nNo, not magically. You would bring over your own IPs to stop getting theirs banned, and pay enough for them to make it worth cover their traffic. That's quite an empirical solution, and they wanted commitment from you to that end. They make it very clear that they will not budge.\n\nThey give you ANOTHER week, during which you didn't actually even entertain the idea of migrating, but keep trying to get a better deal after it was already made clear where they stand on your company, despite you having broken the TOS before and causing Cloudflare losses in doing so. Which is kind of a big thing.\n\nThen, in another call, your boss claims that you now have an alternative in a bluff (you were NOT ready to migrate despite telling Cloudflare you had an alternative). That was probably what they were waiting for as they can't be held liable for your downtime when your CEO was stupid enough to make that bluff. \n\nYour boss told them that there is no way for them to keep supplying your business while turning a profit because, according to your boss, Fastly would supply you for cheaper.\n\nUnderstandably, Cloudflare immediately stops wasting their resources on your company.\n\nThe last part is, of course, entirely your boss' fault by invoking the aforementioned used car salesman tactics in negotiating.\n\nTL;DR you're a bunch of shady fuckers that can't be reasoned with and failed to understand that no, you can't get away with being a net loss while actively damaging cloudflare, and your \"24 hours\" was actually 29 days.\n\n&gt; TL;DR you're a bunch of shady fuckers\n\nThe more thought I waste on this, the more this seems the only reasonable conclusion. \n\n* OP admits they are engaged in domain rotation. (‚ÄúArguably‚Äù) I wonder when the last new domains were added. \n* OP all but admits that they are knowingly operating illegally in many countries.  They only stop when told to. \n* OP admits that this blog post was written to shame CloudFlare into compliance, but they took too long to post it. \n* Post is made on a brand new account, just for this. \n* Post is shared from an 8 year old Reddit account with no content. Likely either purchased or explicitly hollowed out to avoid ties to casino or OP personally.\n* OP pretends that they believe they are being charged 10k for bandwidth when they know full well that they are being charged for BYOIP and enterprise support. \n* OP admits that they knew about the TOS violation for two full weeks before the takedown but they took no action, assuming they could bully CloudFlare instead.\n\nEverything seems both shady and incompetent.\n\nI can‚Äôt imagine why a casino with 4 million MAU didn‚Äôt just pony up $120k. Either the claim that this is a large online casino is a lie or their leadership is incompetent.\n\nMy guess would be it's shady plus less than excellent on the IT side, especially the intersection of business, risk, and networking intersection.\n\nIf BYOIP is the fix CF is proposing, then the issue that CF is mad about is that you're using their IP addresses and causing them immediate or future-threatened harm by getting them blocked by one or more national firewalls...\n\nSooo... what is this \"online casino\" you talk about? Posted by a new completely blank and anonymous Reddit &amp; Substack account that never have posted anything before, with all domains and information redacted. \n\nSomething feels really shady here.\n\nThis is about Gamdom. (gamdom.com)\n\n&gt; with all domains and information redacted\n\nThat's business practice. If he shared something else, it would be subject to termination.\n\nDo you even NDA?\n\nRedacting the actual name of the company technically doesn‚Äôt mean you skirt around NDA. It‚Äôs still leakage of information and who it‚Äôs about can be implied\n\nGamdom. Theres another online casino (CSGOEmpire) that has been attacking like everyone else in the space, so I wouldn't be suprised if they are the ones that instigated this\n\nSince from the business side this affair is mostly over, I wrote this from a personal perspective. I didn't want to get the business involved since as soon as you associate it they will have to evaluate whether it's good PR for the company or can harm it, etc.\n\nAlso, if it had a company name people would accuse the post of being marketing, so I guess it's a lose-lose either way?\n\n&gt;  I didn't want to get the business involved since as soon as you associate it they will have to evaluate whether it's good PR for the company or can harm it, etc.\n\nOh noooo, crypto gambling site worries about its rep! \n\nlul\n\nYet you created a Reddit account just for this too?\n\nGood on cf for losing you as a costumer.\nHopefully you never get another domain and your casino goes bankrupt üëç\n\nWhile this seems quite nasty, I doubt fastly will be cheaper. But as a matter of principle probably a proper decision. I like that they actually acknowledge they were getting a lot for $250, and were ready to pay more, just not that much more and not for essentially blackmail tactics.\n\nRisk plays a huge role in their pricing from what t I can tell, big reputable organisation and we were paying $60k for years and it only recently went to $72k on last negotiation\n\nThis was an org that would get constantly attacked as well\n\nExploits people for money, gets mad when someone tries to exploit you for money\n\nCF didn't try to exploit them for money, they were costing CF way way more than that $200/month running their online casino that probably rakes in millions. CF simply cut their losses, no contract, no obligation. They even had the audacity to mention going to a competitor üòÇ\n\nI run a 3 person shop and $120k per year for CDN services would be a glorious dream that I never expect to experience.\n\nHahahah, so you've been abusing the living hell out of the $200/month business plan running a multi millon dollar casino business, and they caught you. It's their platform, and you were costing them way more than the $200 a month. L rip bozo\n\nAnyone know what casino it is ?\n\nGamdom\n\nThey mention it just as an aside, but I have to think there's a serious chance the fact it's an online casino is relevant to this. Either directly (in that there's a real problem with fraud or money laundering or similar that CF are trying to manage legal liability for but for whatever reason aren't able to communicate directly), or just in general, that they classify such a business as very high risk.\n\nReading between lines it sounds to me like a decision was made that this account had to be shut down and within 7 days and all the rest is just implementation details. There was never going to be another outcome, the $120k was designed to cause a switch to another provider. If they had stumped up the money, CF would have found or created another problem.\n\nBeing ‚Äúright‚Äù doesn‚Äôt keep your infrastructure online.\n\nThis is why as a business you pay lawyers or hire someone to manage your SAAS accounts who knows how to read terms and understands how to handle them.\n\nStopped reading after I saw online casino. Time to pay up\n\n[deleted]\n\nNice, casinos should be banned.\n\n[deleted]\n\nOnline casino gets what it deserves I guess brother.\n\nWhat country do you live in OP, is this an illegal casino or a licensed, regulated casino? I‚Äôm just curious do illegal casinos get shut down is there any enforcement on this stuff. If someone makes a probably fair  slots or blackjack meaning it‚Äôs not a rigged scam, but a game of chance with a slight advantage for the house will anyone ever come after them ? This is interesting to me there are so many online casinos registered to a shack in the Caribbean.\n\n&gt;Copyright ¬© 2016-2024 Smein Hosting N.V. Abraham de Veerstraat 9, Willemstad, Curacao (Company Registration No. 141727)\nPayment processing: Vilnius IT Solutions UAB, Ateities g. 31B-101, LT-06326 Vilnius (Company Registration No. 304988128)\n\nLegal‚Ä¶ in Curacao.\n\n- online casino with 4m MAU\n- potential violation of ToS\n- complain on a $250 per month plan\nü§°\n\nYour article is misleading, it‚Äôs not a business, it‚Äôs a racket.\n\n[deleted]\n\nAs soon as I read \"online casino\" I said \"Good\" and then said, \"There's way more to this than CF being a bag of dicks.\"\n\nThis has a Terms and Conditions violation written all over it.\n\nThen reading some of the comments, it was Crypto Gambling. I believe the term is \"A hive of scum and villainy\".\n\nWhat did casino expect! Oh right. To collect every ounce of profit and not pay for the repercussions of gambling business. \n\nPay up! Can't tell me don't have enough $$. No such thing as infinite profits without causing issues for others. \n\nCloudFlare was right.\n\nYour core business is your web application and you were running security and delivery for its 4mil users at 250$ per month.\n\nI mean, come on, seriously.\n\n\"Boo hoo. I run an online casino that's been abusing a loophole in CloudFlare's pricing to avoid paying for the bandwidth I'm using and now they're tired of my crap and insisting I pay my fair share.\"\n\nWay to spell out in excruciating detail why they're justified in running you off their platform, OP.\n\n&gt; fairly large online casino\n\nI can't express how big the freak in \"Freak you!\" is. Destroyer of lives! Everything you suffer from is deserved. I would have forced you to pay until bankruptcy!\n\nI can't even imagine how/why a \"fairly large online casino\" would bat an eye at a $10k/month shakedown if it kept their infra vendors happy.\n\nTo borrow a quote from \"How High\", regarding this casino... \"If you pimp, you broke pimp!\"\n\nI thought casinos own their servers and infrastructure in general.\n\nHow does cloudflare take down your website, it‚Äôs a CDN, just point you domain names to a different dns server rather than cloudflare\n\nThey also offer DNS and Name Registry.\n\nCloudflare is much more than a CDN. They handle DNS and they have all manner of features that require you to proxy your traffic through them (WAF, DDOS protection, rate limiting, cert management etc.). Not to mention they have other services (Zero trust) that you may be reliant on. CDN is the tip of the iceberg of their offering.\n\nIf your relationship with them turns sour and they disable your account, you are very likely completely screwed, at least for quite some time.\n\nAn *online casino* complaining of unethical behaviour?\n\n^^^üéª\n\nBecause it's harder for them to her around regional restrictions *for places where their business is illegal*. Watch me shed the tiniest possible tear.\n\nI hope CloudFlare rips them a new one.\n\nAnyone with a functioning brain or who can actually *read the terms of service* knows anything \"unlimited\" has ... limits. Usually fuzzy, ill-defined acceptable use policies. Yes, this is stupid. It's also routine. Avoid such services, or get what you should expect if you are an outlier customer for them. And they weren't paying \"really unlimited unlimited\" money.\n\n&gt;Cloudflare took down our website after trying to force us to pay 120k$ within 24h\n\nNah, your decision to rely on an SPOF took down your website.\n\nThe moral of the story, is that you can not get sympathy when you run an ethically questionable business. And you can't pull the \"BuT ThErE Aree ManY CoUnTrIes WhEre It's LeGaL!!!!!!!!!\"\n\nA hoe will always be a hoe, no matter if prostitution is legal or not.\n\nLmao. what a joke. This substack account created a few hours ago just to talk shit about Cloudfare.   \nRegardless whether its an online casino, the website has a huge traffic and wanted to save money.  \nIts pathetic and I have no sympathy. I bet the alternative they proposed Fastly would cost more than $250/month. Even Fastly has custom pricing for their basic plans. The sales team from Cloudfare should have picked up this account way earlier and not delay since 2018.\n\nI bet the tech r/sales people would agree that this is a clown account to manage.   \nAlso the BDR is just the bottom of the ladder and just following for an opportunity to hand over to the sales executive (AE) for a bigger deal which was the 120k/year.\n\nI‚Äôm torn, because on the one hand, Cloudflare‚Äôs communication is infuriating, and I strongly disagree with the commenters defending Cloudflare, basically saying that‚Äôs just business, or normal for B2B, when it‚Äôs not.  I‚Äôm a founder, and I sure am glad that professionalism, ethics, good faith, etc exist.  It would suck not to be able to trust another business, expect to be treated like trash, go into every sales call where a service you pay for is trying to upsell you making sure you have ‚Äúleverage,‚Äù as another commenter suggested, so that they don‚Äôt immediately close your account.  Like it‚Äôs some kind of mob dealing.\n\nThat said, you are technically trying to ‚Äúevade‚Äù countries blocking you.  That‚Äôs not something most of us are likely to be doing with Cloudflare.  Someone at Cloudflare might have thought they were doing you a favor by being willing to have you as a customer at all, for a price.  You don‚Äôt know what issues you caused for them that they had to handle.\n\nI still count this as a strike against Cloudflare and a reason not to use them.\n\n[deleted]\n\nIn most European countries they're perfectly legal.\n\nFor example, [News UK](https://www.news.co.uk/latest-news/sun-bingo-is-back/) ( the parent company of the Times in London) operates its own online casinos in the UK, for example. (\"Sun Bingo\")\n\nNot clicking a substack.  TL;DR?\n\nI was only aware of people disliking Medium, what's wrong with substack?\n\nTL;DR: _We've been on the Cloudflare Business plan ($250/month) for years. They suddenly contacted us and asked us to either pay them $120k up front for one year of Enterprise within 24 hours or they would take down all of our domains. While this escalated up our business we had 3 sales calls with them, trying to figure out what was happening and how to reach a reasonable contract in a week. When we told them we were also in talks with Fastly, they suddenly \"purged\" all our domains, causing huge downtime in our core business, sleepless nights migrating away from CF, irreparable loss in customer trust and weeks of ongoing downtime in our internal systems._\n\nYou have a substack, maybe you can get your subscribers to help out! \n\nTo put it very mildly, I don't believe you. \n\nA mafia shakdown for **40 years** of your montly spend? Because you were \"in talks\" with fastly to host your whatever the hell basic ass site?  IN TALKS for 250/MO? \n\nNo one cares about your 250/month. Nobody would be \"in talks\" over that amount. What were you **really** doing?\n\nYeah they were probably running multiple $250/mo accounts and abusing the systems.\n\n[deleted]\n\n&gt; why wouldn't they hike it to $50,000/month next year?\n\nI can say from experience that if you just renew your existing enterprise contract with Cloudflare without any changes or even contact with them you'll probably be fine and stay at your negotiated price - but lord help you if/when you ever need to adjust your contract - they absolutely get drunk with dollar signs and try to squeeze all the juice out.\n\nIf you ever exceed your contracted limits, they'll be on your ass within a week. And no matter if you need to negotiate up for more service, or negotiate down because you don't need as much as you used to - the per-unit price is always going up, substantially. As if it got dozens of % more expensive for them to transit your bytes since a couple/few years ago.\n\nCloudflare sales should be lumped in with Oracle and shit.\n\nWe were probably underpaying at $250/month. So they wanted more money. That part is reasonable. Just $120k is not reasonable, and the sales tactics aren't either. I'm not gaining anything from this article, it's purely a precautionary tale.\n\n&gt; the sales tactics aren't either\n\nI have pretty much zero sympathy for your company's specific situation - but I have to agree that Cloudflare's sales tactics are industry-leading shit-tier.\n\nNah, Cloudflare does shit like that to growing companies on non-enterprise contracts all the time. At some point, they‚Äôll decide you need to pay some arbitrary amount more or you‚Äôre going to get abruptly shutdown with no warning, and it all happens on whatever arbitrary timeline they feel like.\n\nSame as with medium. Subscription.\n\nSo your criminal enterprise that was using their services got cut off when they caught on and you're mad they didn't work with you enough?\n\nTo be honest, this post just made me like Cloudflare more.\n\nThey‚Äôre just doing good business\n\nThere's no way Cloudflare is going to want to deal with the trouble this cryptocurrency gambling site brings for a mere $3000 a year.\n\nThey should have moved even quicker once Cloudflare started paying attention to the situation. Surely if you've dealt with DNS blocking and IP blocking before you have to have a better backup plan just hoping you're given enough warning to move your resources before DNS updates propagate through.\n\nInformative for any business model /s\n\nThey were running their business without a contract.   They should have seen this coming.  Dumb really.  Then they're surprised to find out that sales has a custom price for everybody.  Who are these people...  This is standard\n\nCloudflare embraced the \"fuck you pay me\" business model, huh?\n\nAlso what kind of backyard op is it when you use one vendor for everything?\n\nThis is why Akamai is known for being the best. Cloud Flare is just a shit company with good marketing.\n\nEdit: I see a bunch of people downvoted this to 3. The reality is, CloudFlare is a greedy company. They are good at lying to make their stock sell better. The company with the best reputation for a stable CDN is Akamai. They service like every major content provider in the world (everything Disney owned, including sports - think of that data...)\n\nCloudFlare just has a pretty dashboard and marketing team. They don't have the best reputation on the backside for large companies.\n\nThey purged all their domains instead of routing to the original IP address."
  },
  {
    "title": "Jenkins was invented b/c an engineer ‚Äúgot tired of incurring the wrath of his team every time his code broke the build.‚Äù",
    "body": "",
    "score": 1745,
    "url": "",
    "created_utc": 1712874963.0,
    "author": "fosterfriendship",
    "permalink": "/r/programming/comments/1c1slh3/jenkins_was_invented_bc_an_engineer_got_tired_of/",
    "all_comment_text": "If I'm not mistaken, Jenkins was invented because Hudson got Oracled.\n\nFrom the article: Sun Microsystem‚Äôs engineer, Kohsuke Kawaguchi, was key to ushering in the next era of testing. In 2004, he created ‚ÄúHudson‚Äù (later renamed to Jenkins in fun Oracle drama). At his day job, Kohsuke ‚Äúgot tired of incurring the wrath of his team every time his code broke the build.‚Äù He could have manually triggered tests before each code contribution, but instead, Kohsuke chose the classic engineering solution and created an automated program.\n\nThis is correct.  I had never heard of either.  Then the Hudson thing happened and I heard of both.  Then I got a job and we were using Jenkins.  I noticed in several places it still said \"Hudson\" (I think in package or class names).\n\nIt still does\n\nThank goodness for that. When the javax packages got renamed to Jakarta, it was a pain to upgrade libraries.\n\nYou're on the bleeding edge if you've dealt with that already... I imagine the vast majority of enterprise still has this issue to come\n\nIf you use Spring Boot it was Spring Boot 3.0 that pulled in Jakarta dependencies and 3.0 was released in November '22. Is being on a release that was released a year and a half ago really bleeding edge?\n\nSadly yes. The number of places still on java8 are too many\n\nWait till you hear how many companies require things to be coded in C++17 and not C++20 or C++23.\n\nI worked for one such national company until 2021.\n\nC++11 you mean\n\nAfaik C++20 isn't yet fully supported across the board because of modules.\n\nModules have issues, especially with compile times, but you can forbid modules while still adopting the rest of C++20.\n\n&gt; Is being on a release that was released a year and a half ago really bleeding edge?\n\nAbsolutely. Many places still use java 8 under the guise of \"if it ain't broke, don't fix it\", even though they will be out of support and don't receive security updates unless they're paying big money for the paid JDKs.\n\nMy company is not on the \"bleeding edge\", but we have a security team that forces us forwards when things go out of support. We are now only just in the transition to JDK17, hibernate 6, spring 3, and so are in the middle of dealing with the jakarta namespace rename.\n\nThe sad reality is that even the dependencies themselves are not fully there yet, either. For example if you used Freemarker, they technically don't even have a release with the jakarta namespaces - it's still a snapshot build. Also, Spring security has broken compatability with it as the JSP taglibs are no longer supported (the way they recommend you integrate) - in its current state it requires a lot of workarounds to get working. Ask me how I know. A lot of enterprises will not spend a month upgrading everything and risking it all breaking just to run on Java 17.\n\nAs the article points out, when that occured it was called Hudson.\n\nJenkins is just a name, it was not \"invented\", its just a new name.\n\nMore forked/renamed than invented, but yes (and the article mentions this).\n\nThis reminds me of an old co-worker I used to have when I worked at a small, really early-stage startup; we'll call him Jacob.\n\nJacob was an absolute database god. Each time we hit scaling issues or have a particular hot path, Jacob would disappear for a few days and then inevitably come back with some 10x win. It'd be some composite index that'd lead Postgres to select another join strategy under the hood that would in turn unlock its own additional optimization. Or some fine-tuning of a Postgres setting for a particular table. The man lived and breathed query plans and I don't know how he did it, but I swear each time we found ourselves backs up against the wall, he managed to squeeze even more water from the rock.\n\nUnfortunately that's not where the story ends; in any other part of the codebase, Jacob was just a plain, unmitigated disaster.\n\nYou see we needed a DB expert, but with our team size as small as it was, we also needed everyone to help with everything. And let me tell you, each time Jacob tried his best to help out with some application code or was oncall and tasked with attempting to fix user bug reports, it was an unmitigated disaster.\n\n\"Jacob, when you change the app code, you need to boot the app server, start the website, and just make sure the website loads\" we'd say. I can't remember how many times we had this debate. He swore, if it compiled it was good enough (it never was).\n\nAnyways, I wish Jacob could've just invented CI. We eventually had to let him go because we just couldn't justify a specialist that early...\n\nI dearly hope he found a more fitting position fast! Well, crafty DBA usually do\n\n[deleted]\n\nMost software problems are management issues. It‚Äôs Conway‚Äôs law in action.\n\nThis is now why I refuse to work at a small company or ‚Äústartup‚Äù ever again. Large companies obviously are still utterly miserable with fake agile, fake scrum, incompetent management and all the usual problems.\n\nBut small companies have all that plus often narcissistic and arrogant micromanagers.\n\nWhereas you can fade into the background and be shielded by multiple layers of bureaucracy and management at a large company, you are directly in the firing line of shitty management at a small company.\n\nI had 26 managers in 20 years at my big company (2 of those chosen, the rest were manager shuffles by the company).  Some were really, really bad... some were really great.  A big company's just like 1000 small startups.  Some with the hurry up attitude of a poor startup.  Some with the laid back attitude of a financially secure startup.  Some you fit in well with, some you don't.  It's just easier to switch between startups if you don't like where you're at.\n \nThey made it harder and harder to switch between teams though.  The last team switch I did I landed on a team with a two faced, petty, vindictive cunt of a manager and then couldn't switch off so I had to leave the company.  Of the 26, she was the worst... just God awful and a miserable human to boot.  I would have felt sorry for her if she didn't spend a year making my life hell.\n\nEarly on in my career I got a new manager after my old one moved away. He was fine, nothing to write home about one way or the other, and we both knew he was only there as a stopgap measure until the \"real\" next manager could be found, but when it came time for the annual performance review he marked me down as \"needs improvement\" on literally every metric on the explicitly stated grounds that \"there's always room for improvement.\"\n\nNeedless to say this fucked up any chance I had at getting a raise that year.\n\nWhat? It just sounds like Jacob wasn't willing to do basic click testing of his code changes, and was kicking and screaming about it. It's not hard to boot the server and test your change, and if it is‚Ä¶ fix it.\n\nIf management knows what needs to be done and an employee repeatedly refuses, that's not a management issue. Especially if it's something obvious like \"you have to verify tcode before putting it into production.\"\n\nFR, I understand that some people are experts at one thing and below mediocre at other... But honestly we've had devs that never checked their changes before committing and I'm really glad they're gone. \n\nRegarding Jacob \n\na) you don't fix database every week so expecting a start-up to keep someone to use their skills few times a year is ridiculous,  \nb) the codebase definitely lacked proper integration tests.\n\nKind of.\n\nThe problem here was having a specialist try to be a generalist.\n\nThis dude was a DBA. DBAs are not developers, there's virtually no crossover between the skillsets and very few people want to be both. Management couldn't handle having him as purely a DBA and wanted him to do things he didn't want to do and wasn't qualified to do.\n\nDid this guy do the *wrong* ~~right~~ thing by doing the absolute bare minimum when tasked with work outside his speciality? Yup.\n\nIs it possible he took a job he shouldn't have? Who knows how the position was described to him.\n\nShould he have quit? Probably, but that's not easy for people.\n\nBut Management is on the hook for hiring a specialist and expecting them to be a generalist. Management is on the hook for making him perform tasks he didn't want to and wasn't qualified to do. Management is on the hook for how it played out.\n\nStartups are notorious for devaluing speciality but needing it anyway. This company was quite obviously pushing their database farther than either it could go or farther than what they'd paid for. In either instance it takes a specialist to handle those scenarios, they needed this guy as a specialist (or to buy more infrastructure), but couldn't let him be one.\n\n&gt; Did this guy do the right thing by doing the absolute bare minimum when tasked with work outside his speciality? Yup.\n\n\nNope. Even if you're the janitor and they need you installing network cables, or you're the network specialist and they need you sweeping floors, you have agency. You either take the money and do your best, or you say thanks for the offer and leave. You don't throw untested code into production and cause problems for everybody.\n\n\nI mean sure, you do it once or twice because you didn't know any better. We all make mistakes. But making the same mistake over and over isn't related to working outside one's specialty, it's just being obstinate.\n\nI reversed that one in my brain I've fixed it in the original.\n\nOne of those \"did he do the right thing\" converts to \"did he do the wrong thing\" in your brain things.\n\nNot a very tall order. There‚Äôs a million and one places that need good DBA‚Äôs, sure he found something.\n\nI work in small teams, but have not been on call for ages.\n\nNot verifying the website even works when merging is pretty clearly dummy territory.\n\nNo, it's a Jacob issue.  If you won't actually test your damn code, even after being told to, that's not OK.\n\nIt's pretty clear that most of the work wasn't about DB optimization so having a specialist for that was not needed compared to all the other task he couldn't do that also needed to be done. It's not about squeezing labor out of him.\n\nYeah, if he was really creating that much value they would have found an excuse to keep him, just let him spend all his spare time doing pre-mature database optimization, or work on improving the database architecture to make data models better align with the business case and more easily support growing complexity in the back-end.\n\nIf you only have the budget for one engineer, would you rather have the engineer who ships good features that are so popular they force your company to struggle with new scaling issues? Or the engineer who will brilliantly solve those scaling issues but can't ship a product that will actually create demand to save their life?\n\n&gt; He swore, if it compiled it was good enough (it never was).\n\nHave you heard about our lord and savior, the crab language?\n\nCan't have production issues if you never get done because of compilation complications!\n\nJokes aside I've deployed rust services plenty of times and I don't have issues with the compiler after the initial learning curve of a couple months\n\nYea for real lol after learning rust every other language is such a painful sludge to work with, even go is terrible when you learn more.\n\nGo felt exactly like Python when I was starting to learn it, I don‚Äôt really understand the niche it‚Äôs supposed to fill. I‚Äôd much rather invest time trying to be a crustacean.¬†\n\n&gt; I don‚Äôt really understand the niche it‚Äôs supposed to fill\n\nPython, but compiled and statically typed\n\n[removed]\n\nRust is very obviously a replacement for C and C++ for server development and \"systems programming\" (low level programming where control over memory is required). \n\nGo was never a systems programming language. In practice it's a replacement for Java and maybe Python.\n\nJealous.\n\nWe're starting a new project where it actually makes sense to just go full typescript. _sad noises_\n\nOuch, I'm sorry. I recently (January) deployed a relatively complex service at work and it hasn't crashed a single time. I've fixed one bug since then regarding async task cancellation in some rare http requests. The codebase is 26k lines. Honestly I'm in awe, there's zero maintenance burden\n\nAnyone using the service? ;-)\n\nIt gets around 3-5k requests per minute and around 50k SSE connections active on average. Handles it with 2-3 instances at 4gb of ram each (mostly because of the number of active SSE connections). Pretty solid, never needs a restart\n\nThat‚Äôs awesome! I was just giving you shit but really cool.  50k SSE huh, so definitely HTTP/2. Reason for SSE over WebSockets strictly no need for bi-directional communication?\n\nYep, one way connection just for event listening essentially\n\nI'll just vicariously deploy rust through you, for now, lol\n\nTypescript ain't bad if you use types religiously. They should be just as much of a pain in the ass as Rust types and you can be pretty confident about the outputted code.\n\nI find TS unwieldy at times. People too often want to make magic types with the type system which makes maintainability difficult. Also you lose enums and gain exceptions--definitely a huge loss\n\nI‚Äôve heard this sentiment from Haskell people.\n\nI love Jacob so much.\n\nDude knows exactly how to play work life. Do something you love, be indispensable at your job, hold back the best shit for the next crisis, and if your boss asks you to do anything else then suck at it so you go back to what you love\n\nThe point of most code is to be maintainable, robust and straightforward and simple, because most of the time most code is doing pretty things.\n\nOptimisation is pretty much the opposite of this. It's taking a complicated task and realising that in certain circumstances you can skip steps, or do two steps at once.\n\nIt's not surprising to me that people who are good at one aren't always good at the other.\n\nI‚Äôm one of those ‚Äùoptimization people‚Äù. I‚Äôve found multiple undocumented cpu bugs and worked around them. I categorically refuse to work on anything grouped under typical frontend / backend / ‚Äùfull stack‚Äù (ie. web applications and similar) both because I have zero interest in those and also because I‚Äôd be really bad at them.\n\nJacob should try F#.    \nOnly time in my life I've written a significantly complicated app in a day, hit go and it just _worked_.    \nUnreal feeling, spent the next week waiting for something to blow up\n\nWe use F# extensively at work. We meme about F# being always correct by construction.\n\nIt's most certainly not. And not meaningfully more than C# which we also use extensively.\n\n&gt; He swore, if it compiled it was good enough (it never was).\n\n\"It builds and passes unit tests on my machine, so it's good to go\" is a huge red flag for me. (And it sounds like like Jacob doesn't even run unit tests.) I don't care how good you are at one specific skill. That's \"I don't need to test my code, and when it breaks other things, you clean it up.\"\n\n&gt; And it sounds like like Jacob doesn't even run unit tests\n\n\"Unit....test\"? I like your funny words, magic man.\n\nIt comes from the Latin *unitus testorum*, which means \"QA will get blamed for it somehow.\"\n\nAll the Jenkins bashing, which I have been guilty of on occasion myself, stems from IMHO\n\n- The Jenkins DSL just sucks. While I don't love groovy, if that's your choice, just stick with it. Don't invent your own dsl on top of it. The pipeline syntax editor is basically an admission that the DSL is too confusing.\n\n- Plugin versionitis - zero guarantees version 1 of plugin X works with version 2 of plugin Y. Now this problem lots of package managers deal with, often badly, but Jenkins didn't even try to deal with it.\n\n- Jenkins libraries - as pipelines (or any code) gets complex, the need to refactor into libraries naturally arises. How many different ways can we import a library in Jenkins?  Why does each way do something different? And how exactly should I test Jenkins libraries? Some first class support for library development would go a long way.\n\nStill... Nothing beats its flexibility...\n\nMost of the time you can just keep all that automation outside of Jenkins. You don't really want Jenkins to be the only thing able to run tests, do deployments and so on. It only needs to define the general workflow and perhaps pass some configuration, but everything should be easily doable without your CI pipeline.\n\nIt's almost a rite of passage to create some test which is only reproducible by Jenkins and one day watching it fail. Trying to figure out how to debug it is when you realize you've fucked up.\n\nHa this is incredibly common and the developers surprise surprise are incredibly hostile to be told the way they are doing it is stupid as hell (nicer in person ofc)\n\nHoly shit gave me ptsd\n\nWe‚Äôve been using Octopus for deploys, Jenkins for builds, and Proget for most artifacts and it works well.\n\n&gt; Jenkins libraries - as pipelines (or any code) gets complex, the need to refactor into libraries naturally arises. How many different ways can we import a library in Jenkins? Why does each way do something different? And how exactly should I test Jenkins libraries? Some first class support for library development would go a long way.\n\nThe issue here is that people decide their build logic needs to be encapsulated in a Jenkins DSL- something no sane person should consider. \n\nInstead, that work should be done via shell or other scripting and Jenkins just wraps it. \n\nBut yeah - some stuff with scripted libraries sucks a lot and I wish could see inclusion in baseline Jenkins.\n\nThat last part is why we just keep coming back to it.\n\nSo many other CI tools, and yet almost none of them seem to understand the importance of flexibility or abstraction properly.\n\n[deleted]\n\n&gt;Reading all these comments I get the impression most of the Jenkins bashing comes from opinionated juniors who don‚Äôt know how their tools work.\n\nI've been in IT for nearly 20 years, a Sysadmin for about half of that, coding that entire time and have extensive automation experience. I am not a junior by *any* stretch of the word.\n\nJenkins is an fucking absolute abomination. It somehow managed to make ***Groovy*** even worse than it already is.\n\nNot moving the company over to Github Actions sooner is a choice that I regret every day. There's one last project living in Jenkins, and once that's migrated, I'm going to take *great* pleasure in decommissioning that piece of shit.\n\nI might even export the VM to an external drive so I can decommission it physically too.\n\nüòÇ\n\n&gt; Jenkins is an fucking absolute abomination. It somehow managed to make Groovy even worse than it already is.\n\nUsers manage to make a poor configuration of Jenkins(IE - using any amount of groovy/scripting besides the minimum to accomplish a good CI build). \n\nI can usually quickly tell if someone actually manages a Jenkins instance or just \"uses it\" by asking what executor types they use, how they configure Jenkins, how many scripted libraries they use and if they know what  Jenkinsfile is.\n\nI'm appalled by the amount of people that configure jenkins via the job ui instead of the pipeline via jenkins file. \n\nAs for executor type, it really depends on how jenkins was setup. I would have loved to use docker executors, but lol our build machines were windows 2008 boxes that management prevented us from tossing out or running something more recent on them.\n\n&gt; I can usually quickly tell if someone actually manages a Jenkins instance or just \"uses it\"\n\nUnfortunately, [I manage a Jenkins instance.](https://i.imgur.com/G18fcZp.png)\n\nNot for much longer, though. üéâ\n\nFool - show your jcasc or GTFO. /s\n\n\nWhy are you deploying in the same pipeline and what executor type are you using?\n\n0 builds allowed on the Controller node and using Docker executors, which became very interesting in regard to \"which scope am I in?\" in some projects' Jenkinsfiles.\n\nThey actually wanted *all* deployment in that same pipeline because \"automation is hard!\", and I was tired of arguing so it became a \"whatever man\" point for me and I put the \"Dev\" and (not really) \"Stage\" deployments in that pipeline. Actual *Prod* deployments were different pipelines and that's not something that I would budge on. This was an acceptable compromise to me instead of watching the spectacular garbage fire process that was happening before continue to happen, and I was real sick of getting calls at 3AM from PagerDuty about outages.\n\nAlso, \"Stage\" isn't really \"Stage\" in that pipeline, it's mislabeled and really closer to a \"Dev 1b\" environment.\n\nI know Jenkins like the back of my hand. Odds are high that you‚Äôll quickly end up having to bootstrap your own pseudo-CI within Jenkins via Dockerfiles at most companies using it.\n\nIn my opinion, Gitlab, Github Actions, Azure Pipelines, CircleCI are all better documented and easier to maintain over time.\n\nThe greatest Jenkinsfiles are basically just `sh \"docker run test\"`\n\nWhat you said doesn't make any sense. \n\nAre you talking about deployment of Jenkins itself, use of build images within a CI workflow or management of Jenkins?\n\nIt's either they don't know how their tools work, they can't comprehend that one tool might be better than another tool in a specific case, or it's the PHP problem where their only experience with it is hearing bad things or reading memes bashing it so they just assume that's fact.\n\nAlso from opinionated \"seniors\" who can't comprehend it's not a bad tool just because it's not a good fit for their use case.\n\nWhat's curious to me is that, in all the Jenkins bashing I've seen, no one is bashing the high-requirements: My DO droplet, 1vCPU/1GB RAM with a single repo triggering a single pipeline, was not enough to run Jenkins - it would repeatedly get into a state where the RAM would not be enough, the machine would thrash like mad and stop serving anything timeously (everything else on that machine would time out, including the statically served files on the webserver).\n\nI mean, I just want something to checkout out a branch, compile it, run the tests and deploy if all previous steps succeeded[1], or save the output to a statically served directory. Why does the tool need 500MB+ of RAM to do this?\n\n[1] My stopgap[2] measure is a bash script that does that, and no over-pressure on the RAM since.\n\n[2] Stopgap for 6 months now. The final thing is a small program I am developing that uses a sane input protocol and negligible (&lt;2MB) RAM to run the same steps.\n\nTo be fair it's going to depend on what it is you're trying to build or test. Optimized production builds or e2e tests that invoke a browser can prove to be resource intensive\n\nEdit: oh nvm, I missed the part where you explained your RAM usage\n\n&gt;- Plugin versionitis - zero guarantees version 1 of plugin X works with version 2 of plugin Y. Now this problem lots of package managers deal with, often badly, but Jenkins didn't even try to deal with it.\n\nWhat's a good way to deal with that?\n\nAnything that can execute scripts on an event is flexible enough to do what you really need. Jenkins was sort of in that position to start pushing it into the public eye. Hell, for all you care, you can write a java based script and do what you need.\n\nIt all depends on how locked down your runners/agents/botnet really is. At the end of the day you still have to maintain the infrastructure regardless of what you use, such as cleanups, upgrades, environment setup and what not.\n\nHow is Jenkins more flexible than, say, Gitlab CI and GitHub Actions? I‚Äôve used Jenkins for a few years back in the day and what I remember is how brittle everything was, not flexibility. And I don‚Äôt remember being able to do things on Jenkins that I  can‚Äôt do on GitHub Actions or Gitlab CI. Also the Groovy DSL (and its‚Ä¶ documentation, if we can call it that) gave me nightmares.\n\nWell it works with Perforce, so, it's more flexible than Gitlab CI or Github Actions on that metric alone.\n\nI do remember using git as frontend for svn via gitlab ci. Then again, my repository was git first.\n\n&gt;Also the Groovy DSL (and its‚Ä¶ documentation, if we can call it that)\n\n\"documentation\"\n\nlol\n\nSo now he's incurring the wrath of his Team every time someone needs to configure CI, smart move.\n\nWatch out for CircleCi. They treat you like a wallet looking to increase your credit usage instead of helping optimize. They also used to hide metrics in the Ui that would help lower your bills but you can get them since those metrics are in the json response for those graphs.\n\nA terrible engineer made Jenkins? Never would have guessed.\n\nMost people on this thread probably haven't used Jenkins pipelines with kubernetes executors and a sane requirement to not do stupid shit with the DSL. \n\nDo that, and keep your plugins in review, you'll have a powerful platform that is the equivalent of a living fossil like a crocodile. Effective and ancient.\n\n[deleted]\n\nNews flash: being a user is easier than a admin.\n\n\nTradeoff is you have to pay someone to do that job. Which is perfectly okay and preferable almost all of the time.¬†\n\n\nAs aside, did you use config as code to manage things?\n\nJustified &amp; Ancient?\n\nNo mention of Cruise Control (c.2000). I don't think this history is complete.\n\nI'm confused. This title and article seems to suggest that Jenkins was the first CI (hence the word \"invented\") but even if we assume they meant Hudson, it would still not be true, because by that time CI applications already existed for some years.\nJenkins eventually won the \"popularity contest\" but I don't see how it could be considered \"invention\".\n\nIt's graphite.dev blogspam\n\nAre there any alternatives or other approaches to Jenkins type tasks?\n\nLots. GitLab CI, CircleCI, TravisCI..\n\nI heard GitHub Actions isn‚Äôt too bad, I kinda want to try it‚Ä¶\n\nGithub Actions is fantastic.\n\n[deleted]\n\nWe make pretty heavy use of it and I've never ran into that.\n\nWe use self-hosted runners though, so that might make a difference.\n\n[deleted]\n\nBuildkite is really nice\n\nLiterally thousands. Google \"Jenkins alternatives\".\n\nAnd now I hate him because Jenkins is ass.\n\nit was pretty cool in like 2012\n\nKinda agree.  I've used it for various jobs from 2008-2018, even helped convert legacy builds to it.  Going from a custom legacy build to Jenkins feels like a massive uplift.\n\nBut when I revisited it in 2022 it just gave me weird vibes.  Like its been abandoned or subverted by commercial motivations.  Putting up with its arcane usability quirks and limitations seemed fine in 2008 but it doesn't feel like its improved any since.\n\nJenkins is incredible. I don‚Äôt use it anymore but that tool was crazy powerful when I did.\n\nit's still powerful but now there are tools that are just as powerful while not as complex.\n\nOh definitely, I‚Äôm not arguing otherwise. I would say that is true for 99% of early tools. For its time Jenkins was really amazing.\n\nYeah, we use Jenkins at my company. Just today 3 of my jobs became corrupt (couldn‚Äôt clear workspace without error) after weeks of running without issue. Only solution is to clone the job.\n\nHow did you manage to pull this off? Are you using pipelines at least?\n\nProbably doesn't even know what buttons he's clicking. Wouldn't be the first time I witness it.\n\nI have witnessed this. They're the same people that ask you why something isn't working and post an error to you that literally has the solution in it, if only they could read...\n\nWe get this, YMMV but we find if you go to your jenkins server and kill all dotnet processes then try clear the workspace again you should be able to. We get this sometimes, never fully investigated as the fix is simple.\n\nJenkins isn't \"ass\", it's just *more* complex than the alternatives. It takes time to be a Jenkins expert, and nowadays most people don't have or don't want to spend that time.\n\nIt ¬†has no true active active high availability and uses xml files as the only supported data store. In terms of a service that you want in the critical deploy path, it‚Äôs pretty poop. Plugin management also awful.\n\nHow many dev teams actually _need_ high availability, and what's wrong with XML?  XML is great actually.  Source: I said it just as confidently as you did.\n\nI worked on two projects that were similar in scope and size, one that went all in on the buzzword bullshit of high availability, k8s, yadda yadda, and the other just ran their Jenkins instance off a single dev machine.  You wanna know something funny?  It wasn't the latter project that had stability issues and it wasn't the latter project that had less dev time dedicated to working on the project instead of mucking with infrastructure.\n\nFor small teams, you probably don't need to invest into HA. If you are a 250+ eng org reliant on larger jenkins instances, a day of downtime == a year of eng salary in lost productivity, at which point things like high availability start making sense. If you're a large org and solve it by sharding to many jenkins instances to keep the impact of one going offline low, your costs go up and the investment into jenkins management go up.\n\nXML is mostly problematic because the downstream impacts of it are what make HA hard, as well as make the config management layer of jenkins annoying, and it's also part of what makes it fiddly and annoying in a kubernetes environment. A lot of groups reliant on kube isolate their app processing from their data storage because kubernetes is not a great use case for super stateful data storage solutions due to the churn that is naturally part of using a resource bin packing solution like kube. So in this case, the fact that Jenkins has chosen to use XML makes it natively less of a good path for kubernetes, which is a silly thing for such a critical app to do.\n\n&gt; XML is mostly problematic because the downstream impacts of it are what make HA hard\n\nNonsense. You are going to hurt yourself waving your hands about so much.\n\n&gt; If you are a 250+ eng org reliant on larger jenkins instances\n\nYeah so just spin up more Jenkins instances.\n\n&gt; If you're a large org and solve it by sharding to many jenkins instances to keep the impact of one going offline low, your costs go up and the investment into jenkins management go up\n\nWhat exactly are you all doing to your Jenkins instances?  Do you know how much we manage our Jenkins instance?  We don't.  It's set and forget.  You keep frankensteining Jenkins no wonder you have to keep fixing it.  You keep it bone stock and it just works.\n\n&gt; XML is mostly problematic because ...\n\nI dunno man, seems like a skill issue to me.\n\n&gt; So in this case, the fact that Jenkins has chosen to use XML makes it natively less of a good path for kubernetes, which is a silly thing for such a critical app to do\n\nFirstly: \"It's silly tool A used technology X even though technology X is suboptimal when used with tool B which wouldn't be available for a decade after tool A was created\"\n\nSecondly: Going back to my previous point, don't try to high availability your Jenkins instance and your problems go away :)\n\nThere is a real issue with Jenkins in that it's secret and storage medium is badly in need of modernization. \n\nWe need a clean way to execute blue-green deployment on Jenkins, something durable pipelines does a great job helping accomplish but the core parts of Jenkins need changing to support it. \n\nThat said, this is mainly for a modernization issue where I want Jenkins clustering and the ability to roll out upgrades in a fairly tight manner where I can ensure that events aren't missed.\n\nWe deploy billion dollar software with it. It's rock solid. Just don't use plugins. But I do absolutely hate the configuration story. It can be so much better but it's stuck.\n\nThere is plenty of shitty code shipping billion dollar software.\n\nIn fact at that scale, I‚Äôd expect it, and be oddly worried if there weren‚Äôt.\n\nThe whole thing is plugins, if you‚Äôre using multibranch pipeline type stuff. I‚Äôm not saying the core app isn‚Äôt reliable, but everything fails eventually , and for a mission critical tool like ci/cd you want it to have high availability¬†\n\nThe core app is plug-ins too :) Literally everything is implemented as plug-ins, all the way down.\n\nI tried Jenkins a long time ago and thought it was useless. A year later I tried it again (2016ish) and realized it's just a clunky thing you put plugins into to actually do anything, and 20 plugins later it was doing exactly what I wanted.\n\nIt's quite clunky by modern standards but perfectly serviceable if your internal tooling pipeline doesn't need more than two nines availability (smallish shops that can stand a few hours downtime on CI here and there). \n\nMy workplace still uses it for legacy reasons. We use more modern stuff too though.\n\nMy jenkins setup is at four nines, but I've also been using it for ten years. You CAN run Jenkins in a sane way...but it is non obvious and not trivial.\n\nThe JEP for that is underway but I'm hoping will get some attention(with luck, we might be able to work on it) - moving the job.xml to a better storage solution coupled with moving build folders to S3/bucket storage will go a long way.\n\nBut yeah - same story. We support a large chunk of a very large org via Jenkins using Kubernetes executors. With some guard rails in place and a good bit of security, we support a pretty robust platform.\n\nI‚Äôd love different data stores to happen, but honestly it feels like since the 2.x release the vision has been scattered enough that not much seems to make it into the core features, so I am not holding my breath.¬†\n\nIt's suffering from the same problem most crucial open source platforms do - lots of users(big ones) that don't contribute nor provide leadership to the software. \n\nIt seemed like things were starting to turn a corner right before COVID happened - after that, it's been scattered just like you said.\n\nWhat do you use instead?\n\nFor personal projects, GH actions And previously gitlab. For work work, Jenkins. Jenkins still wins in how it approaches GitHub events with the webhooks + polling strategies, and the scripted options are often a little nicer than yaml when trying to provide turn key CI/CD at the enterprise level. It just also forces a higher level of investment and care than seems warranted. For ‚Äúlegacy Jenkins‚Äù ie Jenkins as an operational task runner instead of CI, I‚Äôm using Rundeck or whatever pagerduty rebranded it to.\n\nWhat's a good alternative?\n\nWe switched from Jenkins to GitLab CI and it made our lives much better\n\n\nI hear GitHub Actions is largely inspired by it, but GitLab is open source and easy to run.\n\nwe use gitlab and Jenkins combined so that‚Äôs fun\n\nMy job is making us switch from gitlab ci to jenkins and this topic isn't making me happy about it.\n\nyou shouldn't be. they're going backwards.\n\nLiterally any of the modern ci/cd systems that support config as code.  Gitlab, Travis, bitbucket pipelines, or (my preference) GitHub actions.  U can't really complain about the 2k free minutes per month actions gives you.\n\nSetting up your own runners is also pretty trivial so if you don't want to pay you can easily just do that.\n\nJust switched to CircleCI and it‚Äôs been huge. Running builds on a cached docker container has drastically reduced our build times.\n\nCircleCI is okay. It‚Äôs certainly better than Jenkins.\n\nI also think there is a lot better than CircleCI, especially Github Actions. Pipelines just tend to take less time to build, and have less issues. That‚Äôs in part due to there being far more community support around GA.\n\nIsn‚Äôt that dangerous? I thought you wanted a completely clean environment each time.¬†\n\nYou can layer docker images, and only do things like have it rebuild application changes, unless your dependencies have changed. So you can have a base docker image, then an image with the dependencies thats based on the base image, and then build your app code on top of that, every time.\n\nIt‚Äôs on you to rebuild the container every once in a while, but reinstalling JDK on every PR is kind of a lot.\n\nDo you mean cached container or image? I‚Äôm not that well versed in docker, but wouldn‚Äôt you just have an image with JDK and other core dependencies already installed, then spin up a fresh container each build?\n\nAnd of course there was cruise control released before Hudson in 2001. Not sure if it was the absolute first:\n\nhttps://en.m.wikipedia.org/wiki/CruiseControl\n\nHe could have reached out to Cruise Control instead, now dead.\n\nhttps://circleci.com/blog/a-brief-history-of-devops-part-iii-automated-testing-and-continuous-integration/\n\nhttps://en.wikipedia.org/wiki/CruiseControl\n\nI am somewhat confident that Cruise Control pre-dated Hudson.\n\nThought that said \"jenkem\", man that shit would've been a little extreme\n\n&gt;Modern dev teams test every code change before merging. This isn‚Äôt just a convention; right along with code review, it‚Äôs a default standard enforced across almost all company codebases.\n\nThis man leads a sheltered life\n\nJenkins was invented because Cruise control was shit.\n\nAs somebody who used CruiseControl. It was absolutely great, but incredibly inflexible. \n\nHudson/Jenkins improved a lot by making your build pipelines more flexible to configure, better feedback, etc.\n\nNow using Gitlab CI and GitHub Actions... just a wrapper around trying to jam everything into shell scripts.\n\nWhat Hudson/Jenkins got right and the other still haven't caught on: build timelines. I have easy access to the previous builds in this branch, and perform differential analysis. Going this in Gitlab CI or GitHub Actions is just an absolute pain.\n\nEvery build server solution I have used so far has various levels of shit. I haven't used Jenkins for almost 5 years now, so I don't know how it has changed. But it was absolutely amazing in handling quality control and delivery of the software we actively work on.\n\nWhat‚Äôs your explanation for Bamboo? :)\n\nI thought Jenkins was invented because Hudson changed its licensing.\n\nJenkins is just a fork of Hudson rebranded since Oracle gained the ~~copyright~~ trademark for Hudson when they bought Sun.\n\n&gt; Oracle gained the copyright\n\nThe name was changed due to Oracle trademarking the name Hudson, not because of a copyright issue.\n\nOh, believe me, Jenkins was a life saver back in the day. Busch better and easier to deploy and maintain than alternatives at the time. \n\nTimes have moved on and there are better options out there now. No fault of Jenkins. It‚Äôs a product of a different time. \n\nI wish GitHub Actions style CI would be more common and just as well supported across the board, but that is probably not going to happen anytime soon\n\n[deleted]\n\n&gt;I Love Jenkins. I think it works great.\n&gt;\n&gt;I‚Äôm so surprised that so many of you like using Yaml for your builds, maybe I‚Äôm old, but it seems so wrong.\n\nYAML isn't bad once you get over the \"spacing is syntax\" thing and learn what data type is what. It's essentially easier to read JSON. Except with comments and anchors that can refer to other previously-defined values in the file, kinda like a pseudo-variable. Makes a great config file format too.\n\nI would write every document for the rest of my life in YAML rather than even *think* about touching Groovy again.\n\nIt isn't really easier to read than JSON though, maybe slightly. But the problem is you don't know what level you are at in a long file because you can't see the start of the indentation. Also it is hard to share keys via cut/paste because all of these are valid:\n\n    foo.bar.some-key: theValue\n\n    foo.bar:\n      some-key: theValue\n\n    foo:\n      bar:\n        some-key: theValue\n\nSo you can't just paste the key into your YAML because you have to figure out where it fits in at.\n\nI love YAML as it is used in two contexts: Ansible and Travis CI.\n\nI mostly hate YAML as it is used everywhere else (Kubernetes, GitHub Actions, Appveryor CI).\n\nI think the main difference is how many levels of indentation I need in front of my shell script.\n\nSo in turn he broke everyone‚Äôs builds. I jest but seriously I have a strong dislike for Jenkins unless it‚Äôs run with a velvet gloved, iron fist. Groovy also isn‚Äôt my (anyone‚Äôs?) favorite\n\nI once had a SWE tell my team that groovy was an anti pattern. He was right. No one want's to learn it, and when you have to the code is utter shite.\n\nGroovy is a nice scripting language. What's not to like?\n\nJenkins is absolute dog shit\n\nWhat's a good alternative? My only problem is thr lack of documentation.\n\nDepends on your setup. GitHub actions/gitlab Pipelines, Buildkite, CircleCI, Jenkins would be my choices, in order.\n\nCircleCI incident really devalue that company.\n\nEverything is better than Jenkins. The core issue with Jenkins is that they never really made the transition to scripted pipelines that you can put into your repo along with your code. Also, every pipeline depends on a fragile combination of way to many Jenkins plugins that all have to be installed and maintained manually and have ugly side-effects with each other.\n\nIn other words: you can't reliably re-produce a Jenkins build despite all the hard maintenance work you have to put into a Jenkins instance and that makes it a very useless tool for its purpose.\n\nThey did add scripted pipelines in your repo a few years back (Jenkinsfile), it‚Äôs not half bad either.\n\nThat said, Jenkins is still a pain to manage and plug-ins are its biggest strength and also its complete downfall. Everything else, including self-hosted options, is just much simpler.\n\n&gt; Also, every pipeline depends on a fragile combination of way to many Jenkins plugins that all have to be installed and maintained manually\n\nThere's the [Jenkins CasC](https://plugins.jenkins.io/configuration-as-code/) plugin, which combined with running jenkins via docker can give you a way to reproducibly^1 bring up instances without having to manually install all that garbage.\n\n^1 With the caveat that this setup is still hot garbage that breaks half the time and is a pain in the ass to do any in-depth configuration with, but at least it's vaguely better than starting from scratch and doing it manually each time\n\nThe issue with JCASC is that the Jenkins leadership needs to pull the bandaid off and start massacring out of date/abandoned plugins and forcibly keep them from loading if they don't support JCASC. \n\nIn addition, there needs to be a standardized definition of config vs each plugin getting to decide syntax/formatting/java constructor overloading.\n\n&gt;The core issue with Jenkins is that they never really made the transition to scripted pipelines that you can put into your repo along with your code.\n\nWhat? this is pipelines from the get go - define your pipeline and point jenkins to the repo holding the Jenkinsfile. \n\n&gt; Also, every pipeline depends on a fragile combination of way to many Jenkins plugins that all have to be installed and maintained manually and have ugly side-effects with each other.\n\nThat's not...even remotely true. You need to actively fuck shit up to end in this situation. Your pipeline should really just be encompassing your build scripting that does the heavy lifting. The CI pipeline is there to provide infra for execution and processing test results.\n\nSome people believe that the CI tool should be able to talk directly to umpteen million things. \n\nSome of us just want the CI tool to run the same scripts we could run manually with almost no special code in the build system (possible exception being uploading build artifacts somewhere). These are the sane people, and everyone else is fucking nuts.\n\nYou mean Jenkins pipelines that we've literally used for years?\n\nOr is your experience of Jenkins 20 years old and that's all you can parrot?\n\nTeamCity for life\n\nI don‚Äôt have these terrible memories of Jenkins, but it‚Äôs been a while.  They‚Äôve all been supplanted by unpleasant memories of Bamboo.  Which may actually be worse than cruise control.\n\nCorrection: Groovy (the language) is dog shit\n\nI always recommend people to use write makefiles and use Jenkins as a wrapper to run those makefiles. Stop using Jenkins to run complex logic, it‚Äôs a nightmare to debug\n\nIt's not actually. When you need to build stuff on mac, windows ,and linux, and all the flavors in between, it's the best option. It could be better though.\n\nJenkins was from the time of the other tool from IBM that I don't remember the name, I think at the time there was this general need for pipelines where at some point a team could click a button to run and take responsibility around it - with different set of roles. I don't remember if it was at the same time or not too late after that we got the one from Microsoft (VSTS pipeline?) with the same roles config and not that long later the first iteration of Team City. I think things would only start to shift to give more empowerment to the developer when Travis appeared and offered free tiers for open source (I don't remember when, was it 2014?), and then it was the pipeline as a code era kick-started, so the pipeline responsibility started to shift to the developer from the devops team (that usually had a different name at that point)\n\nUrban Code is maybe what you are thinking of.\n\nHow come they made plugins that broke Jenkins after the experience that bootstrapped the project?\n\nHudson was invented as an open-source alternative to Cruise Control.\n\n&lt;/end&gt;\n\nI wish gitlab/github code support rather than using yaml as the logic creator\n\nAt one of my works emails and review marks from Jenkins come signed as \"leeroy jenkins\". I was unaware for several years about what personage this is referring.\n\nI still doubt whether this was the true origin of selecting this very name:)\n\nAnd now we get mad when someone breaks Jenkins, which in turn beaks the build. Jenkins needs a jenkins\n\nJacob's story really highlights the balance between specialization and general skills in small teams. It's tough needing to be a jack-of-all-trades."
  },
  {
    "title": "Uncle Bob Martin: \"I am in the midst of writing the second edition of Clean Code. It's a complete rewrite, and it's coming out very different from the first. Oh, the message is the same. But the presentation is entirely different.\"",
    "body": "",
    "score": 1665,
    "url": "",
    "created_utc": 1723217231.0,
    "author": "markiiitu",
    "permalink": "/r/programming/comments/1eo2lo5/uncle_bob_martin_i_am_in_the_midst_of_writing_the/",
    "all_comment_text": "Commit message: small refactoring\n\nLines changed: 21586\n\nTBF, this happens frequently when you do some massive rename like \"MessageBus\" -&gt; \"SQSMessageBus\". Then you find out why nobody did this rename before.\n\nThat's fine, but do not add anything else to a commit, then you can tell at code review about that comment. Resolving conflicts there will not be that bad.\n\nI've seen an even better approach at one company I worked at, but I never have enough time to re-implement this at other companies and/or opensource tool.\n\nBasically they had a directory with \"code migrations\", which are a similar concept to \"DB migrations\" but for your code. The \"code migrations\" were written using some code-parsing/generating library, and ran by a separate independent worker. \n\nThis way you would have one PR with something like (rough pseudocode): `foreach file; file.imports.replace(\"MessageBus\", \"SQSMessageBus\")`. Then you would get this PR approved and merged.\n\nThe worker/bot would then see this new \"migration\", run it, and create a new PR with 5000+ files changed. It would also have a link to the first PR in it's description. Then it would wait for CI to run and merge it.\n\n&gt;foreach file; file.imports.replace(\"MessageBus\", \"SQSMessageBus\").\n\nYikes. I hope this isn't the code. Now the ClientMessageBus is the ClientSQSMessageBus and everyone is even more confused.\n\nDidn't Twitter do something like that to change all `twitter.com` links in tweets to `x.com`, and someone realized that's what they were doing so they registered the URL `spacetwitter.com` so that they could post what looked like links to `spacex.com`?\n\nEdit: importantly, I believe they only did it for the *display* text, but not the href, so the tag would end up something like: `&lt;a href=\"https://spacetwitter.com/\"&gt;https://spacex.com&lt;/a&gt;`\n\nNot for a refactor, but in live code. Same terrible use of find/replace though...\n\nSimilarly, when the British exam board OCR merged with MEG, physics syllabuses were infamously printed with \"Ocrawatts\".\n\nI don't know that is but it sounds delicious and dangerous.\n\nOr if you ran it multiple times or with code already using that convention\n\n- MessageBus -&gt; SQSMessageBus\n- SQSMessageBus -&gt; SQSSQSMessageBus\n- SQSSQSMessageBus -&gt; SQSSQSSQSMessageBus\n\nI've had to unpick and repair some trash that got sed trashed like this, wasn't a happy camper.\n\nMeh, if you know what it means, it is not too bad. Also, the code still works fine. We'll fix it next sprint.  \n/s\n\n^(Wow, I just managed to trigger an anger response within myself)\n\nLook I'm just thinking right now in this instant that you might want to go maybe fuck yourself.\n\nWe all share this pain, in one form or another.\n\n[deleted]\n\nAlso, make sure the script that actually does the changes lives exclusively in the CI/CD pipeline that runs exclusively after merging the PR. For some exotic reason it is not possible to run this bot locally, and nobody thinks it's worth the time to clean this up.\n\nI use regex. Helps you deal with many of the edge cases when you can say things like 'SQSMessageBus, exept when it's preceeded or succeeded by another character that can be part of a variable name'\n\nAlso: modern IDEs do this kind of renaming really well, as they don't need to guess if you're talking about the same 'MessageBus'.\n\nThey've already parsed it, and they *know* which definition you're referring to.\n\nScott, it's the weekend, give me a break from your shit please\n\nI was thinking the same. I work on some \"i'm the only dev\" 10k loc repos and regex \"find in file\" refactors are pretty harrowing even when it's just a rename or LDAP path change-- so many corner cases ready to ruin your day....\n\nI can't imagine foisting that off to a PR bot at 4pm and sleeping well that night.\n\nNo, as I mentioned it was just a super rough pseudocode of how the top level PR would look like. The library they used fully understood the language syntax (in that case Java), and you would have to provide a fully qualified class name where needed. In other words it was not a dumb find-and-replace, but a proper code refactoring library.\n\nYou could maybe use a library like Python's `rope` to invoke a refactoring routine.\n\nInteresting, although this is one more tool you need to support, but not very complex it seems.\n\nSounds a bit like the codemods package in JS\n\nThat's an interesting solution to that problem!\n\nGiant, shallow refactors like this are really easy to coordinate if you are willing to work exactly one extra hour:\n\n1. On Monday, communicate to your team that a massive, every-branch-must-be-rebased change is coming later this week.\n\n2. On Wednesday, let everyone know that no new PRs can be open after lunch time.  Merge any open PRs that can be merged in.  Tell everyone to rebase their feature branches off of latest develop, push their most recent code, and go home. \n\n3. Rebase your refactor branch, open a PR with just the shallow refactor and have it merged in as everyone goes home.\n\n4. Wait for the develop build to run and tests to pass, then rebase open PRs that are unconflicted.  Rebase feature branches for your team too if that's a thing your team does.\n\nTa-da.  It's as simple as coordinating everyone rebasing their branches and pushing latest code on the same day, then rebasing their branches the next morning (or doing it for them).\n\nIt could be done like that yeah. That's a more proper? way than I thought of:\n\n1. You do the refactor in your own branch for a task when working on a feature if it's allowed, or in a branch specifically for a refactor task\n\n2. Create MR/PR, code review, tests\n\n3. The branch gets merged somewhere (develop, master)\n\n4. Other devs update the master when working on their tasks. I also prefer to rebase in this situation\n\nYou need to have everyone sync twice to prevent scenarios where you have cascading conflicts because of long lived feature branches with poor source control hygiene.  Take for example a scenario where you're changing the name `Customer` to `Client`.  If I'm on your team and currently working on a feature that sends notifications, I'm probably interfacing with a bunch of `Customer` objects.  Under both of our approaches, when I rebase after your changes land on develop, I'm fine.\n\nNow, let's say we have a third team member.  He's been working on some other change around `Customer` objects - perhaps he decomposed them into `Customer` and `CustomerMetadata`.  You picked up this change so your PR was successfully merged, but I haven't rebased yet today, so I don't have it.  Tomorrow, when I come into work, that change *and* your rename will have to be applied.  If I continue work on that branch for another two weeks before rebasing, and several other now-`Client` changes have been made, I've signed myself up for an entire day's worth of git conflict resolution tasks.  This is not your fault, it is my fault.  It's also entirely predictable, common, and guaranteed to happen.\n\nA good rule of thumb for avoiding the black hole of spending your entire day fixing your branch's history when you want to merge a large branch is to rebase like you brush your teeth - the very first and last thing you do each work day.  But not everyone follows this advice.  And it's your responsibility as a conscientious team member to not set your peers up for failure - if you make the extra effort to coordinate rebases across your team, you assume the responsibility for the whole team, and if people don't participate, that's not your failing, it's theirs.  You should always do what you can to set your team up for success, and skipping coordination like this is anything but.\n\nIn short, the way you describe is fine in the abstract, but play it out.  It doesn't account for obvious failure scenarios that are going to happen.  And when they happen, you build up negative political karma - both towards yourself and to the general idea of giant, shallow refactors.  The next time you have to do one, you will get increased resistance, and so on forever.  Eventually you will stop doing them because you don't want to deal with the hand wringing and whining.  If you want to do something that affects other people and requires their cooperation (and do it more than once), you should make it as easy for them as possible; that's just good advice in any situation.\n\nYeah that's why I said it's more proper. Although I rather wouldn't touch other people's branches. My job situation is different that repos have other contributors not from our company, and amount of our devs in repo at the same time is very small. 1-2, sometimes 0.\n\nNow, when it's a deadline rush it's different, but that's not the time to rename a class that is used across the whole codebase :D\n\nYou guys guys make mountains out of molehills.\n\nyou can also then add it to git-blame-ignore-revs so it never shows up in a git blame\n\nProtip: if you ever wanted to sneak in your own code for ... whatever reasons, do it as part of a large PR to \"add autoformatting\" or \"rename variable\". No one's going to review 20,000 lines\n\nPR: 99+ files changed\n\nLgtm. Approved\n\nFriday evening.\n\nUh, we can‚Äôt reach the website. Is something wrong with the internet connection?\n\nDon't worry about the zeros. I'm sure our kernel driver will reject a malformed update like that.\n\nThat's where you sneak in the fix to the really bad bug you caused earlier that nobody noticed yet\n\nThat one guy who CANNOT stand tabs for inline the company is using for 20 years.\n\nI'm sure the past couple decades of not programming have prepared him to really improve this book on programming\n\nHey, maybe his examples won't be broken this time. I love when somebody saying they are going to effectively \"make a competent programmer out of me\" can't even refactor a simple prime sieve without changing the behaviour so it's no longer thread safe and not even realize it.\n\nMy biggest tinfoil hat theory is his original book was purposefully designed to train people wrong to make consulting more lucrative. It contains the worst programming style advice I've ever heard.\n\nWe have purposefully trained him wrong, as a joke.\n\nI am bleeding! ‚Ä¶making me the victor.\n\nI was hoping I could be the chosen one\n\nI cannot remember the last time I even thought of King Pow!, let alone seen it referenced in the wild... \n\nThe dubbed dog made me cry with laughter as a kid\n\n Kung Pow! Enter the Fist gets quoted a lot in the wild - at least compared to a similar very quotable film like Grandma's Boy.\n\nA lot of comedy relies on setting up a joke / punchline so it has a context to stand in - but while the setup gets its appreciation after the punchline, it's often either not memorable or funny.\n\nKung Pow!'s writing basically used a high throughput philosophy of jokes to get both.  The only hitch is that the first jokes / gags have to land AND setup the viewer to be receptive to the nonstop quotable lines.\n\nKinda like the [fake interview with Stroustrup](https://www.snopes.com/fact-check/program-management/) where someone wrote a story about Stroustrup inventing C++ to drive up developer wages\n\nWorst part is, many people follow that book like its a cult. Once you work on a \"clean code\" codebase, you'll never want to ever again.\n\nWhy is that?\n\nI think lots of \"thought leaders\" are giving advice that's a thinly veiled attempt to create work for themselves.\n\nI mean yeah, this Bob guy lives off of conferences and selling books.\n\nMy immediate reaction to this reddit post was \"hasn't he done enough damage?\"\n\nHe is more into GOP politics these days because the other party are \"communists\".\n\nYeah that‚Äôs why I blocked him on Twitter. Got a bit insufferable.\n\nEven the period before the 90s in his carreer is a mistery. The only known constant is that he worked at a company that failed to release a single piece of working software.\n\nChapter 1  \nIf a function has more than 5 lines it needs to be refactored.\n\n\"Are you using an enum? Hide the switch statement behind an abstract factory.\"\n\nA method should ideally take 0 arguments (hide them as private members of your class!).\n\nThat‚Äôs his actual advice from the first book.\n\nThe fact that anyone seriously thinks implicit side-effects are better than explicit arguments and return values boggles my mind.\n\nUncle Bob also argues that errors-as-value is bad because a function should only ever return one thing, so we should instead use  `try/catch`. It's probably one of his worse takes.\n\nThat‚Äôs because he doesn‚Äôt believe that idioms from the language trumps his preferences.\n\nDoes he still argue that? I figured that since he seems to be a clojure guy lately he might've come around on things like that...\n\nHe argued this point during a recent livestream with The Primeagen (at 58:25).\n\nUncle Bob argued that Go's error handling was bad because functions that return multiple values \"complicates things\".\n\nPrime argued that an exception is essentially a \"second return value, or return channel\" but worse since you don't have to handle the exception immediately, and if you don't, you have a control flow problem because you don't know which piece of code is going to catch the exception.\n\nUncle Bob's answer was that you should always catch the exception immediately after you invoke a function that may throw... which is exactly the reason why people use error value... Uncle Bob eventually agreed that they might be the same.\n\nUncle Bob look confused during the whole exchange.\n\n&gt; you should always catch the exception immediately after you invoke the function\n\nThat's taking the worst parts of both options and putting them together.\n\nGo's error handling is bad, but not for the reason Uncle Bob said. I think what Prime was arguing was that in Go, a function that can throw an error returns a member of a *product type* (aka a tuple) whereas in Rust, an error returns a member of a *sum type*.\n\nUncle Bob's solution is just Java's checked exceptions, which are just Rust's errors but with worse syntax and aren't as compatible with lambdas. It might not be as good as Rust's, but it's better than Go's.\n\nSee https://go.dev/blog/error-handling-and-go:\n\n    func Sqrt(f float64) (float64, error) {\n        if f &lt; 0 {\n             return 0, errors.New(\"math: square root of negative number\")\n        }\n        // implementation\n    }\n\n0 is a dummy value and it is easy to not handle an error in Go and just use the dummy value.\n\n&gt;Uncle Bob's solution is just Java's checked exceptions\n\nI don't think what bob wants are checked exceptions. Checked exceptions are not \"I always handle exceptions immediately when they could come up and pay attention that I never go further than one level deep with my handling\".\n\n&amp;#x200B;\n\n&gt;which are just Rust's errors but with worse syntax and aren't as compatible with lambdas. It might not be as good as Rust's, but it's better than Go's.\n\nI think there's a misconception here. Yes, they're certainly closer to \"errors as values\" in that they give us type-level information about possible errors, but they're really not \"like rust's errors but with worse syntax\" and they're also not inherently incompatible with lambdas.\n\nYou may have heard of the [keyword generics (totally not effects)](https://rust-lang.github.io/keyword-generics-initiative/updates/2024-02-09-extending-rusts-effect-system.html) initiative for Rust: checked exceptions are a special case of that. They're a particular kind of effect. Have a look at [koka](https://koka-lang.github.io/koka/doc/book.html) for example to see \"checked exceptions done well\" (in particular there's absolutely no issues around lambdas and closures) and also how they're really orthogonal to rust's current system. The two mechanisms (monadic errors and error effects) essentially life in two different worlds that we can move between\n\n&gt; He argued this point during a recent livestream with The Primeagen (at 58:25).\n\nProviding a link without timestamp is common. But rarely do I see the opposite xD\n\nI assume you just forgot to add the link? Thanks btw\n\nHere's the link: https://youtu.be/UBXXw2JSloo?si=V9P58MaUWcfqq1Uw\n\nI'm just a lazy phoneposter :P\n\nWith timestamp: [https://youtu.be/UBXXw2JSloo&amp;t=3505](https://youtu.be/UBXXw2JSloo&amp;t=3505)\n\n&gt; Uncle Bob eventually agreed that they might be the same.\n\nI just checked the video and Bob just seems like he wants to get away from an indefensible position without admitting he was wrong.\n\nYeah. Uncle Bob has the whole \"I'm not wrong, you just didn't understand what I _really_ meant\" energy thoughout the entire interview, even after completely contradicting his original statement.\n\nI respect Prime for not wanting to be confrontational during this interview, but I have colleagues who argue like Uncle Bob and it makes my blood boil.\n\n&gt; \"I'm not wrong, you just didn't understand what I really meant\"\n\nWhat annoys me about this is that they basically are admitting \"I failed to communicate\" but instead they *always* make it a \"you\" problem.\n\nI had a boss like this. *Everyone* was just constantly \"misunderstanding\" him. The only thing in common was... him.\n\nHe could never bring himself to ever admit fault. If I don't understand what you meant then you failed to communicate it. If you put it in a book - then you, literally, failed at your job. If you can learn to admit it - you can then fix it *and move on*. Instead they'll double down and spend ten times the effort because they *have* to protect that ego.\n\nOof okay that doesn't sound great.\nEDIT: Just saw your edit and watched the bit. Hot damn the guy is as terrible as ever and *so* full of himself\n\nDon't use enums, just make each enum value a subclass and instead of switching on the value of a variable, call into a method on that variable which expresses the behaviour that was in the switch.\n\nOh yeah, makes sense. And be sure you put those subclasses inside a service that you get a reference to via dependency injection.\n\nIf a chapter has more than seven\n\nChapter 2\n\nMy favorite comment of the day!\n\nif you cant fit it onto an index card, break it up\n\nWhat to do if it's 5 lines of java-style name of variable?\n\nIf a book has more than 5 chapters, then it must be split in two books. I am sure this will apply to all books, just like the 5 line rule applies to all code /s\n\nI've read Clean Code and Agile Software Development. They were good books and I learned a lot from them at the time. They changed the way I wrote code and thought about the practice of writing code. \n\nHowever, I've since come to (what I think is) a deeper and broader understanding of software quality and what it means. Why we do certain things. What it means to be \"readable\" or \"understandable\". What it means for something to be \"singular\" or what a \"responsibility\" is, etc. A lot of what I think about software design now is pretty different from Bob's conceptualizations, and in some cases my ideas are directly contradictory to what he said back then.\n\nI'd be interested to see what a second edition looks like, and how he changes the \"presentation\" of the ideas in it. At this point in my career, however, it's pretty rare that an author is going to fundamentally change the way I view any part of the software development process.\n\nI highly recommend \"Philosophy of Software Design\" by Ousterhout, in my opinion it covers a lot of the same subjects but with some more nuance and some really good guidelines and ideas\n\nI have read Ousterhout and enjoyed him quite a lot. I think that was a better book than anything Martin has written, though it has gotten only a fraction of the success.\n\nIt's a brilliant book and among the most pragmatic of the books on coding that I've read.\n\nThe trouble with \"readable\" is that without enough context it boils down to subjective feelings or, even worse, the lowest common denominator. If a complete novice fails upward and gets to define what \"readable\" code looks like, you get something that none of the seasoned developers can maintain without losing their shit.\n\nReadability is extremely important and a good thing when the definition correlates with how *at least moderately experienced* programmers envision it. It should never, ever be readable in the eyes of the village idiot. And of course you don't want the biggest Brainfuck fanboy at the office to define it, either.\n\n&gt;  It should never, ever be readable in the eyes of the village idiot. \n\nHow about this then?\n\n\"*It should be readable by the dumbest person that fully understands the problem*\"\n\nInstructions unclear, I have written code that is readable in the eyes of no one.\n\nHahaha perfect\n\nThere are objective criteria for readability, including such factors as how many steps it takes to locate the information you need, how many lines of code you need to read to learn how it behaves, and how much external context is required to understand any particular piece of code. While the effective readability for any individual person will vary depending on their knowledge, skills, and conditioning, we can still quantify the objective factors which apply to everyone and optimize those.\n\nEspecially when you consider bad rules for readability enforced by novices, the problem isn't that these rules make the code more readable for them and less readable for others, but that they are simply wrong about what makes the code readable to anyone. This is because they never had to actually read code (just recognize code they wrote) or they are so bad at reading code that they can't tell what makes it easier or harder, it's all just hard to them. So the best they can do is try to make the code more *familiar*, which is of course entirely subjective.\n\nI don't buy the argument that readability is completely subjective. In fact, we know quite a lot about what makes code easy to read: shorter lines, fewer lines per method, left-to-right and top-to-bottom control flow without a lot of deeply nested structures, well-named variables and methods which make proper use of nouns and verbs and contextual clues, and statements which emulate common English prose. We also know a lot about the psychology of cognitive load, the amount of information a person can keep in mind at one time, how keeping like ideas close together (and ideally all on the screen at once) allows us to pickup things faster and reason about them more clearly. We know how using common jargon between teams, or using a pattern language can help simplify communications and make them more concise and precise.\n\nA lot of developers really throw their hands up at the idea of \"readability\" because they want to focus on the technical (and that's what many programming \"teachers\" want to teach), but we really do know quite a lot about the psychology of human-to-human communication and it's a shame that more programmers don't get exposed to it.\n\nI'd argue that shorter methods actually worsen readability. Compare the preceding sentence with the \"short methods\" version of the same thing:\n\n    main(): what_id_argue()\n    object(): readability\n    premise(): subject() verb() object()\n    subject(): shorter methods\n    verb(): worsen\n    what_id_argue(): I'd argue that premise().\n\nThe most damaging thing for readability is being forced to skip around to untangle logic. The body of a function should be as long as it needs to be to convey a self-contained and cohesive unit of logic, such that the need to cross-reference other functions to understand this one is minimized.\n\nIf I'm dealing with a big chunk of highly cohesive code, I find a single 1000-line function much more readable than 50 20-line functions.\n\nThere's very little concrete guidance about how short methods should be except \"they should be small enough to fit on a single screen at once\" which isn't much of a limitation with modern large monitors. I do tend to prefer them to be much shorter than that, but if a method isn't meant to be a single line, then I wouldn't force it to be.\n\n&gt;¬†being forced to skip around to untangle logic.\n\nThis strikes me as being part of the problem. Having to untangle logic implies it is in a tangled state. If your methods are named in a descriptive way, and if your team is trained to and trusted to have methods do what their name implies, you shouldn't have to dig around to figure out what's going on. That's the fundamental basis of the Abstraction principle.\n\nCreating proper abstraction boundaries, using meaningful naming for methods, limiting side-effects, having a common pattern-based language for the team, and having a set of standard conventions that you follow, all have the effect of reducing surprise and increasing understanding. The most important reason to create a method is to give a good, descriptive name to a block of code. If you have a 1000-line method, you are missing out on a lot of opportunities to give good descriptive names to things and to create good abstraction boundaries.\n\nIt's hard to argue against this without concrete examples but in my experience writing readable code means writing maintainable code too. I've never heard a seasoned developer go \"oh no, this code is too clear and easy to understand! How am I supposed to maintain it!!\"\n\nWould love to hear some examples where ‚Äûresponsibility‚Äú or ‚Äûsingular‚Äú mean something different nowadays in comparison to his first Clean Code book.\n\nMy feeling is that the CleanCode evangelists took many statements to the extreme and misled lots of engineers by preaching extremism. But the core concepts are still valuable.\n\n&gt; My feeling is that the CleanCode evangelists took many statements to the extreme and misled lots of engineers by preaching extremism. But the core concepts are still valuable.\n\nIt's Robert Martin. He's the evangelist. He was the one preaching extremism.\n\nIn his book, he claims that functions should be no longer than 4 lines. That is an extremist position. It's also horrifically wrong. The fact that he has a disclaimer in the front of his book saying \"you technically don't have to follow these rules\" doesn't mean the advice he's giving isn't absolute garbage.\n\nPeople didn't \"misinterpret\" his book. People read his book, and believed it. That was the problem.\n\nOne one project a decent enough developer had been reading Clean Code and decided to refactor a class he'd worked on to adhere to the \"principals\" ... it was a simple enough class one public entry point with 4 or 5 six line functions. It ended up being 20+ functions, some 1 liners, most 2-3 lines WithFunctionNamesThatWereSoLongYouDidNotActuallyReadTheNameOfTheFunctionBecauseItWasQuickerToReadTheCode\n\nI‚Äôve had the unfortunate experience of working with someone who claimed to be following clean code. It‚Äôs ironically the most coupled codebase I‚Äôve seen. \n\nPeople get so weirdly religious about things. ‚ÄúI‚Äôve read one book about programming and it‚Äôs now my bible‚Äù. \n\n‚ÄúI‚Äôve used one programming language and I‚Äôll use it forever!‚Äù \n\nAnd don‚Äôt get me started on the functional evangelists. ‚ÄúI used to program in the dark using object oriented methods, but then I found the light that is functional programming! Hallelujah!‚Äù\n\nMy grandparents actually dragged me along to a Christian evangelist camp when I was a kid, and some co-workers dragged me along to a functional programming conference. Apart from the talking points they were eerily similar in so many ways.\n\nYeah - this. I wrote in another comment that he hears all the recent criticism and \"he feels people don't understand Clean Code because he gave bad examples, and not that as a prescriptive approach it is bad\".\n\nHe just seems like the kind of person that when people poke holes in his ideas he doesn't think about how addressing these concerns could make his ideas stronger, instead he just thinks they don't understand what he's saying and if he says it a different way they'll understand.\n\nI still think Clean Code is worth reading - there are some solid ideas there - it's just not worth following at all.\n\nHe does seem to backpedal a lot and say things like (paraphrasing) \"I didn't mean it like that\" or he keeps on saying \"well for most developers what I say is true but maybe not in your case\". He's just a guy with some vague ideas that don't stand up well to scrutiny, although on a broad level they sort of make some sense.\n\nMartin has a vile philosophy. He divides the world into good programmers and bad programmers. \n\nIf you don't agree on a technical point, you can be hit with SOLID programmer good, not solid programmer bad, unprofessional, why do you even have a job? You are, definitionally, wrong.\n\nAnd I think that comes directly from Bob, it is not a misreading of what he said.\n\nHe knew what he was doing when he called it Clean code, anyone who disagrees with him is Dirty (and not in a good way).\n\nI don't know, man. I read his book when I was an absolute beginner and I still thought to myself that, sure, small functions are nice, but I guess it's not always possible. He gives some advice, recommendations that you strive to apply when possible. That's it. I still find the book to be very good for basic ideas about clean code.\n\n&gt; I still find the book to be very good for basic ideas about clean code.\n\nLike what? I've seen countless examples of bad advice from the book. There's the [well-known article](https://qntm.org/clean) exposing some of the bigger flaws. I've heard a lot of people say, \"Well, there's still some good stuff in there.\" But I've never seen anyone manage to illustrate that. It should be a trivial matter to point to specific quotes or chapters with valuable advice.\n\nThe good stuff is the table of contents and section headings. Maybe some of the introductions to sections. The defenses of the book are usually along the lines of \"if you ignore everything he actually says, it gives some great advice\", and I think what this tells us is that the book does a good job of introducing beginners to concepts they should be thinking about. The more concrete parts go over their head, but that turns out to be a good thing.\n\nI can't actually find my copy of Clean Code right now, so I can't quote from it. I do have Agile Software Development sitting here so I'll go from that. \n\nI don't like his conflation of \"responsibility\" with \"reasons to change\", or his assertion (which I believe came from his blog) that the SRP is all about the relationship between the code and the people from whom the requirements come. A responsibility is about what the code does, and how one module interacts with another module. It doesn't, in my mind, have anything to do with people or requirements or the process of changing code.  Designing the code while trying to predict how we might be asked to change the code later is problematic in many ways.\n\nThe concept of \"singular\" also feels pretty fuzzy in a lot of his work, and often he tries to tie classes to real-world objects or nouns like a modem or a rectangle. There's also not a clear discussion in his books about singularness as a function of level of abstraction. Adding two numbers is singular but we wouldn't make a class to surround the + operator. Performing a single calculation is singular but we but a calculation is a method, not a class (and whether that method should be wrapped in a class that only does that one thing is a question that's hard to answer with just what Mr. Martin writes in his books). \n\nA lot of what he has to say about SRP has to do with people, changing code, and coupling. Not that these things aren't important, but they don't do a lot to inform design of code as it is, so much as it informs the iteration of a design over time. Iteration is important, but thinking that you're smart enough to anticipate how code might be asked to change in the future is foolhardy.\n\nEven though there were things I did not agree with, those two examples you are highlighting feel right and correct in my head. But maybe that's just up to individual interpretation of those ideas and that's why they make sense.\n\n&gt; I don't like his conflation of \"responsibility\" with \"reasons to change\". ...\n&gt; Designing the code while trying to predict how we might be asked to change the code later is problematic in many ways.\n\nThe way I understood it, is you are not supposed to actively think about everything's reason to change. Instead - you might accidentally notice that two components share their \"reason to change\" and that might prompt you to think about that and discover that there's a hidden unifying concept around both components that you did not capture in your code. And same can be applied the opposite way - if the reasons to change are different - they should not be similar.\n\nFor a very dumb example, imagine your class has \"errorCount\" and \"successCount\". They both share common \"reason to change\" - metrics/telemetry work. Meaning that they probably can be extracted into some sort of \"MyClassTelemetry\", or at least grouped together if there are not many related fields.\n\nAnd for a counter-example, you notice that while \"successCount\" is only used in telemetry, \"errorCount\" is used both for telemetry but also to dynamically adjust buffer size for better throughput. Those two are very different reasons to change - one is telemetry, other is transport layer improvements. Therefore \"errorCount\" should not be a single variable, and ideally you split it into \"MyClassTelemetry\" and \"MyTransportLayerConfig\", and you increment the \"errorCount\" on both separately.\n\n&gt; The concept of \"singular\" also feels pretty fuzzy in a lot of his work\n\nMy interpretation of this (somewhat influenced by other books I read from other authors), is that the bottleneck we are trying to solve here is human's ability to interpret information (code). So if you are looking at a block of code and are thinking \"wtf is going on here and why\" - there's a high chance that some metadata is missing for you to understand this easily.\n\nIf you buy a tool, and there's \"Hammer\" written on it, but it looks super-futuristic with wires and various indicators on it - you would still be fairly confident to try and hit a nail with it. Also you would then look at the indicators and try to understand them in context of \"hammering a nail\". Now if it does not have a \"name\" - it will be super difficult to understand what this piece of technology is.\n\nSame with code - if the code is difficult to understand - most frequently there are multiple concepts intermixed, and extracting those concepts and explicitly naming them will make the code much more readable.\n\nSo the \"singularness\" only matters until the code is readable. This is very subjective, obviously, but I don't think there is any other way.\n\nThank you very much for the detailed response.\n\nI guess I only remembers the key concepts which, imo, still make a lot of sense ‚Ä¶ but seemingly I have forgotten his style of explaining/framing these‚Ä¶\n\nThere certainly are lots of people that misunderstand and \"mispreach\" tons of concepts like this but Clean Code also straight up gives some terrible advice in a very explicit and clear manner, like for example that functions should ideally not ever be longer than 5 lines. See also https://qntm.org/clean for a great summary of the main reason why it's really not a good book for beginners and experienced developers alike.\n\nI worked at two different places where I was the first person to get away with writing five line methods. I lost political capital with some people and gained it with others. ‚ÄúIt was a boring conversation anyway.‚Äù\n\nActually in Software Architecture, like other field I presume, we all tend to re create something under another name.\n\nContrary to medical field where a group of people tried and continue to align wording and definitions, SA didn‚Äôt catch up. \n\nBest example is Martin F.: great books, many definition but if you read SA from a decade before.. Well wait who did define what and when?\n\nAt \\~20 years of professional experience (more as a hobbyist) I'm still learning new approaches - they're just not coming from books but from reading/using other peoples code and seeing novel ways of structuring things or listening to talks.\n\nI think an update would be awesome.¬† The original is heavy Java, old Spring, and examples that garnered a fair amount of criticism.¬† A similar message from a new direction could be very helpful.\n\nmake it all about functional programming\n\n[He already did that](https://www.amazon.com/Functional-Design-Principles-Patterns-Practices/dp/0138176396/).\n\nAnd, it's *far worse* than you would imagine.\n\n&gt; Martin examines well-known SOLID principles and Gang of Four Design Patterns from a functional perspective, revealing why patterns remain extremely valuable to functional programmers, and how to use them to achieve superior results.\n\nMaybe the code will be less [weird](https://qntm.org/clean) this time around?\n\nI would want to strangle whoever wrote this if I had to deal with that\n\nDear lord, that's *bad*\n\nOh neat, lol. I just read ‚Äúthere is no antimemetics division.‚Äù\n\nOh is that the same qntm who wrote that? I read it fairly recently as well, great SCP book!\n\nShameless [self-plug](https://theaxolot.wordpress.com/2024/05/08/dont-refactor-like-uncle-bob-please/). Here's to hoping he presents better refactoring, that sounds like what he's planning.\n\n&gt; I attribute Chapter 2 of Clean Code to Robert Martin, however I was recently informed that this particular chapter was actually authored by Tim Ottinger. That said, Martin is listed as the sole author of this book\n\nI really shouldn't be surprised.\n\nI've never read Clean Code. I've never had a desire to read Clean Code. After just seeing that second code block I am immensely glad I have never read it. What the fuck?\n\n&gt;Well, it‚Äôs because Martin‚Äôs relentless insistence on splitting out functions and having zero arguments means that class attributes are the only way to assign variables inside a function to be used outside that function.\n\nDijkstra famously said _\"It is practically impossible to teach good programming to students that have had a prior exposure to BASIC: as potential programmers they are mentally mutilated beyond hope of regeneration\"_, and this is one of those times when I think that he was actually right.\n\n&gt; So in conclusion, if you‚Äôre gonna read this book, ignore the refactorings and come up with your own. And take his principles with a grain of salt.\n\nThat's too generous for this garbage book. I'd suggest:\n\n&gt; So in conclusion, if you‚Äôre gonna read this book, don't.\n\nHorrific enough\n\nSomeone's running out of royalties it seems...\n\nIs this a joke? \"I'm rewriting it from scratch so that it will do the same thing but in a different way\" sounds like a satirical take on the nature of refactoring.\n\nI'm sure he's got all the unit tests to make sure no change in meaning is possible no matter how much he changes the text.\n\nCode Complete is a great book. It can make you better. Its pragmatic recommendations are often backed by real research.\n\nThen there's Clean Code, if you want to fill your head with nonsense rules for some reason.\n\nAnother one is A Philosophy of Software Design¬†\n\nI'm reading this currently and finding it useful. The advice is practical and sensible. It's also interesting in that its core concept of making deep modules with narrow interfaces is exactly at odds with Clean Code's recommendation. \n\nThe biggest piece of advice I liked from it so far is to avoid temporal dependencies between functions.\n\nNot just another one, it‚Äôs _the_ book people needed when they were unfortunate enough to come across Clean Code instead.\n\nWill code be cleaner now?\n\nsuperclean code! \n\nthe secret ingredient is supersnake oil\n\nIt will be so clean, there will be infinite number of private functions with 0 lines of code in each!\n\nThe code will be in another book.\n\nCan we stop calling this random guy Uncle?\n\nStill could be an email\n\nThis kind of books should be written by people who have actual experience in maintaining complex code bases. Otherwise it's just theoretizing about things that don't subdue to formality.\n\nThose people are generally busy.\n\nA retired dev (or one who's now in management but still up to date) would probably do a good job of it, but yeah people deep in the trenches are either doing non-coding in their spare time or doing open source, and either way they aren't going to have time to write a good book on the topic.\n\nThank goodness [Ousterhout made some time](https://www.youtube.com/watch?v=LtRWu9DErgU).\n\nThis feels like the sort of thing I might have written if I had tried to write a programming book as a teenager.\n\nI mean, I wasn't stupid or anything (at least I don't think so), but I had zero experience working with a team on big software projects and thought I knew a lot more than I did and was a lot smarter than I was. I consequently had a lot of firmly-held opinions which were, in retrospect, idiotic.\n\nI have deep mistrust towards evangelizers who have never actually done anything. \n\nI learned that every time anybody mentions Bob Martin or anything of his... the best thing you can do is ignore them.  Put them looking towards a wall and keep going on with your job.\n\nShow me your github bob.\n\nI didn't know that joke books needed rewriting.\n\nLike all books around software design, it's all opinion; can safely disregard what you don't agree with.\n\nAnd as a rule, maybe don't take too seriously programming advice from someone who writes books for a living.\n\nYeah. Loved the introduction of The Pragmatic Programmer (at least the 20th Anniversary Edition). He clearly stated that it's just his general recommendation based on his experience, and to basically do what works the best for you, your team and the specific project.\n\nPP and, especially, [Code Complete](https://people.engr.tamu.edu/slupoli/notes/ProgrammingStudio/supplements/Code%20Complete%202nd.pdf) by Steve McConnell always resonated more with me than ‚ÄúUncle Bob‚Äù books. The latest edition of Code Complete is from 2008, and tbh it‚Äôs one of the only books in this domain that‚Äôs aged so well it doesn‚Äôt need a rewrite. It‚Äôs purely conceptual (no language acknowledged), but it‚Äôs an absolute master class of proper software development.\n\n‚ÄúThe purpose of software engineering is to control complexity, not to create it.‚Äù\n\n‚ÄúA well-written program is its own best documentation.‚Äù (don‚Äôt take this literally)\n\n‚ÄúGood code is like a good joke: if you have to explain it, it‚Äôs probably not that good.‚Äù\n\nThe list goes on, but of all the books i‚Äôve read on development, Code Complete had the most significant impact on the trajectory of my career, by a large margin.\n\nclean code was by uncle bob, do you mean code complete? also using CC when they're both CC is pretty confusing lol\n\nSorry, in my mind there‚Äôs ‚Äúonly one CC‚Äù ‚Äî Code Complete. Updated for clarity.\n\nFar too much of the rhetoric in this subreddit seems to be predicated on the notion that what the people around you chose to do and choose to do doesn‚Äôt matter. \n\nI find the antisocial undercurrent troubling and I think I‚Äôm going to start calling it out. \n\nYou can‚Äôt ignore ideas that the people around you run with. That‚Äôs not how teams function. Non-participation is of only limited effect.\n\nSame snake, new oil\n\n[deleted]\n\nHe‚Äôs an arrogant prick with a pretentious authoritarian writing tone. Easy-to-impress folks are easily deceived by the facade of UBM.\n\nSimple as that.\n\nNot just writing tone, he's a trump supporter too¬†\n\n[deleted]\n\nLmao I opened his Twitter and it's just him throwing a tantrum about Kamala. Says recordings of Trump are fake. Posts Rasmussen polls that heavily favor Trump and uses it to say \"Kamala WILL NOT WIN!\" Says he talks about programming to educate the ignorant, and talks about politics to educate the ignorant. Just ignore the fact that he's literally repeating what every other Republican on Twitter says.\n\nI checked both Google and Urbandictionary and still have no idea what \"UBM\" is in this context.\n\nThere are many like him, Dave Farley also appears to rehash same ideas of CD in every video. It's like these people have made an entire career out of 1 hour of content.\n\nCantrill is GOAT! Sun, Joyent and now Oxide. His opinions are at least backed by some amazing real life work that most will just dream of.\n\nGod, I can't stand him. He's always claiming \"this isn't my opinion - it's backed by data!\", and on the occasions I've bothered to track down the source - because half the time the citation is a book written by one of his friends that I'm not going to buy - he's either misreprensenting the data or seemingly just willfully lying about it.\n\nNo it's not. He's just strained out the burnt crispy bits and put it in a can labelled Extra Virgin.\n\nWho thinks Uncle Bob is still relevant in 2024? His takes have been outdated garbage for years.\n\nUnfortunately you still see people touting his bad advice even now.\n\nThe one that comes up the most often for me is this inane idea that comments are \"bad\" or a \"code smell\", especially in spaces online with less experienced people or students who don't yet know better.\n\n&gt; Unfortunately you still see people touting his bad advice even now.\n\nAnd this is why I get so annoyed when people respond with \"so ignore him.\"\n\nIf there weren't a lot of people in the professional world who spout his bullshit as gospel, I for one would happily just ignore his existence. The fact it is almost impossible to avoid people who believe CC is a valid way to structure programs means denouncing it from the rooftops is necessary in case we can convince younger programmers to ignore his advice before it takes root in their brains.\n\nIt was outdated the moment the sentences formed in his head\n\nGreat, I will be sure to ignore it even harder now.\n\n\"uncle bob\" can piss off honestly.\n\nI've been genuinely convinced that Robert Martin is actually just the most successful programming troll of all time, not that he actually believes anything he says. The original Clean Code book reads like a folksy set of personal anecdotes and mostly vague guidelines meant to sound really convincing to managers and SCRUM masters who've never written any significant code in their lives. It also seems intended to deliberately make programming harder and more inscrutable, and not to save any of our jobs, but to force corporations to spend tons of money on BS consultants and replacing burnt-out programmers.\n\nIf you read what he wrote about functional programming and then his sudden appreciation for Clojure, calling it \"the new C,\" you'd probably agree with me. The man literally cannot be serious.\n\n(I'm not dissing on Clojure, the language is great, but Robert so completely misunderstood the language and its purpose that it just can't be unintentional)\n\nA good book for a programmer who can‚Äôt think for themselves.\n\nthis time with 100% more racism and sexism\n\nNot again. \n\nOr better as subtitle : advices from guy who never write software.\n\nGreat, I can't wait to be lectured by zealots about how I need to follow the practices of both this edition and last edition. Clean code has terrible practices in it and people follow it religiously. It takes so much effort to train junior engineers out of this.\n\nAlso, uncle bob as a person kind of sucks and it would be ideal to stop funneling money his way.\n\nPeople actually listen to this crackpot?\n\nI‚Äôm glad everyone here dislikes uncle Bob as much as I do. I read the book, and found some good advice, but all software advice sometimes makes sense to break. Can‚Äôt stand dogmatic absolutists. \n\nIt also pissed me off that his lectures on YouTube start with a 20 minute tangent on some random topic that he is not an expert in.  At first, I thought he was going to relate it to something in software development. But no, he just thinks he is qualified to teach quantum mechanics.\n\nThis is to establish an aura of authority. He picks a topic most of the audience is not familiar with (like calculating planet movements) to soften them up for arguments through authority. The perception of credibility is all he has, is advice is bad.\n\nI bought the book because, at the time, it was highly recommended.\n\nI was really confused as I read it. Have I been doing things wrong? This looks like shit code.\n\nit was his example of refactoring the Prime Number Seive that broke me, though. As he had been doing, the refactored version had obscenely long method names. In this case names like  \"SmallestOddNthMultipleNoLessThanCandidate and \"IsLeastRelevantMultipleOfNextLargerPrimeFactor\" (what makes a value \"relevant\" in this context is another question), but what broke me is that the refactored example was broken. The original code was fully re-entrant and thread safe. He refactored all the local variables to be static fields and all the methods operate on those static fields. Two threads calling his \"generate()\" function would literally cause undefined behaviour. This is when I realized that the reason none of what he was doing made sense to me wasn't because I had no idea what I was doing, but because he didn't. This was an example put into the very same book where he basically complains that developers don't take their work seriously enough as a \"craft\", and he not only lays out that dogshit, but somehow never noticed that it was awful before publication.\n\nOh no\n\nSo the code wasn't actually clean you say?\n\nWe need Trump hyping his book - we are going to clean so much, you are going to get tired of cleaning, a yuge cleaning\n\nDoes this guy ever think about retirement?\n\nAs a 25years developer and 20years recruiter, I have to say I hate this book with all my heart. Ok, perhaps not the book itself but the fact that it exists and is available to idiots. I've met, and, to my despair, had to hire and later work with, countless of these, and they all think they write clean code, just because they read that f\\*cking book, and feel no need to leave any inline comments.\n\nNone of them understood the comments are there not to describe what the code does, but, mostly, why I'd does it. At least leave a JIRA link in the commit message, ffs...\n\nThis is, right now, the bane of my existence. Working in a 50 person large-scale SAFE project where everybody read the book and sticks to it religiously. If I ever dare to write a single inline comment, I'll get a PR comment to delete it because if there's a need for a comment, the code is not self-explaining. I'm done with this.\n\nBetter let Casey Muratori rewrite it\n\nLove Casey and his performance aware programming lectures :p\n\nSame!\n\nGlad to see at least some people realize the book is average at best, I mean methods with 2-4 lines at most? Seriously?\n\nCan't wait to not reading it.\n\nCreepy Uncle Bob\n\nI would love to have someone like Kent Beck coauthoring (again), as Kent's had more hands-on codebase experience in the last twenty odd years (if I have it right; maybe Bob does, but I get the feeling he's teaching much more than hacking.)\n\nFor everyone saying the book sucks‚Äî what are some better alternatives?\n\nA philosophy of software design, Code complete, and Pragmatic programmer\n\nI would add \"Refactoring: Improving the Design of Existing Code\" (Kent Beck)\n\nI always took clean code as an example that may identify a good or bad programmer. If they say \"it's good but there are some pitfalls\" it's ok. I once run into a programmer that blindly followed that book as peak of perfection. When i showed them that his \"perfect class\" has uncanny cognitive complexity and many side effects they just explode in nonsensical defens\n\nThis guy sucks\n\nYet you have to read his shit and memorize his opinions to pass interviews with arrogant people that believe clean code, clean architecture and domain driven design are god‚Äòs gift to the world. Pure cargo cult.\n\nOh God, please no.\n\nI don‚Äôt understand the hate, or the love, that Uncle Bob seems to trigger.\n\nHe presents his ideas in a way that does not acknowledge the legitimacy of other opinions or the possibility of exceptions.\n\n‚ÄúYeah, you could do it differently than the way I say, but then you‚Äôd be an idiot who doesn‚Äôt care about performance/quality/truth/etc.‚Äù\n\nEven if you might otherwise agree with him, such attitudes are grating and polorizing.\n\nHe's fairly well known, and has some... controversial advice.\n\n\nIn particular, unit tests and \"just being more careful\" are his silver bullets.¬† He's not a fan of safer languages, of type systems, formal methods, etc. etc.\n\n\n[His advice definitely rubs some people the wrong way](https://www.hillelwayne.com/post/uncle-bob/).¬†"
  },
  {
    "title": "Let's blame the dev who pressed \"Deploy\"",
    "body": "",
    "score": 1591,
    "url": "",
    "created_utc": 1721555217.0,
    "author": "skwee357",
    "permalink": "/r/programming/comments/1e8ipxf/lets_blame_the_dev_who_pressed_deploy/",
    "all_comment_text": "Yep, this is a process issue up and down the stack.\n\nWe need to hear about how many corners were cut in this company: how many suggestions about testing plans and phased rollout were waved away with \"costly, not a functional requirement, therefor not a priority now or ever\". How many QA engineers were let go in the last year. How many times senior management talked about \"do more with less in the current economy\", or middle management insisted on just dong the feature bullet points in the jiras, how many times  team management said \"it has to go out this week\". Or anyone who even mentioned GenAI.\n\nCoding mistakes happen. Process failures ship them to 100% of production machines. The guy who pressed deploy is the tip of the iceberg of failure.\n\nAviation is the same. Punishing pilots for making major mistakes is all well and good, but that doesn't solve the problem going forward. The process also gets updated after incidents so the next idiot won't make the same mistake unchecked.\n\nPositive train control is another good example. It's an easy, automated way to prevent dangerous situations, but because it costs money, they aren't going to implement it.\n\nHuman error should be factored into how we design things. If you're talking about a process that could be done by people hundreds to thousands of times, simply by the law of large numbers, mistakes will happen. We should expect it and build mitigations into designs rather than just blame the humans.\n\nIf you aren't implementing full automation, some level of competency should be observed. And people below that level should be fired. Procedures mean nothing if people don't follow them.\n\nI worked at a place without a working QA for two years, for a platform with no tests. It all came to a head when they deployed a feature, with no rollback available, that brought the product to its knees for over three weeks.\n\nI ended up leaving as the CTO continued to bury problems under the carpet, instead of doing the decent thing and discussing how to make shit get deployed without causing a major incident. That included him choosing to skip the incident post mortem on this one.\n\nSome management are just too childish to cope with serious software engineering discussions, on the real state of R&amp;D, without their egos getting in the way.\n\nI‚Äôm also curious to see how this plays out at their customers.  Crowdstrike pushes a patch that causes a panic loop‚Ä¶ but doesn‚Äôt that highlight that a bunch of other companies are just blindly taking updates into their production systems, as well? Like perhaps an airline should have some type of control and pre production handling of the images that run on apparently every important system?  I‚Äôm in an airport and there are still blue screens on half the TVs, obviously those are lowest priority to mitigate but if crowdstrike had pushed an update that just showed goatse on the screen would every airport display just be showing that?\n\n&gt; but doesn‚Äôt that highlight that a bunch of other companies are just blindly taking updates into their production systems, as well?\n\nMany companies did not WANT to take the updates blindly.  They specifically had a staging / testing area before deploying to every machine.\n\nCrowdstrike bypassed their own customer's staging area!\n\nhttps://news.ycombinator.com/item?id=41003390\n&gt; \n&gt; CrowdStrike in this context is a NT kernel loadable module (a .sys file) which does syscall level interception and logs then to a separate process on the machine. It can also STOP syscalls from working if they are trying to connect out to other nodes and accessing files they shouldn't be (using some drunk ass heuristics).\n&gt; \n&gt; **What happened here was they pushed a new kernel driver out to every client without authorization to fix an issue with slowness and latency that was in the previous Falcon sensor product. They have a staging system which is supposed to give clients control over this but they pissed over everyone's staging and rules and just pushed this to production.**\n&gt;\n&gt; This has taken us out and we have 30 people currently doing recovery and DR. Most of our nodes are boot looping with blue screens which in the cloud is not something you can just hit F8 and remove the driver. We have to literally take each node down, attach the disk to a working node, delete the .sys file and bring it up. Either that or bring up a new node entirely from a snapshot.\n&gt; \n&gt; This is fine but EC2 is rammed with people doing this now so it's taking forever. Storage latency is through the roof.\n&gt; \n&gt; I fought for months to keep this shit out of production because of this reason. I am now busy but vindicated.\n&gt; \n&gt; Edit: to all the people moaning about windows, we've had no problems with Windows. This is not a windows issue. This is a third party security vendor shitting in the kernel.\n\nAccording to crowdstrike themselves, this was an AV signature update so no code changed, only data that trigerred some already existing bug. I would not blame the customers at this point for having signatures on autoupdate.\n\nI imagine someone(s) will be doing RCAs about how to buffer even this type of update.  A config update can have the same impact as a code change, I get the same scrutiny at work if I tweak say default tunables for a driver as if I were changing the driver itself!\n\nIt definitely should be tested on the dev side. But delaying signature can lead to the endpoint being vulnerable to zero days. In the end it is a trade off between security and stability.\n\n&gt;can lead to the endpoint being vulnerable to zero days.\n\nYes, and now show me a zero day exploit that caused an outage of this magnitude.\n\nAgain: Modern EDRs *work in kernel space*. If something goes wrong there, it's lights out. Therefore, it should be tested by sysops *before* the rollout.\n\nWe're not talking about delaying updates for weeks here, we are talking about the bare minimum of pre-rollout testing.\n\nTotally agree. It‚Äôs hard to believe that systems critical like this have less testing and productionisation rigor than the totally optional system I‚Äôm working on (in terms of the release process we have automated canarying and gradual rollout with monitoring)\n\nIf speed is critical and so is correctness, then they needed to invest in test automation. We can speculate like I did above, but I'd like to hear about what they actually did in this regard.\n\nAllegedly they did have some amount of testing, but the update file somehow got corrupted in the development process.\n\nHmm, that's weird. But then issue issue is automated verification that the build that you ship is the build that you tested? This isn't prohibitively hard, comparing some file hashes should be a good start on that.\n\nhere is a fun scenario\n\n1. test suite passes\n1. release artifact is generated\n1. there is a data corruption error in the stored release artifact\n1. checksum of release artifact is generated\n1. update gets pushed to clients\n1. clients verify checksum before installing\n1. checksum does match (because the data corruption occurred BEFORE checksum was generated)\n1. womp womp shit goes bad\n\ndid this happen with crowdstrike? probably no\n\ncould this happen? technically yes\n\ncan you prevent this from happening? yes\n\nseparately verify the release builds for each platform, full integration tests that simlulate real updates for typical production deploys, staged rollouts that abort when greater than N canaries report problems and require human intervention to expand beyond whatever threshold is appropriate (your music app can yolo rollout to &gt;50% of users automatically, but maybe medical and transit software needs mandatory waiting periods and a human OK for each larger group)\n\nthere will always be some team that doesn't think this will happen to them until the first time it does, because managers be managing and humans gonna human\n\nedit: my dudes, this is SUPPOSED to be an example of a flawed process\n\nWhy 2 is after 1? Why don't you test release artifact, eg. Do exactly what is done with it on deployment\n\nNot even though. There should have been a test for a signature update.\n\nIE can it detect new signature? If it‚Äôs corrupted it wouldn‚Äôt so then you‚Äôd fail the test and not deploy.\n\nThis whole thing smells made up. More than likely missing process and they don‚Äôt want to admit how shitty their process is in some regard.\n\nIt's kind of telling how many people that I'm seeing that are saying this was just an X type of change -- they're not saying this to cover but likely to explain why CrowdStrike thought it was inocuous.\n\nI 100% agree, though, that any config change pushed to a production environment is risk introduced, even feature toggles. When you get too comfortable making production changes, that's when stuff like\nthis happens.\n\nYes. No dev ops here, but I don‚Äôt think it is super hard to do automated gradual rollout for config or signature changes\n\nExactly. Automated, phased rollouts of changes with forced restarts and error rate phoning home here would have saved them and the rest of their customers so much pain... Even if they didn't have automated tests against their own machines of these changes, gradual rollouts alone would have cut the impact down to a non-newsworthy blip.\n\nHeck, you can do gradual rollout entirely clientside just by having some randomization of when software polls for updates and not polling for updates *too* often.  Or give each system a UUID and use a hashfunction to map each to a bucket of possible hours to check daily etc.\n\n2012-08-10 TODO: fix crash when signature entry is malformed\n\nAh, is that what the files were...?\n\nOk, so... I looked at them, the \"problem\" files were just filled with zeroes.\n\nSo, we have code that blindly trusts input files, trips over and dies with an AV (and as it runs in the kernel, it takes the system with it).\n\nPhoahhh, negligence....\n\nWait, so there must be zero (heh) validation of the signature updates clientside before it applies them? \n\nHooooooooooly shit that's so negligent.  Like this enters legally-actionable levels of software development negligence when it's a tool deployed at this scale.\n\nYou would think, yet everyone at Boeing isn‚Äôt in jail yet and imo the mcas stuff was obscene negligence. Even worse because the dual sensor versions that prevented the catastrophic situation were a paid option.\n\nShould it be criminal? In my opinion yes. But at best someone at the C level gets fired. Most likely nothing happens.\n\nYeah, it's definitely up there with Boeing -- might even have killed more people, given the massive impacts this had on medical systems and medical care. \n\nI agree it should be criminal but will never be prosecuted like it really is.  Welcome to corporate oligarchy: if a person hits someone they go to prison, if a company kills hundreds of people they get a slap-on-the-wrist fine and nobody sees prison.\n\nI would, because *it doesn't matter what is getting updated*, if it lives in the kernel *then I do some testing before I roll it out automatically to all my machines*.\n\nThat's sysops 101.\n\nAnd big surprise, companies that did that, weren't affected by this shit show, because they caught the bad update before it could get rolled out to production.\n\nMind you, I'm not blaming sysops here. The same broken mechanisms mentioned in the article, are also responsible that many companies use the *let's just autoupdate everything in prod lol* method of software maintenance.\n\nThe last I read was that the update [\"'was a channel update that bypassed client‚Äôs staging controls and was rolled out to everyone regardless' of whether they wanted it or not.\"](https://thenewstack.io/the-crowdstrike-disaster-lessons/) If so, it's hard to blame the sysops.\n\nAre you sure CrowdStrike even allows you to manage signature updates like this? Some products that provide frequent updates via the internet don't allow end users/administrators to control them.  \nThe OneDrive app bundled with Windows for example doesn't have any update settings (aside from an optional Insider opt-in option). Sure you can try to block it in the firewall or disable the scheduled task that keeps it up to date but that's not a reasonable way to roll out updates for administrators.  \nThe start menu Windows Search also gets updates from the internet, and various A/B feature flags are enabled server side by Microsoft with no official way to control them by end users or administrators.\n\nIf a product doesn't allow this, and is deployed anyway, the question that needs to be asked next is: *\"Right, so, why did we chose this again?*.\n\nAnd that question needs to be answered by \"management\", not the sysops who have to work with the suits decisions.\n\nI have 0% confidence that what's coming out of CrowdStrike right now is anything other than ass-covering rhetoric that's been filtered through PR people.  I'll believe the final technical analysis by a third party audit and pretty much nothing else.\n\nPNC bank tested it prior when others didn't and they were just fine.¬†\n\nDo you mind sharing a link about that? I tried googling but Google sucks now\n\nWithout giving away personal details, once it hit my work i had a reason to call them and was made aware they caught the issue by testing the update first.\n\nIt‚Äôs not clear from news articles of that have been shared that the ability to test the update was even possible\n\nI was talking to a friend who runs cyber security at one of the biggest companies in the world. My friend says that for a decade they have never pushed an update like this on release day and typically kept Crowdstrike one update behind. Very very recently they decided that the reliability record has been so perfect that they were better off being on the latest and this update was one of if not the first time they went with it on release. Big oof.\n\nThat didn't matter. Your settings could be org wide set to N-1 or N-2 updates, rather than the latest, and you still got this file full of zeros.\n\nThis is 100% correct. All our IT department laptops are release level. All user desktops and laptops are N-1 and every server is N-2.  EVERYTHING got nuked.\n\nI think in that case they‚Äôd throw a towel over em.\n\nYes, there‚Äôs obviously some poor practices going on at Crowdstrike, but there‚Äôs also some really poor practices going on at their customers as well.\n\nYup, to use the metaphor it's like blaming the head nurse for a surgery that went wrong.\n\nPeople need to understand the wisdom of blameless post mortems. I don't care if the guy who pressed deploy was a Russian sleeper agent who's been setting this up for 5 years. The questions people should be asking is:\n\n* Why was it so easy for this to happen? \n   * If there was a bad employee: why can a single bag employee bring your whole company down?\n* Why was this so widespread?\n    * This is what I don't understand. No matter how good your QA, weird things will leak. But you need to identify issues and react quality. \n     * This is a company that does one job: monitor machines, make sure they work, and if not quickly understand why they don't. This wasn't even an attack, but an accident that crowdstrike controlled fully. Crowdstrike should have released to only a few clients (with a at first very slow and gradual rollout), realized within 1-2 hours that the update was causing crashes (because their system should have identified this as a potential attack) and then immediately stopped the rollout (say that a rollback was not possible in this scenario). The impact should have been less. So the company needs to improve their monitoring, it's literally the one thing they sell.\n* How can we ensure this kind of event will not happen in the future? No matter who the employees are.\n    * Not with enough to fire one employee, you have to make sure it cannot happen with anyone else, you need to make it impossible.\n    * I'd expect better monitoring, improved testing. And a set of early dogfood machines (owned by the company, they are the first round of patches) for all OSes (if it was only Mac and Linux at the office, they need to make sure it also applies on Windows machines somehow).\n\nCrowdstrike laid off 200-300 employees for refusing to RTO and tried to do the pivot to ai to replace them.\n\nAnother piece of this is the trend away from customer managed rev cycles to vendor managed rev cycles. This needs to be demanded from vendors while shopping for software. It still would have effected companies that don't have their own procedures for rev testing.\n\n&gt; We need to hear about how many corners were cut in this company\n\nFrom another thread on this, it sounds like their while QA department was laid off just a few months ago. So that's probably why this happened, lol. \n\nBlame the executive who made that hairbrained decision.\n\n&gt;were let go\n\nWhy do you speak in corporate newspeak? Just say \"fired\" truthfully.\n\n&gt;The reason why Anesthesiologists or Structural Engineers can take responsibility for their work, is because they get the respect they deserve. You want software engineers to be accountable for their code, then give them the respect they deserve. If a software engineer tells you that this code needs to be 100% test covered, that AI won‚Äôt replace them, and that they need 3 months of development‚Äîthen you better shut the fuck up and let them do their job. And if you don‚Äôt, then take the blame for you greedy nature and broken organizational practices.\n\nThe reason why anethesiologists and structural engineers can take responsibility for their work is because they are legally responsible for the consequences of their actions, specifically of things within their individual control. They are members of regulated, professional credentialing organisations (i.e., only a licensed 'professional engineer' can sign off certain things; only a board-certified anethesiologist can perform on patients.) It has nothing to do with 'respect'.\n\nSoftware developers as individuals should not be scapegoated in this Crowdstrike situation specifically because they are not licensed, there are no legal standards to be met for the title or the role, and therefore they are the 'peasants' (as the author calls them) who must do as they are told by the business. \n\nThe business is the one that gets to make the risk assessment and decisions as to their organisational processes. It does not mean that the organisational processes are wrong or disfunctional; it means the business has made a decision to grow in a certain way that it believes puts it at an advantage to its competitors.\n\nPrecisely.\n\nI often say ‚ÄúI can make this widget in X time. It will take me Y time to throughly test it if it‚Äôs going to be bulletproof.‚Äù\n\nThen a project manager talks with the project ownership and decides if they care about the risk enough for the cost of Y.\n\nIf I‚Äôm legally responsible for the product, Y is not optional. But as a software engineer this isn‚Äôt the case, so all I can do is give my estimates and do the work passed down to me.\n\nWe aren‚Äôt civil engineers or surgeons. The QA system and management team of CrowdStrike failed.\n\nAnd that's also kind of by design. A lot of the time, cutting corners is fine for everyone. The client needs something fast, and they're happy to get it fast. Often they're even explicitly fine with getting partial deliveries. They all also accept that bugs will happen, because no one's going to pay or wait for a piece software that's guaranteed to be 100% free from bugs. At least not in most businesses. Maybe for something like a train switch, or a nuclear reactor control system.\n\nIf you made developers legally responsible for what happens if their code has bugs, software development would get massively more expensive, because, as you say, developers would be legally obligated to say \"No.\" *a lot* more often and nobody actually wants that.\n\n\"Work fast and break things\" is a legitimate strategy in the software industry if your software doesn't control anything truly important. There is nothing wrong with this approach as long as the company is willing to recognize and accept the risk. \n\nAs a trivial example, we have a regression suite but sometimes we give individual internal customers test builds to solve their individual issues/needs very quickly, with the understanding it hasn't been properly tested, while we put the changes into the queue to be regressed. If they are happy, great, we saved time. If something is wrong, they help us identify and fix it, and are always happier to iterate than to wait. But when something is wrong, nobody gets hurt, no serious consequences happen; it's just a bit of a time tradeoff. \n\nThough if your software has the potential to shut down a wide swath of the modern computerized economy, you may not want to take this tradeoff.\n\nSure. But even here, they were apparently delivering *daily* updates? It sounds impossible to release updates daily, that are supposed to be current in terms of security, and guarantee that they are 100% without issue.\n\nIt's probably the case that this should have been much less likely to happen than it was.\n\n&gt; QA system\n\nPoor fool, assuming a modern tech company has QA of any sort.  That's a completely useless expense!  We're agile or some shit!  We don't need QA, just throw that shit on to production, we run a tight ~~family~~ ship here!\n\nNow, who's ready for the ~\\*~\\* F R I D A Y ~\\*~\\* P I Z Z A ~\\*~\\* P A R T Y ~\\*~\\*?!\n\nThe company I work for has QA, and, in the project I work on, they have to give approval before a PR can be merged to master, and they're the only ones who can close a Jira ticket as completed. This is sometimes a little bit annoying, but usually very valuable.\n\nJust because your company has bad practices doesn't mean everyone does.\n\n&gt; Just because your company has bad practices doesn't mean everyone does.\n\nI mean...yeah.  Your mileage is gonna vary.  But, there's many examples of fairly big name companies that basically took a hatchet to their QA team (or outright got rid of the entire team) to make line go up enough that the big money investors don't bugger off to whatever new shiny thing is in, this week.  When you don't care about quality, why bother having people assure it, ya know?\n\nThough, I will say, good on your company for realizing the value of QA.  More places need to be like that.\n\nNo no no, it‚Äôs not to make line go up. It‚Äôs because modern tools have enabled developers to also be the QA team! And the devops team! And the support team! And modern agile methodologies let devs be the project managers too! But not the product owners, don‚Äôt _ever_ think you get to make a business decision!\n\nBad practice yes, but common practice in startup land.\n\nAdding on here. ~7 YOE, I've seen multiple orgs get rid of QA in favor of devs QA'ing their own team's work. This has happened in startups and enterprise orgs I've worked at. It does seem to be an emerging trend, at least anecdotally.\n\n&gt; assuming a modern tech company has QA of any sort\n\n*every* company has a QA system, some have it separate from production. :-)\n\nYes the push to deploy quickly at a touch of a button and worry about App Sec and QA after the fact is a huge trend I hope this incident gives pause to.\n\nHaving a background in healthcare, specifically surgery, I think a great big simple thing people are forgetting is that an anesthesiologist (and likely a structural engineer) has the ability to say no. It‚Äôs not a matter of respect, it‚Äôs an industry norm.\n\nIf you‚Äôre going to present a case for surgery and the patient isn‚Äôt optimized or the procedure is too dangerous, the anesthesiologist can, and likely will, just tell you it‚Äôs not going to happen until it‚Äôs safe to proceed. No middle management, no scheduling, no one gets to argue against an anesthesiologist that has a valid point about patient safety. Surgeons will kick and scream and act like babies when this happens, but they don‚Äôt get their way if there‚Äôs a reasonable chance they‚Äôre going to kill someone. \n\nSaying no is the ultimate power here, and non-licensed professionals don‚Äôt have that luxury.\n\nPlus in the case of tech the developers don't get a say if it goes to QA, App Sec, etc... so when those teams get gutted and developers are pushed to deploy quicker without gateing in place.\n\nThese things have been happening more and more often due to rapid deployment CI/CD becoming the norm.\n\nCI/CD is fine, it's \"layoff all the support teams and just have the devs do QA, testing, devops, etc in addition to their actual work and also shorten deadlines\" that's the problem.\n\nSame with professional engineers that have the PE license to stamp drawings. They are essentially swearing on their life that a design is sound and can say no when it doesn't meet their standards. Of course the client can shop around, but most other PEs are going to have similar standards. Plus there is a legal requirement.\n\n&gt; The reason why anethesiologists and structural engineers can take responsibility for their work is because they are legally responsible for the consequences of their actions, specifically of things within their individual control.\n\nThis is a point I harp on a lot, at my current job, and my previous. You *cannot* give someone more responsibility and accountability without *also* giving them an equal amount of authority. Responsibility without authority is a scapegoat. By definition. That's simply what it means when you're held responsible for something you can't control.\n\nThe reality is that the people in charge almost never want to give up that authority. They want all the authority so they can take all the credit. But they still want an out for when things go wrong. And that's where this whole mess comes from.\n\nBut to be more precise, it's not because of regulation, but because the control they can exert over their work, which comes with said regulation.\n\nDevelopers have no control. Everyone and his mother can impose their views in a meeting. Starting with technologically-illiterate middle management, the customers, every stakeholder, agile masters, even the boss and the bosses friends and family.\n\nIn the case of civil engineers at least, the control stems from their legal culpability.\n\n&gt;The reason why anethesiologists and structural engineers can take responsibility for their work is because they are legally responsible for the consequen ces of their actions, specifically of things within their individual control. They are members of regulated, professional credentialing organisations (i.e., only a licensed 'professional engineer' can sign off certain things; only a board-certified anethesiologist can perform on patients.) It has nothing to do with 'respect'.\n\nCrucially here: actual acredited engineers can use those regulations to demand respect and can better leverage their expertise and knowledge because there are actual consequences to getting rid of liscensed professionals. Software engineers working in critical fields like cybersecurity or heathcare software should probably have the regulations and licensing that would allow them to put some weight behind objections. As it stands now, there is no reason that middle or upper management needs to respect or listen to their programers because they can just fire and replace them with no ramifications. \n\nThe issue here is that I have 0 faith in the US Congress to put any effective legislation in place to do this. Maybe the EU can once again save us but enforcement of the EU's laws on American companies is tenuous at best despite the successes that the EU have had so far.\n\nFormal accreditation &amp; licensing for software engineers would not do a single beneficial thing for software quality and reliability. \n\nIt takes *multiple orders of magnitude* more time &amp; work to create software that is provably free of defects; for those that are curious there are really good articles out there on how they prove Space Shuttle code bug free, but even tiny changes can take months.   Companies will never agree to this because it's vastly more expensive and everything would slow to a crawl... and companies don't actually *care* about quality that much.\n\nThe reality is that we cannot create software at the pace companies demand without tolerating a high rate of bugs.  Mandating certification by licensed software engineers for anything shipped to prod would be crazy; no dev in their right mind would be willing to stake their career on the quality we ship to prod, because we KNOW it hasn't been given enough time to render it free of defects. \n\nThe best we're going to get is certifications for software that mandate certain quality &amp; security processes and protections have to be in place, and have that verified by an independent auditing authority (and with large legal penalties for companies that falsify claims).\n\nPlus with physical engineering, there are margins of safety such as with material strength. So you can balance more uncertainty (less cost) with more safety factor (more cost). There isn't really such a thing with software as the values need to be exact.\n\nCorrect, I work and have shipped software for FDA class C medical devices. To get FDA clearance requires adherence to, for example, IEC 62304 Processes. The documentation and validation and verification takes longer than the coding ( often). Naive clients ( often doctors, btw) come to me with great ideas, but when they get a look at what's involved ( and the cost) they often have a hissy fit. It takes great discipline and good processes, along with a good safety culture ( Boeing??) to produce highly reliable and robust software. Crowd Strike didn't probably realize that their software is safety critical.\n\n[deleted]\n\nThanks for the clarification. I must admit, I went a bit into a rant by the end.\n\nIn general, comparing software engineers at its current stage to structural engineers, is absurd. As you said, structural engineers are part of a legalized profession who made the decision to participate in said craft and bear the responsibility. They rarely work under incompetent managers, and have the authority to sign off on decisions and designs.\n\nIf we want software engineers to have similar responsibility, we need to have similar practices for software engineering.\n\nAs someone who works as an electrical engineer, and has friends in all disciplines from civil to mechanical to chemical. I can say for certain that incompetent managers are a universal constant. The main difference is that you have the rebuttal of \"no I can't do that, it will kill people and I'll go to jail. If you're so confident then you can stamp the designs yourself.\"\n\nThe process of building is also way different. With just \"build a bridge\", a lot of requirements already go in: geotechnical considerations, hazards, traffic demand, traffic load maintenance, right of way, etc. even before specifications for the materials (the design) is even considered. You could say it is strictly waterfall\n\n\nMeanwhile, software POs and company management usually adjust requirements very often, add new features etc. Some cannot even make proper requirements for whatever it is they are making.\n\nThis is the key; 'real' engineers have legal protections in place if they tell their employer 'no, I'm not going to do that' (as long as that's a reasonable response). Devs don't. \n\nIncidents like the CrowdStrike one highlight that there needs to be actual effort put into making software engineering an actual engineering discipline, such that once you're getting to the level of 'this software breaking will kill people', the situation gets treated with the same level of respect as when we're looking at 'this bridge breaking will kill people'.\n\nI've seen grossly over-engineered plans, and plans that tell you V.I.F. - Verify in the Field.\n\n**Nobody** in this event verified a damn thing before deploying, yet somehow **everybody** magically knows the **exact file** that caused the event hours after the event started.\n\nThat tells me that the whole \"cybersecurity\" domain is incompenent and are only skilled at pointing fingers at somebody else when something goes horribly wrong; due to the culture of lazy incompetence and lack of a policy to test before production deployment.\n\n&gt; everybody magically knows the exact file that caused the event hours after the event started.\n\nI mean, there's no magic involved.\n\nAn update went out; it was a finite set of new things and I'm sure literally the entire engineering staff was hair-on-fire screaming to find the cause.\n\nThe mystifying thing is that it went out at all, not that it was quickly found.\n\nIndeed. Would you use a road bridge designed and built with software engineering practices?\n\n\"A few of the bolts are imported from a thirteen-year-old in Moldova who makes them in his garage\". It's probably fine, and it saves us time and money.¬†\n\n\"We tested it with a RC car and it went over fine, should be good for 40 tonne trucks. If not we'll patch it\"\n\nNormally those would have to be checked by QA if they are safe to use but the one guy we have to do that is too busy filling out compliance documents for the entire project to do any actual testing.\n\nHaven't this outage showed us that it's way easier to bring a country to it's knees by introducing a software bug rather than destroying a bridge?\n\nTruth is, we already live in a world surrounded by the works of software engineers.\n\n[deleted]\n\nthe Baltimore Bridge collapsing wasn't really an engineering oversight. I get the point but I don't think you'd have years of downtime due to an engineering error. You could, but so could anything, including a software fuck up.\n\nA week to be through with the immediate fallout.\nA month until we don‚Äôt get reminded regularly of what happened.\nA year and nobody remembers without being prompted that there was an outage or what was it all about anyway.\n\nSame as the bridge, I don‚Äôt live anywhere near Baltimore and completely forgot about that bridge. I wasn‚Äôt directly affected by this outage, won‚Äôt take me long to forget about it.\n\nControversial in r/programming, but this is why there is gatekeeping on the term 'engineer.' It's a term that used to exclusively require credentialing and licensing, but now anyone and everyone can be an engineer (i.e., 'AI Prompt Engineer', sigh).\n\nEven in the post, you slip between 'software engineer' and 'developer' as if they are equivalent. Are they? Should they be?\n\nTo a layperson non-programmer like me, just like on a construction job, it seems like there should be an 'engineer' who signs off on the design, another 'engineer' who signs off on the implementation, on the safety, etc. Then 100+ workers of laborers, foreman, superintendents, all doing the building. The engineers aren't the ones swinging the hammers, shovelling the concrete, welding the steel.\n\nI mean no disrespect to anyone or their titles. This is merely what I see as ambiguity in terms that leads to exactly the pitchforks blaming the developers for things like Crowdstrike, in contrast to how you'd never see the laborers blamed immediately for the failure of a building.\n\nThere is no actual difference between ‚Äúsoftware engineer‚Äù and ‚Äúdeveloper‚Äù in the real world, no. I don‚Äôt think the solution of making more signoffs is actually going to fix anything but NASA and other organizations do have very low-defect processes that others could implement. The thing is they‚Äôre glacially slow and would be unacceptable for most applications for that reason.\n\n&gt; There is no actual difference between ‚Äúsoftware engineer‚Äù and ‚Äúdeveloper‚Äù in the real world, no\n\nThat is not true. Several countries have regulations in place to protect the title engineer. You cannot call yourself a an engineer in Germany for example without formal education and a corresponding degree. Putting someone with a 3 or 4 year degree in the same bucket as a code monkey that went through a 3 weeks JS boot camp, is ignorant.\n\nSame in Canada except for software they are trying to let anyone use 'software engineer' in some locations but they can't have Software Engineer which will make things very confusing. P.Eng is still legally protected though.\n\nIn programming, engineers are the ones actually building the software and the terms engineer and developer are pretty much equivalent.\n\nI personally think that the titles are somewhat meaningless, because you simply cannot sufficiently learn this job in a university. Education helps mostly when things get mathematically challenging, but the job includes constantly learning new things which were never even mentioned on any class.\n\nI get what you are saying about having a \"certified\" guy approving everything, but in programming world if you are not actually wielding the hammer you are quite likely less knowledgeable about the code and best practises than the people who work on it.\n\nI agree with you, but the term ‚Äúengineer‚Äù as applied to software, is partly the blame of the industry.\n\nWhen I started in this industry, everybody called themselves ‚Äúprogrammer‚Äù and ‚Äúweb developer‚Äù. But then the entire industry has shifted into using the term ‚Äúsoftware engineer‚Äù.\n\nAnd if you want to regulate this term, it should come both from the developers and from the industry as a whole. You can‚Äôt expect the industry to hire software engineers, bootcamps to churn software engineers, while programmers will call themselves developers.\n\nEdit: forgot the education. Universities handing out engineering degrees without having real engineering implications of the degree\n\n&gt; Even in the post, you slip between 'software engineer' and 'developer' as if they are equivalent. Are they? Should they be?\n\nimo \"engineering\" at it's heart means the application of science in decision-making. There's no inherent rule that an engineer at a construction site can't swing a hammer, but there is an expectation they are coming from a scientific point of view before they do so (or tell someone else to).\n\nIt's the same with software engineers.\n\nedit: and we can bullshit all we want but we all know the only people who sign off on anything is the c-suite. That's why they skip the whole charade in software and give us product owners to sign off instead.\n\nIn structural engineering, the difference is in title, reinforced by title laws, certification, liability, education, on-going professional practice and management, and oversight.¬†\n\n\nI'm a software developer with an (actual) engineering degree. My friends are civil engineers that build sky scrapers. It's night and day. There's no charade. If they (partners, team leaders, project engineers) say of some on-site unplanned solution \"this is unsafe\", time is taken to resolve the issue. Critically, the engineering teams are contracted separately from the architects and construction teams. They are absolutely experiencing a downward price pressure, though. So maybe this changes in a decade. And what happens when some developer normalizes in house engineering teams?\n\n\nI'm a software director/executive for non-silicone valley, small/medium companies. It's not the same. Move fast or die. Do the best you can with not enough resources. Low barriers to entry for disruptive competitors. Completely unrealistic client expectations. Very little ability to differentiate good and bad practice among buyers.¬†\n\nEngineers far outdate engineering certifications. I get what you mean that in modern construction that is typically what the term means, but the certificate is not the thing that makes something engineering. Also frankly even in professions you need a cert for I don't think the blame structure really shifts. Every industry has institutional failures and poor incentive structures. It varies role by role and problem to problems but generally I don't think a single structural engineer is the sole person to blame more often than a single software engineer is to blame.\n\nI was a structural engineer (still hold a P.E.), now I develop software for structural engineers and design workflows.\n\nWorking with CS majors who haven't dealt with the negative consequences of having something go wrong is frustrating. They lean hard on the clause in the EULA that says we are to be held harmless. \n\nI tend to lean on the idea that we shouldn't cause damage to life or property because every year that I worked in a profession, we had lawyers come in and tell us to stop fucking up and to raise our hands, based on the actions of their other clients. We can try to tell users to always check their own work, but things are complex enough where we know they won't. When something goes wrong, lawsuits spread in a shotgun pattern. Being named in a lawsuit sucks.\n\nAnyways, the battle of software engineers being held to the same standards of Professional Engineers working in structural engineering has been lost many times. There used to be a P.E. for software, but nobody really wanted it. There are some ISO accolades you can try to get, but those targets take too long to set up to be useful. The history of the need of P.E. is long and riddled with things that don't make sense (like railway/utility engineers not having to stamp stuff, but I have to stamp roof reports so home owners can get reimbursed by insurance companies).\n\nBest I can do is tell my boss that I won't do something because we can't do it with any level of confidence, so I simply tell the user `Sorry, this is out of scope, good luck` instead of just green-lighting it like we used to.\n\n&gt;The reason why anethesiologists and structural engineers can take responsibility for their work is because they are legally responsible for the consequences of their actions, specifically of things within their individual control. They are members of regulated, professional credentialing organisations (i.e., only a licensed 'professional engineer' can sign off certain things; only a board-certified anethesiologist can perform on patients.) It has nothing to do with 'respect'.   \n    \nYou know what? There *should* be licensing for a class of software developers. Not every software developer should need to get licensed, but those who work on critical systems which directly impact people's physical health and safety *should* have some level of liability the same way other engineers do.  \nWe could/should also make \"Software Engineer\" a protected title, differentiating it as a higher level.   \nA software engineer for airplane systems or medical devices should not be able to yolo some code and then fuck off into the sunset.    \n    \nAt the same time, those licensed developers should be able to have *significant* control over their processes and be able to withhold their seal or stamp of approval on any project that they feel is insufficient.  \n    \nIf anyone thinks that software developers get paid a lot *now*, those licensed developers should be commanding 5 to 10 times as much.\n\nTL,DR: blame the CEO instead\n\nI‚Äôm actually completely fine with taking all the blame as a programmer.  Just as soon as they start paying me the same as the CEO and giving me the same golden parachute protection.  Sign me up for some of that üëç\n\nI work in finance as a FPGA engineer and I'm fine taking the blame if it's my fault or the fault of someone working under me who owned up to their mistake. But this only works because I have the power and authority to unilaterally halt production and tell the business \"No\" without consequences for me or my team. Oh, and I get paid a shitton to do essentially the same work that my undergraduate thesis was doing a decade ago.\n\nSorry, just out of curiosity does FPGA mean something other than \"field programmable gate array\" in your context?\n\nFinance needs to go fast boooooiiiii\n\nAh I guess it would make sense that HFT runs on specialized hardware.\n\nThat's exactly what it means.\n\nCool.\n\n...\n\nWelp, see ya later.\n\nOr letting you decide when something is ready to release. Not some arbitrary PI schedule made before the pre-design work even started.\n\nFuck that.  You'll still be working more than a CEO.\n\nBut for honest work this time.\n\nI'm already doing more work than a CEO, getting paid like one would still be better for me.\n\nFacts.\n\nThe companies I worked at, the highly placed people all work way more hours than the devs like me who stick to their 40 hours. They take most of the heat if shit goes wrong. Problem is a lot of their work is not visible to lowly devs. \n\nStick to hating management if that makes you happy, but I believe the circlejerk of \"all management is bad\" is just false :shrug:\n\nFull blame? ¬†‚Ä¶. As-in you need my signature 100% to do *anything* and everything in this project/solution/deployment will be done exactly to *my* satisfaction and specification? ¬†Every time, on every issue? ¬†\n\nLike, even in late Q3 when the big numbers are The Most Important Thing you want me, personally, to dictate when and how you‚Äôre allowed to update or change our product or environment‚Ä¶ based overwhelmingly on my technical opinions? ¬†\n\n‚Ä¶ no, didn‚Äôt think so, just cog in the machine as per usual :D\n\nBusiness level accountability calls for business level salaries.\n\nThe article goes on to say that when a software engineer is given absolute sign-off authority like structural engineers are given on bridges, then you can blame the programmer. But if programmers are just silently replaced whenever they air a grievance, their approval means jack-shit\n\nCEO, the board, middle management. Everyone responsible for not the code and button pushing, but making sure good practices are in place across the company.¬†\n\n\nAirline safety is a good example of how it's done. Even if pilot or service men fuck up, the whole process goes under review and practices are updated to reduce human factors (lack of training, fatigue, cognitive overload, or just mentally unfit people passing).\n\n\nNot all software is as safety critical as flying people around, but crowdstrike certainly seems on this level. For dev being able to circumvent qa and push to the world seems organizational failure.\n\nI believe that the Boeing scandal has certainly left a significant impact on the overall reputation of airline security. The 737 Max crashes, which resulted in the loss of hundreds of lives, were a major wake-up call for the entire aviation industry, exposing serious flaws in the design and certification process of Boeing's aircraft.\n\nThe fact that Boeing prioritized profits over safety, and that the Federal Aviation Administration (FAA) failed to provide adequate oversight, has eroded public trust in the safety and integrity of airline travel. The FAA's cozy relationship with Boeing and its lack of transparency in the certification process have raised concerns about the effectiveness of airline safety regulations.\n\nSo long as they only get some theatrical scolding by politicians pretending to give a shit I don't think anybody that calls the shots woke up. I would be much more surprised to find out that they were prioritizing engineering again.\n\nMulienberg got a nice payout and disappeared from the public eye and Calhoun stepped in to make it look like they gave a shit but that company is infested with vampiric hyper capitalists.\n\nThe recent reduction in governmental regulation pretty much ensures that things will only get worse.\n\n&gt; that the Federal Aviation Administration (FAA) failed to provide adequate oversight, \n\nThat's not what happened. Boeing lied to the FAA that's why they were hit with a massive fine. I don't see how you can you blame the FAA in this situation when they were purposefully lied to.\n\nhttps://www.justice.gov/opa/pr/boeing-charged-737-max-fraud-conspiracy-and-agrees-pay-over-25-billion\n\nThis. It shouldn't be possible for one single person to be able to push such an update to a production environment.\n\nAirline safety...I thought you were going in the opposite direction with that example! \n\nI think airline safety is a good example of where it all goes wrong. Medical devices/regulated medical software is probably another example of where it goes wrong. My worldview was shaken after working in that industry.\n\nYeah, no surprise there with Boeing being a hot topic. They also pushed crashing products into production, all the puns intended.\n\n\nBut watching YouTube pilots explaining accidents and procedures show the other side of the airline safety story, which is pretty positive.\n\nYeah I think the pilot/service men safety processes are probably better organized as far as safety than the software dev part.\n\nWhere were the software testers? How could they let code pass that caused a BSOD?\n\nFrom what I understand (can be wrong) the error came in at a CICD-step, possibly after testing was done. If this was at my workplace, this could very well happen, as testing is done before merging to main and releases are built. But we don't push OTA updates to kernel drivers for millions of machines.¬†\n\nThe lack of a progressive/staggered rollout is probably what shocks me the most out of everything in the Crowdstrike fiasco.\n\nBro my company makes shitty web apps and we feature flag significant updates and roll it out in small waves as pilot programs. It's insane to me that we're more careful with appointment booking apps than kernel drivers lol.\n\nObviously a feature flag wouldn't do shit in this case since you can't just go into every PC that's updated remotely and deactivate the new update you pushed. A slow rollout, however, would limit the scope of the damage and allow you to immediately stop the spread if you need to.\n\nThe Crowdstrike situation can't be reduced to a soundbite like \"CEO is to blame\" or \"dev is to blame\" because honestly, whatever process they have in place that allowed this shit to go out on a massive scale like this all at once is to blame. That's something that the entire company is responsible for.\n\nEveryone keeps saying this as if it‚Äôs a silver bullet, but depending on how it‚Äôs done you could still see an entire hospital network or emergency service system go down with it.\n\nSomething slipped through the net and it wasn‚Äôt caught by whatever layer of CICD or QA they had. If a corrupt file can get through, then that‚Äôs a worrying vector for a supply chain attack.\n\nSure, depending on how it‚Äôs done. The company I work for has customers that provide emergency services. Those are always in the last group of accounts to have changes rolled out to.\n\nThis was a massive fuck up at several levels. Some of them are understandable to an extent, but others demonstrate an unusually primitive process for a company of Crowdstrike‚Äôs dimension and criticality.\n\nThe testing part is one thing, what I‚Äôm most baffled about is that they pushed an update to EVERY system instead of a gradual rollout.\n\nYup, 100% this¬†\n\n&gt; as testing is done before merging to main and releases are built\n\nWhy test if you're not even testing what you're deploying?\n\nYou shouldn't release something different to what was tested. Are you saying the QA is done on your feature branch then a release built post merge to main and released without further testing? That's nuts.\n\nSee my reply to the other guy. We ended up doing this because we found that frequently a single feature requiring a change or not passing a test would hold up all the other ready to go features when testing was done on the complete release builds. Doing testing/QA on the feature builds allows us to actually do continuous delivery. Of course, our extensive suite of automatic tests are performed on the release candidate.¬†\n\nDid it cause BSOD in all systems, or a subset?\n\nAll systems. It would have been a simple smoke test by a junior dev that could have caught this\n\nThat's ... not remotely what the article says\n\nTL;DR: actually read the article you lazy fuck, it makes a quite nuanced point which can't be summed up in one sentence\n\n---\n\nEDIT since I can't reply to /u/Shaky_Balance for some reason: I'm not saying that the point is *good*. It's perfectly fair to disagree with it. I'm saying it's more *nuanced* than \"blame the CEO\".\n\n---\n\nEDIT 2 (still can't respond to /u/Shaky_Balance, but this is a response to [this comment](https://old.reddit.com/r/programming/comments/1e8ipxf/lets_blame_the_dev_who_pressed_deploy/le93tif/?context=3#le80enm)): you can't just say that the article is as simplistic as saying \"blame the CEO\" *and also* say that the article says that you can blame the board, the government, middle management, the customer, the programmer, ... -- those two things are completely diametrically opposed. The article is either saying \"blame the CEO\", *or* it is saying \"the blame lays at the feet of the CEO, the board, the C-suite, the government, middle management, etc etc, and it could be laid at the programmer if some set of changes are implemented\".\n\nI don't understand what this argument is. Even if the article was no more nuanced than saying \"blame the CEO, the government, the middle management, the board, the customer and the C-suite\", that would *still* not be appropriately summarized as \"blame the CEO\". What the actual fuck.\n\n---\n\nEDIT 3 (final edit, response to [this comment](https://old.reddit.com/r/programming/comments/1e8ipxf/lets_blame_the_dev_who_pressed_deploy/le96xde/)): I could not possibly care less about this tone policing. If you dislike my use of the term \"lazy fuck\" then that's fine, you don't have to like me. But yeah this has gone on for too long in this weird format, let's leave it here.\n\n---\n\nEDIT 4 (sorry, but this is unrelated to the discussion): No, they didn't block me, I could respond to [this comment](https://old.reddit.com/r/programming/comments/1e8ipxf/lets_blame_the_dev_who_pressed_deploy/le96eij/), and I can't respond to any other replies to this comment either. Reddit is just a bit broken\n\n&gt; EDIT since I can't reply to /u/Shaky_Balance for some reason\n\nIf the reply button is just missing, this usually means they blocked you.\n\nI haven't as far as I can tell. I still see the block option on their profile. When I've blocked others, I can't see their comments anymore and when I was blocked once their comments disappeared for me as well. [Reddit's support article on blocking](https://support.reddithelp.com/hc/en-us/articles/4413520308372-How-does-blocking-work) seems to back this up:\n\n&gt; Blocked accounts can‚Äôt access your profile and your posts and comments in communities will look like they‚Äôve been deleted. Like other deleted posts, your username will be replaced with the [deleted] tag and post titles will still be viewable. Your comments and post body will be replaced with the [unavailable] tag.\n&gt;\n&gt; ...\n&gt;\n&gt; This means you won‚Äôt be able to reply, vote on, or award each other‚Äôs posts or comments in communities.\n\nBlocking also prevents replies a few levels below. So it could've been a parent comment instead. If you can see the comment itself in the post (not just your inbox), but can't reply, then look upthread to find who's at fault.\n\n&gt;EDIT since I can't reply to /Shaky_Balance for some reason\n\nHe probably blocked you.\n\nI think the argument structural engineers sign off on their work but swes dont was huge and more insightful than blame leadership\n\nWait until they find out that there probably was no \"Deploy\" to be pressed...\n\nContinuous delivery! All PRs go to prod right away\n\nOr the opposite, things don't go to prod until something totally unrelated must go to prod and it drags things to prod...\n\nAhaha so true.\n\nLet's blame the guy who wrote the 'Deploy without approval from a smoke test' button, or the guy who approved building it.\n\nHardened systems simply don't allow for bad things to happen without extraordinary effort.\n\nIt should have consequences for Crowdstrike.¬†\n\nBlame only really matters when malice is involved. If someone makes a genuine mistake, the only reason to find who is responsible is as part of a process to prevent it from happening again.\n\nIf someone pressed \"Deploy\" and shouldn't, we need to fix the process. Deploying shouldn't be possible without full testing.\n\n&gt; Blame only really matters when malice is involved.\n\nWe need to be careful here, though.\n\nUsually people invoke Hanlon's razor here: \"Never attribute to malice that which can be adequately explained by stupidity.\" I also like to swap out \"stupidity\" for \"apathy\" there.\n\nBut let's be clear: *when someone is in a position of authority, stupidity and apathy are indistinguishable from malice*. Hanlon's razor only applies to the barista who gave you whole milk rather than oat milk, not to the people responsible for the broken processes capable of taking down half the world's computers in an instant.\n\nGrey's law; \"sufficiently advanced incompetence is indistinguishable from malice\"\n\nI would agree, but with a caveat: often trusted developers are given special permissions that enable them to bypass technical processes or modify the processes themselves.  There have to be checks and balances for use of those permissions.\n\nThose powers are there so they can fix problems with the process or address problems that the process didn't consider (ex: certain break-glass emergencies). \n\nIf those special permissions are misused in cases where they shouldn't be it is *absolutely* right to hold the developer responsible and punish them if there's repeated misuse.  \n\nFor example, I have direct root-level production DB access because one of my many hats is acting as our top DBA.  If I use that to log into a live customer DB and modify table structures or data, I should have a *damned* good reason to justify it.  If I do it irresponsibly and break production, I would expect a reprimand at minimum, and potentially lose that access.  If I make a habit of doing this and breaking production then my employer can and should show me the door.\n\nOr put another way, the Spiderman principle: with great power comes great(er) responsibility. Edit: I just wish executives followed that principle too...\n\nReally my solution was horribly oversimplistic. \n\nWhen there's a high level of access, we also neeed a machanism to prevent you from doing something silly. For example typing \"rm -rf \\*\" in / rather than in /tmp because you're in the wrong tab. \n\nThe \"break glass\" metaphor is a good one. You don't want people borrowing a fire axe to prop open a door. People absolutely would do that if it didn't require breaking the glass to access it. So we add an extra irreversable step that forces people to think.\n\nI think rather than \"If I do it irresponsibly and break production...\" the rule should be \"If I do it irresponsibly...\". Everything you do with this user privelege should be justified. How we make sure it's justified is a case-by-case thing.\n\nIf you accidentally kill someone it's manslaughter. A genuine mistake can still be the result of unacceptable negligence, at which point there should be consequences.\n\nI generally agree with this.  Until and unless devs can say \"no, this is running an unacceptable risk and I won't sign off on it\" then there is no right to hold them responsible for honest mistakes.  \n\nUnless an individual dev found a sneaky way to bypass quality controls and testing and abused it in violation of norms,  the fault lies with the people that define organizational processes -- generally management, with some involvement from the top technical staff.  \n\nSoftware with this level of trust and access to global systems should have an *extensive* quality process. It should be following industry standard risk-mitigations such as CI, integrated testing, QA testing, canary deployments, and incremental rollouts with monitoring.  I'd bet a day's pay that the reason it didn't have this process was some exec decided that these processes were too expensive or complex and wanted to save money. \n\nExecutives insist the \"risk\" they take is what justifies their high compensation...  okay, then they get the downside of that arrangement too, which is being fired when they cause a massive global outage.  That would apply to the CrowdStrike CEO, CTO, and probably the director or VP responsible for the division that shipped the update.\n\nLet‚Äôs blame the person who only had one button. ‚ÄúDeploy to world‚Äù\n\nHow could it get deployed without local IT getting a look at it first on a test machine in their env.\n\nClient CTO's/COO's should be at blame for allowing a third party to control their infrastructure willy nilly.  They never should have signed on to a company that doesn't offer this type of deployment option.\n\nedit:sp\n\nI work for a smaller software shop.  We are often praised by clients for having our crap together when it comes to releases and upgrades.  (The bar is kinda low...)\n\nOur method isn't really suitable for the edr space.  Here's what our release process looks like:\n\nFirst off the unit tests.  Obvious, right?\n\nThen the QA team gets their hands on a stable build.  They run through a battery of tests, including feature tests and user acceptance tests (tests where we have their process and walk through it).\n\nThen customer care and project services get their hands on an RC.  They do their own tests.\n\nThen we deploy it to the demo servers.\n\nThen, finally, one production server, usually one hosting a customer that needs or wants something in the new release.\n\nThen we wait a few days or week depending on the size of the release.  (This is where things would break down for security software - they can't wait a week.)\n\nAnd you know what?  I'm still not happy with the level of testing we do.  I am  currently working on a set of integration tests that have already identified issues that we think have been there for years.  Those integration tests will go into the CI/CD pipeline, which we're also finally starting to do.\n\nThats right.  We're actually behind the times.  The pipeline isn't even set up, and it really needs to be.\n\nIn the CrowdStrike outage, one thing that I wonder is how this wasn't caught in the QA or UAT phase of testing.  It's widespread enough that at least some of their tests VMs should have manifested it.  So what went wrong?\n\nI look forward to their RCA disclosure.  Which they need to release if they hope to regain some trust.\n\nAs a devops engineer I see this kind of shit and think about all the times teams have ignored my advice on making sure smoke tests pass before deploying, about waiting the 30 minutes to make sure unit tests are passing. To make passing test cases a requirement for the codes.\n\n\nTo have a pre prod server identical to production.\n\nTwo day code freezes. \n\nRelease flags \n\nBut there's never time to do it right. \n\n\nI'm certain there's a devops team at Crowd strike in meetings with the CEO saying \"yes here's the email from April warning the team about this. And this one is from Feb 2019. And this conversation is from 2021.\"\n\n&gt; As a devops engineer I see this kind of shit and think about all the times teams have ignored my advice on making sure smoke tests pass before deploying, about waiting the 30 minutes to make sure unit tests are passing. To make passing test cases a requirement for the codes.\n\n&gt; To have a pre prod server identical to production.\n\nInterestingly, this reminds me of all the times operations refused to provision more compute (30 minute unit test runs, non-matching pre-prod) or owned the build pipeline and refused to implement automated gates (smoke tests, passing test cases). \n\n&gt; Two day code freezes.\n\nUgh, code freezes. You can have them if you're the one who has to argue why nothing can be released with less than x weeks notice because of the freeze.\n\nAs someone who‚Äôs run several dev and ops teams, it should be the team‚Äôs responsibility. No decision that important should be on a single person, and if it is then your processes are shit.\n\nI won‚Äôt even name the devs that break things (except for that one time when we had someone deliberately and maliciously sabotaging us), because it‚Äôs not their fault, it‚Äôs our fault for not looking hard enough at what they were doing or my fault for not implementing or enforcing a solid enough policy.\n\nIt should be the team‚Äôs responsibility but they can‚Äôt have that without autonomy\n\nI agree with some of the stuff but this paragraph was hilarious: \n\n&gt; And, usually, they fail upwards. George Kurtz, the CEO of CrowdStrike, used to be a CTO at McAfee, back in 2010 when McAfee had a similar global outage. But McAfee was bought by Intel a few months later, Kurtz left McAfee and founded CrowdStrike. I guess for C-suite, a global boo-boo means promotion.\n\nLike, I thought you were gonna say that George Kurtz got hired as CEO of an already big crowdsrike when you say he ‚Äúfailed upwards‚Äù, not that he founded the company. \n\nYou say you‚Äôre an entrepreneur - you should know that founding a company is not a promotion or failing upwards. It‚Äôs up to you whether it succeeds or fails\n\nHave you ever stopped and really thought about why 'security' as a term has gained so much more traction than 'quality' when we talk about software?\n\nI suspect it's because security is something that can be blamed on an external actor, some entity or party separate from those who wrote the software. Whereas quality is the responsibility of those who wrote the software. Security requires some, typically portrayed as evil, entity acting on a software product from an external position. Whereas quality is an essential aspect of software products.\n\nThey both cost money, but quality is a lot less sexy than security. Also, if someone exploits a security bug we have a villain to blame. It helps to deflect the responsibility onto the external actor. No such luck with quality. Bad quality will always be perceived as the fault of the producer.\n\nThe IT groups and IT executives at all of the companies whose production systems were affected - bear a huge responsibility for this.\n\nThey specifically allowed a piece of software into their production environment whose operating model clearly does not allow them to control the rollout of new versions and upgrades in a non-production environment.\n\nAny business that has a good Risk group or a decent \"review process\" for new software and systems ... would have assigned a high risk to CrowdStrike's operating model and never allowed it to be used in their enterprise without demanding that CrowdStrike make changes to allow them to \"stage\" the updates in their own environments (the businesses' environments, not CrowdStrike's).\n\nA vendor's own testing (not even Microsoft's) cannot prevent something unique about your own environment causing a critical problem. That's why you have your own non-production environments.\n\nHonestly based on this one principle alone - impo - 95% of the blame goes to the companies that had outages, and whatever idiot executives slurped up the CrowdStrike sales pitch about \"you're protected from l33t z3r0 days by our instant global deployments\" ... like as if CrowdStrike is going to be the first to see or figure out all the zero day exploits.\n\nInsanity.\n\nWhile I mostly agree, many security components tend to work on the model that they should automatically pull in the latest data and configuration to ensure the highest protection. This is anything from Windows Updates,  Microsoft Defender definitions, all the way up to networking components like WAF bot lists and DDoS protection solutions.\n\nIf you had to do a production deployment every time something like that changed, it'd be useless to most companies that aren't working on a bleeding edge devops \"immediately into prod\" model. Many of the things being protected here have to be protected ASAP otherwise it is useless to most people.\n\nThe issue here is the separation between updates to core functionality and updates to data used by the tools. The functionality itself shouldn't be changed at all without intervention, and this was the whole issue. However, the data used by the functionality should be able to be updated (e.g. defender software updates vs virus definitions).\n\nCrowdStrike should also have been canarying their software so that in the event it was broken, it only impacted a subset of users until data showed it was working correctly.\n\nWe can't just blame the developers, or even the company they work for. The finger of blame also needs to be pointing at all the companies that have cut corners on their deployment teams. Because it's cheaper to just allow auto updates than it is to properly test code before it's deployed to your systems.\n\nIf you aren't testing software changes to systems that are business critical, that's on you. I'd love to say that they'll learn their lessons from this, but they won't. They'll still see it as an unnecessary overhead and go back to burying their heads in the sand.\n\nThen this will happen again in a few years time. And the same company executives will do surprised Pikachu again.\n\nlol, i've worked at smaller companies that have a tight multi-stage prod rollout.  To think that CS has a single deploy-everywhere function that'd be used for something like this seems like a bubblegum fantasy\n\nWhat if it was actually this: NSA urgently tells Crowdstrike about 0-day exploit in their system that terrorists are about to push worldwide in 10 minutes and ransomware every single one of their customers. Hero programmer gets wakened from sleep by 4am phone call asking what we can do, we have 10 minutes. Think! Programmer pets cat, yawns, looks at clock.\n\nComes up with idea: we push out a definition file of all zeroes, which will cause a null pointer dereference and brick every system, but at least it will block the ransomware. Gimme five minutes.\n\nGenius. NSA reminds them it remains top secret until the 0-day is found and fixed and do not tell anybody. Hero developer has to take the fall as the idiot who pressed \"deploy,\" but saves all of western civilization.\n\n&gt;  it makes sense to run EDR on a mission-critical machine\n\nWTF? No! This is exactly the kind of machine where nothing else but the software should run. Why would you install what (potentially) ammounts to a backdoor in a critical system? If people fail to understand this, no wonder half of the world gets bricked when third party dependencies break.\n\nSome of us are old enough to remember when the machines and software that ran these mission-critical systems were specialized and on isolated networks.  Every time I see a BSOD'ed public display at some airport or restaurant, I think, \"_In what world should this be a Windows application?_\"\n\n&gt; I think, \"In what world should this be a Windows application?\"\n\nBecause there are significant **costs** associated to developing your own OS or something to run on bare-metal, and Windows is the most well-known OS to develop GUI apps for.\n\n&gt;Why would you install what ammounts to a backdoor in a critical system?\n\nBecause all those \"critical systems\" are nowadays just desktop computers running regular software. A doctor has to be able to access life-critical equipment, but also send emails and open pdf attachments. Your patient records must be stored in a secure and redundant system, but also be available to you via the internet. Airport signage must be able to display arbitrary content, so it's just a fullscreen web browser showing some website.\n\nSure, you *could* separate it all, but that costs money and makes it harder to use. Both management and users don't want *that*, so let's just ignore that overly paranoid security consultant who's seeing ghosts.\n\nI don't consider client terminals to be that critical. Some of them might be. But the airport's, the doctor's, these terminals run an OS image and a standard installation of some client application, most often a web client. The entire OS+application can be downloaded and reinstalled from zero over the network using something like PXE, since these machines don't usually store local data.\n\nCareful, if you say that you'll get \"experts\" descending on you about how idioticly wrong you are. \"If you're paying for endpoint protection you should put it absolutely everywhere!\"\n\nNo, you shouldn't run it on kiosks or servers. Endpoint protection software is primarily meant to protect the network from the end-users. Kiosks and servers should just be locked down so only the business app can run in the first place.\n\nOr, *at the very least*, if you absolutely must run an EDR on servers, don't have it auto-update on the broad channel. Evidently not even signature updates are guaranteed safe.\n\nI dunno about the update cycles of crowdstrike, but regardless the whole \"who pressed deploy\" discussion I'd like to hear why a team, heck, a whole company does updates/deployments on friday?\n\nI once worked at a company that had written into their SLAs that the allowable maintenance window was after 9pm PT on Friday. This was no automated deploy either. Maybe twenty engineers representing every team with a pending deployment were required to get on a call starting at 9pm and wait their turn for a manual deploy and smoke test, with the entire process typically ending sometime between 2 and 4am. The CEO was quite adamant that everybody in the industry does this thing I‚Äôve never seen happen anywhere else. I only wish I could say it‚Äôs the shittiest thing I‚Äôve ever seen, but it‚Äôs pretty high up there.\n\nYou should always blame managers instead. Managers make more money specifically so they can assume more responsibility. Ask them what corners they allowed/encouraged to be cut.\n\nThere is a lot of incompetence in management, middle management and C suite in licensed engineering. To imply the opposite is naive. \n\nJust like your tech bro manager that cuts corners, there are terrible managers in all fields. Difference is they are ALL legally liable if the bridge goes down, not just the peasant who did the first draft of the design.\n\nSDE job is/should be ideally signed off by multiple people in multiple levels of management. If they all were legally liable with consequences should damages occur, do you think this situation would be different?\n\nWithout leaning to any side, I think it's a debate worth having!\n\nIt really isn't only about someone writing the code: testing is supposed to be there to catch problems like these.\n\nAnd considering how widespread and easily triggered the problem is, it should not have taken much effort in testing to find out (it's not a subtle bug).\n\nThe release and testing procedure design should be there before releasing (or \"deploying\" as some say). It is a failure in that procedure that it wasn't caught. Testing should always test what you are going to release, changing it after testing will just nullify the effort made in testing. If your testing/release procedure doesn't have means to support this then it is worthless and needs to be changed.\n\n\"But our tools don't support that\" - your tools need to be fixed. No excuses. Your customers won't care if you have to do it all manually or not, they want reliable results.\n\n&gt;‚ÄúEntrepreneurship implies huge risk and lays the responsibility for failure on the shoulders of the founder/CEO‚Äù. And it‚Äôs true. Founders/Entrepreneurs bear a lot of risk.\n\nYeah, they probably don't. They take risk alright, but by and large, the risk is offset by the various versions of the proverbial golden parachute.\n\nAnd indeed, case in point...\n\n&gt;And, usually, they fail upwards. George Kurtz, the CEO of CrowdStrike, used to be a CTO at McAfee, back in 2010 when McAfee had a similar global outage. But McAfee was bought by Intel a few months later, Kurtz left McAfee and founded CrowdStrike. I guess for C-suite, a global boo-boo means promotion.\n\nAs for the blame game, **all** of the parties TFA mentions are to blame, **the question is only to what extent**. All, the engineers, the management, the customer, the government, you name it, everyone played their part.\n\nSo what is there to do? A generic \"everybody should do a better job\" is the best I can come up with. And I have to say, **in this case, the bar is low**. The company shipped a massive blunder, what the fuck are their development, testing and processes doing...? The customers, too. Where were the gradual updates, to lower the error impact...?\n\nNo testers involved at all for a code deployment is the wild\n\nimma say this: if one vendor can take you out, that's on you and your engineering teams (most likely engineering leaderships fault for probably choosing the cheaper route of dealing with circuit breakers as tech debt for faster delivery to market or cut costs)\n\nthe only people who should really be mad crowdstrike are those paying for it, otherwise be mad at the people who went down for not having DR plans or failure tolerance\n\nI was nodding along until this part:\n\n&gt;We could blame United or Delta that decided to run EDR software on a machine that was supposed to display flight details at a check-in counter. Sure, it makes sense to run EDR on a mission-critical machine, but on a dumb display of information? Or maybe let‚Äôs blame the hospital. Why would they run EDR on an MRI Machine?\n\nThe reason you run EDR on these endpoints is because otherwise they get ransomware'd. End of story. And an MRI machine is 100% mission-critical if your mission involves performing MRIs. If they weren't mission-critical, then it wouldn't have mattered that they went out of service on Friday.\n\nAll other issues aside, I really don't want MRI machines connected to the Internet if they don't absolutely have to be.\nPreferably the critical code for an MRI machine wouldn't even run on a traditional operating system.  \n   \nThere should probably be a lot more freestanding programs which simply don't have the attack surface that comes with a whole OS. It's more expensive and time consuming, but at some point it'd be nice if people came before easy profits.\n\nso when does the CEO testify in front of congress?\n\ncringe\n\nTesting? what's that??? ...\n\n&gt; But then [other author] engages in an absurd rant about how the entire software engineering industry is a ‚Äúbit of a clusterfuck‚Äù\n\nThe author of this article then goes on to describe in highly accurate detail the *exact* absurd clusterfuck that modern SW development and deployment is:\n\n&gt; Because blaming software engineers is nothing more than satisfying the bloodthirsty public for your organizational malpractices. Sure, you will get the public what they want, but you won‚Äôt solve the root cause of the problem‚Äîwhich is a broken pipeline of regulations by people who have no idea what are they talking about, to CEOs who are accountable only to the board of directors, to upper and middle management who thinks they know better and gives zero respect to the people who actually do the work, while most of the latter just want to work in a stable environment where they are respected for their craft.\n\nI've never seen a better case of \"violent agreement.\"\n\nMaybe we shouldn't have a single button that can break the entire global infrastructure.\n\nWEF, major cyber attack simulation, DNC, Ukraine, Crowdstrike. Connect the dots... üòé\n\n&gt;The reason why Anesthesiologists or Structural Engineers can take responsibility for their work, is because they get the respect they deserve. You want software engineers to be accountable for their code, then give them the respect they deserve. \n\nThis was a really great section and makes me feel more inspired to push back on management and take the time to ensure my code and processes are battle tested and bullet proof \n\nI‚Äôve already begun saying and sticking to read only Fridays. That means only automated deployments already in flight can proceed on Friday, otherwise they wait till 9 am Monday. \n\nSure it slows things down but it ensures we have all hands or most hands on deck when new code rolls out. \n\nI have also been pushing back on admin work on Friday as too. \n\nAnyway I loved this post and it‚Äôs inspiring me to continue approaching my profession with rigor\n\nCrowdstrike's Falcon is a kernel level device drive that somehow is allowed to execute dynamic outside unsigned code. If you do not know what the consequences are of this you should not be working in IT.\n\n\n\nThis is how Murphey's law was born. Everything that can go wromg will go wrong, eventually.\nThis outage was a certainty. And the root of the problem is an OS that not only allows this design, but slaps a WHQL label on it.\n\n\nThere *should* be consequences, starting at ms headquarters and their poor excuse for systems qa. Then at crowdstrike hq for their poor excuse for system design, team management and qa. Then at the IT consultant who thought that running a mission critical system on windows would be perfectly fine.¬†\n\n&gt;I remember times when leaders had dignity and self-respect. They would go on stage and apologize. They would take responsibility and outline an action plan. Some even stepped down from their position as a sign of failed management.\n\nwas this... in the 1600s ... BC?\n\nDev: \"I was tired, I thought it said 'reply'!\"\n\nAnd make sure s/he never presses \"Deploy\" again! As we all know, these problems are caused by people who pressed \"Deploy\"."
  },
  {
    "title": "Lessons learned after 3 years of fulltime Rust game development, and why we're leaving Rust behind",
    "body": "",
    "score": 1542,
    "url": "",
    "created_utc": 1714150286.0,
    "author": "progfu",
    "permalink": "/r/programming/comments/1cdqd3m/lessons_learned_after_3_years_of_fulltime_rust/",
    "all_comment_text": "The core thesis seems to be that fast iteration is effectively impossible with rust. That's my disappointing conclusion as well. The awkwardness of dealing with the borrow checker along with coding basically everything as a state machine is just too much to deal with. I've found I'm incredibly productive with tools that provide coroutines or similar (e.g. lua) which provide an escape from state machine hell.\n\nI started my prototypes with Unity and after a week I couldn't deal with the wait times when I'm testing things. There are tools like Hot Reload plugins and what not, but I swapped over to Godot/C# for Prototyping and its really just reloading the scene and its there. This is how I also work in my professional job. Turnaround times have to be close to zero to keep motivation high.\n\nThe article references this [awesome Tomorrow video about their in-house development environment](https://www.youtube.com/watch?v=72y2EC5fkcE). An absolute must-watch.\n\nHolly hell, my mind is blown.\n\nmiddle grandfather hunt offbeat plucky support salt slim squeamish start\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*\n\nNo problem. Note: there is a ‚Äúsave‚Äù function under each comment to do exactly that.\n\nFeel free to tell us what you thought!\n\nI find it that's the key reason why so many people like typescript. Sure it's not 100%, but iterating on things is super quick and if you want you can ratched up the strictness of the transpiler. What I really wish will be possible one day is to have something close to a super strict mode where all the weird javascript nonsense is straight up disabled (at the runtime level even) and things get close to go or rust where there's an actual compiler involved.\n\nIt's a pendulum. People are souring on Typescript. Next is JSDoc. Then JavaScript, then NextTypeScript.\n\nI dont think we'll ever return to pure javascript at all lol\n\nJavaScript keeps adding so many things. It is not a static target. They've threaten to add optional types.\n\ntrue, but thats only \"type comments\" a la python, where the types dont actually do anything themselves (i.e they are ignored at runtime), you'd still need typescript in the background to actually enfore the fact that you can't pass a string to `function foo(a: number) {}`\n\nthere are also other things that typescript has such as enums, namespaces and access modifiers that aren't covered by this proposal\n\nI feel like the thesis is less that that's fundamentally impossible, but more that that's not how Rust is currently set up.\n\nLots of specific ergonomic issues that are hard to work around, lots of compiler stuff that could be improved, and the need to add fast reload. And the meme of it compiling means it works still applies -- but that doesn't get you out of the need for rapid iteration. In game dev you still need to try lots of different \"business logic\" -- it doesn't matter as much that the code itself works as is. That just means you need less iteration. But here, the greater logical iteration count need holds Rust back. You never eliminate that, only the lesser bug side of iteration.\n\nAlso ecosystem stuff.\n\nDon‚Äôt know much about rust but it does have async await right? I am not totally clear on the differences between Futures and Coroutines but I thought they should fulfill a similar purpose.\n\nthe borrow checker hates async awaits, it almost feels like its discouraging you to use async await\n\nWhat the borrow checker hates is usually moving things across threads.\n\nMy understanding is that anything accessed in an async block needs to be Send (trait). Basically any async block is \"moving stuff across threads\". Your comment kinda sounded like a refutation, thats why I wrote this comment.\n\nThat's not quite right, async blocks themselves don't have a requirement to be send,  but any multithreaded runtime won't accept them unless they are. You can run non-send async blocks on e.g. the tokio current thread runtime.\n\n`Send` (the trait) is a property of a type that is independent with borrows, and therefore borrow checker does not check that. However, when you send (the action) anything to other threads, borrow checker check if you send any borrowed data, and stops you when you do, because it is impossible to prove your data outlives the borrow. That's why a lot of times you need to clone things before you spawn threads or tasks, because the type systems does not know how long the thread/task live, so they must not borrow anything.\n\nA trick that I find useful for writong `async` code is creating multiple `async` blocks and `select`/`join` them. That does not spawn any tasks and so I can freely borrow the data from the surrounding scope.\n\nNot a refutation, because you can‚Äôt really separate the future-ness from the underlying runtime and possibility of moving between threads.\n\nIt‚Äôs just that there fact that you need to make guarantees for a multithreaded runtime is what makes it a challenge from the perspective of the borrow checker.\n\nIt is only the problem if you use a some kind of multi-threaded async runtime (such as tokio). You do not have to ‚Äî in fact, tokio even has `current_thread` runtime flavor which is exactly what it says on the tin. There is no inherent reason for all the futures be `Send` and `'static`, it is just that the most popular one ‚Äî work-stealing tokio one ‚Äî requires it for obvious reasons.\n\nTBH if you are doing game development would you be doing the fast iteration part in Rust? You certainly wouldn't do so with C++. I'd expect the slowly changing core to be Rust/C++ and the top level to be a scripting language of some sort.\n\nEverything in gamedev is fast iteration development, including core engine functionality three days before release\n\nAnd three days after\n\n&gt; You certainly wouldn't do so with C++.\n\nI'm not a game dev but I do interactive public installation software which has the same iteration loop and performance requirements and I absolutely do all my iteration in C++. Hot loading assets and DLLs or using something like Live++ is totally common practice, as is building complex in-app tweak UIs with Dear ImGui for tuning based iteration where the code itself isn't changing.\n\nThere's many benefits to this, but for me, having your core engine and \"gameplay\" code be in the same language is a massive win, both for performance and maintainability, since you're not wasting any time keeping your scripting layer in sync with the underlying code it's bound to. Or worse, having to port all your scripting code back to C++ way down the track when you realise it's just too slow.\n\nYou'd typically use something like JS, Lua, or even data files for iteration in C++, but honestly C++17 is dramatically better to rapidly prototype in than C++ when I first learned it.\n\nI've rapidly iterated on device driver code using modern C++.  People who haven't used it really don't understand that it's not that bad.\n\nWhat does the workflow look like? Hot reloading drivers?\n\nThat's how it works on Linux. It's fairly straightforward as long as you aren't dealing with virtual machines running on the host system accessing the resource.\n\nHowever, for most people saying \"it's not that bad\" is a lot worse than \"it's good\" tho.\n\nYes. I'd say it's about neutral in terms of effort required. It's not great but it could be much worse. Would I recommend it for game dev? Not if you were starting from scratch on a new game engine. But if an engine is already in C++, then I wouldn't recommend against it. Whereas I'd recommend against rust for anything other than high security required or safety related software.\n\nI‚Äôve seen titles use a data driven approach with C++ fairly well. We could dynamically configure event emitters, listeners, actions, property values, behavior modifiers, and link them to assets and game object properties. The game designers could tweak things all day while engineering focused mostly on core engine stuff. The title I‚Äôm thinking of was fairly simplistic though.\n\nSo make the whole game in the scripting language? Why even bother with Rust then? I am trying to wrap my head around what you are saying because it sounds like you aren't understanding why he didn't make the a Rust version of Unity to solve his Rust iteration problem.\n\nThat's a good point and I think it's likely the endgame for gamedev in rust. It's just kind of a disappointment to give up the type system, compile time guarantees, and other niceties of rust to go back to the luas, pythons, and C#s of the world for implementing the \"business logic\" of games. I¬†think¬†a¬†lot¬†of¬†people¬†are/were¬†hoping¬†to¬†just¬†do¬†everything¬†in¬†rust.\n\n&gt; The core thesis seems to be that fast iteration is effectively impossible with rust. \n\nMy experience has been the opposite, and I think the difference lies in where the iteration occurs.\n\nI don't work on game development, I work on server applications. This means that for me, the architecture is (now) mostly settled, and it's the core logic I need to iterate on, refine, go back on, etc...\n\nThus, confronting the two disparate experiences, I think the fundamental issue raised in this post is not quite that Rust is bad at fast iteration _in general_, but more that Rust is bad at fast iteration _over program architecture_.\n\nI could definitely see that. Rust forces you to lock more decisions in place than Python or JS would.\n\nIndeed.\n\nServer applications typically work well with Rust due to their \"pipeline of transformation\" nature which works well with ownership. Adding/removing steps to the pipeline is easy, iterating over the exact algorithm of a step is easy. Transforming the pipeline into a graph? Uh oh...\n\nFantastic article, loved it and after 4 years spent working on a game in Rust I can relate to pretty much all of your points and conclusions.\n\nIt took me 4 years to read this article.\n\nYou should have just borrowed it.\n\nRemind me! 4 years\n\nI will be messaging you in 4 years on [**2028-04-27 01:20:29 UTC**](http://www.wolframalpha.com/input/?i=2028-04-27%2001:20:29%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/programming/comments/1cdqd3m/lessons_learned_after_3_years_of_fulltime_rust/l1fulzl/?context=3)\n\n[**5 OTHERS CLICKED THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2Fprogramming%2Fcomments%2F1cdqd3m%2Flessons_learned_after_3_years_of_fulltime_rust%2Fl1fulzl%2F%5D%0A%0ARemindMe%21%202028-04-27%2001%3A20%3A29%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete%20Comment&amp;message=Delete%21%201cdqd3m)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List%20Of%20Reminders&amp;message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&amp;subject=RemindMeBot%20Feedback)|\n|-|-|-|-|\n\nPrediction: in four years will say, ‚ÄòNewp! I didn‚Äôt finish the article.‚Äô\n\nNot a game dev here, but after reading through a lot of the post, it seems like Rust game-dev suffers from a focus on functional paradigms, where OOP might alleviate some of the stress of statefulness across the application. Am I just misunderstanding the scope of problems? For instance, I had never heard of ECS before, but when I found a blog trying to teach the concept, I was left with the feeling that it was a horribly convoluted system for sharing state across members.\n\nGame development suffers from one-size-fits-all solutions in general. It doesn't always have as much consistency from game to game as other product to product in other software domains. Particularly when trying to get something new and unique out quickly, trying to stick to someone else's OOP, ECS, functional, etc. best practices is always going to slow things down. Rust is opinionated about best practices, and just plain may not be a good fit here.\n\n[deleted]\n\nThere is even the article that equals ECS to a database:\n\n[Why it is time to start thinking of games as databases](https://ajmmertens.medium.com/why-it-is-time-to-start-thinking-of-games-as-databases-e7971da33ac3)\n\nAlso AFAIK ECS is often used with OOP in mind.\n\nECS is also often applied to projects where it doesn't make sense in relation to the games scope. \"But Overwatch used it so we have to also!\". Yeah, but you are making a non-networked single player game...\n\nECS is useful and can make sense, but in my experience on smaller projects when asked \"but why?\" you won't get a good answer. They don't have an answer to what its supposed to solve for them.\n\nPeople normally adopt ECS to alleviate the problems that come from strict hierarchies when using an OOP world model. It's not particularly convoluted in practice, really. An entity is just an ID, a component is just a struct of data and systems iterates over that data. Use of entity IDs allows you to request \"all entities that have X and Y component\" or \"this entity and all of its components.\" It's just a database, really.\n\nYou're misunderstanding the rust specific problem of how ownership and lifetime tracking makes this harder. Rust supports OOP, but it requires you to be specific about what you want from an object if you want to use it in many places at once, so you can't just \"do the thing\" - you have to \"do the thing correctly\". In many cases this is a good thing,  but the whole premise of the article is that in game development (or indeed any development where you don't know what the solution looks like), this is a bad thing.\n\nFuck dude, you killed my boi\n\nGreat article.  I don't feel like I know enough to argue you're right or wrong, but I definitely agree with you on your core values.\n\n&gt; Making a fun &amp; interesting games is about rapid prototyping and iteration, Rust's values are everything but that\n\nThis one stood out for me. Yeah.\n\nOof. That is a must. I feel like if I have an idea I need to bust out a prototype in under a couple hours.\n\nYou know that in League of Legends, *everything* (including projectiles) is base-classed as a Minion? Yeah Rust doesn't play that.\n\nthat's not a badge tho, everything being a minion has been the source of countless issues with league.\n\nI agree with prototyping being core for getting nice ideas out, but that example is probably one of the worst ones\n\nThey‚Äôre crying behind billions of dollars\n\nOh of course not. Regardless of good or bad coding practices, Rust is not conducive to games due to the nature of revamping internal systems quickly or having extreme dependence between them that may need to be dumped and redone.\n\nLeague of Legends and being programmed well, pick one\n\nBeing programmed well doesn't matter when you are making millions.\n\nThis reminded me on an old talk:\n\n* Bret Victor, [Inventing on principle](https://worrydream.com/Home2011/#!/InventingOnPrinciple), 2012\n\nHis 2nd demo shows how he envisions rapid game prototyping.\n\nI think Rust is meant for OS level or even lower level programmign where mistakes are unacceptable. Games are none of that.\n\nTip: there is a **finite** number of ways to spell de**finite**ly.\n\nholy .... you made my life so much easier with this!\n\nhope I can actually remember it tho ....\n\n2 is definately finite.\n\nForth programmers push it all the time!\n\nAll six of them are super excited to tell everyone!\n\nThanks for the tip\n\nHaving never touched game dev but having dabbled enough in server-side Rust and a bit of WASM frontend Rust as well, I can absolutely see how a game would be a nightmare to iterate upon. Rust just becomes a thorn if you have to manage a ton of global mutable state because the language fundamentally doesn‚Äôt want you doing that. There‚Äôs good patterns to design away from that on the server side where, like the article says, your application‚Äôs stateful needs are not rapidly changing. Iterating on that stuff is complicated and expensive and while I love Rust for what it‚Äôs good at, I can‚Äôt imagine having a good time trying to write a game in it.¬†\n\nIt's almost like they're saying no language, no matter who good, is perfect at every problem!\n\nGood article that confirms my own thoughts about Rust. \n\nAt my previous job we evaluated Rust and Go for rapid development of financial microservices. One point we wanted to check is how easy we can write dirty-hacks in these languages. In our line of work there were often incidents when we needed to fix things fast in production, because every second of inaction cost us thousands of dollars. These issues originated at much higher level than some source code: they were caused by holes in analytics, unexpected behavior of our partners' services, complicated network issues that could spread like a wave across all our services and raise a message storm with subsequent DoS. You can't reliably fix issues like these overnight, but you can sometimes mitigate them with some monkey-patching.\n\nLong story short - we found out that we can't dirty-hack a Rust service without total refactoring of its whole code. That's why we chose Go.\n\nOn the other hand at my current job half of our codebase is in C++ and our C++ developers spend most of their time hunting memory leaks, thread-races and functions that throw unexpected exceptions. I can see how Rust could make their life much easier.\n\nBtw. You have two hanging points in your article that are not related to the previous paragraph and are not explained (unfinished notes?):\n\n- Coroutines/async and closures have terrible ergonomics compared to higher level languages\n- Debugging in Rust is terrible no matter what tools you use or what OS you're on\n\nI like this response. Every language is a trade off between competing concerns. We use rust at my work and for us it‚Äôs perfect. We **really** care about correctness, every mistake costs us hugely. We cannot easily ship fixes: it‚Äôs far more important for us to get it right the first time. So much so that we have an entire team whose sole job is to verify the correctness of what we‚Äôve built.\n\nWe also **really** care about performance. We run on machines with terabytes of memory and hundreds of CPUs and if we could get more grunt we would. Any piece of code could end up being a bottleneck and we need to know we can make it fast if we need to. We cannot use a language with a GC: our memory scale is too big, we know from painful experience GCs will choke and die. Parallelism is essential to what we do but we can‚Äôt afford the threading bugs that come with C/C++. Rust is tailor made to our use case, but fast iteration (whilst nice) is not our highest priority. \n\nCoding with a GC is honestly just easier most of the time. Rust makes you jump through a lot of hoops. IMO if you weren‚Äôt very seriously considering C/C++ you should really question whether rust is the right choice.\n\nTBH I‚Äôm not a fan of Go as a language, I think it has a lot of poor design choices. However, a GC language in general is going to be an easier choice for many problems - probably including a lot of game development as in the OP‚Äôs case. However, when you really care about correctness and performance nothing beats what rust can offer. Rust really is for software that rusts: you don‚Äôt mind it takes longer to build because it‚Äôs going to be around for ages and it needs to perform, it needs to be right and you need it to last.\n\n[deleted]\n\nAn [OLAP engine](https://en.m.wikipedia.org/wiki/Online_analytical_processing), basically like a giant N-dimensional spreadsheet. It‚Äôs an in-memory database and calculation engine. \n\nOur customers use our platform to build business critical planning applications at huge scales: it needs to be right, it needs to work reliably and it needs to scale.\n\nThat‚Äôs fucking cool.\n\nI agree, that's fucking cool. Parallel processing of the multidimensional arrays.\n\n[removed]\n\n&gt;I interviewed a guy last week who told me that virtual meant something akin to how Python looks up functions by name in a dict...\n\nI don't know much about C++, but is it not? It should create some lookup table to emulate late function binding from more pure OOP languages, where classes are just objects that store method tables.\n\n[removed]\n\nThank you =)\n\nI've watched the video and googled more on the vtable topic. So if I understand it right it works like this:\n\n1. When you mark a function \"virtual\" a C++ compiler creates for the class an array of virtual function pointers, called \"vtable\";\n2. It precalculates the vtable at the compile time, so virtual functions use their overriden implementations;\n3. Then it rewrites all calls to virtual functions to use a pointer to the vtable, called vpointer. Something like c-&gt;vpointer[1], where 1 is the index of the virtual function;\n4. Finally at the run time the vpointer will be added to each object of the class. Therefore all calls to virtual functions will always use the correct vtable, even if at the compile time we didn't know which child of the class will be used.\n\n[removed]\n\nWhen was this article written? This blog comes without timestamps.\n\nThe article was written today, sorry for the missing timestamps, I'll add them.\n\n&gt; Rust as both language and community is so preoccupied with avoiding problems at all cost that it completely loses sight of what matters, delivering an experience that is so good that whatever problems are there aren't really important. This doesn't mean \"ship crap games\", it means focusing on the game being a good game, not on the code being good code.\n\nThis single quote just changed my worldview and perspective on software engineering.\n\nThe enjoyment we get from a game comes from its constraints (a.k.a 'the rules'). This is the same for music, sport, art, or anything else that people tend to do for the lols. As much as practicable you want those constraints to come from your game design, rather than be dictated by the technology.\n\n&gt; As much as practicable you want those constraints to come from your game design, rather than be dictated by the technology.\n\nAmen. Sometimes, we put people on a pedestal who could do both, and forget that that only happened because they already fully achieved goal1, so they had time to also achieve goal2. goal2 is not the main priority.\n\nDid you see that Twitter post about Balatro, a recent, super successful game? It was written in Lua, and apparently there is one .lua file with 1000+ lines that define every card behaviour.\n\nExcellent example. Yes, situations like that are unfortunate, but demonstrate the spirit of game development. It is not something to strive for, but it IS a tradeoff.\n\nI really feel this too, but I came to it from the opposite direction. I've come out of a job drowning in the dirtiest possible python. Low-skill devs passing endless dicts with each call wrapping or rewrapping the last dict. You would never know what you had at any given line in the codebase.\n\nIn that case, what mattered was a framework that guides low-skill devs into the pit of success. We needed something strongly-typed, that trades iteration speed for correctness. The maintenance costs of garbage code completely ate the benefits of getting v1 out quickly.\n\nPreach.\n\nOptimizing for arbitrary developers banging out code as fast as possible is _literally always_ the wrong call.\n\nOh wow, I see what you mean. I think there's a threshold where quick, dirty code is the best way to solve a problem -- rapidly iterating on a throwaway prototype that gets a point across. But once that code needs to support multiple modules of functionality, it is time to refactor into something statically/strongly typed.\n\ntl;dr: rust really loves bikeshedding\n\nI don't know that I would call it bikeshedding. I think it's just a language trying to enforce a level of safety while not giving the programmer enough tools to facilitate that level of safety. But I'm no Rust programmer. I am happy with Java.\n\nIt does, and it's very much double edged. I personally disagree with the sentiment in this thread that Rust is poor for rapid iteration or development. I've personally found the opposite, and find myself turning to Rust over alternatives for building something quickly. Part of that is because you can have a high confidence your stuff will work. You can make changes on an existing code base, and be confident everything you haven't touched is fine.\n\nOver Christmas where I work we had an incident. This hit a system currently being migrated to Rust. This meant we had to ship a fix in two code bases. The Rust fix took less time, whilst the older system in TypeScript not only took longer but also had unintended bugs (which turned out not to matter but the point still stands).\n\nHowever I also actively work to simplify bits done by other developers (with them on board of course). This is a huge part of what makes that work. I would admit saying Rust is great if you have someone full time cleaning the code, is a poor excuse.\n\nThere is a lot of responses to pain points people run into of \\_'you can just use X + Y + Z to do that.'\\_ Even when true, it means you are basically saying you need a lot of knowledge to get anywhere and work around things. Which again, is a weak counter argument.\n\nWe also have production Rust that is now several years old by people who are no longer here, and it's still far easier to dip into than anything else we have (if you are experienced). I can actively not care about how much of it works because I know the many things the compiler will enforce for me. That's really strong on old code bases.\n\nI dunno what the full point of my comment was. I guess it's something like Rust can be really sweet for quick work. There is also a mountain of knowledge to get there, which requires a lot of handholding. Without that it's easy to get lost for a long time.\n\nUntil you realize that your widely used game has become a wide open attack vector for hackers and get sued into oblivion when they find your online comments about how it's better to be fun than correct.\n\nNo joke, I'd pay good money for every gamedev I ever work with again to have this imprinted in their heads.\n\n\nThere are far too many who are primarily concerned with 'playing defense' i.e. covering every possible base, theoretical or not, to completely rule out any possible issue down the line even if that means progress grinds to a halt and whole departments sit around waiting for their output.\n\nIt's painful to intentionally put aside short-term or specialized quality in the name of meeting a larger goal. It's a game of tradeoffs -- which tasks will maximize the quality of your game? Sometimes, that means knowingly leaving problems in your code so that you can work on something else that will deliver more value.\n\nAbsolutely, but how painful it is really depends on what drives you in the first place. Is code a means to an end or the goal itself? I think a surprisingly large number of devs would answer the latter if they were honest.\n\nThat's not necessarily bad. There are plenty of industries and contexts where that mindset is *exactly* what is required. But most gamedev, and particularly the first 1/2 to 2/3rds of a project are rarely one of them in my experience.\n\npython says hello\n\nI certainly appreciate Python. If I use it as a scripting language, I feel that it is the most developer-friendly scripting language out there.\n\nBut I really find that it starts to buckle under its own weight when you start to build non-trivial software. Something as large as a video game? I would rather build that in a strongly, statically typed language like Java.\n\n&gt; Unfortunately, this falls under the #1 problem this article tries to address, and that is that what I want to be doing is working on my game. I'm not making games to have fun with the type system and figure out the best way to organize my struct to make the compiler happy.\n\nThis has basically been my experience with Rust. Yeah, I know deep down that if I worked harder, wrote my code better, just Did It Right then I'd get an awesome entirely stack-allocated and mostly bug-free program. But it would take me 10 hours to design around the language, to work around rust-analyzer's general jankiness.\n\nOr, I could just set Pyright to strict and write it in Python and have fun there.\n\nThink of the opportunity cost. Take a pick, make the rust compiler happy or... make a better, more fun game with extra time? Hard choice.\n\nI feel like the real heart of the issue is this doesn't strictly have to be a binary choice, but rust fights tooth and nail against letting you write any type of quick dirty prototype code at all, which means you never have an opportunity to quickly test something in a large monolithic project scope, and then solidify it later.\n\nThere's types of projects where you want 100% of your code to be perfectly tested/validated, but there's also types of projects where the % is lower for very good reasons, and most languages seem to want you to pick 100% or 0%\n\nI feel like Rust's thesis has been that you can have your cake and eat it too.\n\nAnd that a lot of work has been done making \"proper\" versions of dynamic code, in Rust and outside of Rust over the years. But Rust goes far in disabling the bad patterns, but not enough in providing good replacements for some. Or the ability to do some at all, that should be allowed.\n\nIdeally, with the right knowledge of it plus Rust guiding you towards it, it should be possible to have a good maintainable design that didn't take you all that long. But the ideal form isn't always there, and the \"ideal\" that's shared isn't ideal at all.\n\nSee but that's the thing - games are throwaway. You play test it, release it, fix the most glaring bugs users scream about, and then throw it away. People have moved on to more impressive games.\n\nComplete opposite for a lot of enterprise code - that shit is immortal. Spending some extra time up front to not end up with maintaining spaghettios forever is often well worth it. Totally different use cases.\n\nNo, bad games are throwaway. Great games will last for decades (maybe longer).\n\nYou can get similar safety with much simpler Java /.NET. The trade-off is some performance, but that's quite irrelevant for a large majority of enterprise projects.\n\nThis attitude is part of why most games are shit.\n\nComing from C# Python was an absolute nightmare until I discovered pyright has static type checking which is disabled by default for some reason?? Also, the fact that pyright is a proprietary product, and the language itself does not have an official type checker is wild. I genuinely don't understand how anyone can write a python program more than ~500 lines without a static type checker.\n\n[removed]\n\nAh I got mixed up, didn't realise pyright existed independent of pylance. I am talking about pylance in vs code yes.\n\nI like this flexibility you have in python. You can easily use type checking whenever you feel it's worth it, but you're not required to do so all the time.  \nI always use type annotations in all my \"serious code\", but recently I noticed that most of my scripts fall much below this 500 lines threshold. I'm using python almost as a calculator, to process data that I used to throw in a spreadsheet. Strict typing would make this use case too cumbersome and not so productive.\n\nI feel the same but with Go. I honestly love Go for trying things out very fast. Not long ago I had an idea for streaming torrents and I was able to create a mock up in Go in about 2-3 hours just to see if my idea worked and then was able to double back around and rewrite my project knowing that what I wanted to do would work.\n\nCan someone help me understand why you would want to even attempt game dev with Rust? Is this being done as a replacement for high performance code written in CPP?\n\nRust is excellent at handling complexity.¬†\n\n\n¬†If the design is kept (not thrown out) Rust is *very* high value since the software is more robust; your code is practically ship-ready when you have an alpha build.¬†\n\n\nSince rust is the only other big name in town that does native compilation (for speed) without garbage collection (for speed), its specs on paper makes an appealing case for game dev.\n\n\nThe author's key point is that the design is most frequently not kept. It's played and iterated frequently as the design is explored, as frequently as possible. Most code gets thrown out or refactored.\n\nShort answer: yes.\n\nSlightly more info: Rust gives you native code with no managed runtime (think JVM or .NET), excellent abstraction-building facilities (think C++), and compile-time guarantees of absence of memory-management bugs (dangling pointers, double-freeing) and data races (shared memory being mishandled by code running on different threads).\n\nAll of this is _extremely_ attractive to game (engine) developers.\n\nThe comments to the effect that there isn‚Äôt yet a _mature_ engine in Rust, and that getting there won‚Äôt be easy, are correct.\n\nWhat the critics who say you can just use something other than Rust are missing is: no, you can‚Äôt. Not without sacrificing those guarantees. And anyone who has tried to write an actually multithreaded renderer, to name just one example, are well aware of the difficulty of getting that right in C++.\n\nSo wanting to write an engine in Rust is _very_ well-motivated, but a distinct goal from wanting to write a _game_ in Rust. And one need only reflect on the difference between C++ and Blueprints in the Unreal Engine for an example of the scale of the difference.\n\nGames can be very complex. As with any very complex software type product, C++ is starting to put too much burden on the humans to be right 100% of the time, which they just won't consistently be. Rust takes a lot of the cognitive load off of the developer and puts it where it should be, on the compiler, while still providing the needed performance.\n\nThis is the reason in general for Rust's appeal. As someone who has worked on and written very large, complex system code bases, I want to spend my time working on the problem, not watching my own back. Both will require a lot of up front work, but the up front I do in Rust will pay back far more over time, because it's work explaining to the compiler exactly what I mean so it can make sure I always do what I intended.\n\n&gt;C++ is starting to put too much burden on the humans to be right 100% of the time, which they just won't consistently be.   \n     \nI'd argue that it's pretty much always been that way, and just got worse over time, not just because of the language itself, but also because industry changes.    \nI feel like the expected development time has gone down, while the demands for what a program does has gone way, way up, and a single developer is expected to have a far wider skillset.    \nAnd then there's the curse that is \"Agile\", where business types got a hold of it and turned it into \"Don't plan or document anything. Development only. Make a monetizable thing every sprint.\"\n\n'The community as a whole is overwhelmingly focused on tech, to the point where the \"game\" part of game development is secondary.'\n\nThis is almost every industry I've worked in (outside of game dev).\n\nIt‚Äôs not industries, it‚Äôs software engineers that act this way imo.\n\nThere is a very good reason to care deeply about code quality. Most of us aren't game developers and the products we write continually change. Changing a poorly written product is a nightmare and will eventually cause a loss of business.\n\nI can see how an indie game developer won't care all that much about code quality because they just need to ship something that sells and they're most likely not going to change that code again (apart from bug fixes).\n\nI‚Äôm not defending poor code quality. But a lot of software engineers think that the ‚Äúhighest quality‚Äù code is the cleverest, most compact, most generic, and most sophisticated code. Almost like they‚Äôre playing code golf. Personally I think the best code is code that‚Äôs easy to read and that flows intuitively.\n\nI think it's a mindset issue, mostly.\n\nAs far as I can see, people are not excited about Bevy because it allows them to make great games, but because:\n\n* Bevy somewhat challenges existing approaches to building a game engine. From going all-in on ECS and parallelism, to making everything swappable for custom implementations.\n* Bevy, therefore, promises a bright future: it makes people dream.\n\nOf course, this can be misunderstood, and someone looking at all this bubbling excitement and thinking it means Bevy is the best game engine available so far may end up quite disappointed.\n\nI mean, don't we all get excited when getting news of the NASA recovering Voyager 1, or running a rover on Mars? Same, same: bright dreams, even if not much day-to-day applicability.\n\nJust wanted to chime in to say that there is hot-reload for C++ in the form of Live++, which will hopefully soon support Rust as well.\n\n\nThat alone probably won't make you go back to Rust though :).\n\nGlobal mutable state is actually a pretty good paradigm for game development. Its still quite safe when used in the way the OP describes - where you have a global Audio object and you can just call `play(sound)` and the object takes care of all the underlying complexity for you. You can easily implement thread safety as well, by having these calls just push data to a concurrent queue for processing later at the appropriate time in the frame.\n\nThere's no reason to DI / IoC / interface / mock these kinds of things. Games run on a real computer that has 1 Sound Card, 1 GPU (in use), etc... you aren't going to swap out the implementation like it's some kind of enterprise software.\n\nYou don't even need a Singleton / Lazy static for these variables. These abstractions introduce overhead and again, the game needs these things to run, so just declaring them as standalone globals is a better choice, and with statically compiled executables the compiler can generate very efficient code in directly accessing globals at a known fixed location.\n\nThe other thing DI can buy you that _is_ useful for games imo is thread safety without needing to worry about external synchronization.  That's what my C++ engine uses it for - game/engine systems are just free functions whose arguments are processed at compile time and injected from resource scopes at runtime.  Behind the scenes, the scheduler guarantees that no two systems that access the same resources in an unsafe way are ever running concurrently, where you can define the rules around what is safe per resource type.\n\nI've enjoyed using that sort of paradigm a lot, especially combined with a fiber based job system for system-local parallelism when necessary.\n\nThe main reason to use DI in a context like that is for unit testing.\n\nI may not work in games, but I do work with single-threaded processes as much as I can.\n\nEven in single-threaded processes, global state comes with challenges. Or at least one challenge: re-entrancy.\n\nIt's mostly an issue when you start combining global state with callbacks, ie when changing something on global state can trigger an action, and that action will also access the global state. You can experience this without global state -- a cyclic graph of objects has the same issue -- but global state tends to make it easier to accidentally run into.\n\nThe main advantage of DI, here, is that it tends to make the issue apparent upfront.\n\n&gt; There's no reason to DI / IoC / interface / mock these kinds of things\n\nSure there is: testing.\n\nI notice you don't mention testing a single time in your post.\n\nGlobal variables make testing extremely challenging, that's why DI is preferred for this in modern development.\n\nYeah, that's inherently true. Try testing any feature that depends on system time without ability to control it.\n\nGlobal can be done in rust just fine too.¬†\n\n\nWe have mutexs, arc,.relock, etc with sane APIs.\n\n\nWe have lazy init too.\n\n\nGlobal singletons work just fine.\n\nLocking a mutex anytime you want to access game state is expensive. Not to mention opening yourself up to deadlocks. Rusts global singletons are not a free lunch.¬†\n\nNeither are they in other languages. In Java, making thread-safe singletons is  similarily hard.\n\nAre there any languages trying to be similar to Rust but with easier semantics?\n\nI was talking to a guy the other day who exclaimed that he thought everyone would be using \"whatever replaces Rust\". I think that'll depend on what people interpret as 'better than Rust' but for now all I can say for sure is that the idea has potential.\n\nMaybe OCaml? Since it's garbage collected and doesn't make you jump through hoops to fit into its idea of memory management. But it's not exactly the 'new thing', it's one of the languages that Rust was inspired by.\n\nEDIT: or maybe modern Pascal: https://castle-engine.io/\n\nI've found rust to be more pleasant to use, partially due to syntax and partially because back then ocaml didn't believe in threads. \n\nWriting `+.` to add floats sucks. Floating point operations are very common in gamedev or anything math related and since all common operators require extra frustrating typing(and making code ugly), it adds up.\n\nAnd god help you if you changed variable type from int to float for whatever reason, because ocaml wouldnt. Also converting types around is more convenient in rust: you use as/to/from. In ocaml there are functions with names as `inf_of_float`\n\nMaybe not similar, but I would say [Odin](https://odin-lang.org/) is one of the interesting contenders in the \"systems space\", especially with gamedev focus. It doesn't even attempt at any \"safety\", but it does fall under the \"what if modern systems language\".\n\nSwift has easy to use defaults with automatic copying and reference counting. It provides good ergonomics with reasonable performance. Then, for when you need it, the language provides more control over copying, borrowing, etc., with an ownership system inspired by Rust. This is still work in progress, though.\n\n[deleted]\n\nAgreed - I use rust personally and at work where it makes sense to. I like the language for many reasons, but I definitely would choose something else for game development\n\nis the phrase \"there's like 5 games made in rust, but 50 game engines\" still relevant?\n\nGreat article OP. The overall vibe of the article is pretty much exactly the kinds of reasons I tell people that if they can use a GC language (in terms of their performance, memory, etc) requirements, they should. I'm always shocked at how many folks genuinely think of Rust as a silver bullet, and don't think they're paying a price in productivity for having to deal with many things that GC would just handle for them automatically (I also see this in the C++ community, as funny as this probably seems outside of the C++ community), and the many higher level features that are more easily built on top of that GC chassis.\n\nAnd indeed, it seems like you were \\*mainly\\* comparing Rust to C#/Unity.\n\nI think where it gets more nuanced is when you start comparing to C++. C++ also lacks real reflection and built in support for hot-loading, C++ refactors can also end really badly; they just have different cost pattern. In Rust your refactor won't compile, even though 90% of the time it is \"actually fine\", but you'll have to spend a bit of time fixing it up regardless. In C++, you refactor and it compiles, and that 90% of the time you come out ahead, but 10% of the time you have a use-after-free or other UB and you will spend 10x longer tracking it down. So, there's a trade-off there and I'm not sure who's coming out ahead. Too early to say probably. I'd be curious to hear your thoughts on the more direct Rust/C++ head-to-head. Certainly for writing indie games I wouldn't be excited to use \\*either\\* of these languages, but there are some cases where it's the only real choice (e.g. high performance AAA game dev).\n\nBut definitely props to writing this out, and writing critically but with a level head. I like Rust a lot but I've also definitely experienced those moments where writing anything critical about it leads to an unpleasant conversation and I prefer to disengage, so good on you for going ahead with that. Criticism is an important part of every language's evolution!\n\nYou get reflection and hot-code reloading in C++ by using engines like Unreal, and tools like Live++ or Visual C++ hot reload.\n\nAnyone that is serious about Rust, also knows how to do their homework for static/dynamic analysis tools and IDE tooling on C++.\n\nIt's really confusing when Rust is not only a programming language, but also the name of a popular video game. \n\n\"Rust game development\" can definitely mean working on a video game titled \"Rust\" (in any language), and can also mean \"Developing a video game in the programming language Rust\"\n\nWhat if it means developing the video game Rust using the programming language Rust?\n\nFun story: I work at Oxide Computer. We, as you might imagine, write basically all of our software in Rust.\n\nOne weekend I set up a Rust server on our testing rack employees can use to kick the tires. It was a fun afternoon.\n\nHi Steve!\n\n/r/rust used to have a problem with that. Someone did a bit of machine learning to classify missubmitted posts: https://www.youtube.com/watch?v=lY10kTcM8ek\n\n[deleted]\n\nI love using Rust, it's the Rustaceans I try my best to avoid.\n\nOn the issue of 'why do I have to do this if my whole program is single threaded', I don't get the problem. \n\nIf the whole program is single threaded and you know for a fact that nothing will ever be accessed by more than one thread a time, then don't bother with runtime borrowing. Put the state in a global with a non-mutable interface and use interior mutability to do whatever you want.\n\nBut, if you are seeing multiple mutable runtime borrowing panics, then clearly you don't have such a situation and writing it in C++ where it doesn't have any such safety requirements would mean that you are clearly going to have things stepping on each other's toes, and those panics ARE telling you that that's what would have happened in a less safe language.\n\nYou would have to deal with this issue in any language, or you should do it. The primary difference is that C++ won't make you do it, it'll just let you change data behind the back of something else that thinks it has exclusive access to it.\n\nI obviously get that being forced to do the right thing is not convenient, that it takes longer, and so forth. If the argument is \"well I'd prefer it to be convenient for me more than provable correct\", then, yeh, maybe Rust isn't for you. But, that raises questions of liability to users of the product. Covering your own butt by proving that you used the best tools you could to deliver a safe product has something to be said for it.\n\nI believe Rust is good when you have a clear spec for your program and it is important for you to implement it without errors.  The thrust of the article is that just writing a perfectly correct program does not mean the program will be doing something useful.  \n\nTo write programs (like games) which succeed in the marketplace you will need to iterate on what the program is doing. The \"spec\" and the implementation must co-evolve. Seems like Rust is not the best language for that.\n\n&gt; \n&gt; But, if you are seeing multiple mutable runtime borrowing panics, then clearly you don't have such a situation and writing it in C++ where it doesn't have any such safety requirements would mean that you are clearly going to have things stepping on each other's toes, and those panics ARE telling you that that's what would have happened in a less safe language.\n\nI think we're talking about different things. Interior mutability doesn't prevent overlapping borrows. Global state with non-mutable interface and interior mutability is what the article was talking about (with `AtomicRefCell`), but the problem is that borrow checker rules prevent you from having multiple mutable references, even when you're not doing anything invalid.\n\nFor example, consider a global camera\n\n    static CAMERA: Lazy&lt;AtomicRefCell&lt;Camera&gt;&gt; = ...\n\nyou start your code with\n\n    let cam = CAMERA.borrow_mut();\n    // do things\n    player_system();\n\nand somewhere deep inside this wants to do screenshake, so it'll do `CAMERA.borrow_mut().screenshake();`, and you get a runtime crash.\n\nThis isn't a case of \"mutating a vector while you're iterating over it\", because what you might practically want is to just touch a field. You're not even necessarily touching the same data while it's being iterated, you just have a borrow.\n\nBut as explained here https://loglog.games/blog/leaving-rust-gamedev/#dynamic-borrow-checking-causes-unexpected-crashes-after-refactorings, you can't always do the \"shortest possible borrow\".\n\nwhy are you borrowing a mutable if you don‚Äôt intend to mutate it? I am not that familiar with rust but this seems like an easy thing to work around?\n\nDon't do that then? \n    \n\n    let cam = CAMERA.borrow_mut();\n    // do things\n    drop(cam);\n    player_system();\n\nOr better yet, put the logic that calls borrow_mut() into a function.\n\nYes this works for simple cases. Maybe you want the camera borrowed for a duration of something like an ECS query so that you don't have to re-borrow on every access, there's more than one reason why it's not always convenient to borrow things for the shortest possible time.\n\nThis is always a problem in real applications. Classic example is object/connection pooling in a server, where you have one chunk of code pops something out of the pool and call a function that also pulls an object from the pool (or worse, needs to start a transaction or something). You're going to be at risk of deadlock when the pool is empty and there's nothing you can do about it. \n\nA RefCell is essentially an object pool of size 1 that errors when you try and pull from it when it's empty. And just like an object pool, the solution is \"don't do that.\" \n\nAnd none of that has to do with Rust, you can have the same issue in any language.\n\nYou only have this problem if you're dealing with collections. The problem of `RefCell` is that it behaves like you describe even when you're just mutating fields.\n\nFor example in my case I might simply have `camera.shake_timer` and I want to do `camera.shake_timer += 0.2;`\n\nThat's not going to be a problem in any other language, because there's no memory being moved around, no collection that's changed while iterated, it's just two pointers to the same memory.\n\nYeah, in terms of memory safety, (safe) Rust's universal imposition of the \"exclusivity of mutable references\" rule is overkill. To prove it I implemented a statically-enforced essentially memory-safe subset of C++ that attempts to impose only the minimal restrictions necessary to achieve performant memory safety. (So some \"mutation exclusion\" on (the structure of) dynamic containers and dynamic owning pointers, but that's about it.)\n\nI wrote up a [preliminary article](https://github.com/duneroadrunner/misc/blob/master/202/3/10/memory%20safe%20C%2B%2B%20vs%20Rust%20language%20design%20limitations.md) comparing its language design limitations with Rust's, which includes a brief mention of some ergonomic challenges in Rust, though not nearly as comprehensively as your article does. But I have reservations about making (or having conviction in) strong statements about ergonomics without being able to express the issues explicitly and unambiguously, and why they are unavoidable. I have no problem doing this with respect to Rust's functionality/expressiveness and performance. It'd be nice to have concise examples that demonstrate the unavoidability of ergonomic issues (and how they exacerbate with scale).\n\nI'm a little curious about what motivated you to go with (and seemingly invest so much effort into) Rust over C# originally? Do you find any significant issues with C# in practice? Cross-platform support/consistency? Memory use? GC pauses? Code correctness? Performance?\n\nThat's why you do the things you want to do then¬†release the borrow,¬†it's no different to making sure to free memory or¬†not use after free. If you really know¬†it's single¬†threaded then just use unsafe lol, nobodys stopping you. The difference is¬†the guard rail existing for most development existing is great,¬†don't need it then get¬†rid of it.\n\n\n- Like the argue that borrows aren't free is insane, I use refcell borrows tens of thousands of times in a parser and it completes in milliseconds. Just borrow every time you're in the loop and call it a day or refactor your code. Also don't use atomicrefcell if you're single threaded just use regular refcell it's faster and you've already said you're not threaded.\n\nIf it‚Äôs single threaded why even use atomic? the first sentence in the docs says\n&gt; Implements a container type providing RefCell-like semantics for objects **shared across threads**.\n\nWell, you can use an unsafe cell and do anything you want internally, there's no enforcement of borrowing rules if you don't enforce them yourself.\n\nBut this is one of those can't have your cake and eat it, too things. You either prove to the compiler it's correct, or you depend on human vigilance, which is totally fallable when you are talking about stuff like this (i.e. different, completely separate code accessing the same stuff in an inter-mingled way.)\n\nI get why you would complain about it. But it is what it is. You can go back to C++ and just let those things interfere with each other in quantum mechanical ways over time, or go to a GC'd language, or prove to the Rust compiler it's right, or implement some queue and process for some of these things.\n\nOn the topic of \"you can't directly query components on entities\", its worth calling out that in Bevy you can absolutely query for \"whole entities\":\n\n    fn system(mut entities: Query&lt;EntityMut&gt;) {\n      let mut entity = entities.get_mut(ID).unwrap();\n      let mob = entity.get::&lt;Mob&gt;().unwrap();\n      let audio = entity.get::&lt;AudioSource&gt;().unwrap();\n    }\n\nHowever you will note that I *didn't* write `get_mut` for the multi-component case there because that would result in a borrow checker error :)\n\nThe \"fix\" (as mentioned in the article), is to do split queries:\n\n    fn system(mut mobs: Query&lt;&amp;mut Mob&gt;, audio_sources: Query&lt;&amp;AudioSource&gt;) {\n      let mut mob = mobs.get_mut(ID).unwrap();\n      let audio = audio_sources.get(ID).unwrap();\n    }\n\n  \nOr combined queries:\n\n    fn system(mut mobs: Query&lt;(&amp;mut Mob, &amp;AudioSource)&gt;) {\n      let (mut mob, audio) = mobs.get_mut(ID).unwrap();\n    }\n\nIn some contexts people might prefer this pattern (ex: when thinking about \"groups\" of entities instead of single specific entities). But in other contexts, it is totally understandable why this feels backwards.\n\nThere is a general consensus that Bevy should make the \"get arbitrary components from entities\" pattern easier to work with, and I agree. An \"easy\", low-hanging fruit Bevy improvement would be this:\n\n    fn system(mut entities: Query&lt;EntityMut&gt;) {\n      let mut entity = entities.get_mut(ID).unwrap();\n      let (mut mob, audio_source) = entity.components::&lt;(&amp;mut Mob, &amp;AudioSource)&gt;();\n    }\n\nThere is nothing in our current implementation preventing this, and we could probably implement this in about a day of work. It just (sadly) hasn't been done yet. When combined with the already-existing `many` and `many_mut` on queries this unlocks a solid chunk of the desired patterns:\n\n    fn system(mut entities: Query&lt;EntityMut&gt;) {\n      let [mut e1, mut e2] = entities.many_mut([MOB_ID, PLAYER_ID]);\n      let (mut mob, audio_source) = e1.components::&lt;(&amp;mut Mob, &amp;AudioSource)&gt;();\n      let (mut player, audio_source) = e2.components::&lt;(&amp;mut Player, &amp;AudioSource)&gt;();\n    }\n\nWhile unlocking a good chunk of patterns, it still requires you to babysit the lifetimes (you can't call many\\_mut more than once). For true \"screw it give me what I want when I want in safe code\", you need a context to track what has already been borrowed. For example, a \"bigger\" project would be to investigate \"entity garbage collection\" to enable even more dynamic patterns. Kae (a Rust gamedev community member) has working examples of this. A \"smaller\" project would be to add a context that tracks currently borrowed entities and prevents multiple mutable accesses.\n\nAdditionally, if you really don't care about safety (especially if you're at the point where you would prefer to move to an \"unsafe\" language that allows multiple mutable borrows), you always have the `get_unchecked` escape hatch in Bevy:\n\n    unsafe {\n        let mut e1 = entities.get_unchecked(id1).unwrap();\n        let mut e2 = entities.get_unchecked(id2).unwrap();\n        let mut mob1 = e1.get_mut::&lt;Mob&gt;().unwrap();\n        let mut mob2 = e2.get_mut::&lt;Mob&gt;().unwrap();\n    }\n\nIn the context of \"screw it let me do what I want\" gamedev, I see no issues with doing this. And when done in the larger context of a \"safe\" codebase, you can sort of have your cake and eat it too.\n\nThis is actually something I hit quite a bit when writing editor tools for my game in just the past week.\n\nI have a `&amp;mut World` but getting two components from it at once is annoying.\n\n `components::&lt;&gt;()` would help greatly!\n\nRust is fantastic for game _engine_ development.\n\nRust is terrible for developing the parts of a game that don't need to be fast, then again so is C++. For that I would use a scripting language, especially for an indie game where developer time is much more valuable than CPU cycles. One of the good things about Rust is that it's probably the best language around for bridging to other languges.\n\nC++ is not too bad for iterating quickly.\n\nIt's not as bad as Rust, but C++ is far from the peak productivity that could be achieved. As mentioned in the article you really want a language that has good support for hot reloading so you can get instant feedback on changes, and that's definitely not C++.\n\nVisual Studio supports hot reloading in C++, though I have never tried it so I don't know how well it works.\n\nI agree though that C++ is not the best language for rapid iteration. Somewhat better than Rust, but not great.\n\nUnreal also has blueprinting to try and get around some of these problems.  It seems fairly common to have your designers prototype in blueprint and if the feature gets the greenlight then engineers will make it more correct in C++.\n\n&gt; Rust is fantastic for game engine development.\n\nI can understand the line of thought, but is it _actually_ good for game engine development? AFAIK, there aren't any usable Rust game engines that let you write gameplay logic in a scripting language. I suspect that this is because there is a bad impedance mismatch between Rust's memory landscape and any garbage-collected scripting language you would use. I think it's much harder than it looks to empower an embedded scripting language to actually mutate the state of a Rust game engine.\n\nRust is not built for bridging to other languages. It's FFI is almost completely done through C abi.\n\nso... the same thing every other system programming language has? lol\n\nIf it's the same as every other systems programming language it doesn't make it the \"best\"\n\nThe language and compilation is [highly extensible](https://doc.rust-lang.org/reference/procedural-macros.html) and it makes bridging very easy. Other languages require code generation to do what Rust can do using macros.\n\nCheck out for instance [NAPI](https://napi.rs/) which bridges to v8. You just add `#[napi]` macro to a function and the compiler automatically generates everything necessary to expose that to v8, including marshalling between the different data models and error handling:\n\n    // Rust\n    #[napi]\n    fn square(x: u32) -&gt; u32 {\n      x * x\n    }\n\n    // JS\n    const { square } = require('./index')\n    square(69)\n\nThe equivalent in C++ is _much_ uglier and requires a lot more manual intervention.\n\nSimilar feats are possible for other VMs, although napi currently has the best implementation of it.\n\nI think there used to be definitely some cargo cultish behaviour around Rust because they are gaslighting and ignoring the concerns of op on the rust related subReddits while we have a much more balanced discussion here. I‚Äôm not a rust programmer but have been interested in it for the last 3-4 years and have been following developments in it on social media and all its drama.\n\nI love Rust as a language a lot, but yeah, gamedev is one of... a few spheres where the language's philosophy just makes it terrible to work with. Which is tragic, but it shows once again that some tools are better for some purposes than others\n\nThe simple answer is Fortran‚Ä¶\n\nGlad such an article exists.  \n  \nI usually 'try' a new language rather than 'learn' it. What I mean is, pick up a simple or semi-simple library/tool and try to augment it to my needs. And start learning the language as I go.\n\nI realized after going at it for days that it was impossible to modify the rust tool I was interested in without major refactors. What seemed like one line change if it was any other language, seemed like hell.\n\nLike it doesn't let you easily focus on chunks of logic without understanding all parent or past logic leading up to it.\n\nSadly I couldn't read it all!!   However I'm not surprised at all that through extended use people will find that Rust sucks a massive amount.    It sort of reminds me of the early days of C++, where one idiot after another would climb on the hype bandwagon but eventually fall off as the development jerked along.   It took a long time for C++ to become usable and then they just keep adding to it so that it is now a massive kludge of ideas.   Rust on the other hand doesn't have the usability of C that C++ started with, Rust is a strange bird that doesn't fly straight.   If the features of the language result in a slow down in the development process, which is what happens with Rust I don't see a good ending for the language.\n\nI think if most of the Rust advocates where honest with themselves they would be looking at other languages to transition too.   Apples Swift is remarkably better as a language for example and then we have Mojo which is coming along and very similar to Python.   I really don't see the point in Rust when we already have C++, if you want a difficult language to work with.\n\nWord üíØ \n\nC and C++ are everywhere as far as systems programming.\n\nRust devs are like vegan soy boys, they know that borrow checker add a lot of friction and it's not a silver bullet, yet, lotta Rust zealots think Rust should be used for everything.\n\nIn the latest Ada meetup it was discussed how good Ada is for game development. I have little idea on games dev myself but a couple of users contested that Ada is great for games. One user said Ada met almost all the criteria that the CEO of Unity or Unreal engine (I forget which one) desired if a game focussed language was to be developed. I'm not sure it has hot reload but it certainly has fast compilation. The Ada user also said he doubts the CEO would have even considered looking at Ada.\n\nTsoding enjoyed making a game in Ada in just 20 days but binding to raylib in C.\n\nhttps://youtu.be/MUISz2qA640?si=zgQvZzkGo-Lo0UGO\n\nAnyone who thinks Ada is a good candidate for game development compared to Verse understands neither Ada nor Verse.\n\nNice read, but assumes a bit much for me to follow.\n\nWhat is ECS and what are arenas?\n\nECS is [Entity Component System](https://en.wikipedia.org/wiki/Entity_component_system), which is a design pattern used in games for managing memory and composition. Arena is basically a vector into which you \"allocate\". This allows you to have objects neatly next to each other in memory, rather than floating around on the heap.\n\nI don't know enough Rust to understand the technical side of this. Buy I love the article. Nothing like a great brain dump! Thanks for the insight!\n\nThe tone of this article is almost vindictive at times. It seems to be written out of a lot of frustration. I can't comment on large-scale game development in Rust. I haven't done it. I _have_ done large-scale application development however, and I take serious issue with statements like:\n\n&gt; Making a fun &amp; interesting games is about rapid prototyping and iteration, Rust's values are everything but that\n\nI have never developed in large-scale codebases faster than with Rust. Of course the author has their own opinions and plenty of experience, but I often see this notion spread by people who have little or no experience in Rust at all. It's a little frustrating to see this repeated in a post that has a lot of valid points. It makes the whole things feel a little _charged_ to me.\n\n&gt; But it's especially sad for a language that aims to be so fast and optimal to have to resolve to wasting cycles on re-allocating memory more often than one would like, just to stay productive.\n\nThis might be one of the real problems for the author. If you balk at something as trivial as this, I can see how you'd have lots of problems with iteration speed in Rust.\n\nLater, in reference to the awareness of Rust gamedev being nascent:\n\n&gt; I would say that the outside world has a very different view though, and I will attribute this to very good marketing on the side of Bevy and a few others.\n\nI think I'm starting to understand. It seems like the author got into Rust, got very excited about the language, and started trying to make indie games in the budding and exciting ecosystem.\n\nIn the case of Bevy, however, it clearly, _obviously_ presents itself as an incomplete engine. It's not 1.0. It has no proper, official docs. Breaking changes are pushed every three months. [They recommend you use Godot right in the introduction.](https://bevyengine.org/learn/quick-start/introduction/) The way the author presents this bit feels really disingenuous.\n\nI think the thing people should take away from this article is not that Rust is fundamentally bad for game development. (Many of the arguments against Rust here could be used against C++ after all, and there's plenty of C++ engines!) Rust just isn't ready, yet. And maybe it never will be! But things like UI, ergonomics, and the overall ecosystem are moving in an exciting direction, and I don't see that stopping any time soon.\n\nI'd say check back in a couple years and see where things are at.\n\n\"Written out of frustration\".    \n\nOP spent 3 years, i'd say they've earned the right to their frustration\n\nC++ devs can use well developed things like stl or even monsters like boost if they must. Those where created and maintained by well paid C++ gods. I worked in projects where we used minimal C++11 for performance reasons, it worked like a charm and the code looked like Java. So I hear all the time from reasonable Rust devs that they are there partly and will be there somewhen.\n\nIn another discussion, five threads to the left, I hear that those \"situations\" or \"concepts\" are rarely a problem in real programming tasks and people just don't get it. So in a way its C vs Python or C++ vs Java all over again.\n\nEvery time I see an article criticizing rust, I hear the same thing.  \"Rust isn't quite ready yet, come back later\". \n\nRust was announced in 2010, released in 2015.  How many years of development does it still need until us mere mortals can use it, rather than devotees?\n\n&gt;How many years of development does it still need until us mere mortals can use it, rather than devotees?\n\nFrom the outside looking in, it seems most of the \"mere mortals\" are looking for their current ecosystems to be completely available in Rust equivalents before adopting it. It's something I've noticed in a lot of \"new\" things.\n\nIt seems like for the \"masses\", they expect a new language, framework, application, or business to be able to completely replace the old immediately which is just unfeasible. \n\nI think Rust is in the stage where a lot of core people who are willing (and able) to contribute have to produce the libraries and frameworks to make it appealing to the broader user base.\n\nI doubt Python would have become nearly as popular without its ecosystem (ex. Numpy, Django, Pandas, etc.).\n\nAll very good points.\n\nI guess I'm not really the target audience here.  I'm an applications programmer, I've always worked in OO languages, and on top of that, I'm actively moving towards management rather than specializing in actual development. \n\nI think that's something I haven't personally taken in to account.  Rust isn't the kind of language that I would use.\n\nIt depends on the domain. For many things it's top-notch in its current state!\n\nThe primary sticking points I generally see are `async`, native UI, embedded ecosystems and, as we see here, game engines.\n\nThe development of Rust can be slow at times, especially when the best way forward isn't clear. Each of these are really quite challenging in their own way, either because of how they integrate with Rust as a whole or because Rust itself makes them challenging.\n\nI don't think there's anything wrong with this, personally. Rust doesn't need to be used everywhere by every team. (It won't stop me from trying, but it's good to be aware of what you're getting into if you deal in these areas!)\n\nTrue enough.  Different languages are good at different things.\n\nI'd never try to write an OS in java for example, but it makes a pretty solid real-time system.\n\nEmbedded has got significantly better in the last 2 years.\n\nRust definitely has some catching up to do with UI things but I think that's to be expected.  C/C++ have had UI libraries for decades before rust even existed.\n\nThis is my take as well. The embedded ecosystem feels _so close_ to being ready for what I need for work.\n\nI think Rust is in a different enough world from C++ (when UI solutions arose for the latter) that I'm really not surprised it's been slow going. Cross-platform, performant, and ergonomic UI is not easy to make in any language, and that domain has been dominated recently by web technologies anyway (I'm doing it myself!).\n\nAfter years of the UI ecosystem working itself out, I think we'll end up with an astoundingly good solution that rises to the top. Or it'll just never happen at all! Who can say.\n\n&gt; But things like UI, ergonomics, and the overall ecosystem are moving in an exciting direction, and I don't see that stopping any time soon.\n\nDelusional commentary.\n\nIs it hard to use Reference Counted objects in Rust?  I know that C++ can make reference-counted objects very easy to use through use of destructors.  Then C# just makes everything garbage collected so that reference counting doesn't matter anymore (except for disposable objects that might be shared), aside from the GC stopping the world to clean up garbage periodically.\n\nActually reference counting easy, and made easier by the fact that Rust knows if data is being accessed across threads or not, so it supports a non-atomic reference counter (RC) that has very low overhead that you can use for single threaded data.\n\nEven with reference counted objects you still have aliasing rules. When you use `Rc&lt;RefCell&lt;T&gt;&gt;` you end up having to do `.borrow/.borrow_mut()` to get what's in the refcell, which will perform runtime borrow checking.\n\nThis is fine, except for the points where two parts of the code want to borrow the same object at the same time. Which can unfortunately arise _very_ easily if you do something like\n    \n    let thing = x.borrow_mut();\n    \n    for mob in world.query::&lt;Mob&gt;() {\n        // maybe we need to do something for every mob,\n        // and borrowing at the top of the loop makes things faster\n        thing.f(mob);\n\n        // if mob had shared ownership of x and tries to borrow it,\n        // you get a runtime crash\n        update_mob(mob);\n    }\n\nThe thing is, just because one is using `RefCell&lt;T&gt;` to get interior mutability and \"disable the borrow checker\" with internal unsafe, it doesn't mean the rules still don't have to hold. You still can't ever have two mutable references, and the implementation has to ensure that to be the case at all times. Which means it will dynamically crash if you break the rules.\n\nThis potentially saves some bugs, but also crashes on what would otherwise be totally valid code in other languages.\n\nRust is designed for interviews, not for gamedev)"
  },
  {
    "title": "My snake game is now 58 bytes thanks to an idea I once had",
    "body": "5 months ago I had the idea of simplifying the branching tree by using the carry flag from operations in the next pre-branching instruction instead of branching twice ([#40](https://github.com/donno2048/snake/pull/40)).\n\nSounds simple enough, but it turns out to be more complicated than it seems at first, and that's why I abandoned it then.\n\nHowever, this week I for some reason looked at the code again and thought about the exact same approach ([#62](https://github.com/donno2048/snake/issues/62)).\n\nAfter a lot of trial and error, I managed to get it working and to reduce two bytes ([#63](https://github.com/donno2048/snake/pull/63)).",
    "score": 1535,
    "url": "",
    "created_utc": 1713003343.0,
    "author": "Perfect-Highlight964",
    "permalink": "/r/programming/comments/1c2ym57/my_snake_game_is_now_58_bytes_thanks_to_an_idea_i/",
    "all_comment_text": "Dang... I only have 57 bytes of free space left... Guess it's time to upgrade my phone.\n\nLook at this guy with his x86 DOS phone!\n\n/s\n\nThat would actually be a very nice thing.\n\nNeeds a better keyboard though. I had to SSH from my phone a couple times and it was a pretty terrible experience with the standard keyboard that focuses just on a-z and is oriented toward autocomplete rather than tab completion.\n\nThe SSH app I use (juice SSH) overlays its own keyboard at the top of gboard with common keys used by SSH (modifier keys, tab etc).\n\nI‚Äôm just a middle aged programmer that misses the good old days of dos.\n\ncheck out Unexpected Keyboard\n\nAdded bonus of this is nobody else can use your phone because the keyboard is \"too cluttered\"\n\nMy son says it's \"weird\", and doesn't like that swipe doesn't work on it.\n\nIntel did work with Asus to release phones with x86 chips about a decade ago, the original zen phones and a sequel or two. You might actually be able to natively run dos on those bad boys\n\nHmm. I didn‚Äôt know about that. Thanks.\n\nNokia 9000 and 9110 communicator phones are i386 and i486 if you're interested in retro.\n\nThanks.\n\n8080 DOS phone\n\nlmao\n\nOk I think you are wasting your talents here.  I think you might be able to take a few bytes off of Ff7 rebirth and my ps5 would thank you.\n\nMost of that is going to be resources, textures, sounds, models, etc. They can be compressed but you're still going to need ram/disk to store the decompress versions and loading is going to take longer.\n\nThat's mostly true for compression but you could also optimize the assets and actually reduce the loading time (which is harder to do).\n\n\nAlthough compression will probably be better at those orders of magnitude...\n\nThe demo scene had .kkrieger, a 96KB large game that would need ~300 MB if its assets where uncompressed. I think it stored the operations used to create the assets instead of the raw pixel/geometry data, so starting it was probably not as fast as it could have been.\n\nFun fact, they released a version where you couldn't look up. The reason? They used an analyzer that checked which codepaths were run while playing, pruning anything unused, and in doing so forgot to actually look up! At least so the story goes as told by my co-workers who were into the scene\n\nPlease make OP work COD mobile everytime I open that shit it asks for 2GB update and takes 23 GB on my phone. üò≠\n\nI know a way to optimize it down to 0 bytes\n\nWith this level of assembly knowledge they can probably get a job at an HFT shop optimizing their C code.\n\nDos CPUs were easier.\n\nWasted talent\n\n/r/yourcommentbutshorter\n\nWhen you are done with this. I had an idea called qr code gaming. Make a website framework where the game bytes are included in the URL. Then makers would only need to share the URL/QR code and your site will play it\n\nThat's actually a very interesting idea!\n\nEDIT: Moved to [https://g01f.eu](https://g01f.eu)\n\nI decided to go ahead and set up something like that for javascript code: [https://troido.nl/u/](https://troido.nl/u/)\n\nWould a website even be necessary?\n\nwdym? In order to share the game as a URL you'll need a website, and if you're not using one you'll have to download an emulator\n\nI think you might be forgetting about data URIs\n\nedit: idk why I zoned on the emulator bit but I guess if you had a data URI that contained an HTML document you could just link to the script for the emulator lol. Still a lot of bytes though\n\nA data URI that contains an HTML document? At that point not making a website is just criminal\n\nThoughts on a mobile app equivalent?\n\n\n¬†\"Scan this code to play this game\"¬†\n\n\nDepending on the size of the game and code you could probably have a link at the start to prompt to download the emulation app\n\nMake it an API call, put request....\n\nWhy stop with just the game code? Write a simple backend that reads a query param, and returns its value as an HTML response. Now you can embed an entire webpage, including any javascript, directly in the URL!\n\nWe‚Äôve had that forever, it‚Äôs called an xss attack‚Ä¶\n\nI know, that was the joke...\n\nYou could sign the urls to contravent that\n\nStill, what would prevent someone from, for example, making a script with a URL source that he controls, and after getting the URL signed just changing it?\n\n[deleted]\n\n&gt; Changing the URL would invalidate the signature. \n\nThe attacker won't change the URL, he will own the site the URL points to and change its content, which won't invalidate the URL...\n\nBut has anyone monetized it?\n\nEDIT: I made a prototype for Javascript: [https://troido.nl/u/](https://troido.nl/u/). The bytecode language will have to wait.\n\nEDIT EDIT: Moved to [https://g01f.eu](https://g01f.eu)\n\nI've been thinking about setting up something like that too. To be efficient you'd probably have to make some sort of bytecode language (or a language using only url-safe characters) optimized for code golfing. I'm currently working on some other projects but if anyone is building this I'd like to join.\n\nAlso, check out my 218 byte (html+js) minesweeper: [https://tilde.town/~troido/minisweeper.html](https://tilde.town/~troido/minisweeper.html)\n\nbro\n\nhttps://troido.nl/u/?s=&amp;e=#d2luZG93LmxvY2F0aW9uPSJodHRwczovL2RldmVsb3Blci5tb3ppbGxhLm9yZy9lbi1VUy9kb2NzL1dlYi9KYXZhU2NyaXB0L1JlZmVyZW5jZS9HbG9iYWxfT2JqZWN0cy9ldmFsI25ldmVyX3VzZV9kaXJlY3RfZXZhbCEiOw==\n\nRunning arbitrary code is kind of the point of the project. There is nothing of importance on the page that could be at risk of XSS and any website you visit could run some random JS.\n\nIt may be than other ways of running javascript, but this is still a prototype. It's fast enough for what I've tried with it\n\nYou don't want them to be able to put another URL somewhere on the page, it would accidentally get clicked. You also done want xhr requests to be possible\n\nI think the real concern is that people become accustomed to playing games on the site and one person uses javascript to use the site as an url shortener for phishing.\n\nWould that avoid having to get assets from a server? Like would the whole game be able to be saved in a qr code? And the only downside would be the decoding time I guess?\n\nThe site can have it's own assets. There would need to be some sort of vm, and it decodes the URL to run the game. For security, there should be no way for the vm to manipulate the site in such a way to make a URL and embed it somewhere or make xhr requests itself. Difficult challenge for sure.\n\nI have some spare time today and tomorrow, can I steal this idea and implement it for DOS (with credit of course)?\n\nSo like sharing a url but way more restricted. Why?¬†\n\nNot sure what you mean by restricted, but initially the website would just have a canvas and enough JavaScript to parse the URL and begin execution. But later it could include a graphics library the game bytes could execute those gl \"sys\" calls\n\nYeah but why?¬†\n\nWhy do anything? What do you mean why lol. It's in the same vain as the OPs game being 58 bytes. But now everyone can participate. Developers can get it to work locally, run a generate step, and his website/framework can play the game..\n\nOh sure, that's cool I guess. That's what I mean by why üôÇ\n\nHave you ever tried doing anything \"for the lulz\"?\n\nhis username suggests he has. not sure why he's harshing OP's buzz.\n\nI love that this has become a saga. Keep up the great work!\n\nThanks!\n\nI keep wondering what is the lower bound of bytes for a snake game. It most probably is higher than 1, now I'm not so sure about 2.\n\nPretty sure SNAKGAM is an instruction on VAX.\n\nnot sure if it is intentional or not but the online demo doesn't work for me. It just jumps a cursor all over the screen in random positions\n\nJust press an arrow key and it should work.\n\nThe random jumping cursor is initialization of the map.\n\nah, so it wont work on mobile properly then I guess.\n\nYou can swipe too\n\nTried it! It works :D However, if I swipe the opposite direction of where I'm going the snake crashes into itself and dies, except for when it's two A's long (beginning). It happened a lot when I wanted to, for example, rapidly go down and left, it doesn't register my down swipe, but registers my left swipe and the snake does a 180 and dies by crashing into itself, it seems.\n\nSmall sacrifice in usability for the sake of bytes\n\nIt works on mobile, I just did it. You just have to swipe to start it.\n\nLooks like it simply doesn't like basic edge cases‚Äîwhich I say is fine, if the goal is a small binary above all else. It mostly works for me if you only touch the arrow keys. Mine jumped all over until I pressed an arrow key. It also jumps all over again when you die (or at least when you hit the edge of the play area). Hitting an arrow key made it work again.\n\n&gt; Looks like it simply doesn't like basic edge cases‚Äîwhich I say is fine\n\nI dunno. Often \"edge cases\" can be reasoned for as regular things a game would need.\n\nThis, of course, then begets the question what IS a snakes game? If he'd call it a \"snakes-like game\" then people could not object, but IF it is a \"snakes game\" then it really also needs to support everything the \"default\" snakes game would support as-is (IF there is a \"default\" snakes game, but usually it is the first well-known game that fits the description).\n\nI mean, it does everything a snake game is supposed to do, the initial buffering doesn't affect the game and you can think of it as kind of an opening screen before you press a key.\n\nIt's almost like this (really impressive) project is meant as a challenge rather than a perfect game.\n\nInsane - what did you do?\n\nYou can look at the PR, I think I managed to make it quite self-explanatory if you read the comments\n\nI can assure you it isn‚Äôt üòÜ But well done, this is a solid achievement. You seem qualified for writing moon landing code on punch cards\n\nIt seems like many people agree that I didn't do a good job writing the comments as I thought üòÖ\n\nThe idea is that instead of asking whether we hit a wall and then whether we hit the snake itself or the food we use subtract the size of the screen from the current location which will set the CF only if we hit a vertical edge and use that value **without branching** to change the result of the check of whether we hit the snake such that if either of them if true we will reset the game so if both are false but we hit a food character the ZF will be set.\n\nMaybe I'm stupid but I still don't understand.\n\nOkay, every time you write an `if` clause in your code what the compiler actually does (this is oversimplified because I can't fit all the details of branching compilation into one comment) is it takes the expression you put inside the `if`, runs it, and then checks a certain flag (for example, if you check whether the output of a function is zero it will run the function then check the zero flag ZF) and if the flag is not set it'll jump over the clause.\n\nAnother key idea is that when you add some value to another there is a flag called the carry flag (CF) that's set only if an overflow has occurred so if you want for example to add two 32-bit numbers on a 16-bit CPU you could do an `add` to the lower parts of the numbers and then (just like long addition) `adc` (add with carry) to the high part.\n\nNow, what I'm doing you can think of as (again oversimplifying) writing an empty `if` clause just to set the CF and then do an `adc` so what it means is we can write just one if clause for both the `if`s and we just need to account for the change in the output based on whether the last `if` should have been executed.\n\nMaybe I'm stupid but I still don't understand\n\nWhat don't you understand? I can try to explain but It'll just waste a lot of your time (and mine too) if I'll just try to simplify the entire explanation instead of the specific part you don't get.\n\nI think that last \"I don't get it\" was a bit disingenuous lol.\n\nYeah I know, but for the one percent that I could help someone understand it, it is worth it to not ignore the comment.\n\n[deleted]\n\nHonest question, I mean no offense. Do you have a basic idea of how registers and flags work in a CPU?\n\nYou‚Äôre doing a great job it‚Äôs just many devs don‚Äôt have a lot of asm/mc experience so there‚Äôs a learning curve to understand the different processor flags and their impact on instructions.\n\nThanks\n\nI think it would be good to have a version changelog / dev blog on the github page as would be cool to see short explanations of all the little tricks you've used to shave bytes off here and there.\n\nI don't think there's a big audience for it.\n\nI also tried writing a non-so-technical piece about it that got little to no attention and took a pretty long time...\n\nMiddle manager?\n\nSoftware developer, I love reading those kinds of extreme programming stories!\n\n&gt;It seems like many people agree that I didn't do a good job writing the comments as I thought¬†\n\n\nif I had a nickel for every time I told myself this I could retire. And usually the \"many people\" includes myself 4 months later\n\nIt‚Äôs not your comments, it‚Äôs more this is several layers beyond my understanding. Thanks for your other explanations below, they are super\n\nThanks!\n\n&gt;Thanks!\n\nYou're welcome!\n\n&gt;  I didn't do a good job writing the comments as I thought\n\nI am neutral here, did not upvote or downvote you, so I can not comment on that part. BUT, on the general part: many programmers who think they wrote good documentation, often do not realise that their documentation is STILL really bad. In general the more high quality documentation the better. I much prefer FAQ + small examples, whereas others focus only or primarily on the API. So projects that offer both, are, to me, much superior. You kind of have to treat documentation on equal level with the code, as annoying as it is, as usually people write code first, then they are tired, and stop before writing the documentation, let's be honest here. At the least for unpaid work aka open source (well, usually it is unpaid e. g. no external funding; of course some open source projects are funded, but most are not).\n\nI think you are vastly overestimating how much people in this sub know about x86\n\nThis is very neat. It would make a good example project to help teach the ins and outs of assembly. Any chance you write a blog post?\n\nSadly, I don't think many people will actually read it...\n\nI might.\n\nThis reminds of when I was a kid writing games for the 1K ZX81\n\nAre you ever going to improve it by getting it back to 69?\n\nhttp://www.jargon.net/jargonfile/b/bum.html\n\ngoogle chrome should hire this guy!\n\nWhy would they chrome is a bloated pile on purpose\n\nHave you ever tried gas optimisation? You seem like you'd do really well with it and it pays really well: https://www.rareskills.io/post/gas-optimization\n\nI'll check it out, thanks!\n\nI've been following the whole journey and it's impressive! but I'm here to break stuff..\n\nThank you for following along\n\nLove following these posts! So cool!\n\nThanks!\n\nDiabolical. The funniest/most surprising thing about this project is that you have third party contributors lol.\n\nI'm not sure I understand, it's open source, and for some reason got pretty popular, and there are a lot of bright people out there. It makes sense someone will contribute to the project...\n\nYes of course. I just think it‚Äôs cool that it *did* get  popular enough for other people to spend time thinking hard about it. Gotta admit it‚Äôs an odd, unique project, in the best way!\n\nThen I agree, I didn't think it'd get that popular\n\nYou should be able to run this on a quantum computer now!\n\nI once wrote a web version. I think it was a little over 1.5mb after webpack.\n\nYou are still going on with this, I saw your youtube video a long time ago.\n\nI think you're confusing me with MattKC\n\nSo you guy are different people, sorry for the mistake.\n\n[deleted]\n\nIt can't because the bytes of the `mov` are being used to initialize `ds`\n\nI am writing my own snake game in Arduino and using 196 AdaFruit Neo LEDs to have 14x14 game area on 20 breadboards. The game logic is a few kb, which I thought was quite good already, but this smoked my attempts. In case you want to check it out (it is not fully done and I don't have good videos of it up yet)\nhttps://github.com/TheTask/Snake-on-breadboards/\n\nThis is super impressive. Great job! Honestly this should be a neat project on a resume.\n\nThanks!\n\nDamn man that's cool, I saw your last post some time ago.\n\nThanks!\n\nMy snake game is bigger, but really, what matters is the motion of the ocean.\n\nIn the demo there seems to be a rather high chance of food not appearing when the snake spawns\n\n◊ú◊ê ◊ê◊û◊®◊™ ◊©◊û◊™◊û◊ò◊ô◊™ ◊î◊õ◊ô ◊ß◊¶◊™ ◊©◊ê◊§◊©◊® ◊ñ◊î 59?\n\n:(\n\nFeel you bro, I think I‚Äôll just forget CS and start tilling the soil for a living.\n\nThis is insane, congratulations!\nIs there any video/podcast going into the main ideas?\n\nNot that I know of...\n\nI‚Äôm sorry"
  },
  {
    "title": "JetBrains Makes Rider and WebStorm Free for Non-Commercial Use ‚Äì A Game-Changer for Web Devs!",
    "body": "",
    "score": 1528,
    "url": "",
    "created_utc": 1729779164.0,
    "author": "chriswoodruff",
    "permalink": "/r/programming/comments/1gb3l0c/jetbrains_makes_rider_and_webstorm_free_for/",
    "all_comment_text": "Nice, so Linux finally has a good alternative to VSCode when it comes to developing C#. :)\n\nI know that Microsoft has been angling for .NET development across all platforms, but I can't imagine having to rely on VSCode for C# development. I haven't used Rider since it first came out, but I had a pretty common workflow back then of creating a new project using Visual Studio, and then working on it in Rider. Even then, Rider couldn't cope with some of our legacy C# projects (dating back to 2009), and it literally ate up all of my machine's resources overnight trying to index the damn thing, just for it to spit out &gt;100k errors related to an antiquated code generation system that had to be kicked off manually, or w/e.\n\nVSCode was a snappier editor to use, obviously, but it would regularly cause me more grief than it solved because of the old solution file approach (XML tree representing the relational structure of the code, rather than the simplified file system approach used by .NET Core today)\n\nRider is very good for C# development now.\n\nWe prefer it to Visual Studio, but I think that's a momentum thing, as both are good.\n\nI come from using VS for years and years over to Rider relatively recently, and there's some crucial stuff that VS does a lot better.\n\nDebugging async code. If an exception is thrown in async code in Rider the debugger is almost completely useless. In Visual Studio it breaks where you would expect it to, but in Rider it breaks on the awaited task, which is useless. I think this is actually a very serious downside to Rider compared to VS because debugging async code, which is most code today, is very time consuming in Rider compared to Visual Studio.\n\nVisual Studio's auto complete is much better than Rider's, even without copilot. Rider will mostly suggest stuff that's just plain wrong and often doesn't even compile. I don't think I've ever seen VS suggest code that doesn't compile. Rider also ends up formatting it weird.\n\nThe continuous testing from dotCover uses a very poor indication of code coverage. First of all the colors are extremely subtle and the markings are very thin. First time I used it the colors were so muted I almost wondered if I had even enabled it. In addition the indications are red/green/gray horizontal line in the margin. Because the colors are so muted at first glance it's hard to distinguish either green or red from gray. In addition most people with a color impairment struggle to separate green from red. Visual Studio Enterprise (which is what you need for this feature in VS) uses a symbol (cross/checkmark/minus) to show coverage which I think Rider should do as well.\n\nRider is also very slow to start, and it uses more memory. It will show the IDE quickly but it can take some time before it's actually usable.\n\nWe've standardized on Rider in our company and we're satisfied with that decision, but there's definitely still important stuff that Visual Studio does much better than Rider.\n\nWe have licenses to both Visual Studio and Rider, for their differences. Sometimes one does stuff the other doesn't.\n\nI've never had Rider suggest code that doesn't compile, but we're probably doing different things or I've been lucky.\n\nI've been using Visual Studio the past couple of days to do some tedious work and it's autocomplete / auto suggestion doesn't even function half the time.\n\nIt's not even making a suggestion to tab complete `();` to a function call, e.g. I typed `myObject.Dispose` and half the time it auto suggests `Dispose` (press tab), and then half the time it doesn't even auto suggest the function parens.\n\nWhen it does work in Visual Studio, it's also has created code that doesn't compile. E.g. it added a duplicated function name to a unit test class.\n\nLast time I use rider it was missing some code scaffolding options which VS has ... has this improved\n\nI love Rider. I'm not sure if it's the case for everyone, or just bc of the license server we use at work, but I haaaate that it just won't open if I'm offline\n\nIt opens for me when I'm offline...\n\nOur company buys the licenses for each of us and it's tied to my account with JetBrains.\n\nI have to log in from a Rider pop up when I open it, to renew the license periodically.\n\nI have long since abandoned Visual Studio for Rider - and it is infinitely nicer to use.\n\nI can't speak to your own legacy stuff, but it works fine for all of our legacy projects from at least back in dotnet framework 4.5 (and probably older, that's just the last project I remember updating).\n\nRider has come a long way, it‚Äôs fine for large legacy project now\n\nDo you know where i can read more about the xml tree vs. the current impl\n\nI stand corrected, it was the project file, not the solution file. Here's the [MS build XML schema](https://learn.microsoft.com/en-us/visualstudio/msbuild/msbuild-project-file-schema-reference?view=vs-2022). The thing I was referencing was the `Item` element, as well as the nested `Project/ItemGroup/Item` element. Additionally, there was a `Project/Import` element that would reference other projects, potentially within the same solution.\n\nSuffice to say that I'm not a C# expert, and it's been ~5 years since I wrote anything in it. My recollection is the .NET Core, or at least ASP.NET Core, uses file system conventions to represent namespace constructs, and all external C# code is registered as a dependency rather than a project import (including the .NET Core standard library).\n\nI'm speculating that the *long term* answer to Visual Studio will ultimately be VSC. You'll just add addon's that mimic what you can get. This will take *years* to develop though.\n\n&gt; I'm speculating that the long term answer to Visual Studio will ultimately be VSC.\n\nI agree. Microsoft has been pushing hard on marketing C# as a platform agnostic lang and vscode fits that ‚Äòcode anywhere‚Äô image much better since it‚Äôs been multi platform forever. The writing on the wall for me was when they abandoned visual studio for Mac (aka monodevelop) and told people to use vscode+the C# plugin. The C# plugin constantly nags about logging into an ms account to access features so it‚Äôs clear they‚Äôve already been thinking about how they‚Äôre going to keep their visual studio license income stream going in a world where people are using vscode.\n\nIt's already been some 8+ years at this point, right? I remember in 2013 using Sublime Text 3 as the latest and greatest text editor with plugin support. Sometime after 2015 I first heard about Visual Studio Code, and Sublime Text dropped from the public consciousness pretty rapidly at that point. Atom was the underdog for a bit, but it took was dropped. I experimented with an alternative called Brackets for a bit (loved the flashing braces plugin).\n\nAnyway, bit of a tangent there, but I was trying to say that it's already been close to a decade of active development, and Visual Studio is still going strong. I do agree with a theory someone said elsewhere, and that's that Microsoft is trying to grab as much market share as they can, and then they will do a rug pull for licensing of some sort. Not a massive enterprise license like Visual Studio, but enough that they will likely see a noticeable increase in revenue relative to their already massive business model. Even something small like $5 is a lot of money when you have millions of users\n\nAnd a *fuck load* of work has gone into VSC. Have you seen how much of an IDE you can make out of it?\n\nI also said *long term* answer. If I have to explicitly say it out loud I will: They aren't just up and abandoning Visual Studio, nor did I even imply that was happening even remotely soon. It's disappointing I have to elaborate that but...\n\nFair enough. I don't think the problem was with your intent or my understanding, but rather that \"long term\" can be ambiguous. \n\n* Long-term plans for my living situation, renting an apartment is measured in months, like 6-18 months (1-2 lease terms). \n* Long-term plans at work are often 1-3 years, with some fuzzy idea of maybe a 5-year plan.\n* Long-term for my pets is measured in years (¬º to ¬Ω their lifespan, so ~5yrs). \n* Long-term plans for my finances are 10-20 years. \n* Long-term plans for a municipality or sovereignty can be on the scale of 100s of years.\n\nSo, long-term is indefinite. Microsoft has been around for 40+ years at this point, so it's reasonable to think long-term for them is in decades, but corporations most often make decisions on a quarterly basis, so long-term goes back to 1-3 years.\n\nTo give credit where it's due, however, putting any specific time scale on such a plan is foolhardy. You have no way of knowing if they are making this plan, much less when they would enact it. Long-term is exactly that: not now, but later.\n\nTL;DR - Long-term is ambiguous. Given the context, I assumed 5-10 years to be a long-term timeframe relative to the release of Visual Studio Code. You either meant long-term for Microsoft (10-20 years), or long-term starting from today (so another 5-10 years), or maybe both!\n\nC# Devkit for VS Code is fine imo\n\nMay be you did not try to use it for really huge projects.\n\nWalking to the store is also fine. Unless I'm buying 8 bags of concrete and the store is 8 miles away.\n\nIts a pretty poor experience imo. (VSCode for C# is in general though).\n\nIntellisense / Intellicode consistently breaks (not the AI shit, just actual things like namespacing, basic syntax errors, auto suggest).\n\nIts fixed by using the omnisharp part of the C# extension without the LSP.\n\nIt also doesnt really support Aspire that well (new features come to it slower I suppose), even using preview version of it, it just doesnt want to import Aspire namespaces.\n\nThe issues it has are really basic stuff that should just work. Rider and VS do not have these issues.\n\nNow that Rider is free, there is zero reason to use VSCode for C#. Its not even open source / free software.\n\nCan you debug a unit test yet? I dropped it years ago when I found out there was no way to do that at the time. In fact, the whole test runner situation at the time was unacceptable.\n\nI don't see it as an alternative but an additional tool, but I get that some hate VS Code with a passion.\n\nI like VS Code, but Rider is waaaay better as a daily driver for .NET.\n\nAs tooling is concerned, the fact that it‚Äôs not a Swiss Army knife is nice. It‚Äôs very intentional in its design. That‚Äôs the benefit. VS Code has its benefits too though. That‚Äôs why I say that to me it‚Äôs an additional tool. \n\nI pay for it and have for a while and I use it for hobby development mostly. I doubt I‚Äôll stop paying unless they raise the price on me.\n\nSame. I got the complete pack for hobby development. It‚Äôs really nice having a few focused IDEs. You can get something similar with VSCode profiles but that was annoying as well.\n\nAh I misunderstood, I thought you meant Rider was an additional tool and not the other way round.\n\nI'm with you, I use VS Code in that way too. Usually just to quickly edit a config file or whatever.\n\nI only have experience coding C# with VisualStudio. Is that not the most common way to develop C#? I couldn't imagine doing C# with VSCode\n\nI don't know about most common, but if you've used ReSharper then you've got a vague idea about what Rider is like. I couldn't do back, would recommend giving it a go.\n\nBecause VS Code is a text editor, not an IDE. It's a pretty good text editor, and it's customisable so you can kind-of turn it into an IDE, but  in my experience it isn't as good as a dedicated IDE.\n\nThat said, the plugins for javascript/typescript are good enough that it's a decent alternative to webstorm.\n\n&gt;Because VS Code is a text editor, not an IDE.\n\nTrying to make that distinction is pretty pointless IMO. It comes with the tooling for debugging and source control support. It is absolutely supposed to be used as an IDE. It might, as you said, just not compare well to a dedicated one.\n\nWhat's wrong with vim/emacs?\n\nNot just Linux, I feel like Rider is just superior to VS in Windows\n\nThe new roslyn LSP that microsoft made for vscode is MIT and you can already use it in most other editors. Although with the standard microsoft bullshit, in this case using a non standard method of starting the LSP, different from the protocol. But that only matters for the ones maintaining the integration plugins :). So you can pretty much 'steal' the good stuff without the other VSCode crap :)\n\nAfaik, vscode works fine in linux. Rider is nice for c# (the little I have played with it).\n\nUnless you do government work.\n\nThis is great, Jetbrains IDEs are just very good and I hope they stay in the game for a long time along with a healthy dose of competition. IMHO they are still the best, though the competition is catching up.\nThe Rust IDE was launched using this same licensing model some time ago... Will the Go IDE also start using that now?\n\nCompanies pay for a shitton of licenses, a dev in a good company will never pay for Jetbrains but he will have the whole suite on the company's dime\n\nThere is 0 competition for ides they are the best, hands down. Vscode is a tragedy how popular it is, it‚Äôs free sure for some of it but it‚Äôs so feature lacking. \n\nRustrover forever\n\nBut sadly they are starting to fall behind,  their IDEs are incredibly slow, and the remote dev is just trash compared to VSCode. I hope they improve and keep beeing the best\n\nTheir remote dev environment is probably more complex and more ‚Äúbattery included‚Äù than VSCode‚Äôs. Also, JetBrains IDEs are the most performant I‚Äôve ever used. No other IDE is that fast.\n\nSure, is more complex and battery included. But half the plugims dont work. And the worst offense is that its asks for access to the internet in the host machine,  which is incredibly painful to make it work with my employer security requirements. Vs code only asks for an ssh connexion and makes in work. The remote dev experience is just better in VSCode. But I am too used to having all the jetbrains conforts so I keep using it. But I really hope they improve it\n\nSo serious question, why is it a game changer for web devs?  Are there that many people doing web dev for non-commercial use?\n\nYou know, the people doing web dev out of the kindness of their own hearts, not to collect a paycheck.  I'm sure there are literally dozens.\n\nI interpreted more as implying there are many hobbyist web devs. I wonder how many there are.\n\nStudents. Many many students. I pirated everything as a student. Eeeeveryyyyythiiiiing.\n\nStudents have already been able to get free licenses for most JetBrains products for years.\n\nAnyone with a personal or hobby website could benefit from using the same tools they are used to working with daily.\n\nAlso, if they weren't free, a hobby dev might be tempted to log in with their work license for their personal project. I imagine this will cut down on that.\n\nYep, I user Rider daily for work. I was working on something as a hobby at home and it was so painful to use anything but Rider - so I sucked it up and bought the license.\n\nOf course, now I'm the sucker, haha. I'm 3 months outside the refund window as well.\n\nI think the big things is that this makes it more likely that WebStorm will  stay around rather than fade away.   That means more people can bet their fortunes on it. And non-commercial users like students etc. will often later become commercial users.\n\nI think this is a good license-model. If somebody makes a profit using WebStorm they should pay something for the further development and ongoing maintenance of the tool.\n\nOpen source and non-profit work is covered by the free license.\n\nnon-profit work is not covered by the free license, it clearly states that in the FAQ:\n\n&gt; If you‚Äôre working and receiving payment, **even if your employer doesn‚Äôt receive commercial benefits from the end product, such as in a non-profit organization, you should be using a commercial license.** For startups and non-profit organizations, we have separate offers mentioned on [this page](https://www.jetbrains.com/store/?section=discounts&amp;billing=yearly).\n\nThey also link to their definition of non-commercial use that is covered by this: https://www.jetbrains.com/legal/docs/toolbox/license_non-commercial/\n\nGenuine question, how would they know? Not talking on a corp level, of course they'd eventually know an entire company is using unlicensed software, I'm asking on the individual level.\n\nThey wouldn't. But lets say someone develops the next minecraft using rider, and starts making millions. Jetbrains could notice that the analytics say they used the non-commercial version during development, and presumably sue for damages.\n\nIt's a bit of a stretch admittedly, but it could theoretically cause issues later on.\n\nAnalytics are anonymous though, how would they link them to specifically that one developer?\n\nOooh, good point. For some reason I assumed it was tied to user ID or something.\n\nMore probably they could get the information accidentally through technical blog posts and interviews.\n\nThey're probably not as anonymous as you might think, otherwise you'd be able to opt out.\n\nThat sounds illegal\n\nWho knows what their gdpr compliance looks like, gdpr does give broader allowances than people may think like for preventing fraud or for \"security reasons\" for example\n\nIt's a matter of risk: you can do it but you're breaking the rules and the damages they'll sue for if they ever find out will destroy you\n\nPlus just put the shoe on the other foot: you're making software to make money, but you're using software robbing other people of making their money. Support the tools you use by at a minimum complying with software licensing\n\nIf their approach is like Microsoft they'll randomly audit your company and ask for proof of licensing then anything that isn't licensed properly you'll need to purchase the appropriate licenses. Only after that fails would they bother litigating against you, nobody wants to go to court.\n\nBut they already had a license for open source projects.\n\nOpen source license shit from jetbrains tends to be a chicken and egg thing. Do you already have a working codebase, website, domain tied email, etc? great! click here!\n\n\nOh you don't? fuck off.\n\nI submitted a basic github repo with some readme documentation. It a simple IRC library. And I got accepted..\n\nbefore you had to have an active already-in-development open source project and/or contribute to one and request and be approved for it.\n\nThis new license allows anyone to just download and take the license as part of sign-up. Making it a good choice for people who are just getting started, such as someone who wants to learn on their own, make a career change, or try their hand at open source for the first time.\n\nYea most non profits are just cash funnels for executives. Just because the legal entity is non profit doesn‚Äôt mean it doesn‚Äôt exist to make money.\n\nI had free WebStorm as a student and still switched to VS Code because it was better for my use case. This was in 2018.\n\nI bet the number of people using WebStorm for non-commercial use who aren‚Äôt using VS Code is very slim. I wonder what WebStorm can offer that VS Code can‚Äôt‚Ä¶ pretty much every extension is developed for VS Code first so I guess it comes down to the base functionality?\n\nHonestly, it's the extensions (or lack thereof) that make me go with Webstorm. I never need to configure Webstorm or keep track of extensions as webstorm just comes with so much out of the box. It's just download and go\n\nIt offers a lot considering that they‚Äôre now both free (for non-commercial). The experience with Webstorm is so much nicer overall, feels much smoother and I think the analysis of the codebase is still a lot better in Webstorm.\n\nHere‚Äôs a concrete case where WS proved superior for me. At work we have a .NET server with a lot of JS code running in an embedded V8. To debug this we use the Chrome inspector protocol (or whatever it‚Äôs called) and normally debug with the browser developer tools attached to the V8.\n\nRecently Chrome made some kind of a change that completely broke this setup. We found two solutions: a) use a headless Chrome where this still works running in a container that attaches to the V8, b) just attach the VS Code debugger in inspector protocol mode.\n\nThe VS Code option works horribly. It‚Äôs slow and disconnects *all the time*. Practically unusable. So most people run the headless Chrome. Since I have a WS subscription, I tried using it instead of VS Code in the first variant and the difference is night and day. The speed and crispness and reliability cannot be compared ‚Äî it blows VS Code out of the water. Not to mention it‚Äôs even easier to configure in WS. There are still some edge cases that only the browser dev tools can handle in this scenario, but those aren‚Äôt handled by VS Code either. So I think a clear win for WS in this instance.\n\nOpen source and hobbyist developers might begin to use it. But more so than that, if beginner developers start using it and get used to it, then that‚Äôs what they‚Äôll gravitate toward once they become professional devs at which point they either won‚Äôt mind paying for it or have their company pay for it.\n\nMy wife volunteers some hours on the weekends updating and maintaining our neighborhood elementary school's website and another site for its associated fundraising. Not sure which IDE she's using, but that's at least one example of non-commercial use.\n\nI interpret this as VSCode eating JetBrains' lunch. It's a last ditch effort to gain market share and hopefully convert them later into paying customers.\n\n100%\n\nWhy would anyone use proprietary, paid software when the significantly more popular alternative is free and open-source? They know no one wants this shit so they're giving it away. \n\nDo CLion and then we'll talk.\n\n&gt;Why would anyone use proprietary, paid software when the significantly more popular alternative is free and open-source?\n\nBetter user experience of course, but no one knows what they're missing if they have no point of comparison. I used to ask this same question years ago when I was using Eclipse and found IntelliJ licence to be prohibitively expensive. Everything changed when they made the Community Edition available... and emacs keybindings were supported.\n\nAccording to this https://ghuntley.com/fracture/ , it's not all roses from Microsoft and I would remain very suspicious of what they do next (and cautious about describing vscode as opensource). JetBrains offers more compelling products, IMO, but more importantly, they have delivered without deception for many decades at this point.\n\n&gt; Why would anyone use proprietary, paid software when the significantly more popular alternative is free and open-source?\n\nBecause that open source alternative is way worse.\n\nI use my IDE ¬±200 days a year, 8 hours a day. Paying $150 a year for a much better experience/features/productivity is a steal.\n\nAfter years of using WebStorm, I switched to VSCode after all the AI bullshit they tried to force on users. VSCode is certainly not \"way worse\", or else more people would actually use WebStorm.\n\nbruh, copilot is also terrible\n\nNote: If you got your VSCode binaries from Microsoft, they are *not* FOSS. You need to download VSCodium if you want it FOSS.\n\nYes, probably. I think unless people are prodded it's more likely that someone using Visual Studio Code will move to Visual Studio rather than to Rider, which I think is a big part of Microsoft's strategy.\n\nHope they make DataGrip free one day\n\nJetbrains makes the beta versions of all of their software available for free including for commercial use. https://www.jetbrains.com/resources/eap/\n\nThis is awesome, thanks for sharing!\n\nIsn't all the functionality included in the \"Database Tools and SQL\" plugin? I've been trying out Rider and so far it seems to work with databases just fine using the non-commercial license.\n\nThat would be great! For IntelliJ you need Ultimate as far as I know.\n\nWell worth it btw, the plugin/Datagrip is _by far_ the best allround database client I've used.\n\nThis seems like one of the tools you're least likely to need for noncommercial work. I use data grip all the time at work but I don't have a lot of data warehouses to query in my day to day non-work life. Whereas my IDE i use for both work and personal stuff.\n\nCorollary: I‚Äôm full stack, commercial, and I use DataGrip every single day. Well worth the paid license. It could be better but it gets the job done and very well.\n\nGoland next please ü•∫\n\nYes! I'd happily pay for the licence but I don't code enough outside work to justify it.\n\nI'm honestly considering just biting the bullet and getting a personal copy of intellij ultimate.  I know it has a official golang plugin (i use it daily for work but I'd bet it also has one for c/c++ and rust too\n\nGoland is pretty popular, so I don't think it is gonna happen. Both WebStorm and Rider has a much more popular IDE. It is not a gift, just a advertisement\n\nI've already had their \"All products\" subscription for several years, and have enjoyed it immensely \n\nBut I'm a bit annoyed they don't seem to be interested in supporting local LLMs so I've been trying other IDEs lately\n\nIs their Fleet editor dying on the vine or what?\n\nI tried to use Fleet on the side for a bit and wasn't a huge fan. It wasn't that it was bad but it felt more like a VS Code clone than it did a jetbrains ide that I was use to. \n\nI hope they extend this to their other product lines. I've used Webstorm for years at work and home. Every time I've wanted to pick up a new language, like Go, needing to buy a new license has always been a large obstacle in my path.\n\nSame. If I wanted to use an editor like VS Code, I would have just used VS Code. I'm paying for JetBrains IDEs because they are superior to VS Code in every way, except speed.\n\nIt is hard to say. I try it from time to time and performance is so bad, which is ridiculous as it was the main selling point \n\nIMO it is more like experiment. JB is scared of VS Code dominance, so they made an experimental editor from scratch, with heavy influence from VSCode (modularized, good support for plugin, good performance, lightness) with IJ platform strengths (as I understand they extracted code analysis modules from IJ to language servers used by Fleet)\n\nIn case of Fleet I think the most crucial aspect is not a vision or validity of it's goal, but sheer quality and performance. Time will show, if they can polish their new kid\n\nNow do CLion\n\nThat is weird. I cancelled my WebStorms subscription yesterday because \"ah, I don't use it that much.\" Thanks, Jetbrains, I guess.\n\nQuick! Cancel some streaming services and see if you can get us more free shit!\n\nüè¥‚Äç‚ò†Ô∏è\n\nAnd you can‚Äôt opt out of the telemetry that gets sent about usage etc.\n\nSorry for the late reply. Here is the part of the EULA (End User License Agreement) for Rider. Now, for the free non-commercial license, anonymous data collection cannot be turned off. It can be in the paid license. I wanted to show what data is collected and what is not.\n\n7.4. If you opt in to anonymous data collection through the Product, the Product may electronically send anonymous information to JetBrains related to your usage of the Product features. This information may include, but is not limited to, frameworks, file templates being used in the IDEs, actions invoked, and other interactions with Product features. **This information will contain neither source code nor your Personal Data, nor information about your JetBrains Account.**\n\nThanks for the reply. It is most illuminating   They‚Äôd collect enough info to be able to determine if you‚Äôre in compliance with their terms and conditions. Names of folders or projects. Titles that in of themselves are not to be disclosed. Anything that‚Äôs free then we‚Äôre the product, for me as a general rule of thumb.\n\nhttps://blog.jetbrains.com/blog/2024/10/24/webstorm-and-rider-are-now-free-for-non-commercial-use/#is-there-a-way-to-opt-out-of-sending-anonymized-statistics?\n\nPerhaps this is the real reason they are doing this? ü§î\n\nI seriously doubt they're making them free for the main purpose of getting my anonymized statistics.\n\nMore likely they decided to make them free to get more aspiring devs hooked, and figured demanding anonymized statistics was a fair price for a free IDE.\n\nThis is for sure the real reason, it's the same reason  Adobe hands out ~~free~~ discounted Photoshop licenses to college kids and doesn't crack down too hard on hobbyist piracy. When those college kids and hobbyists go to work in the industry they're gonna ask their bosses to pay for the tools they know and are comfortable with.\n\nIMO it's a win for everyone involved. Hobbyists get good tools for free and Jetbrains gets more business.\n\nAdobe doesn‚Äôt give free licenses to college students though? Unless something has changed in the last 3 years‚Ä¶\n\nI took a class that used Photoshop in college, and my options were either to 1) go to a computer lab that had a Photoshop license, or 2) create a regular Adobe account and use a free week long trial. They had student discounts, but it still cost money.\n\nUsed to be free, is now a student discount I guess? The logic is the same.\n\nyes, then those devs get decision power in their jobs, and choose what they know\n\nwhich honestly not many devs know intellij outside of their work giving them a license\n\nYeah, the VS Code is present so much in online courses, YT content and memes that JetBrains has to have some sort of an answer and I don't think AI and another ten supposedly specialised IDEs are gonna do the trick (speaking as a JetBrains fanboy so so we're clear, I even have friends there)...\n\nI got Jetbrains on an educational license and now I'll probably pay them until the day my body can't type anymore\n\n&gt; https://blog.jetbrains.com/blog/2024/10/24/webstorm-and-rider-are-now-free-for-non-commercial-use/#is-there-a-way-to-opt-out-of-sending-anonymized-statistics\n\nYeah, the real reason is clearly the continuous loss of traction to VS Code, compounded by the new emerging IDEs.  They're going to have to differentiate on other things moving forward, and they're trying to stave off irreversible market loss.  Cmon.\n\nWhat? VS Code is why they're building Fleet. There aren't enough C# users using VS Code for this to be much of a factor in their decision (because VS/Rider are significantly better). If anything, they're finally trying to capture the group who uses Visual Studio Community Edition.\n\nEdit: based on [their tweets](https://x.com/JetBrainsRider/status/1849491444375093423) it seems like going after Unity (game) devs is a big part of their strategy with free Rider.\n\nRider has been amazing for Unreal ever since they launched Unreal Engine support like 2 years ago. I swear by it.\n\nI wouldn't be surprised if this is a move to try to get the hobbyist gamedevs off of Visual Studio and into Rider so they can convince management to buy the commercial Rider license. I have been a Rider evangelist in my studio since the day I got access to it, and I'll bet they want to convert others like me.\n\nHow popular is Fleet? I don't know anyone talking about it, nor do I see it in online spaces (and I work excusively using JetBrains IDEs and so does my coworkers and programmer friends).\n\nC# is way out of my area of expertise, but WebStorm makes perfect sense as a better alternative to VS Code for all the aspiring developers who watch Udemy and YouTube where every single instructor shows examples in VS Code because it's free.\n\nI do hope they'll be successful to be frank... I love their products - however faulty, especially recently - and I absolutely despise Microsoft and see VS Code for the Sauron's ring of power that it is: an instrument of control.\n\nI don't work at JB so I can't tell you what their goals are, but it currently just seems like Beta software to me. So I'm not surprised adoption is low.\n\nFleet is still only EAP and not fully released.\n\nHaving said that I don't really understand what's its value proposition. I know it's meant to be lighter, but don't know if that will somehow convert the VSCode users.\n\nYes of course, I just use VS Code for short, kinda like when I'm using a Puffs tissue and I still call it a Kleenex.\n\nAlso, I didn't know fleet existed, cool.\n\nWell if you didnt want to pay (or pirate) your options are VS Community (utterly dogshit, none of the features for the terrible performance) or VS Code (poor experience but very light weight and can do the job).\n\nNow all the C# VS Code users can just move to Rider.\n\nVisual Studio Community is fantastic. What makes you say it's dogshit?\n\nIve extensively used Enterprise and I wouldnt go back to Community.\n\nI dont think the bad performanec of Visual Studio is worth it on anything but the Enterprise version, its so bad.\n\nThings like the time travel debug or snapshot debugging makes the world of difference.\n\nIf you cant get those you might as well get Rider tbh (its pretty good)\n\n[deleted]\n\nhttps://visualstudio.microsoft.com/vs/compare/\n\nit is not (or MS hasnt updated, also likely).\n\nCan they gain traction using a non commercial only license ?\n\nPeople using tools they like outside of work might ask their employers to buy them for work\n\nWell yeah that possible, taking that into account it will improve jetbrains usage.\n\nBut I still believe is hard to compete with other solutions like vscode that doesn't impose any requirements .\n\nAnyways, more options is always good in my opinion\n\nVSC is good enough, but Jetbrains is better.  I've worked with a lot of VSC devs, most of them don't really care about their editors and aren't looking to optimize their experience inside it; the ones that do eventually move over to Jetbrains and are happier for it.\n\nMaybe.  Its a nice IDE with pretty good autocomplete.  \n\nIf being free gets students to try it out they have a potential of future profit when they get jobs.\n  \nIf those same students get used to always hacking together some Visual Studio Code plugins then that's what they will do when they get jobs.\n\nI'm out of the loop, what other ides are coming out?\n\nhospital illegal seemly fine offer rob saw advise elastic hateful\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*\n\nProbably AI based ones like cursor\n\nAny already-existing IDE with any sense already support a bevy of plugins to make them AI-enabled.\n\nNot exactly IDEs, but text/code editors with AI integration.\n\nAny text editor can become IDE for any language with [LSP](https://microsoft.github.io/language-server-protocol/) and [DAP](https://microsoft.github.io/debug-adapter-protocol/) nowadays.\n\n‚ÄúIDE‚Äù at most. Also, this is one area where I don‚Äôt think the fuzziness of current AI help - dumb example, but I don‚Äôt want to rename 96% of the uses of this function, but all of them.\n\nAI isnt for refactoring, its for building brand new shit. the refactor button usually works fine\n\n[deleted]\n\nStill far from making any dent in the IDE market.\n\nZed is in infancy right now. Won't be a serious competitor for many years, maybe ever as there are not so many rust developers in the wild.\n\nAbsolutely the case.  Shocked at how many people are using vscode at my current company for Java.\n\nPeople love free stuff. If the company don't pay for it, why bother.\n\nUnless changing IDE can increase my salary, then I'm in.\n\nDelivery is way faster.  I suppose that's not the greatest draw for some people?\nI'm in and out of various languages, databases, environments and vcses...  No idea why people wouldn't want a single tool to smoothly handle it all\n\nWho doesn't use intellij for java!?! Any idea why?\n\nIn conjunction with copilot its really good.\n\nGood catch\n\nJust block their domain via dns\n\nI literally just renewed my subscription  for these two products last month. üò≠ Still, great news though.\n\nRiders on the Storm\n\nDoors song... \"Riders on the Storm\" :-)\n\n[https://www.youtube.com/watch?v=7G2-FPlvY58](https://www.youtube.com/watch?v=7G2-FPlvY58)\n\nI only know the one with them and Snoop Dogg from Underground 2\n\nRegardless of what platform you're on, Rider is your best choice for .net development.¬†\n\n\nThis is great news for the dotnet ecosystem.\n\nThis is huge! I‚Äôve used Rider professionally for years, but for personal projects I‚Äôve been using VS Community‚Ä¶ which is fine, but I‚Äôve been spoiled by the QoL improvements in Rider. I‚Äôm stoked to have this for personal projects!\n\nI‚Äôd take a non-commercial license for ReSharper too, but Rider runs better than VS+ReSharper (for me).\n\nWhenever something is free on the internet 99 out of a 100 times.. you/your data are the product.  \nBut Free IDE is good, jetbrain makes decent stuff\n\nDoesn't really apply in this case. The only thing JetBrains get in this trade is informations about how you use their IDE. Which is worth nothing to everyone else except JetBrains, and is only worthy to them in the sense that it allows them to improve their software. I don't believe it would even qualify as \"personal data\".\n\nFor Rider it could be a strategic move. Visual Studio (the real VS, not VS code) is already free for non-commercial and even for small-to-medium companies (5 free seats, unless you have &gt;250 PCs or &gt;$1 Million US Dollars in annual revenue). It's a good way to get an industry to use your tooling.\n\nIn this case, I think it's because all the younger devs are moving to VS Code.  Because that's what was free and had the coolest-looking \"dark mode\" theme back when they were learning to code in school.\n\nAnd I'm starting to see that mindshare loss cascade up the professional ranks as well.  I have to pay for my own personal Jetbrains license now, because my current company is like, \"Why don't you just use VS Code?\".  I'm starting to hear chatter about standardizing all the devs on the same editor/IDE, so we can get some benefit from all using the same plugins for certain things.  I haven't heard that kind of chatter since the Eclipse days back in the 2000's.\n\nWhen you're competing with free, you have no choice but to be free... at least for the newbies, to get them into your ecosystem in hopes of making their employers customers later.  Honestly, I think Jetbrains is on a path toward a death spiral if they don't find a way to stem their losses against VS Code with the younger newbie crowd.\n\nGotta admit, Jetbrains converted me to Rider with their 60$ Visual Studio for Mac is canceld promotion. Tried it on hobby stuff, then made the company pay for a full license.\n\nI would't use my employers hardare/license on my hobby stuff but thats just me.\n\n&gt; your data are the product.\n\nTools like these don't care to profile you, they just want crash reports and usage statistics. It's always ~~funny~~ annoying when people freak out about that.\n\n&gt; Whenever something is paid on the internet 99 out of a 100 times.. you/your data are the product.\n\nThis is a risky business strategy. How would they even know if you used a non-commercial license for a commercial software? Sounds like people can just use it for free without receiving any drawbacks from not paying.\n\nIf you work for a moderately serious company, using a unlicensed IDE is an easy way to get fired. Anything that's supposed to be internal, suddenly isn't.\n\n\"Anything that's supposed to be internal, suddenly isn't.\"  \nSorry if I sound like a dumbass, but I don't understand, what do you mean internal stuff suddenly isn't? we're not talking about pirated software where anyone could be snooping on your machine/code, just a non-commercial licensed legit software.\n\nsure, but what if you're a freelancer or solo dev?\n\nThey don't care. Also, if for some reason it starts compromising their profits, they can just make it paid again and it will be the same as before.\n\nI don't think they care that much. They're after big businesses buying licenses in bulk. Their corp. pricing is more than a double of a personal license. They already got that position established in the Java world - in the past 10 years all the companies I've worked at had a license server with all-products-pack license seat automatically assigned to each developer.\n\n&gt; It‚Äôs important to note that, if you‚Äôre using a non-commercial license, you cannot opt out of the collection of anonymous usage statistics.\n\nkeyword: anonymous.\nI don't think they can detect and sue/prosecute over this\n\nIve tried both Rider and WebStorm, while Rider is great, WebStorm was unusable for me, it was absurdly slow to syntax highlight the code, give intellisense and jump to definitions.\nI tried following their tutorial to fix the performance issues by disabling features, allocating more memory but nothing changed.\n\nReally? I use almost exclusively JetBrains products related to web dev and data (WebStorm, PyCharm, DataSpell) and out of those WebStorm was always the most impresive to me, since it couples so nicely with type inference from TypeScript and helps with the API from different external libraires when you include them.\n\nHuh. The only time I've ever seen WebStorm perform poorly is on my ancient-ass bottom-of-the-barrel laptop, but *everything* chugs on there. The other 3 devices I've used it on, it ran like a dream.\n\nIs it possible if we use firejail we would be able to stop them from collecting any data\n\nThis is AMAZING\n\nI'm just transitioning back to VSCode from WebStorm. It's slow, a memory hog, bugs are not fixed. Instead they developed their own AI features that are crap. (Source: paid for those, too for a couple months)\n\nWhatever happened to fleet?\n\nIt's in public preview: https://www.jetbrains.com/fleet/\n\nLooks like many people miss the \"non-commercial use\" part.\n\nProbably trying to steal some of that vscode market share.¬†\n\n\nI use intellij ultimate which has all of the webstorm / rider features included. I love jetbrains products but since a few years it feels like they get more and more bloated and buggy. I hope they focus a bit more on quality over quantity again\n\nNice, these are the exact two I've had on-again-off-again subscriptions for just for the sake of some hobby projects.\n\nYou can already use rider too early access for free for commercial projects\n\nStupid question, how would they stop people from using it for commercial use?\n\nHow do they check if someone‚Äôs using it for commercial purposes?\n\nJetbrains hooked me on Resharper nearly 15 years ago, when I was in high school.\n\nThey enabled me to ship software to hundreds of thousands of users as a kid. They enabled my first startup. Their tools taught me to think differently and program more effectively. Because of their tools, I have a stronger understanding of the systems I work with and can keep up with language design changes.\n\nI have recommended jetbrains to every coworker I have worked with since. It is the only product I am ecstatic to pay for annually, which I would happily pay for if they hiked their rates 2x.\n\nGenuinely, their policies are genius - win for the community, win for their company. I know I am not the only one who feels this way. I'm very happy they are privately owned and can make smart decisions.\n\n8 years after your comment, your prayers are answered! Community edition!\n\nhopefully CLion is next\n\nThose are gateway drugs\n\nNot much of a change. JetBrains always provide free license for education.\n\nAfter education, 99.99% of people are working on commercial projects.\n\nEdit: It may be good for those who interest in coding but isn't in any institutions.\n\nCould just download it without having to providing any identity first.\n\nI don't think this is accurate.\n\nFrom the article:\n\n&gt;According to various surveys like¬†[Stack Overflow](https://survey.stackoverflow.co/2024/work#coding-outside-of-work-coding-activities), 68% of developers code outside of work as a hobby,\n\n*out of all the people that bothered to respond to the survey\n\nThat's a skewed metric, id wager a large part of that 68 percent is people doing after hours work on personal projects with their work Jetbrains licenses.\n\nI think it's probably more interesting for people who work with one set of tech for their day job (say, ruby) and use (say, rubymine) for that but want to do something like game development in Unity for hobby/gamejam/etc. stuff.\n\nIf the employer only buys the rubymine license, this lets someone work on Unity in a familiar interface for free. And that person probably wasn't going to pay for tooling for that hobby anyway, but might say something nice about it to people who would. It's not a big gamble for Jetbrains that way."
  },
  {
    "title": "Why good engineers fail technical interviews",
    "body": "",
    "score": 1515,
    "url": "",
    "created_utc": 1725033176.0,
    "author": "Bobeyna",
    "permalink": "/r/programming/comments/1f4yoqd/why_good_engineers_fail_technical_interviews/",
    "all_comment_text": "Working engineers spend forty hours a week getting better at writing working software. They spend very little time getting better at gaming interviews.\n\nNever in my over a decade long SWE career, have I had to figure out how to solve an algorithm problem while someone breathes down my neck and watches my screen as part of my actual work.  It's literally checking if a fish can climb a tree.\n\nI have. Mostly because it was a pricing algo that was in prod which under very extreme circumstances was giving weird prices on backfill ads, one day (due to a typo), it was super widespread and the company lost of a few grand, and made metrics look bad to clients. Nothing too serious, and we negated it temporarily by just not backfilling. But the fact it was there and I was the one who flagged it months ago.. I had 5 execs staring at me &amp; my computer in our open floor plan office while I tried to debug it with the rest of the company in the office wondering what was happening.\n\nThat was a stressful day.\n\n[deleted]\n\nClose. Timezone &amp; dst on a timestamp.\n\nTimestamp was midnight for the day which ads should be displayed and what the spend / impressions for that day at a maximum if the row exists.\n\nIt should have been an interval between two timestamps instead, or at least normalized between input time zones. But instead it was based on the local time of the user who made it. So when someone was on the west coast until 5 it would be fine. Or before 8 in th east coast. But working late screwed stuff up.\n\nPretty amateur, but yay scrappy startups.\n\n&gt;  or at least normalized between input time zones.\n\nthis is the way.\n\nI had a coworker lose a few million in microseconds not once, but TWICE. He was called the cowboy because he loved to test his code live at the market open. He is honestly a really smart guy but even smart people make big mistakes for a myriad of reasons. In this case, hubris, though he would probably say pressure. To be fair to the guy, it was probably both. You have to be at the very top of your game to survive in these places, but still‚Ä¶.\n\nFirst time it was ok, this is a big fuck up, but it was considered a mistake. And this was when HFT firms were making millions per day so it was slightly easy to write off when you considered it was a single day of profit. \n\nBut then he did it again and was gone within a day or two. He yelled at as one time over email, on Christmas Eve. Told us that we all sucked and suggested to go get a job at McDonalds. \n\nSo after they let him go, I walked down the street to the nearest McDonalds to ask for a job application. And then I mailed it to his home address. \n\nAnyway that‚Äôs my story about losing a ton of money doing software development.\n\n&gt; he loved to test his code live at the market open. \n\nIt's a failure of the company that he was allowed to do this enough to earn a nickname. Though it's his fault he did it again after getting burned.\n\nThis is why I'm more than happy to give a stupidly difficult interview question... but I leave the room *and give them access to the internet*.\n\nAfter some time as elapsed, I'll come back in and ask them to explain the code and their thought process behind the logic.  I don't care if it works, I don't care if they legit pulled the code off of some StackOverflow page... I care that they're able to explain what the code is doing and why.\n\nAsking someone something that they'll literally never do in a real-world situation is fucking stupid, I want you to solve an actual problem that you may actually face, and I want you to understand why its a problem. /shrug\n\nI failed an interview at Google because the interviewer expected me to derive the [Sieve of Erathsones](https://en.wikipedia.org/wiki/Sieve_of_Eratosthenes) on the spot.\n\nI'm sure Erathsones was able to come up with it in 20 minutes while someone stood over him, watching every single stroke of his quill.\n\nI had a \"barkeeper\" at OCI ask me what an interesting problem I had solved recently was. I said that I had managed to implement leveshtein distance in pure SQL (weird client requirement). he said \"sounds great, we have 20 minutes left, can you do it again for me?\"\n\nmate, fuck off.\n\nI would have got the job if not for him.\n\nI guess you should solve less interesting problems?\n\nWhat round were you on?\n\nI failed an on-site at Google because I couldn't write a 4-dimensional tensor to matrix conversion in log time, and of course it was after 2-4 screenings with 10 people all being paid upwards of 200k leading up to that paid on-site series of interviews so it makes perfect sense to say one guy just overrode the whole process to just flunk me for not pioneering discrete math.\n\n&gt;!shout out to the homies laughing at this thread!&lt;\n\nGoogle's process is quite insane - as are any teams or managers who actually want to copy it outside of Google. If it's one thing I wish I could convince them of it's that _they're not Google_.\n\nI failed a google interview because I literally couldn‚Äôt understand either of the interviewers. They both had heavy accents and called in from different countries. It‚Äôs a dehumanizing process. You‚Äôre just a number and the interviewers don‚Äôt care because they‚Äôll never meet you¬†\n\nOddly enough I can write a prime sieve on the spot¬†\n\nEh, if they were doing the interview right, they probably didn't care if you got the most optimal solution, or just a solution.  You could have come up with a less optimal way to find all the primes in a set and still done okay.  They just wanted to verify that:\n\n* You had enough math to know what a prime number was and how to detect one.  \n* You had enough basic comp-sci to be able to come up with some kind of algorithm.  \n* You could talk intelligently about the runtime complexity of whatever you came up with, and if your first pass was something inefficient, could come up with approaches to try to improve it.\n\nLike, don't get me wrong - Interview problems that are just \"do you know this algorithm by heart?\" are ass, and too many people still give those.  But unless they specifically asked for the algorithm by name, \"find all the primes in this set\" is a pretty reasonable technical interview question.  Certainly for someplace like google.\n\nI know this probably isn't what you want to hear, but, I guarantee that everyone I know who has worked there could write something pretty close to an optimum in under 15 minutes.\n\nI appreciate you taking all the time to explain all of that. I wish the interviewer or recruiter would have given me any of that as feedback back in 2010 instead of just \"sorry, you're not a fit.\"\n\nThis; if doing the right Job isn‚Äôt good enough for the interview; probably the interview is broken.\n\nI'm a guy in my 40's working in big tech, and my observation is that the interview machine has created a generation of engineers who see a codebase as a series of one-offs.\n\nWe don't test for \"how are your OOP skills\" or \"how will this change impact another part of the system\", \"do you understand threads/concurrency\", or \"if you make a mistake, can you monitor the deployment and recognize what happened?\".\n\nI have a team full of people who can sort the shit out of a list in 45 minutes but lack fundamentals.\n\n&gt; but lack fundamentals\n\nAnd people love to say that the leetcode interviews are to make sure you know your fundamentals.\n\nNo, it is working as designed. Companies like Google and Microsoft have so many applicants that missing good engineers doesn't matter, it is all about making sure that the ones that do come true are as good as possible on average. Lower sensitivity in exchange for higher specificity.\n\n&gt; No, it is working as designed. Companies like Google and Microsoft\n\nGonna stop you right there as you're only half right. It's working as designed _for companies like Google and MSFT_.\n\nMost tech companies aren't FAANG or do FAANG stuff. These types of interviews don't \"work as designed\" for most companies.\n\nIf the company is able to fill its engineering positions in a timely manner, then it is still \"working as designed.\"\n\nLetting qualified people slip through your fingers is only really a concern if you're not able to fill your positions.\n\nIt is biased, some people are not fast but they are solid thinkers. You need diversity in your workforce.\n\nBut the point is that it doesn‚Äôt matter. They get so many applicants that they will find solid thinkers who can jump through their interview hoops.\n\nI don‚Äôt know why there is such confidence that an interview can be designed that 1) meaningfully differentiates skill 2) cannot be gamed by preparing specifically for it. They haven‚Äôt cracked this problem in most fields of endeavor and that‚Äôs why an entire test prep industry exists.\n\nNot only that you really can't tell if someone is actually good until they are on the job for a bit even with a filter, a filter that is probably filtering out good people more over just interview preppers. \n\nPeople try to act like they are filtering out bad hires but really they are filtering out people that aren't looking every year for a new job and constantly just in the interview game. People that have worked places for a while are creating value clearly, those that bail every year and just playing interview games are making a mess in most cases then bailing.\n\nThey say, well if we hire bad then it can wreck a product, but in most cases there are checks on that now. It would be better to do contract to hire type setups where the job needs actually are what are tested for. The first 3-6 months of a job, even the first few weeks, are much more important than the interview tests.\n\nThe tests are so disconnected as well, especially if you have a CS or engineering degree and already been through this. If anyone is writing their own sort and not using one that already suffices and is proven, that is a bad look unless you are hiring for a platform that specializes in fast sorts, otherwise it is almost always quicksort3 or a sort by some guy named Tim, never a bubble but in a small enough situation maybe, it is all dependent on so many factors. As long as engineers are aware of those, how they might work and of time complexity and trade-offs there that is enough, especially with all the tools today and even AI. \n\nInterviews are so disconnected with the needs for the job it is actually encouraging leetcode terrible solutions and that is wrecking products and encouraging non pragmatic and inflexible solutions. Software is stuck in a bad cycle because of it. They are attracting the interview gamers and in most cases the 3-5 year engineers that are in the phase of their career where they are complexifying more than simplifying. Simplifying complexity is the job of an engineer, it doesn't mean it isn't complex, it just means you don't take something simple and make it more complex, you go the other direction for usability/interactions/presentation.\n\nIt truly is one of the most disconnected things especially when someone has a history of shipping, creating value, degrees, multiple experiences and more. I can understand doing this for people that just came out of college/university but for experienced it seems to be completely borked.\n\nThe problem with contract to hire is why would someone ever leave their full time stable job for it?\n\n&gt; They say, well if we hire bad then it can wreck a product, but in most cases there are checks on that now. It would be better to do contract to hire type setups where the job needs actually are what are tested for. The first 3-6 months of a job, even the first few weeks, are much more important than the interview tests.\n&gt; \n&gt; \n\nI would absolutely love more C2H jobs but the US seems pretty allergic to them compared to Europe probably for health insurance reasons.\n\nI'm still pissed that this industry hiring process is a cat walk. I avoided shallow fields mostly because of that.. being in a trade where improving your craft is the goal.\n\n&gt; Working engineers spend forty hours a week\n\nI wish it was only 40\n\nI've been a coder for 16 years (mostly in VFX).  I've also been unemployed for 10 months now (after 10 years on a job) and these coding interviews have absolutely wrecked my mental health.  I'm at the point where I actually don't see myself as a coder anymore, because these live coding tests make me feel like an idiot.  Not really sure how I'm going to get hired at this point.\n\nEDIT:\n\nMan, this blog post makes me feel so seen.\n\nThis hit straight home to me. I've been coding for 12+ years, but facing and taking these coding interviews sends my anxiety and stress through the roof. Luckily I have a contract gig right now, but I'm now on year 2 of trying to find a full-time job without any luck and I can't see myself ever passing these types of interviews. I've started to look into different roles within tech, but the future is daunting.\n\nKeep faith in yourself.  Trust me, I know it's hard.  But I know deep down that bad engineers don't work by chance for 12, 16, or 20 years.  It's the surface levels thoughts that fuck us up.\n\nI had an. Employer that I had worked at before (I went with a company that splintered off years prior) and they gave me a gnarly coding test.  I guess the 4 years I worked there weren't enough.\n\nBrudda, the SWE job market is ass and has been for *at least* 10 months. I can‚Äôt even get a job when I‚Äôm referred by a current employee.\n\nSame, didn‚Äôt even get an interview when I had a referral and know a recruiter at the company. Really awful out there rn\n\nYeah there is that.  These interview scare the shit out of me though.\n\nBruh it seems like 10y of experience in multiple projects with a referrals from managers and engs of all of them is not enough. \n\nThey will still want to run you through 5 stages of stupid ass leetcode interviews with a homework added too.\n\nAh, homework assignments... yeah no. If I get an interview that assigns homework I'm 90% not interested in working there anymore.\n\nThat said, my reply to them is, \"Sure thing, my consulting rate is $120/hr USD with a 4 hour minimum commitment up front. If you're good with that, here's my payment info and I'll get started upon deposit.\"\n\nWhich is weird because with that much YoE they should focus a lot more on your interpersonal skills and workplace problems, like how you deliver things to clients, what were your obstacles working in teams. A client isn't gonna be impressed that you can balance a tree\n\nI‚Äôm with you. 12 years of Java/SQL but basically anything my jobs have needed, I‚Äôm an engineer after all. Have gotten one interview in a year of being unemployed, only because I knew someone at the company, CarGurus. Nailed every question because I had extensive experience of real world knowledge on each topic. I knew the question he would ask for the coding part, and I coded it perfect but printed the answer in the method, when in fact main was the one with the print statement. Quickly fixed it. Feedback was the coding part didn‚Äôt go well. And it wasn‚Äôt like I was being tested on print methods, I did all the complex logic fine. It‚Äôs insane - common sense goes completely out the window. Talked to a recruiter who said - ‚Äúya we stopped working with Cargurus because they reject 99% of people for asinine reasons.‚Äù \n\nDidn‚Äôt make me feel much better, as I‚Äôm still unemployed.\n\nCargurus interviewers are one of two companies I‚Äôve interviewed with where the interviewers were aggressively condescending and, worse, wrong and when that was pointed out tried to add more technical stage interviews because they knew the team wasn‚Äôt good (like 8 people were on the call so they saw the main interviewer fucking up). I straight up told them I wasn‚Äôt interested in their role after that.\n\n The other was Wayfair. In both cases they were clearly not interested in being there and viewed treated the whole thing as beneath them. Maybe it was just the wrong person but your story and recruiter comment matches my experience.\n\nI've been doing this for 25 years, and I usually go on a few interviews each year. I still struggle with this, and a lot of it comes down to what I consider to be silly \"gotcha\" or \"leetcode\" questions. At least over the years I've come to realize it almost doesn't matter, and that usually they've made a decision ahead of time and the code questions are more difficult if they've decided to hire their buddy and are just going through the motions.\n\nUnfortunately we operate in an industry that's decided that memorizing the phone book over and over again, instead of building a solid understanding of the underlying problems and solutions is more important. I partially blame media, when you see shows with \"smart\" people like Mike Ross of Suits held up as the paradigm of intelligence, when what he's doing is being a very bad Google search in most cases.\n\nKeep your chin up, the questions will get easier again when the Fed cuts interest rates in Sept and the VC money begins to flow, and everybody needs programmers.\n\nKeep trying my guy! I‚Äôm 11 years experience, came out of a job after 5 years to suddenly doing these intense coding tests. I failed the first 2, thought I failed the last one but apparently they thought I was really good and I got the job in the end. Point being, they saw through my shitty test, someone will see your brilliance through the shitty test as well. Believe.\n\nIf you are interviewing with companies that have open source software, take a look through their code. Then laugh/cry as their leetcode tests have nothing to do with the coding tests.\n\nWhat's even worse is when they talk about performance problems, and think leetcode solutions are the fix.\n\nGood luck to you. Glad I still have the luxury of seeing a leetcode interview and walking away from the dumpster fire.\n\nI'm finally a doctor, guys! But really I'm a loser :).\n\n[deleted]\n\nTwenty years in and I probably fail nine out of ten of these.\n\nI‚Äôve published a book full of my own code, got an A in my grad school algorithms class, and most importantly was the primary dev for teams bringing half a dozen products to market in a number of different languages.\n\nI doubt I‚Äôll ever practice these interview questions ‚Äî there‚Äôs always something interesting and useful I could be building instead.\n\nYeah yeah yeah but can you do linked list using only your butt cheeks to type? Sorry you're not a good fit\n\nI failed a Microsoft interview once and I'm pretty sure it's because when I was being interviewed (bear in mind I have like 30 years experience) the person was asking me to solve some problems in a linked list on a whiteboard... and once I'd solved one of them, they asked \n\n&gt; What's the performance of this solution?\n\nAnd I answered that it was O(n) which was the best possible solution.  But they took issue with the fact that my approach made two passes over the list, and asked if I could do it in one, and I essentially refused.\n\nI know how to research.  I know how to profile and make changes is something is the blocking issue.  Asking me to change `O(2n)` to `O(n)` struck me as a pointless waste of time, and I immediately decided that I didn't want to work in the kind of environment that would make a thing out of that kind of distinction, especially in an interview.  My thinking was \"I answered your linked list question... maybe move on to something more interesting and informative\"\n\nEDIT: please stop \"correcting\" me that O(n) and O(2n) are the same, because you drop constants.  That was the point I was trying to make.\n\nIf Microsoft cares about N vs 2N Teams would work way better. Interviewer asking pointless questions.\n\nTeams feels like it's trying to solve the halting problem on its main thread\n\nO(n) and O(2n) are the same complexity anyways, right? As n trends to infinity, the 2 becomes completely negligible.\n\nAcademically, yes. Practically, I wouldnt consider the difference between 5 hours and 10 hours insignificant\n\nGood thing the interviewer asked for the big O complexity and not the runtime!\n\nDid they, though? That‚Äôs not clear from how the story was told¬†‚Äì it says the interviewer asked ‚Äúwhat‚Äôs the performance of this solution?‚Äù\n\nThese big O questions are absurd imo and truly academic evals....  i find young, inexperienced teams lead by young, inexperienced leaders do these academic like evals.\n\nSo annoying.\n\nBig-O questions are useful for gauging if candidates know the basics and can think through the implications of what they wrote.  So probably more useful for junior engineer interviews.\n\nThough I don't do much leetcode myself as I don't find toy coding problems interesting.\n\nI wish more interviewers would prepare coding exercises that are relevant to the team &amp; role.\n\nTwo passes over a list is still O(n). O(n) and O(2n) are the same thing. Big-O disregards constant multiples.\n\nI can do it with one butt cheek and use my d for the shift key.\n\nThis is the needful and you‚Äôre not doing it.\n\nI've gone to tons of technical interviews, and I've conducted tons of technical interviews, and the only thing I know for sure is that they're a good way of eliminating people who are having bad days.\n\nAlso, I guess on rare occasions, you're doing the interview, and you think, \"If we hire this guy, he's going to outrank me pretty soon.\" That only happened to me once, and I was right.\n\nI hate doing technical interviews because it is so hard to find the right questions.\n\n&gt; 20 years of experience working in a complex field? \n\nI've met some where I'm not smart enough to come up with interesting questions and they should be interviewing me to see if I'm still good for my job. \n\nI've also met some that couldn't write a single line of code on a white board.\n\nI feel like an idiot for asking simple dumb coding questions to someone with decades of experience, but I've met too many people who couldn't answer them, at all experience levels.\n\nMaybe people lie on their resume?\n\nI'm not trying to tell the person's exact level, just whether they'd be good at the position we have.\n\nAlso, I *like* to ask simpler questions. One of the senior engineers on my team clued me in on that idea early in my career. I often ask questions similar to the problems they'd get on a day-to-day basis. Not only am I very familiar with those problems, I can often add on and make the problem more difficult if I want to delve further in.\n\nAnd also, if I stick to a simple question, even a person who is in over their head can feel more relaxed. It's good if the interviewee leaves the technical interview feeling like they did okay, even if they're not a good fit. I feel like a relaxed candidate performs closer to their true level, as well.\n\nThat seems like a good strategy. The candidate will feel better about the process, and they can't blame you if the other candidate was a rockstar coder.\n\nIf you ask nightmare questions people will feel insulted if the job is easier than the interview, and it'd be hard to assess the answers unless you're a genius developer yourself.\n\nI have found presenting code to someone and asking them to point out problems / talk through it has been very useful to identify any people that couldn‚Äôt truly do it vs couldn‚Äôt do that thing that day.\n\nThey‚Äôre useful but not as a hard block. IE ask easy questions to weed out the people who literally cannot write any code.\n\nThen ask one difficult question but focus on how they work with you and think. Their answer isn‚Äôt the most important part of the interview. Give them little hints but just ask them to run with it. \n\nAlso don‚Äôt prematurely shit on a candidates answer. Sometimes you don‚Äôt know where they‚Äôre going with their work. Let them cook.\n\nJust in case you were wondering, I wrote a comment here about you responding to the wrong comment, but finally I realized you hadn't, so I deleted it. Egg is all over my face, and I would have been the one to fail the easy interview question here.\n\nMy preferred style is when they ask you a question that's easy to solve but can be made arbitrarily more complicated by adding new requirements.\n\nI find this both helps me get into the mental swing of things and gives time to fully wrap my head around the problem, rather than having the initial flood of \"oh god how do I solve this _right now_\", and the interview usually ends up being a lot of chit chat about tradeoffs you're making.\n\nIn over 15 years I can only remember one interview where it was clear the company had made a genuine effort to help the candidate's potential shine through. I'd name them, but then everyone else would chime in to contradict me.\n\nI think it's just really difficult to come up with a process that allows for that level of consideration, and the right kind of person needs to run it. It turned out the hiring manager advocates for neurodiverse people in tech, which is awesome but it's rare to find a technical manager with that kind of background\n\nI have a couple pretty commonly-used NPM packages and am on the core development team for a reasonably popular javascript framework.  I still frequently fail technical interviews because I just generally suck at interviewing.\n\nLike... ffs... I'll have interviewers ask me about specific functions within our framework and I'll not know the exact usage.  I've had one ask if I even know this framework?  Like, my guy, look at the \"our team\" page on the framework's website - I'm literally the *nth* person down.  I can assure you that I know more about this framework than you do - it is just more in-line with my specific contributions.\n\nFortunately, I somewhat-recently (within the last year) landed a job with a company that *really likes* this particular framework as an IC distinguished engineer, and was tasked with \"make the framework better\".  Its weird having a job where I don't actually really have a manager or anyone assigning me tasks.  The only meetings I attend are when people aren't quite sure on the best implementation.  The only real \"projects\" I have are related to conferences and talks I give, wherein I am assigned content writers and designers to help me put together presentations and whatnot.  It's *super* cushy.\n\nDang, having someone pay others to put your conference talks together for you is an enviable cheat code!\n\nI'm ultimately the one working on the draft and general topics covered in the talk, I just get a technical writer to help it work for a more general (albeit, technical) audience, and a designer to make it actually *look* good... because ultimately, my company is likely a sponsor for that conference, and they *really* want it to look *extra polished.*\n\nAmazon has bar raisers that can reject you regardless of what the interviewers think. I had a bar raiser correct one of my answers (erroneously mind you, they were reading off a script and the script was outright wrong) and they blacklisted me from Amazon for 2 years.\n\nFew months later an Amazon recruiter reached out to me praising my performance on that interview and asking if I'm interested in joining a dying Amazon team.\n\nWhew. These companies.\n\nYeah I too had shit bar raiser round at Amazon. The interviewer was rude and lacked any humility. He went on to just demean me over and over again. He even complained about my internet connection being slow when he was the one dropping out multiple times.\n\nTo be fair, that's kind of the experience you would have as an amazon employee on quite a few teams.\n\nIt's particularly awkward when literally all the other interviewers including the manager loves you.\n\nAs someone who has interviewed a bunch for Amazon, I can confirm that while there are some that are truly great, bar raisers (and especially bar raisers in training) are generally condescending and have a superiority complex.  Hiring managers CAN override a bar raiser, but it‚Äôs oftentimes not worth the fight and heartache.  Some of those debriefs get spicy.  My team has a growing list of bar raisers we absolutely refuse to include in our loops for these reasons.\n\nDid you ask him to eat a bowl of shit in response or did you just skip the bowl part altogether?\n\nall the big companies do. At google it's known as the hiring committee. \n\nIn the end you're reliant on your interviewers to write a packet more persuasive than some other interviewer wrote about the candidate they interviewed....none of the interviewers make the actual final decision.\n\nThe HC isn't one person who sits in on your interview who can harass you if they wake up on the wrong side of bed, though.\n\nThere‚Äôs always something interesting and useful we could be building instead, yes.\n\nI don‚Äôt want candidates studying interview questions. My interview is an algorithm thought exercise but it‚Äôs not a question and then wait for a full answer. It‚Äôs more of a discussion where I present a hypothetical scenario that has many solutions. I‚Äôm never looking for optimal solution, I‚Äôm looking for someone who can discuss a solution with me and when presented an argument shooting holes in that solution can either argue the merits or come up with a variation that addresses the issues posed. It‚Äôs a technical conversation rather than a an and a session that hopefully mimics our day to day work together.\n\nThat is the kind of interview I prefer to do when I'm interviewing people. And definitely the kind I'd prefer when I'm on the receiving end. I really don't understand this leetcode-style thing. At least leetcode is better than \"how many cats are in NYC\" questions.\n\nThere are common things devs should know and there are obscure things they may know. It‚Äôs important for everyone involved to know the difference.\n\nRegardless of whether you can answer the question or not, follow up with ‚Äúhow often does that happen here?‚Äù\n\nI had a guy get pretty upset when he was explaining that I didn't do what he wanted on the challenge. My solution worked, and worked well, probably better in a real world situation than what this guy had in mind.\n\nBut he wanted me to use a heap, specifically. Which yeah, I didn't even think of when he laid out the requirements because they're just not practical for most things. And only work in the situation because we're only pretending to have a database and instead just have all out data in memory. So I was treating our fake database, like a database.\n\nI told him hadn't used a heap for anything outside of university. And he immediately goes on about how it's a valuable tool every developer should know. Which idk maybe, I think it's good to know about, but realistically not something everyone will use. He said something like every good developer uses heaps. I asked if he'd ever used one here. He went quiet for a bit, said no, and ended the interview.\n\nIs that problem limited a single process or is it across multiple machines ? If it's latter, you did nice but if it's former then - that's out of scope right ? \n\nThat's definitely a weird person to be upset over such interesting thing.\n\nIt was a 1h interview problem. Pretty much everything is out of scope. But the hypothetical situation was a food delivery / ordering api\n\nAlso interviews are a detection system. All detection systems will have false positives and false negatives, people will adjust their detection system to optimize the tradeoffs to minimize one or the other.\n\nThat performance anxiety problem is really spot on-\n\nSomething I remember from psych classes is that there is a 'sweet spot' with anxiety &amp; performance. Some anxiety is good. Too much is bad. You could imagine a bell curve with anxiety as the X axis and performance as the Y. On the left side you have bad performance caused by apathy &amp; boredom. In the middle is the peak. On the right side is bad performance because of panic and being overwhelmed.\n\nSo the fundamental problem with in-person coding is that it's drastically more anxiety-inducing than the real job.\n\nSo a lot of perfectly good candidates, candidates who would hang out in the 'sweet spot' zone during the real job, their stress levels can get pushed into the 'panic &amp; overwhelm' zone during the interview. They freeze up. I've seen it happen!\n\nBut that's not the only problem, another problem is that you can get smart candidates who thrive during the high intensity interview, but then when it comes to doing the actual job (not as thrilling), they fall into the \"apathy &amp; boredom\" zone, and don't actually do the job that well.\n\nSo I personally hate running in-person coding tests, unfortunately a lot of orgs require them. I like OP's thoughts on project deep dives. You can tell a lot about a candidate just by asking very specific, very low-level questions about past projects they worked on.\n\nI just finally finished 15 years trudging through academia and I have never had test anxiety like a proctored coding interview. And I failed my comprehensive exams for my doctorate the first time lol.¬†\n\n\nLive coding interviews are brutal\n\n[deleted]\n\n&gt;Not to mention a lot of interviewers are not from the USA, but from a country where there is a culture of learning things by heart to pass exams. \n\nI would like to elaborate on that. Many engineers truly believe that their path to their current position is the only true path, so they don't tolerate any deviations.\n\n\"How could you not know this?\" they say. Well, you yourself only know this because of your previous position. If you had been hired by a different company two years ago, you wouldn't know that either.\n\n[deleted]\n\nI had an interview and the night before I looked up JS interview questions.  Once I got to the interview I realized they were asking the same EXACT questions I had seen the night before.\n\nI didn't get the job because I had just started studying the night before and skipped over the hard ones and of course those were the ones they asked lol.  I'm also not a JS dev.  I know a bit of frontend but have taken it off my resume after that experience.\n\nOr ‚ÄúI don‚Äôt have that memorized because I‚Äôd look it up at a real job‚Äù\n\nMy team had a very basic leetcode problem as an interview question, just a little bit more complex than FizzBuzz and involved data structures, as our team worked quite a bit with data structures. We've had soo many candidates that couldn't get their head wrapped around pointers or data structures, we were bewildered.\n\n\nI'm of the mindset anything rated a \"medium\" in leetcode should only be used to evaluate how a person approaches a problem, not their actual solution. But any candidate should be able to do an \"easy\"\n\nAligns to my experience interviewing there as a fresh grad, and on top of that, they won‚Äôt tell you what sort of group you‚Äôre interviewing with beforehand.  I was interviewed for a UX test role with a resume of embedded, digital hardware, and kernel development.  Literally every interviewer asked me some variant of ‚Äúwhat are you doing here?‚Äù.  You guys tell me you‚Äôre the ones who flew me out to interview here!\n\n&gt; embedded, digital hardware, and kernel development\n\nHow did you get all that experience as a fresh grad? You don't mean your Uni course work do you?\n\nI mean, how else do you expect someone to have five years of experience for an entry-level position?\n\nI know you're joking, but my engineering college requires 6 quarters of co-op (read paid internship) as a requirement for graduation.\n\nIt was on my resume as a combination of course work, project work, and a coop and part time work at an engineering firm.  And admittedly those things also as ‚Äúwhat I‚Äôd like to work on based on what was interesting to me‚Äù.  I did all three of those at my coop actually though, it was honestly a dream coop in terms of resume building.  Single board computers with FPGAs in them, so you could do VHDL to create your own ‚Äúhardware‚Äù and then write kernel drivers to interface with it.   My coolest example was a classic ‚ÄúI made the lights blink‚Äù but it went from a Linux driver to the FPGA to something like an i2c module out to a separate LED driver chip.  It was a comical number of layers but makes for awesome interview fodder.\n\nI got a company to (mostly) stop using riddles by telling them in the interview that riddles are bad and then solving two of the three they gave me in under ten seconds. One I had seen before, one I started a sentence I didn‚Äôt know how was going to end and solved it before the period, the other almost that fast.  \n\nOne of the conceits that makes me hate r/programming is that only people who are bad at something hate it. As if no sharpshooter has ever abhorred gun safety problems.  It‚Äôs called sympathy, dickheads. You can feel it for people who are getting the sharp end of the stick, even if you‚Äôre not one of them.\n\nYou ever notice how posts in this subreddit get downvoted if they're not authoritative? There ain't no room for low stakes conversation about anything.\n\n[deleted]\n\nI want to slap a lot of people.\n\nCareful you‚Äôll hurt your arm.\n\nDon't worry. I'll keep my pimp hand strong.\n\nOh I get voted down for sounding authoritative plenty. Just be authoritative in a domain where the right answer is the least bit counterintuitive. I think this is why some people love A/B testing to a fault. We can intellectualize the problem all day long but what are the outcomes?\n\n&gt; One of the conceits that makes me hate r/programming is that only people who are bad at something hate it. \n\nI don't think it's just r/programming. I've stopped telling people I have serious issues with git because the reaction is usually very negative. We'll ignore the fact that I've used about a half dozen different source control systems, and git is easily the most complex for little gain.\n\nHad a friend in college go and learn all the details of how git works to demystify it for himself. Put on a presentation for the club about key takeaways, mentioned several gripes he had with git, and ultimately said learning git in detail was not worth it and recommended what parts were worth learning.\n\nGuy got a masters, worked at apple on metal, and generally pretty brilliant. So I believe it.\n\nI'm curious what your problems are with git. I'm also a bit of a grey beard and I used a bunch of other source control systems including perforce, svn, tfs, and a very little CVS. For subversion in particular, I was my team's svn+build guy back in the 2000s when teams still had a \"build guy\".\n\nAll that to say, once I discovered git, I never looked back. It's the fastest and most dependable/transparent/predictable source control system I've ever used. I've never lost a single piece of work that was under source control by git.\n\nBut I have seen teams implement git in ways that make their own lives very complicated. Mostly by dropping the \"D\" in DVCS or by cargo-culting complicated branching schemes that don't fit their use case (I'm looking at you, git flow).\n\nMy main issue with git is that the interface is terrible. Commands have arcane names that don't do what you'd expect them to do.\n\nMan, remember how bad branching and merging was in most VCSs was before git? It's _wild_ how many days, perhaps weeks, I spent fighting to merge branches in SVN over the years.\n\nFor me git was a straight upgrade when compared to it's predecessors. But man, the porcelain was really ugly and despite slow &amp; steady improvements still is to some extent. I totally get people who are still annoyed that it was the winner of DVCS war.\n\nEver use Perforce?  Powerful branching and amazing visualization tools, but IMO it was too powerful because every file was individually branched not the repository, so to know if everything was fully merged you NEEDED those visualization tools.\n\nI worked with 40 people who needed my help to do git surgeries properly and still heard I must be using git wrong if I thought it needed to be replaced. I do graph theory problems in my head for fun. This is my wheelhouse. Maybe that‚Äôs why I hate it. I see the dancing bear aspects and dream of more.\n\nThe only time an interviewer was like an actual dick to me was when I interviewed at M$. It was an indian(?) guy so I guess that checks out. Dude suggested I go through this giant book of leetcode problems and try again. I started a company instead. It‚Äôs going well, but it‚Äôs pretty early-stage. It pays the bills, though, so that‚Äôs something.\n\nGoing back to that comment about ‚ÄúI‚Äôd rather build something useful in my free time‚Äù\n\nI got something similar from google. The guy told me to interview as a QA tester instead of a SWE\n\nCompletely depends on what you mean by leetcode question. If it's a gotchya question that requires some specific knowledge about the problem, I agree, it's not a good question. If it's just a problem that requires use of simple programming concepts to solve (loops, if conditions, etc), this is a great way to determine someone's problem solving skills.\n\nIt's what made FizzBuzz a great question (before people started memorizing the answer). A half decent developer could solve it in minutes and anyone else is weeded out. No, it didn't determine if someone is a great engineer, but it weeds out a large chunk of people quickly.\n\nBad questions are things require specific knowledge sets. Having to know the acceleration of gravity, knowing you can determine a prime number by dividing by some weird constant, if using 32 bit numbers, or knowing some details about a specific framework.\n\nI think they are talking about the harder leetcode problems? A lot of those are of the type \"either you know this or you don't\". With only a few folks being able to solve them on their own when left alone for a few hours.\n\nThe easier to medium leetcode questions are often solvable by knowing some basics about these kind of problems. Though some of the medium ones vary.\n\nI had some interviews that were very hard and I just solved it in the full hour barely and with some edge cases not handled but mentioned.\n\nI was told I was too slow and I should practice my data structures and algorithms.\n\nif I had gotten a problem I practiced I'd be really good q___q\n\nbut I didn't so I barely solved it in the full time (taking the asking your interviewer questions time)\n\nit's silly, some problems aren't solvable first time seeing them in 1 hour for some people \n\nand that doesn't make them bad engineers\n\nWhile I generally agree that those type of questions aren't the best (I do think that easier questions of the same genre can do a good job, especially for more junior positions), a good interviewer can also get a lot from questions that are too hard to solve.\n\nWhat I mean is that they can see the way you reason, the way you approach problems, and the way you deal with knowledge gaps or problems above your level.\n\nI personally have passed multiple interviews without solving every question (sometimes solving the first but not the second, etc). Also I had some where the problem was pretty complex, but I wasn't expected to spit out a solution, instead it was more like I gave a naive solution, then the interviewer helped me identify the problem and guided me towards a better one.\n\nIn my final interview for Apple, he gave me a wrap up question which he prefaced by saying that it required a certain trick that pretty much no one would figure out quickly. He gave me a few minutes and then gave me the answer, and asked me to explain why it worked.\n\nI feel so seen.\n\n&gt; I have never had to, nor heard of, a do or die moment where there was a need to implement a prefix trie and an O(n) search solution within 30 minutes of being presented with a problem.\n\nI bombed a \"simple\" technical interview yesterday for a job I would love to get. The \"get to know you\" part of the 30min interview went long leaving me less than 10min to solve the leetcode style problem. By the time I had written pseudocode, formatted it, and ran it once, I was out of time.\n\nWhen it didn't precisely solve the , the interviewer said I could have a minute or two more, but the anxiety and panic had already destroyed my ability to focus and problem solve. Heart racing and palms sweating I tried to spot the error, but to no avail.\n\nSo, I didn't have a completed solution. I was thanked for my time and told, \"someone should contact you soon\". Their demeanor was that someone who had just tried Popeyes' cheddar biscuit butterfly shrimp.\n\nI hope they can see my merit and value as a seasoned engineer with 10+ yoe, look past the tail end of the interview, but I'm dubious.\n\nI‚Äôve been there. Same amount of experience. One interview, the first interface with the tech team was ‚ÄúHi, nice to meet you. Ok, open an IDE and the project we emailed you.‚Äù In front of 5 engineers, I had to wire up a few back end calls and show a list. Should be pretty easy, but I let my mind run away with the situation and completely flaked. Interviewing is just a separate skill. It‚Äôs hard to replicate and do well at it without actually doing it.\n\nWhy on earth do they have 5 people involved in an interview?\n\nNothing better to do but make candidates grovel at the feet of the council\n\nThat's kind of crazy to me that they held you strictly to time.\n\nWhen I was interviewing people, I never scheduled them back to back, so there was always at least 30 mins for it to go over. Also, it was my job to keep the interview moving along and ensure the candidate had time and was as relaxed as possible.\n\nAlso, the programming technical questions I asked were always dead simple, like find an element in a list that might not exist, find the second highest numbers, reverse a string, count words in text, etc. They all had some edge cases and some degree of ambiguity in the spec for the person to ask about or explore when describing how they would test it. But, the actual coding was meant to be simple (and reassuringly so). The exercise is really about trying to get some insight into how someone goes about solving a problem, how they figure out what should be done, and how they can communicate about why they chose the approach they settled on.\n\nOf course, there were some people who still somehow struggled on the most basic things, but even then, I tried to figure out if it was just interview stress or actual lack of knowledge/capability.\n\nAlso, when training up people to interview, I interviewed them with the same script and problems, so they could feel what it was like as an interviewee, and be a bit more understanding. Plus, it was one way for me to get some honest feedback on my interviewing style.\n\n&gt;the interviewer said I could have a minute or two more, but the anxiety and panic had already destroyed my ability to focus and problem solve.\n\nThis sounds like a bad approach on their part. They should have asked some leading questions to Socratically guide you to the problem, not just let you sink or swim. Normally, when I have a co-worker having an issue, I help them and talk with them, so I don't get why interviewers think leaving a potential co-worker out to dry like this is the way to go. IMO, I'd learn way more about them as a co-worker by seeing how they collaborate and react to feedback rather than watch them stress out. If the person gets guided to a solution but gets mad about it, then I probably don't want to hire them.\n\nI don't want to give you false hope because you probably know best what it felt like, but I also have friends who left places feeling like that and ended up getting the job. The reason they felt totally dejected was because they learnt afterwards the interview was designed to make them question themselves and their abilities and feel like they just totally failed.\n\nFucking stupid strategy I would say.\n\nI appreciate that sentiment. I really do hope they overlook the incomplete solution, but only time will tell.\n\nI hate interviews where they have you screenshare to solve a problem in real time. Putting me on the spot and watching essentially over my shoulder is a cute fire way of me bombing it.\n\nI had something similar, where during the interview they said I'd have less than 10mins to complete a coding challenge. And what was worse was that during the live coding I'd have to talk the 3 interviewers about what I was doing during the challenge, and explain why I was making certain decisions.\n\nWhomever had created the interview was utterly clueless.\n\nThe technical interview (live interview, not take-home) I had for my current job wanted me to create a calculator, and as a second step, implement an nth root function for it without using the built-in System.Math library.\n\nI spent almost the rest of the interview just trying to remember/figure out how calculate the nth root by hand. I thought I would never hear from them again. I got the job offer two days later.\n\nI don't want to give you any false hope, but sometimes these interviews are really just set up for you to feel like you failed, whether you actually blew it or not.\n\nHad the exact same experience. I wrote down and told the interviewer exactly how I would solve this problem, but didn't have time actually implement the solution (It was a two part probably in which I solved the first part with a working/runnable solution).\n\nJust got rejected today for \"pace\". 10+ yoe. You gotta be kidding me.\n\nI kind of feel what you write here, it's been similar for me. I had 22 years of career so far an had to seek a new job three times. What's very apparent is that despite high technical acumen and proficiency that built up over time, I still never got better at interviews. I still suck as much right now at interviews as I did the first time. It's kind of a different discipline.\n\nNow I've been sitting on the other side of the table for at least 40 times, either interviewing myself for a direct report or being invited for the technical interview of positions in other teams to assess candidate skills that are difficult to assess - and despite using a formal process that should lead to objective feedback about candidates, at the end of the day, people (including me) are extremely subjective in their choice and just making themselves believe they are choosing objectively. We're doing ourselves in a false sense of security. Despite all those elaborate steps, it's still the first impression that counts most, and charisma is a huge factor. \n\nPersonally I think the traditional way of hiring is completely broken and ineffective . If I had the power to change that, I'd love to try and attempt radically different and more lightweight approaches. But nobody wants to take risks, so I'm stuck with following a process I don't really believe in.\n\nThe introduction to Cracking the Coding Interview is so, so telling as to the source of the problem.\n\n&gt; I, in particular, was disappointed.  We had rejected one of *my* candidates.  A former student.  One I referred.  He had a 3.73 GPA from the University of Washington, one of the best computer science schools in the world, and had done extensive work on open-source projects.  He was energetic.  He was creative.  He was sharp.  He worked hard.  He was a true geek in all the best ways.\n\n\"Could my interview format be so out-of-touch?\"\n\n&gt; I had to tell him the unfortunate truth: those books aren't enough.  Academic books prepare you for fancy research, and they probably and they probably make you a better software engineer, but they're not sufficient for interviews.  Why? I'll give you a hint: Your interviewers haven't seen red-black trees since *they* were in school either.\n&gt; To crack the coding interview, you need to prepare with *real* interview questions.  You must practice on *real* problems and learn their patterns.  It's about developing a fresh algorithm, not memorizing existing problems.\n\n\"No, no, it's the candidates who are wrong.\"\n\nOh, and the book is largely devoted to computer science topics that none of us has seen since we were in school, and stupid fucking brainteaser questions that have nothing to do with solving real problems.\n\n&gt; Your interviewers haven't seen red-black trees since they were in school either.\n\nThey also somewhat act like when there was a hard Jeopardy question that some of the smartest people didn't get, then in a way a snarky reply of the answer, while looking at the answer, and disappoint. Or a professor that had such a hard test that even the best students didn't set the curve high. \n\nIn any normal scenario, even if you know something well, you are researching it again to validate or improve your solutions. If a developer is only doing it from their head they have lost the beginners mind and their solutions will get stale.\n\nThe book itself is probably partly responsible for these interview questions because the people that were hired off going through that book ad nauseam and nailing these random trivia questions are the same ones that end up doing the interviewing. Nasty cycle\n\n[removed]\n\nImagine you're hiring lab scientists and instead of looking at the research that they've done and talking with them about that you ask them to stand up give an improv speech to a group of people about a topic you won't tell them until they're on stage.\n\nIt would be like asking somebody coming into a biology grad program to do an hour of OChem gotcha questions when they have publications on immunology.\n\n&gt; ask them to stand up give an improv speech to a group of people\n\nNo joke one time I had to \"put together a presentation on the topic of your choice\" for the final round of an interview, and they actually called a dozen(*!?*) or so random employees into the room to hear it.\n\nIt was very clear a minute or two in that no one cared about [my chosen topic](https://en.wikipedia.org/wiki/P_versus_NP_problem) and they were hoping for a more business-focused talk (for a client-facing engineering role). But they didn't tell me this; I was supposed to just know it.\n\nThe entire experience was very uncomfortable for everyone involved, most especially me.\n\nIf a candidate came with a curated list of commits they did for the other companies, I'd love it instead of asking questions, but the previous companies usually have their own opinion on such kind of thing.\n\nI've written a couple of articles about this ([funny interviews](https://jonpauluritis.com/articles/funny-interviews/), [a better way to hire people](https://jonpauluritis.com/articles/a-better-way-to-hire/))... \n\nThe reality is that there are cultural norms around this stuff that arose time and place... **most people/ companies don't know WHY they have an interview process the way they do right now. Seriously.** \n\nThe concept of a processed interview arose to try and be a little objective with an overwhelmingly qualitative examination of an individual where the repercussions of a bad hire can be gnarly. Leet code/ Algorithmic technical screens have their place in this because it basically shows if someone was willing to study for an interview or not. We all know this. \n\nWhat I would say to people, imagine **you are going to get paid an extra 30K-50K every 18-36 months just by memorizing some leet code questions**. Thats actually a pretty good deal for you. Because so many companies are sooooooo bad at hiring you can focus a lot of your effort just on getting good at interviewing, and you will be paid a lot more for it. Companies still haven't really figured out that there are a ton of professional interviewers out there. And there are other companies who are currently suffering the negative effects of hiring people who are great at academic process but not the real world - google has notably dealt with a ton of social justice infighting. \n\n# Why do good engineers fail technical interviews?\n\nSimple answer - technical interviews are not meant to identify good engineers.\n\nTried to point this out to a friend who is a hiring manager and his response was \"yeah well I can't devote my dev time to vetting candidates that deeply so we just rely on this process we know is probably flawed but it is what it is.  Get good.\"\n\nAlright my dude, you do you I guess.  Was just trying to give a perspective from outside the org on your hiring process.  For what its worth I know for a fact his team has the holier-than-thou smarter-than-thou \"how do you not know this?\" type developers so I guess you get what you get.\n\nUnfortunately it is out of our control and the answer is simple. Study these stupid fucking questions and pray they ask one you actually know\n\nI'm at a relatively prolific tech company and these days there's a distinct mix of 2 different types of engineers. \n\nThere are engineers who sound like incredible engineers. Theyre just casually dropping graph theory terms and other extremely technical concepts as part of just regular, mundane projects. Their design docs and other technical documentation reads like a college thesis. And just from speaking to them, you'd think you're talking to an experienced principal engineer. \n\nAnd then comes time for them to deliver actual, real code. And it is _always_ a shit show. \n\nThey always get high praise and promotions and raises, because the theoretical components of their work always sound so impressive in a PowerPoint presentation. But the rest of us engineers who need to integrate with their _actual_ code, transform from 10x engineers to 0.2x engineers. Especially because those types of engineers always seem absolutely toxic to the idea of compromising to \"maybe we go with a simpler, well-beaten path approach, rather than your super technical, novel solution.\"\n\nnot to mention - a lot of that fancy talk is just poor communication skills masked as intelligence. I have gotten a lot of feedback that my projects/solutions seem simple - yeah because I am a good engineer and I work hard to come up with simple maintainable solutions instead of just throwing hacks at the wall.\n\nThis is a great answer. \n\nIt also stems out to most industries too. I am a pretty good interviewer and have landed jobs doing shit I had no experience doing. Time and place also help, because if you interview good and they see no experience, all while absolutely needing to hire someone quickly, this can creates a good reason to hire someone who is professional and trainable.\n\n[deleted]\n\nI feel like its more that most developers aren't trained on how to conduct proper interviews, so they just make up their own bad practice version based on their experiences with interviews with other developers that likewise did the same thing. Also, in my experience great hires are usually very obvious, you don't need tricks or puzzles to find them.\n\nIf you‚Äôre gonna have a puzzle in the interview, it should directly relate to what they‚Äôre going to be working on day to day.\n\nYes, I'm still trying to figure out how getting a dog around a grid to pick up cookies and then get back to his doghouse in the shortest path without stepping on the same space twice is going to come up in my day to day as a react developer.  But I guess 15 years doesn't mean shit anymore.  I can't get fido home in 30 mins while being interrupted constantly, I am unemployable.\n\nI'm always surprised at how little the interview has to do with the job.\n\nI do hiring for Unity developers and I just make them open Unity and write a component that rotates a cube. That immediately tells me if they know anything about Unity and we can expand on it depending on how fast they do it.\n\nYet when I interview at places they ask me oddball algorithm questions that have absolutely nothing to do with Unity. Ask me to code a rocket launcher and I will, but I'm not going to remember how to write something with levenshtein distance off the dome.\n\nLast month, I interviewed for a senior frontend position and was asked what sorting algorithm I would use to sort a list of objects, and what big O that algorithm has.\n\nheh. i would just use whatever is built into the language, or a small package / component i could import and use. it'll be faster and more bug free than anything i could write in an interview so what's the point? use the tools that are available to you while you concentrate on the parts that are not built into off the shelf libraries\n\nI call it the \"second-generation effect\". The founders, be it Google or Microsoft, were emotionally invested in their \"baby\". Then the business school jocks showed up and started enshitifying everything in order to make that arrow go up and to the right.\n\nGoogle search is becoming more useless by the day, and MS Windows as an operating system is becoming a special kind of hell, with non-stop popups, product ads just showing up - \"Did you try playing Deathloop, bro?!\" - and system settings becoming even more confusing, amazingly. There is no stewardship of these products, it seems.\n\nBut they definitely have that cubicle farm filled to the brim with Leetcode warriors.\n\nThe M$ gatekeeping is hilarious if you spend 5 minutes with Windows 11. Windows has always kind of been ass when you look at ‚Äúlower level‚Äù things like the kernel and file system. UAC is a joke.\n\nFuck, I do want to play deathloop.\n\nThe whole false positive thing being more expensive is a misnomer, it is critically expensive for the first few hires, they will establish the culture of the company and the competency. They have an outsized weight on the trajectory of the org, but once you get past a 10 man dev shop, the culture and technical direction of the company has been set, good or bad it is hard for a single hire to change the course (assuming the hire is not a principle or distinguished engineer level) after the core team is established and a bad hire is quickly spotted, and really only the hiring cycle and salary for the time the bad hire was there is the only sunk cost.  \n  \nThis is contrasted with opportunity cost, which is high if you are an innovative company with a roadmap. Everyday the slot sits empty the opportunity cost loss outweighs the risk of a bad hire. If an org cannot spot a bad hire within 2 weeks of hiring, they have an org problem not a hiring problem.\n\nIf a developer cannot spend and hour talking to another developer and walk away knowing if the candidate is qualified for the job, then they are not at the level in there career where they should be interviewing.\n\nWhile I mostly agree with you, I've also worked in company where you would need to show up drunk, punch your boss and puke on a co-workers desk to get fired. Also an org problem, granted, but if that's the culture, they're going to be more cautious about hiring.\n\nI don‚Äôt even want to work for the major companies that do this shit. The last thing I need to be surrounded by self important people who think they‚Äôre gods gift to programming because they made it through 30 rounds of escape room interviews.\n\nOne thing to add is no one seems to question how well trained someone is at giving an interview. From my experience it‚Äôs none (including myself).\n\nI pretty much just had a technical interview like this article suggests we should do and it was one of the best I've ever had just talking about previous projects and general knowledge on the libraries/frameworks I'd be working with.   \n  \nI got offered the job. More interviews like that, please.\n\nGood interviewers don‚Äôt ask coding questions.  Better interviewers ask quick &amp; easy coding questions.  Because there are an unbelievable number of applicants with great looking resumes who cannot program a digital computer, and you have no other way to screen them out.\n\n[deleted]\n\nAside from ego, our industry is also filled with an over emphasis on technical skills vs critical thinking and the ability to communicate.\n\nI saw it as a music major, which is why I feel confident in recognizing it. We were implicitly trained to believe that good musicianship is just playing the correct notes and rhythms, when in practice it also requires the ability to effectively communicate with audiences, tell stories, adjust practiced routines on the fly, mentorship, keep a clear head under pressure, etc.\n\nSimilarly, being an effective software engineer has so much to do with critical thinking and those same kinds of soft skills, it's much more important than the technical skills a candidate can demonstrate at the time of the interview. Ego is part of not understanding that, but I also think it's a cultural issue that goes far beyond the tech industry, unfortunately.\n\n&gt;I can't really think of any other field where candidates are subject to such anxiety ridden hour long subjective judgement sessions, where you strip away all the person's regular tools and simultaneously put their entire career futures at stake.\n\nI think that's due to lack of experience in applying for jobs in other fields. I've come across quite a few hiring horror stories for people in marketing asked to basically create an entire marketing campaign as part of their interviewing process, or otherwise doing significant take home work that is then evaluated (and often stolen). So, I don't think we have a lock on terrible hiring practices.\n\nI'm very curious what the hiring process is for lawyers and doctors and engineers in more \"physical\" fields, like civil, petroleum. mechanical, etc. Do they get asked to design a bridge or HVAC system in the interview? To diagnose a patient? To give opinions on a legal situation?\n\n&gt;¬†I've come across quite a few hiring horror stories for people in marketing asked to basically create an entire marketing campaign as part of their interviewing process, or otherwise doing significant take home work\n\nYour point is not lost, hiring totally sucks across all industries because no one cares about it sufficiently.\n\nEven though it‚Äôs wack to be asked to do that amount of work, at least in the marketing example it‚Äôs literally the same thing you would do as an employee.\n\nTake homes suck, but I would vastly prefer getting one of those instead of a live algorithmic session.¬†\n\n&gt;I am somewhat convinced that the rot¬†*started*¬†with ego. Our industry is full of big egos.\n\nBang on, the best engineers I've worked with have been extremely humble. The worst had the biggest egos and loved to show off and made overly complex solutions to simple problems.\n\nI worked as a software developer from 1980-2017 and retired in 2017.\n\nStarting in the early 2000‚Äôs I found that job interviews were becoming more technically challenging. \n\nI started seeing on line coding interviews often with the interviewers watching my keystrokes and making me debug code or write code from scratch under time constraints and in some cases I couldn‚Äôt look things up.\n\nI also found they were asking me the most obscure programming issues expecting me to often know the 800 page Java manual by memory.\n\nPrior to this I got by without all this nonsense and usually got jobs by just hitting it off with the people interviewing me along with some minor technical questions.\n\nIt was almost is if 30 years of prior experience meant nothing to these companies, with one job lasting 8 years and another 10. \n\nOne idiot outfit made me take a test which I realized was an IQ test. I was so pissed I told the recruiter to tell them to screw themselves.\nI was not applying to join Mensa!\n\nAfter my last layoff in 2017, I tried for 6 months to find a new job but hit the wall with these tech interviews, threw in the towel and retired early.\n\nI spoke with an ex coworker recently and he told me he was sick of people asking him to code bubble sorts and other ridiculous nonsense.\n\nI feel for people going through this gauntlet now, especially with all the corporate layoffs.\n\nWhy technical interviews fail good engineers?\n\n[removed]\n\nI'm just refusing to do these tests. Here are my examples from work, they can ask questions or whatever but if they have some leetcode bullshit or a project to do, I'm out.\n\nDoesn‚Äôt help also when it‚Äôs like 6 something rounds with panels at the end it‚Äôs pretty draining\n\nHaving tried and failed online assessments multiple times I've become jaded with the whole hiring process and I completely agree with the author, leetcode is not representative of what you actually do as a developer, why is that the filter to getting to the actual interview?\n\nMy biggest complaint is why is it timed at all? 3 questions in 90 minutes is either you've grinded enough to see the coding bar trivia on leetcode or you haven't, that's literally it. Wouldn't a potential employer want to see the absolute best code you can put forward to see if they want more of that? Yes you could google your way to a solution but a shoddy developer will cobble together something obviously terrible.\n\nThese interviews are very uncomfortable for me. The reality is I often do a hasty, shitty implementation as a way of visualizing the implementation and to prove it will work the way I'm thinking, and only after I clean it up into the final state and think about designing for maintainability. But I rarely have time for that last part in these interviews, and I feel like I'm being observed and judged for a quality of code I would never commit. Not to mention the pressure of racing against a clock. You could hardly design a way to evaluate how someone codes that's more different from the circumstances people actually code in. ü§∑‚Äç‚ôÇÔ∏è\n\nI would much rather produce some code instead of answering specific questions, but even then for unfathomable reasons sometimes you don't get the job.  Perhaps they subscribe to some coding practice they just don't tell you about.  For example my personal preference is self documenting code, and I use very few comments, but they may be flag planters.  If you want me to plant flags I will but that isn't what I am going to do unless you give me that expectation.\n\nWhat interviewers really want (even though they may not know it) is that you can demonstrate you are a problem solver, but that is a really hard concept to draw out of an interview.  If anyone knows any tricks in that regard I am all ears.  Regurgitating exact syntax imo is worthless.  Discussions of concepts are better but you can always ask the one things they are short on that they could come up to speed in a couple of days on.  Maybe they have not yet used Observables but they know 90% of everything else.  It would be to your detriment to exclude them just because they haven't yet delt with observables.  This goes double for newer concepts / frameworks etc.  If they have done Angular for 13 years, but haven't used Signals yet its probably fine.\n\nI had one applicant one time that answered all the questions (although there was a bit of language barrier) and ended up never contributing even one line of code.\n\nBeing interviewed and engineering are orthogonal skillsets.\n\nhad an interviewee with an online questionnaire, it was so specific to one single book about Spring Java. The answers were all the same, but you had to choose the one with the words in the right order. So dumb. And it was for sure made by some chudd who only knows Spring and thinks java can't do anything without it\n\nnone of the options listed in this article are the kind of interview that I do, which is just talking about various technical topics to judge the candidate's understanding. Maybe more companies should do that, I find it is extremely obvious when someone knows what they're talking about vs not. Also probably a lot less anxiety inducing for candidates because there's no like, question to get wrong per se. It does make it harder to have a rubric and the evaluation ends up being more subjective, but probably better to be subjective about the right thing than objective about the wrong thing (i.e. leetcode)\n\nWorked at Google, Microsoft, Wall Street with 20 years of experience and even ran my own funded company for 7 years.  I no longer am willing to do gotcha live coding interviews with the interviewer.  I tell recruiters immediately that my experience proves that I know how to code and I can point them to highlights of my work on GitHub.  Otherwise, all they would be testing is if I am willing to re-cram special case gotchas from Cracking the Coding Interview.  If the company is unwilling to realize that different experience levels require different evaluation then it‚Äôs not a company that knows how to broadly manage senior people and I don‚Äôt want to work for a company like that.  If they want to give me a take home coding exercise after they‚Äôve done all the other interviews with offer in-hand then sure, happy to give them some assurance\n\nOne cause ... the interviewer is typically asking questions from their own experience - instead of learning about and probing the interviewee's experience.  Example: Interviewing at Google and all of the questions are about horizontally scaled, distributed, eventually consistent search and advertising applications.  The interviewee's background is vertically scaled, always consistent, high-speed financial transaction processing where the customer's balance must be accurate ... all the time.\n\nPreface:\nI've been a head of eng and consulted in building high performing eng departments.\nI've with faang (never have and never will until my last breath).\nI've built and maintained systems that support multi billion businesses. And helped launch number of startups. So I've got a broad T skill set.\n\nTechnical interviews are nothing but a circlejerk, that's it. \nSome a-hole got through into leadership, and needed to improve their department. Instead they blamed it on recruitment process and decided to instantiate an archaic model that DOESN'T work, yes that is correct, it doesn't (plenty of research out there just google it).\n\n\nFunny fact.\n\nSenior Civil Engineers go through less rigorous recruitment then a junior swe. Their hiring rate is higher than see.\nAnd if they fuck up a bridge falls over and kills people, they can't just restart it.\n\nHey look it‚Äôs also me, 20 years in tech having delivered huge scale solutions highly efficient, low cost and virtually scalable forever, but fuck me for not being able to implement a merge sort from memory on a 20 minute limit, or initialize a 2d array in a specific pattern in a recursive way in those 20 minutes.\n\nFuck FANG and what they did to tech. Coding interviews are fully bullshit and asses nothing, in the age of ChatGPT I can legit setup a screen reader to give me the desired answer in any language instantly. And even if you hire a dud guess what happens in the U.S.? They fire your ass on week 3 and you out.\n\nFix the broken tech hiring process, I have called out many interviewers, and companies including the ones I been at for having a shitty process and the answer is always the same, they agree it sucks but then deny my attempts to better it.\n\nWow, it's incredible how much conversation this sparked. Either I hit on a nerve or the bots really just latched on to this one. Lol.¬†\n\nOne thing I see mentioned is specifically how difficult code challenges in themselves are.¬†\n\nTo be clear, the puzzle nature of them is difficult. You stand very little chance of being able to reason out a solution on the spot to a lot of them. In the same way that a Rubik's cube is incredibly difficult to reason about but super easy once you know the patterns to solve it. The only way to be good at them is to expose yourself to them. I.e. grind leetcode.¬†\n\nSo if the org has determined that's what they need on their team for whatever reason and this they optimize their hiring for it, then that's what you need to do to get in there.¬†\n\nI argue most orgs don't need that level of optimization or specificity of technical requirement.¬†\n\nAs an example, and the catalyst for the post itself, I interviewed at a place with a presumed good culture.¬†And everyone there was incredibly nice and kind which seemed to back up that culture.¬†\n\nHowever, for a senior frontend engineering role the process was: \n\n1. Recruiter screen \n2. Hiring manager screen \n3. Code pairing screen (live coding building a thing)\n4. (Then the proper loop)¬† Project presentation (present a project you led etc)\n5.  Culture fit (team values type deal) \n6. Live technical (build another thing) \n7. Live technical 2 (build another thing)\n8.  System design ( let's talk how we might build a thing at scale)\n\nThat seemed wild to me given I know what people on those teams are doing (I know people üòâ) and how daunting/exhausting it all was.¬†\n\nI can say with a good degree of certainty that I was very ho hum in those technicals. I got to working solutions and knew in general what I was doing but I had little confidence given all the things. Plus I could recognize the initial draft state of my code. Could the interviewer? Don't know.¬†\n\nFor the system design, I did solid but we ended talking about backend system stuff regarding some things I hadn't encountered. While I offered solutions and considerations at the level I had encountered, it wasn't enough. So we talked and eventually came to the answer. But it likely didn't land well given I didn't know it off the bat or how I sweated through the whole thing.¬†\n\nAll for a senior... SENIOR frontend... FRONTEND engineer?\n\nWhat does a staff or principal hire loop look like? Meeting with the board of directors perhaps? Is blood involved?¬†\n\nMy issue is this is FAANG level interview loops for a very much non FAANG position. Meaning this could have been 3 or 4 interviews.¬†\n\nI didn't get the job (obviously lol) but had the interview loops been better fitted to the role fair enough. I know I'm not the best or fastest engineer. Far from it, but I do know I'm better than those technicals would have you believe.¬† I've worked with tons of incredibly smart and capable engineers whom I look up to. I strongly suspect they would not be able to consistently pass those loops either.¬†\n\nThe best interview I ever had was with two of the best engineers I've ever worked with and we barely spoke about technical stuff ...\n\nThey had built a REALLY successful software company this way. Even training Microsoft staff on Microsoft technologies ...\n\nIf technical interviewers rely on techie quizzes, they shouldn't be interviewing, IMHO.\n\nGame recognizes game.  I think much of these processes are built around the idea of non-Game trying to recognize game.\n\nI'm a Team Manager who regularly interviews software developers. I don't use technical tests at all, I just talk to the applicants. I ask them about past projects, can they tell me about something cool they've coded, what kind of coding to you enjoy the most, etc. I feel like I get a fairly accurate picture of their abilities by just doing that. I see no need for all these high-stress tests. They're not realistic anyway.\n\nI suffer my fair share of imposter syndrome, but my peers tell me that I'm a good engineer.  In 30 years of doing development I've never had to go through an interview, always recruited to join based on my reputation (even for my first internship) -- I even went solo for a while doing consulting and was turning away more work than I was taking.\n\nI don't know how I'd fare in an actual interview, and the prospect scares me. :)\n\nGot rejected once after a live coding interview. This was already the 2nd interview round after passing the take-home test and the 1st technical interview. The reason they gave me (only after I asked why) was that I didn't follow TDD according to the _exact_ steps and sequence they wanted, i.e. write test, run test and fail it, write/edit code, run test and pass, clean up/format/optimize code ü§∑üèª‚Äç‚ôÇÔ∏è\n\nSounds like you dodged a bullet on that one\n\nInterviews should reflect the team work style and skillsets required to be successful in the role. Most companies seem to want to ignore customization of the interview process and fit to industry norms, which are largely awful. Spend a couple hours thinking about the process and figure out how to test for the capabilities your team specifically needs. Don't make the interviews a pressure cooker if you're not part of a high pressure team.\n\nI've been doing technical SWE interviews for 20 years at a large tech company. There's the \"How many marbles are in this jar?\" or \"Why are manhole covers round?\" type of questions, which I don't really care for.  The reason you get linked list questions, isn't because it's important to know linked lists, it's a common software data structure that we can talk about and understand together.  IOW, getting the answer correct is not what we are looking at.  I'm looking at, \"Can we understand each other?\", \"Are you going to get defensive when I say your code is wrong?\", \"Can you communicate technical details easily?\", \"How does this person tackle a problem?\"  Programming skills can be taught and adapted on the job, but being a difficult co-worker or working in a silo is something that we are trying to avoid.  I've worked with genius software engineers that were incredibly hard to work with and I will avoid these types at all costs to maintain the team culture.  I'll take a good teammate over a strong coder all day long. One of the questions I ask is impossible to answer unless you worked within my company.  The only correct answer is \"I don't know\".  You'd be surprised how many SWEs are not humble enough to say that.\n\nHere's my opinion ... most of the 'technical' interviewers I've run across aren't all that technical meaning they lack the skills necessary to evaluate a good answer.  All they seem to do is match the interviewee's answer with their notes.  Secondly, sometimes they ask questions from the last page of a reference manual as if they assume (incorrectly) that all have memorized every function / keyword.  Thirdly, many technical interviewers have yet to grasp the concept of semantics v. syntax, meaning it's ok if a person doesn't know every syntax nuance ... it's pretty easy to lookup .... for example a mainframe JCL question \"what is the parm MEMLIMIT used for? and how about NOLIMIT?\" ... if they don't know this, it doesn't mean they don't know JCL all it means is they don't know that parameter .. NOT THE END OF THE WORLD!!! ... and instead of asking questions repetitively, let the interviewee talk freely so the interviewer can evaluate the entire answer not just some stupid question about a rarely used feature ....Keith\n\nMicrosoft is notorious for their interview process (or, at least they were when I was joining the workforce in the 90s), but I accidentally discovered how to hack their interview process as I was leaving graduate school. \n\nI had been studying something known as ‚Äúfeature extraction‚Äù in problem solving, which is how humans understand problems and choose the things that they want to focus on in order to solve them. \n\nBecause this was my field of study, every single interview I had with Microsoft ended up being a conversation about my research techniques and problems, at which point the interviewer would go into ‚Äúauto‚Äù mode and tell me about how they perceived problems and how their interviews typically worked. It was pure hubris. I would just sit back and have a conversation. It was all very interesting, but none of the technical questions ever ended up being directed at me.\n\nAmusingly, I had the opposite experience at Google, a long time later and after I had become a VP and spent a bunch of time managing teams instead of coding. I was visiting the campus to interview for an executive position, and *every* *single* *person* *asked* *me* *coding* *questions*. I was incredulous. I finally stopped a senior manager who had asked me to whiteboard some ridiculous algorithm and said ‚ÄúI think we‚Äôre done here. You have no idea what management is‚Äù and left. \n\nTalked to the recruiter later and mentioned my experience and he said, ‚ÄúI wish I could tell you that was the first time I have heard that feedback from other executives.‚Äù ü§£ Permanently took them off my consideration set after that.\n\nIn 2003 I was trying for just a (mostly Linux) Desktop Support/Jr. SysAd position at Google HQ.  They grilled me in 4 sessions with normal questions which I sailed through.  They were oddly not at all interested in ‚Äúfit‚Äù within the team.  Then, they started asking if I had any co-authorships in any of the published Internet RFCs in my fifth interview‚Ä¶ I asked them, ‚Äúso you have RFCs authors working as Desktop Support?‚Äù  They said most did, yeah. I couldn‚Äôt tell if they were yanking my chain or serious and said to them, ‚ÄúWell, I think you‚Äôre looking for something completely different than I am‚Äù.  Google, Facebook, et al, they are (at least were) a bunch of elitist pricks."
  },
  {
    "title": "PySkyWiFi: completely free, unbelievably stupid wi-fi on long-haul flights",
    "body": "",
    "score": 1497,
    "url": "",
    "created_utc": 1720780968.0,
    "author": "wheybags",
    "permalink": "/r/programming/comments/1e1ejon/pyskywifi_completely_free_unbelievably_stupid/",
    "all_comment_text": "&gt; DISCLAIMER: you obviously shouldn‚Äôt actually do any of this\n\n&gt; Here‚Äôs how it works (and here‚Äôs the source code).\n\n&gt;I‚Äôd forgotten to charge my headphones so Limp Bizkit started playing out of my laptop speakers. Fortunately no one else on the plane seemed to mind    \n   \nThey're confessing to all kinds of atrocities in this article\n\nIt's both funny if it's true, and funny if it's not true.\n\n[good ol' times](http://www.textfiles.com/phreak/)\n\nThere was a glorious period like 10 years ago where you could pretty reliably just select the free/way cheaper \"messaging apps only\" option and then just turn on a VPN app to get unrestricted access. Wasn't super fast but I'm not sure if that was because airplane wifi just wasn't that fast 10 years ago or because you were just getting a bandwidth allocation that was supposed to just be good enough for messaging apps and nothing else, but I want to say it was slower than if you paid so probably the latter. But it sure beat the shit out of paying the absolute gouging prices every airline was charging for wifi back then.\n\nThe in flight internet equivalent of \n\n&gt;\"You have a collect call from 'mumcomepickmeupfromschool', do you wish to accept the call?\"\n\nWeHadABaby ItsABoy\n\nBob Wehadababyitsaboy\n\nPut some respek on the name\n\nIt was Bob. They had a baby. It‚Äôs a boy\n\nClassic TV commercial moment https://youtu.be/9JxhTnWrKYs\n\nAnd ‚ÄúBig boy‚Äù https://youtu.be/BE4AgLGLUaM\n\nClassic\n\nWaiting for IPv4 over collect calls\n\nTotally possible as a modification of IPoAC (IP over Avian Carriers). Small, unidirectional data.\n\nNow I just had to come up with the link layer protocol name for avian carriers. The best I can come up with right now is flocknet.\n\nI imagine there's a lot of packet loss, &gt;1%\n\nit's unidirectional\n\nno, just half-duplex\n\nPeople will do anything to avoid reviewing PRs\n\nThis one hit me right in the todo list.\n\nlgtm\n\n\"Let's Gamble, Try Merging!\"\n\nIt still builds, ship it!\n\nFix it in a future bug update\n\ngcc: hello.c: 27 errors, 34 warnings\n\n// TODO: FIXME\n\nThis is exactly what I've been looking for for a long time. Only difference is they are doing it with an Air Miles account and I've wanted to find one that routes through Whatsapp or a messenger app as those messaging apps are usually free to use on several different airlines\n\nI bet that would actually give you a decent throughput to actually do something useful. WhatsApp can fit a whole response into a single message.\n\neven better. whatsapp supports images and video. not sure, if you can access those, though\n\nEncode all data as jpegs\n\nImagine being on that plane and you accidentally get banned because you're just trying to send a picture of a got dang hot dog\n\n\"Not hotdog.\"\n\nDo I look like I know hwhat a WiFi is? All I hwant is an instagram picture of a got dang hotdog.\n\nI've investigated this before. Most flights that provide wifi for messenger or whatsapp (but not anything else) somehow do not allow for images.\n\nI do not know the mechanism for how it's able to tell the difference but images just do not send unfortunately.\n\nimages and videos have to be downloaded separately and use a different endpoint. that's how it can tell. you can actually configure whatsapp to not automatically download images or videos\n\nImages, calls and text go through completely different servers.\n\nhttps://github.com/HybridNetworks/whatsapp-cidr\n\nIf you get caught you're going to get caught by WhatsApp though and losing your WhatsApp access is generally going to be more of a pain than losing an airmiles account.\n\nI thought WhatsApp had end to end encryption? They will probably rate limit your messages, but if you aren‚Äôt scaling up the number of accounts, it seems unlikely they would be able to detect anything.\n\nI would assume it's the same as people who use Google Docs as a \"clever\" workaround for file storage, they're not going to view the file but they're going to detect the volume of traffic and ban you for it.\n\nBan me! For enjoying a review of a succulent chinese meal?\n\nRegister a new account with a burner number then. Risk of losing it is low anyway and it‚Äôs definitely cheaper than paying some extortionate fee for in-flight wifi\n\nOr a couple of burners and send requests through multiple channels.\nOr hundreds of burners....\n\nOops! WhatsApp botnet\n\nJust le me setup some free WiFi...\n\n*Accidently creates entire Skynet Bot Network*\n\nAnd potentially you don't need to use polling if you can hook into the WhatsApp websocket.\n\n[deleted]\n\nWait really? How does one pull this off?\n\n[deleted]\n\nMy wireguard config uses cloudflare DNS at least on my phone. The server is my homeserver which seems to have had the same IP for a long time though I use a dynamic dns service just to be safe... I'll have to try it the next time I fly...\n\nWait, wireguard words if you get the messaging package on planes? This is great!\n\nhmm, I've tried this with PIA and was unsuccessful.  though I don't know if I had signed up for free messaging.\n\nIt seems to limit TCP connections but allow UDP? I've had success using 1.1.1.1 on airplane wifi\n\nIt was nice have the ChatGPT integration into Messenger. I just used it to play simple games and to bounce ideas off of something. Not as good as the internet, but it was a decent proxy. I feel like Messenger would make something like this even more trivial.\n\nWhat you're looking for exists, I saw a post about it similar to the one OP posted a year or two ago but I cba to search for it.\n\nI mean you just have to implement a pipe for WhatsApp.\n\nA lot of flight paywalls will allow DNS requests through, so it might be more effective to make requests to a custom DNS server and send info that way.\n\nI have found that I can use my OpenVPN instance running on my residential ISP to bypass in flight wifi captive portals with frequent success. The trick is to make sure you lookup your dynamic IP and clone the OpenVPN config and switch from your dynamic DNS hostname to the current IP you've been assigned before you take off.\n\nWorks reliably for me on most AA and UA flights. Slow, but works.\n\nyeah there's specific ports that are open, I remember a while back I had to set my openvpn to a certain port and then it worked on flights , though I assume as it becomes more popular maybe it got patched.\n\nWhat I have also noticed is that usually Signal messaging works on flights that allow free in-flight messaging. It has made me want to do what this PySkyWifi project did but just using the \"Note To Self\" Signal channel to act as a data proxy with the signal desktop client (or using the signal API directly).\n\nThat could be done at a very high bandwidth too, since Signal allows attaching fairly large arbitrary files.  I suspect ping/round trip times would be terrible though.\n\nhttps://github.com/aleixrodriala/wa-tunnel was posted here a while ago in a similar post\n\n*Nice.*\n\nSo you just need to hard code your IP and openvpn connects?\n\nYup, exactly. I don't have anything special like alternative ports setup or anything, just a bog-standard OpenVPN server setup on my opnsense router at home. Initially I thought it was because my ISP is google but I helped a friend setup a similar tunnel using a RPi at his place on Spectrum and his works just as well as mine.\n\n[deleted]\n\nI'm not following üòÖ\n\nWhat they posted makes perfect sense. Not sure what your reaction is for\n\nIt does but he could have just said, \"use your VPNs IP address instead of hostname when connecting to it.\" The part he bolded is kind of a crazy mouthful that no one would actually say. \n\nBut I'm conflicted because dude linked LTT who is an absolute moron.\n\nMake sure you take your configuration, right click the file, click copy, then right click on your Windows Desktop, then click Paste, then open the file, and find your Dynamic DNS Hostname, take that host name, and where that hostname is, change the host name to the current IP!!!\n\n[Your-Freedom VPN](https://www.your-freedom.net/) already support proxying over DNS to bypass firewalls (-:\n\nYou can use [iodine](https://github.com/yarrick/iodine) for that\n\nOr just get softether VPN. [Supports both, DNS and ICMP tunneling out of the box](https://i.imgur.com/cer0ZDT.png).\n\nIt also does UDP hole punching, supports common protocols (L2TP, SSDP, OpenVPN) and is stupidly easy to configure. Can be used for remote client access as well as site to site connections. It integrates into RADIUS and AD domains. Iirc on Linux it also does Wireguard. it has an L2TP mode that is compatible with CISCO routers.\n\nSome of them allow message protocols through as well, last flight I was on from Alaska I could use iMessage\n\nYou see, my old method with any in-flight wifi that was using WEP was just spoofing the MAC address of the sucker in front of me who paid to get his iPad connected. \n\nBut this seems a little more ethical.\n\nHow do you figure out their MAC?\n\nMultiple methods, you just need something to sniff ARP packets so you can see the IPs and MAC addresses of other devices on the network/AP. You could use good ol' WireShark but I think aircrack has a more dedicated tool for it, I can't remember.\n\nFar more practical than OP\n\nGiven how insanely slow the connection is, I expected him to add something like xz or zstd on the highest setting that would almost certainly cut the size down by half if not a whole order of magnitude.\n\nThat's a really good idea\n\nLove it - I did this in the '00s with text messaging and email; I'd text an HTTP request to my +http email subaddress, sendmail would read it and do the request, and reply to the email which would of course be the SMS email inbox.\n\nMany carriers actually had an email you could use to text phone numbers on their network. It used to require purchasing a special bundle on the receiving end but they‚Äôd still text you asking if you wanted to purchase it so you could still use it like a notification. \n\nThen they just started sending to everyone. And then most of them got rid of it completely.\n\nIt still exists. I assume the @ domain changes though so it's not reliable. The software we use (from the big red phone company) is still godawful and looks like its from the 90s too.\n\nThis is how I wrote the first version of my website monitoring tool I built for work back in the early 00's so that it would \"page\" me by text message\n\nThat‚Äôs very funny and a great way to pass the time on a long flight.\n\nYeah\n\n&gt; Several co-workers were asking me to review their PRs because my feedback was ‚Äútwo weeks late‚Äù and ‚Äúblocking a critical deployment.‚Äù But my ideas are important too so I put on my headphones and smashed on some focus tunes.\n\nPriorities... I think you have a bigger problem...\n\n&gt; I‚Äôd forgotten to charge my headphones so Limp Bizkit started playing out of my laptop speakers. Fortunately no one else on the plane seemed to mind so we all rocked out together.\n\nOk, forget what I said. You're forgiven.\n\n&gt; Depending on network conditions on the plane I might be able to hit speeds of several bytes per second.\n\nI had a good laugh at this, thanks for the read!\n\nAs the horror of what he had accomplished started to dawn on me, I started smiling slowly.\n\nI tend to ping google to check my network connectivity, and I discovered on a flight that Google subdomain traffic used to be allowed through a lot of airlines' WiFi. If you set your hosts file to map app engine to a Google subdomain, the GFE will still serve it.  Find a proxy server running on AppEngine, ????, profit\n\nI haven't tried this in maybe ten years, but it's always fun when captive wifi is poorly set up (except when the login redirect is broken and you're just trying to get work done -_-)\n\n&gt; At first I thought that I‚Äôd write them using Go, but then I realised that if I used Python then I could call the final tool PySkyWiFi.\n\nYeah, but you could have called it `WiFiOnTheGo`\n\nBrilliant\n\nAnd here I thought I was clever for using SSH tunnels to get free wifi at JFK.\n\nIsn‚Äôt there free wifi at JFK? Lol\n\nThere is *now*, but not 10 years ago\n\nThis is amazing lol\n\nHowever I suspect that the carrier will close this hole when they hear about this.\n\nI would expect them to have rate limiting and request size limits anyway to stop DoS attacks\n\nJust one firewall setting away from giving Robbie boy another challenge to hack on his next flight.\n\nAirlines hate this little trick!\n\nAm I insane? no it is the man who is wrong\n\nAbsolutely brilliant\n\nUnited allows SMS and RCS to bypass the paywall. You could send packets back and forth using text messages. Would probably be super slow and might get throttled but probably can be a form of proxy.\n\nI'm pretty sure that's illegal.\n The Limp bizkit I mean.\n\ndoesn't the geneva convention ban audible limp bizkit? real foresight too, because limp bizkit came afterwards.\n\nI don't have sky miles account, but are there any bigger fields where's you can write more into the fields in one chunk, and/or write into multiple chunks at the same time to greatly improved the bandwidth?\n\nYes, he mentioned that in the article\n\nWhy limit yourself to one account? Get a bunch and start sending all that data\n\nThis was the most amazing waste of time I‚Äôve ever read, and something I would love to mess with. 10/10\n\n&gt;I‚Äôd forgotten to charge my headphones so Limp Bizkit started playing out of my laptop speakers. Fortunately no one else on the plane seemed to mind so we all rocked out together.\n\nEveryone minded, but were just more polite than you.\n\nIt‚Äôs very obviously a joke in the spirit of the post\n\nJokes are funny, but you have to be careful posting them on the internet because there are people on here who've never heard a joke in their life and they **will** take you seriously\n\nWhat is a joke and why am I so angry hearing about it?\n\nI already got my pitchfork and torch out!  I don't know what this \"joke\" thing is but something is getting destroyed before I put it away!\n\nObviously if you're angry, then the joke is about you. You should *totally* be angry!\n\npretty genius.  wonder what the transfer rate was.\n\n&gt; Depending on network conditions on the plane I might be able to hit speeds of several bytes per second.\n\nhot damn\n\nGlorious. Thank you.\n\nI love this. Implementing the CONNECT functionality to make proper proxying work would be a great little project...\n\nway more cursed than I was expecting.\n\nWhat a great article\n\nbecause it fly in the py in the sky\n\nI can only aspire to have this level of development knowledge and patience.\n\nThis is gonna get buried but reminds me of these old internet booths at truck stops back in the 90s and 2000s. They had a splash page where you put your billing info (through a card slot) along with several links to games and other trucking related sites. There was no keyboard, but I found out you could explore the entire web via six degrees of separation by just clicking links without paying. It just took a lot of guessing and trial and error. Eventually the vendor realized they were not making any money on it and removed the machine from my local truck stop.\n\nJust proxy a whole VPN over this kind of stunt and get everything... Until the suits at these companies realise that it is bandwidth they should be charging for, not use cases.\n\nThey were getting everything, through a custom VPN, with a device on the ground updating the username on the airmiles account to send the data through. Did you read the article?\n\nRemind me of a talk I saw at Ruxcon years ago about a too called XFLTREAT which could be used to tunnel through all sorts of protocols. This is the same talk: https://m.youtube.com/watch?v=SA6S_VqtBb4\n\nHilarious!\n\nReminds me of something I built: there's a server where I have ssh access and can host static files, but there is no way for the browser to connect to the server. In theory.\n\nIt is possible to use inotify to detect when a file is read. I now have a chat program where each character to send reads a different file and the server will register that as the message being sent.\n\nsee http://tilde.town/~troido/notifytest/\n\nTldr?\n\naccessing the internet through changing your account name\n\nTo expand on this further- the captive portal on the flight allowed you to log into your Sky miles account (presumably so you could update the profile and pay with air miles for the internet). However by doing so, you can \"leak\" information to the outside world by changing your username. If someone on the ground has your AirMiles login data, they could read the username and then edit it themselves, sending you a reply and facilitating two-way communication.\n\nEditing the username isn't rate limited, so with a little effort you can write a script to send arbitrary data through your username and get \"Free\" WiFi on your flight.\n\nOr course this is a terrible idea for numerous reasons. Don't ever do this seriously, but it's a pretty funny \"exploit\".\n\nNeat, I made a browser extension for a forum that did verification via updating their signature.\n\nBecause anyone who used the extension could say, \"yeah I'm definitely this person!\"\n\nBet. Let's request ``website.com/profile/edit`` and check the page.\n\nThe payment page on the airliner where you would normally have to pay to get internet access, gave you access to your airmiles account so you could use it to \"buy\" internet access with airmiles. This meant you could access your airmiles account freely without paying, as the airline assumed the only possible use of your airmiles account would be to pay for internet access.\n\nGuy decided it would be fun to use this feature to access the internet without paying, by setting up a service on his home computer that logged into his airmiles account at the same time and used the user profile's name field to communicate (very very slowly by proxying all transferred data through airmiles's web UI) back and forth between the client on the plane and the server at his home. He then successfully used the user profile's name to send an entire webpage over the course of two minutes while airborne, for free, and called it a success.\n\nIt is a joke, but it is genuinely kind of fun to poke holes in these paywalls.\n\nThanks!\n\n&gt; I‚Äôd forgotten to charge my headphones so Limp Bizkit started playing out of my laptop speakers. Fortunately no one else on the plane seemed to mind so we all rocked out together.\n\nNarrator: they minded.\n\n\\&gt; But my ideas are important too so I put on my headphones and smashed onsome focus tunes. I‚Äôd forgotten to charge my headphones so **Limp Bizkit** started playing out of my laptop speakers.\n\nGross\n\n&gt; It's my way or the highway! Someday you'll see things my way, but you never know! but you never know!\n\nI‚Äôm confused why anyone would go to all this effort when it was a work trip and you can just expense the WiFi access charge.  If your company isn‚Äôt going to approve it, then don‚Äôt work.\n\nBecause it was a fun experiment.\n\nBecause that isn't the hacker spirit.\n\nIf you had read the article, you‚Äôd know that he *did* pay for wifi access. He build the prototype anyway.\n\nWhy would anyone do anything if not this"
  },
  {
    "title": "Why don't tech companies pay their engineers to stay?",
    "body": "",
    "score": 1489,
    "url": "",
    "created_utc": 1725577505.0,
    "author": "StellarNavigator",
    "permalink": "/r/programming/comments/1fa09fs/why_dont_tech_companies_pay_their_engineers_to/",
    "all_comment_text": "You're lucky if a 2-5% annual raise keeps up with inflation. When you can leave and get paid more as a new hire, the incentive to stay is upside down. Honestly, the only reason I don't job hop more is I really dislike dev interviews. The time commitment of multiple interviews with multiple companies is daunting.\n\n\nThe loss of institutional knowledge is no joke. It takes months to get ramped up on a big codebase, and years to master. Losing devs who understand how it all works is a giant loss for a company. No clue why companies don't try harder to retain talent.\n\nIt's ridiculous they hire new devs off the streets for 10-20% more pay than devs who been at the company for a while. I've been at the same company for 14 years, I enjoy my job and I get paid enough to be comfortable but if they hired someone at my level right now they'd probably get 50k more than I'm getting.\n\nIt's. Called wage compression and it's a problem for companies. They don't appreciate the new blood more. See it as if they purchased a property (you) 10 years ago vs now (new guys). You get more bang for your buck with the old guys and squeeze that for as long as you can for financial gains.\n\nIf they start raising you to the market they need to do it for everyone and they can't afford that shock.\n\nNegotiate a raise and promotion, even if you must create a new role for yourself.\n\n&gt; and it's a problem for companies. They don't appreciate the new blood more. See it as if they purchased a property (you) 10 years ago vs now (new guys).\n\nDepends tremendously on the company, but yes, it absolutely happens at bad places.\n\nIf you are at a company and the regular raises are only for COLA, and *especially* if it is a company that treats COLA as merit based, that's a company with a problem. There is normally zero reason to stay if you're earning below your market rate.\n\nMost of the tech companies I've been at have given an annual raise to whatever the current industry rate was.  The biggest have been a roughly 10% raise when markets  changed, but always it is more than just COLA. \n\nOver my career I've been at a few companies that merely kept up with COLA, and one that offered less than COLA because they said times were tight. In each case I pushed back on it in the review, with something like *\"this isn't keeping up with market rates, meaning I can find more money elsewhere, will you be fixing that?\"*, and in the case that didn't keep up with COLA saying *\"This is effectively a pay cut, not a raise. Will you be fixing that?\"* and in the less-than-COLA raise they said only top performers got COLA.  There was only one time where they came back with a better annual raise. In every other case I had a new job a few weeks later.\n\nGood software engineers will have no problem changing jobs. The good companies know it, and adjust pay accordingly. If you can get an offer elsewhere for a better job, don't overthink the transition.\n\nWhat is COLA? Cost Of Living A....?\n\nCost Of Living Adjustment.  In theory it's the local rate of inflation, but in practice usually is less than that.\n\nI'm a director now leading a super specialized team and I'm pretty much ruler of my own little kingdom. I'll never get fired but I don't think I'll ever get higher than director, the work our team does just doesn't require that level of leadership. Like I said, I like my job and I make decent enough money for my lifestyle. I'll probably just stay here until I decide to get outta the industry.\n\nBut I agree, younger go getters should keep looking for better opportunities.\n\nEssentially set myself to interview every 12-18 months, even if I don‚Äôt want to hop talking to recruiters and browsing can get me a beat on what I‚Äôd make elsewhere and outlining what I do to my current employer and a new employer is pretty similar. \n\nThat lets me outline a convo with my boss ‚Äúhey, recruiter approached me with an opportunity paying x% more. I‚Äôm going to talk to them and see what‚Äôs up. This is what I‚Äôve done/am doing for you/the org. Make an offer if you want me to stay‚Äù have a number in mind to ask for. \n\nOnly really works if you‚Äôre willing to hop if they won‚Äôt meet you at least part way.\n\nAnd you approach your employer with such an offer with that constancy? Wouldn't they be annoyed?\n\nIf engineering interviews weren't so terrible, salaries would be twice as high. They are easily the biggest reason people stay put.\n\nThe hr people reading this are ab to make them harder üòÜ\n\nThe programmers reading this should start writing HR software and soon enough we won‚Äôt have to deal with HR people at all! /s\n\nI believe they are working on replacing much of HR with AI.\n\nA lot of hr is already replaced by hr software, but hr insists on making their processes as obtuse as possible so nobody would try to figure them out.\n\nYou can replace HR with a suggestion box and a monthly kick in the crotch. Fuck those turds.\n\nWell, when you consider AI is just bureaucracy on silicon, and HR IS bureaucracy on carbon, it all makes sense.\n\nI've been at my job 8 years. Don't plan on leaving because I suck at interviews and it's stressful\n\nbeen at my job for 17 years. i know i pretty much destroyed future career prospects, cause some of the stuff I do, no one would really do anymore so fairly out of date....\n\nProblem is, only work 30-35 hours a week, work from home, very little stress, very rarely deadlines, zero overtime, flexible work hours, minimal oversight, only a couple meetins a week,  and I can generally work on what I want as I am a one man team.  Pay is okay at ~140k (im also in canada where pay isnt as high as the states). I know I could make more somewhere else, but at the loss of a lot of those other benefits, and those benefits are easily worth 30-40k for me. \n\nI also like my coworkers. Almost all of my coworkers have also been there 10+ years.  Longest being 30, and 3 others being 20+. \nAnd now I have a family, so the extra time and flexibilty comes in great with the kids. And I do actually enjoy my job.\n \nMakes the job very hard to leave.\n\n&gt; only work 30-35 hours a week, work from home, very little stress, very rarely deadlines, zero overtime, flexible work hours, minimal oversight, only a couple meetins a week, and I can generally work on what I want as I am a one man team\n\nCount these among the non-financial benefits in your calculations.  They have value, even if it isn't shown in your paycheck. \n\nShorter work week is valuable, sounds like 5-10 hours per week valuable in your case, effectively giving a 10%-25% hidden raise against the expected 40-ish hour week. No commute is valuable, depending on distance it can be hours per week, and studies show a benefit of WFH is worth about 10%-15% in total pay. Flexible hours are extremely valuable, studies say on average people are willing to take about 20% less pay for highly flexible hours. \n\nEvery individual could value those benefits differently. To me, I can easily imagine what you described as worth 50K or even more.\n\nI did mention  those benefits were worth at least 30-40k for me  because I do agree they are worth a lot.  Pre Covid my commute was 30 minutes each way, so that saves an extra hour per day, plus gas /maintence  saved, less eating out for lunches, stress from driving..\n\nI mean, what, you're making more than enough to cover your expenses and have a nice lifestyle, *while also* having a nice work environment? How much peace of mind is another 20k going to bring?\n\nI daresay my colleagues are in a similar position, right down to the 'being in canada' part. On the one hand it's a great position to be in if you have other things in life you'd rather prioritize, on the other it's not so good if you want to jump to something better.\n\nI‚Äôve been laid off twice in 2 years. In this market one does a lot of interviews. It is awful and usually has nothing to do with skill\n\nSame. Except 21 years. ü§Ø\n\nNever did the job hopping thing. But I'm at a great company, work on cool projects, and have been able to move my career forward through many promotions.\n\nI probably could have got where I am faster by job hopping, but I've been remote the entire time and it's been a great work life balance.\n\nWow. You're a veteran. How many raises did you get?\n\nHonestly it's been pretty good.  When I started I was right out of college. Salary was 66k which was definitely on the lower end for starting software developers.  Now I'm at 170k base with ~20k bonus. I could get paid more somewhere else but I'm happy for now with the salary. I do hate going into the office but that bullshit is common amongst most companies in the last year.\n\nThe nice thing is that the company seems to like you.  Most devs don't last that long and very often not by choice.\n\nMove to a new company, and you could be moving on in 2-4 years because either you don't like them or they decide your pay is too high (or something else).  \n\nIt leads to one feeling they always have a gun to their head.  You have a good thing going.\n\nHaving said that, I personally would still take 2x-3x the salary for the increased stress, but that is just me.\n\nThey are so dumb. Companies are throwing so much money away to overpay for people to be good at things they don't need.\n\nMan in my experience you're lucky to get that level of raise. The company I'm leaving (mostly not pay related) gave me 0.7% last year and expected me to be act like they were the bee's knees for it.\n\nThis year no raise and the message your lucky to be paid so much!\n\nI get the impression this was one reason the tech interview was made the way it is today. They say it's to filter out candidates. Maybe that's one reason, but for that, there are a dozen ways to skin a cat.\n\nThe real reason they continue to use ridiculous leetcode questions? To suppress labor market competition. As a married man, with 3 kids and a full time job, it is really demotivating to think I'd have to spend hours of my \"free time\" practicing toy problems that will have little to no return on my skill level of actually development work. I strongly doubt I'm the only one.\n\nCan you track experience and the consequences of losing it in excel? No, so the penny pinchers don‚Äôt care.\n\nWell, it's a political issue.\n\nIf you give raises to good engineers and generally treat them well to make them stay, then you give them value and therefore political power to oppose management decisions.  And management as a body hates nothing more than people having the power to oppose them - for instance, see how the reaction to unions or even to basic worker protection laws goes way past anything reasonable.  The workers *cannot* be allowed any power.  Therefore they *cannot* be valued for their technical knowledge, even if the loss of that knowledge hurts the company.  Indeed, replacing an experienced worker with a new one lessens their political power - a new starter knows nothing of internal politics - so it's worth paying more.\n\nThis is, of course, madness, but it's a feature of how humans work in groups.\n\nI don't follow that logic at all.\n\n\nIf you keep people around by paying them well, that has no correlation with decision-making power. In fact, if you pay above-market wages, they will be LESS likely to oppose management decisions.\n\n\nUnions are all about joining together as a group to increase leverage in order to persuade a reluctant management to give you (the unionized workforce) more. If you're already getting more, what would you even use the leverage for? And what would be the nature of the threat? \"Increase our pay, or we'll quit and go elsewhere and work for less...\"\n\nPeople who stay around each other long enough tend to form friendships. Like genuine ones, not just ‚ÄúI‚Äôm friendly to a coworker I met yesterday.‚Äù\n\nA group of genuine friends at a workplace is functionally indistinguishable from a union. And they might be very unhappy if you decide to lay off one of them, or worse, start using Tailwind.\n\nI tell people all the time, companies don't actually care about money. They waste tons of money. The motivation for everything a company does is the top 20% of the company trying to feel powerful. \n\nMost companies could add 20-30% to their profits if this changed.\n\nI don't agree that this is how humans work in groups. I think it's one specific type of person who always fights to get in power and then forces systems to be this way. \"A types\" will (and always have) destroy everything good in the world just to feel even slightly above others.\n\nSince that type always fights to get in power, and groups of people will have those types, it is how humans work in groups.\n\nNot to disagree with what you're saying, but the reality is kind of dismal because of this.\n\nAdapt, abandon companies as soon as they don't pay you what you are worth.  Milk their piggy titties for all they are worth and then dump them as soon as you find a bigger pig.\n\nIt is the same in most industries where skills and knowledge are critical.\n\nThe cost of a new worker includes a \"spin up time\" to learn the ropes. This means it takes the new employee a few months to get productive. HR always seems to ignore this cost when keeping good, experienced employees.\n\nIn software it is one reason why we see the same mistakes repeated over and over again. Those who knew why it won't work are no longer there.\n\n&gt;This means it takes the new employee a few months to get productive.\n\nI would argue it's worse than that. It might be a year or so before even a good engineer confidently knows their way around most of the code and tooling stack.\n\nLots of bigger companies love to promote and push their good engineers towards ‚Äúengineering manager‚Äù roles, and they often entice them with pay bumps. Suddenly your best engineers are bogged down with meetings and managerial work in a middle management role. They‚Äôre often the first ones culled during layoffs. Now they have probably let their technical skills get a bit rusty so they have to either hit the grind to essentially study for IC technical interviews again, or continue looking in the management roles. For some that may be their desired path and they may succeed and get lucky to move their way up the ladder towards VP/Director/Executive roles and make boat loads of money, but there are far fewer of those positions than there are engineering roles.\n\n&gt;Suddenly your best engineers are bogged down with meetings and managerial work in a middle management role\n\nMy life!\n\nThat‚Äôs assuming they know a decent amount of the stack. I went from engineering in Linux + Java to development in an all Microsoft consultancy. It‚Äôs been 10 months and I‚Äôm still lost in the sauce when navigating unfamiliar terrain. It doesn‚Äôt help we don‚Äôt document anything.\n\nI document everything, almost nobody reads it\n\nAnd there's the rub! This is why I find documentation so annoying - I know it won't be looked at.\n\nI have such bad memory that 99% of the times I write documentation for my future self. That‚Äôs the way I convince myself to do it.\n\nGood strategy, thanks. I shall employ that thought process in future.\n\nThat's me. I mainly document for myself. There are too many small details that are easily missed if you're doing everything from memory. But I'm also a documentation nerd. I encourage documentation all over the place; work, home, volunteer organizations I work with, etc.\n\nEven if I do look for it, I half the time am not sure where to find it anyway.\n\nI promise you I'll read it, but I'm the QA guy looking for anything and everything that can tell me what this damn thing was supposed to do because the business analyst hasn't written anything on it in six years and we don't have a curated regression library.\n\nIn one company our team leader has asked us to write a small note under each ticket we've closed, describing what has been done.\n\nI put a real effort into this, documenting all the changes and caveats, making sure my notes are easy to understand by whoever will be reading them in the future. Then after a while I noticed I was literally the only person who actually bothered. It wasn't even an issue with quality; it was an issue of no one else actually doing anything. I kept on writing that documentation but it was only for my sake now, so it stopped being nearly as good.\n\nThe only bit of satisfaction I've had was when I was leaving, team leader has asked me to write down all the information regarding the stuff I've worked on recently and I've replied \"no need, already done\". Doubt they've ever used these notes though.\n\nI'd been working as a system integrator&amp;tester on train projects for 5 years now. There are still subsystems I only have cursory knowledge of.\n\nI'm not sure but to me it comes from above HR. That's a direct consequence of leaders immaturity. They'll refuse efforts until things blow up in their face. Countless stories of companies refusing to pay median salary for their most productive employee only to have to hire a new guy for 30% more after he's gone. Our most paid colleague was hired because somehow the higher ups were anxious and said yes to anything he asked.\n\nAfter working nights for a week to deliver a project that needed more than a week to get done, I got laid off from my previous company. 3 years of service earned me 2 weeks severance. \n\nNever again. I really like my new company, but I‚Äôm giving it a year or two before I start interviewing again. If my raises aren‚Äôt matching my offers - ‚úåÔ∏è\n\nSame with my wife.  Worked for those motherfuckers like a dog for 5 years, puttin' her absolute best into it.  They yeeted her and a fifth of their regular employees for a few extra pennies of stock price.  Severance was good, but that was some real fuckin' brain rot, right there.\n\nWe're doin' our own thing for a bit, tryin' to make games and shit, but if push comes to shove and we gotta get back to working, neither of us is givin' more than precisely what the job requires.  They want more, they can fucking well **pay** more.  No more bustin' our asses so some C-suite prick can throw us away after they get into a gasoline huffing contest with the boys.\n\nLoyalty and dedication are earned, and corporate culture has proven to be unworthy of either.\n\n\nOn reading the first sentence, I really thought this was going somewhere else haha\n\nI made a commitment to myself early on to never work for a publicly traded company.\n\n\nSpent three years in a startup as the second employee working mostly 70 hours a week with promises and carrots and plenty of sticks.¬†\n\n\nNothing came - including a raise - so I asked for one and got countered an insulting amount. Quit on the spot, found another job within three days for $5k more than I'd asked for, told them I work 40-45 hours a week and have gone the management path since then.\n\n\nNow when I hire people, before they even sign an offer letter, I tell them working 50+ hours a week won't do anything but show me they work too much. I'd rather they decompress, spend time learning, whatever. Just not working.\n\n\nIf we fall behind as a team and we're not slacking it just means the business needs to lower demand or add head count.\n\n\nI've been with this company a little over five years now (avg tenure is currently ~12 years), have somewhat golden handcuffs for my area and life/work balance but still interview every six months or so to see what's out there and retain the skill.\n\n\nSet the expectation of your workload early. Ask about the expected hours, state what you'll contribute, and if it doesn't match up it doesn't match up.¬† Burnout just isn't worth it, ever, and everyone burns out eventually.\n\nYep. No company will love you. And most of the people you work with, no matter how friendly you are with them, will forget you after a few weeks. Ultimately, in the working world, you need to be concerned about you, because no one else will be.\n\n&gt; I really like my new company, but I‚Äôm giving it a year or two before I start interviewing again. If my raises aren‚Äôt matching my offers\n\nAlways be interviewing is the best advice I give to everyone. Not only is it a great way to keep those soft skills sharp, but you never know when an even better role may come along.\n\nI put A LOT of overtime into an application during COVID and was able to deliver it and the users were very satisfied. Sadly, I was borrowed from another department and my position was terminated there.\n\nMy reward was that the department that borrowed me fired an incompetent dev to hire me as a consultant earning 3x more.\n\nOnly time my effort was actually positively rewarded.\n\nIt‚Äôs the only way to fight back. Learn or earn is the motto.\n\nLately I've been real short on pigs¬†\n\nSeriously, fuck em\n\nBecause they are arrogant and think they can hire anyone off the street for less money yet with the same technical skills ... and boy are they wrong .... being a \"developer\" is more than learning every builtin function in a language, it's how you put these rudiments together to create a viable system that delivers ALL the business requirements.  My first programming class at UCLA was PL/I (actually PL/C which is a small subset of PL/I developed at Cornell) and one of the texts started with this quote \"Programming is more art than science\"  and I looked at that quote back in the day and gave it a \"oh come on\" ... Forty+ years later I now understand completely what they were referring to ...\n\nThis is honestly why I do not fear AI. The actual coding has never been the difficult part of the job, and in fact is usually the easiest part that comes last.\n\nIt is the designing, team building, consensus building, organizational &amp; domain knowledge, etc etc that is difficult. The reason one engineer is more effective than another is not at all related to how much code they ship. \n\nIt‚Äôs why I roll my eyes whenever I see some ‚ÄúCEO‚Äù on LinkedIn get excited about AI‚Äôs potential to replace devs.\n\nEven the coding part itself can be extremely difficult. Since AI needs prior art to do anything, new or obscure language features are largely unavailable to AI. If we only use LLMs to program, the quality of output will be trapped in 2022 or 2023, and will degrade over time.\n\nAnd when the coding becomes hard the AI fails. It's great when you give it a blank slate and a clear prompt on what to do. But it doesn't understand bloated API's, unclear dependencies, or complicated branching paths.\n\nI don't fear AI. I fear idiot managers thinking they can replace their staff with AI. While eventually that company will have to come back and hire flesh and blood people, there will be tons of harm done in the mean time.\n\nI love this comment. We need to stop teaching people that technical knowledge is itself intelligence.\n\nPro-active companies will offer a Retention Bonus contract, money paid if one stays for a specified time period. \n\nReactive companies wait for a resignation letter then may or may not match the offer to retain talent.\n\nI‚Äôve had several companies try to match offers and I‚Äôve literally laughed out loud in those meetings. If I go through the hassle of applying an interviewing for jobs, you better pay me more than they will because I‚Äôve already got a heavy investment in those positions. Simply matching an offer is an insult.\n\nI feel like anything is an insult at that point. Just match or barely beat the offer? Yagottabeshittinme. Offer significantly more? What, you‚Äôve been purposefully and knowingly underpaying what you feel I‚Äôm worth this whole time?\n\nI won't be insulted by the latter. Money is money in my eyes lol \n \nI understand things don't get escalated unless it's made real, so if me getting another bigger offer made my current company substantially exceed it just to keep me, we good. Then again I like my team and boss\n\nthey could also just be paying you enough to fire you on their own schedule &amp; you end up with no job\n\nA common case for looking for a job was to get a raise.\n\nYou might have had a compensation discussion or two with your manager off the annual cycle to get a significant raise in place. Even if manager wants to do it, acts in good faith, there's HR discussions that need to happen to justify it and those cycles aren't short. It may be weeks to months between hearing about updates. If you're lucky you've gotten a 5%-10% range raise off cycle back already. In current economy state it might be entire quarters before HR even behind to consider it due to cost control mechanisms being tight.\n\nYou've decided to explore outside options to fulfill your raise need. In hot markets, you might have an offer 2-3 weeks later. In colder markets this is still longer but 3-6 months isn't unreasonable to make first offer with some investment in the cycle. No matter what, it's easier to convince a new company's HR to hire you than current company's HR to give you a raise under no duress.\n\nHypothetically you've been strung along for 5 months by your company for whatever reason (manager, director, hr, finance, whoever is the hold up) on getting you the proposed 10% raise. Clearly the standard \"need to show high performance over time\" line has been given. You've submitted 2 weeks notice to go get a 20% raise. Within 5 business days you have a match offer from your original company.\n\nWhat does that say? \n\nTo many, it says you were always willing to pay the new price for my labor but you refused for reasons. It says the company could have moved faster on the original request but chose to drag their feet. At this point it is only indirectly about the money. Faith and respect in the company system is lost. You can definitely work for some time without faith and respect but then you start behaving differently and generally, people want to respect the entities they are interacting with for most of their day. \n\nThere are other dangers in taking the counter offer I won't get into. But that's a common sentiment I've run into about companies waiting to counter offer.\n\nI‚Äôm with you. One of the reasons I never stay is because no matter what their response is, it means they were treating you worse than they could have been.\n\n&gt; Offer significantly more? What, you‚Äôve been purposefully and knowingly underpaying what you feel I‚Äôm worth this whole time?\n\nThat happened with me once. New job offered 30% more of my salary at the time. Counter offer was a 50% raise.\n\nAt first I was excited to stay, then I remembered when I asked for a raise three months before they said there was no budget. So I left out of principle.\n\nEspecially love it when it happens after I consulted my manager multiple times that I want a raise or else I'd leave the company and the only answer was always \"we have no budget\". But then when I hand in my resignation suddenly the budget is there.\n\nPro-active companies will make me stay.   I don't trust anyone who makes a decision with a gun to their head, same reason I wouldn't trust a Reactive company in this case.  Eventually they'll try to get all the information they need from me and let me go rather that keep paying the higher salary I requested.\n\nMatch the offer? You're kidding, right? \n\nOnce the Rubicon is crossed, you're leaving. Only thing you should stay for is an ironclad, 2x salary yearlong contract. Anything less and you're absolutely going to get fucked over\n\n2x is a bit much but yeah, I'd say once the cat is out of the bag it'd be worse for everyone to stay. Management tends to think of quitting as \"betrayal\", which is the stupidest shit after they fail to compensate even for inflation.\n\nEmployees do get poached without first seeking new employment.  When the issue is only money then management has a lot more latitude. An offer letter triggers permissions to take action.  It doesn‚Äôt have to be adverse.\n\nWhy? Because they can. \n\nI think everybody should bounce when it suits their needs. However I've worked at a number of places with good engineers who were too afraid for whatever reason to leave. I've left places I knew were going to have layoffs, and even then nobody wanted to leave. The idea of \"safety and stability\" motivates a lot of them.\n\nLet's face it, you never know what's going to happen at the new company.\n\nThere is tangible risk to leaving a crew where you are decently satisfied with the work conditions. The next gig could be hiding a mountain of garbage code, could have stress factors that you weren‚Äôt able to uncover in interviews, could let you go before your probationary period due to budget cuts, etc. The only thing you truly know about the new job is the compensation.\n\n[deleted]\n\nBecause of toxic leaderships.\n\n\nUltimately the vast majority of companies are capricious and are more dependent on staff supporting their dissonances than actually benefiting from the skills and loyalty they squander.¬†\n\n\nWestern economies are definitely in shit, but if we could figure out a way to outlaw petty politics, GDPs would triple overnight.¬†\nJob hopping is great for salaries, but it also means these companies are stuck in a groundhog day situation, rehashing the same mistakes.¬†\n\n\nAgain. It's toxic leadership.\n\nI used to believe the same thing, that long-tenured staff are much more valuable because of their knowledge of the domain. But the flip side is that new staff bring in new ideas from outside, so the equation may not be simple. A certain amount of churn is probably better than none at all, especially if you can figure out how to churn the lower performers.\n\nI've worked at places at some periods of time where *everyone* was new. Those shops are incredibly dysfunctional. I've worked in places at periods of time where *everyone* was super senior and set in their ways and those shops were also incredibly dysfunctional. For a functional organization you need a few brand new people, a few super senior people, and a bunch of people somewhere in the middle.\n\nA properly maintained organization should have increasingly fewer people as their seniority increases, with a few exceptional cases -someone incredibly senior that never moved up the org chart or some superstar who rose really quickly.  In order to build this, you simply have to pay your people and take care of them well enough that _the best of them_ stick around for 10-20 years (or however long it takes to rise from junior developer to SVP).\n\nIf you do this, and run promotions truly meritocratically, you will get the churn you need.  If you maintain high standards and don't cheap out, occasionally you will have to hire senior talent from outside the company because of internal availability.  If you do a good job developing people, for most ranks you will not be able to promote people quickly enough to keep everyone, giving you a certain amount of turnover.  \n\nYou have to maintain high performance standards (including demoting or terminating people with huge tenure because their work has slipped and they ride on history), maintain high salaries, maintain a fair, meritocratic and equitable promotion policy, and maintain a consistent level of staff.  Do these things (which IMO should be table stakes for running a business, but here we are) and everything else almost always just works itself out.  The occasional interventions to bring in external candidates or replace people who have started to coast provides all the \"new blood\" you'll need.\n\nThis used to be SOP for American businesses.  Then there was Reagan.\n\n[deleted]\n\n[deleted]\n\neven if you hire experienced, for places like meta, google, rainforest or ms with top to bottom custom / proprietary stacks, it will take a long time to get up to speed, and that's not even considering domain knowledge and making the correct design choices for the expected outcomes\n\nHowever, one of the reason why most being super senior becomes dysfunctional is also because by the nature of the salary increase strategy the super seniors a company keeps are almost never the best super seniors of the flock. The ones you get to keep by fucking them over in their market salary are generally the ones with the least options available to them. And the ones who hate change which also plays into a company being stuck in their ways.\n\nThis is wrong more often than its right, in my experience. Nearly all of the very senior employees I've found have stayed in their job because they are respected, they are challenged in their work, and because they enjoy mentoring junior employees. They are mostly extremely valuable resources, so long as you can avoid taking every single thing they say as absolute gospel (even if theyre usually right, down that path lies cargo cult thinking amd stagnation) The more senior people get, the less they tend to want to move. If the company goes bad they usually just retire.\n\nI feel like what you're getting at is a need for diversity.  Real diversity of viewpoints, experiences, ways of thinking, etc.  You need seniors.  You need juniors.  You need old, you need young.  You need detail oriented people, and you need big picture people.  Risk takers, and people with a sense of caution, etc.  Stagnation is the alternative to lack of diversity.\n\nThe key to making diversity work non-dysfunctionally is respect - the ability to respect those who think, believe, work, and function differently from yourself.  Usually that part is lacking.\n\nA lot of times it's just someone with a business degree wondering why an engineer is getting paid so much to \"do nothing\" while everything is running smoothly. And then once shit hits the fan the new hire that replaced the old engineer has no idea how to fix anything and the guy with the business degree has already conned their way into getting paid more at another company because of the way they were able to \"cut costs\" and turn a temporary profit for the previous company.\n\nThe consulting firms parasitic life cycle is very similar to this.\n\nTo be fair there is something to it. If you never cut, you never know how much fat you are running. As things settle into a rut, there's little inherent incentive to change processes. The issue usually is that this process is done too randomly or too quickly or too late.\n\nI‚Äôve worked places where people have been in the same department for 30 years and they definitely suffer from lack of industry exposure.\n\nA lot of the job becomes about navigating internal org charts and politics and less about solving problems in the most effective way.  Sometimes a fresh perspective can cut through that red tape.\n\nWorking for a big French aircraft manufacturer right now as part of an innovation team. This is exactly the problem we are facing. It feels like this place is where all enthusiasm and creativity go to die.\n\nNot gonna lie... Boeing just showed us that doing things differently when it comes to engineering aircraft is probably a bad idea.\n\nCutting through red tape here may not be the wisest choice... Slow, methodical, evidence based engineering will win me over any time in this and the medical field.\n\nBoeing wasn't \"doing things differently\" they were just cutting corners. I hate most of what Musk stands for but the way SpaceX develops rockets harkens back to the way we did it during the space race and that's not slow, and arguably methodical - but plenty evidence-based.\n\nBut I wanna move fast and break things üòÜ\n\nBut yes I understand. It is a conservative industry for good reasons. It‚Äôs just frustrating that even for exploration of concepts, they expect adherence to heavy-handed processes. \n\nFor industrialisation, I would understand.\n\nThere's few things as frustrating as being someone who wants to improve things but the old farts want things to stay the same or are so apathetic they believe it can't change. It used to bother me much more when I was younger, with experience this doesn't get to me as it did. Try not to let it affect you emotionally while trying to not let that part of you die or you'll find yourself becoming those old farts.\n\nAnd to be fair to the old farts, its likely they have been through dozens of \"Innovation Initiatives\" that will fix all the problems of the world for everything to be the same but with new buzzwords.  Or often, things are worse than before, but management is happy because one obscure metric went up, \"Hooray, we are so innovative.\"...  Lots of big organizations go through flavor of the month consulting firm change overs that can create some really jaded old timers.\n\nAnd it might be even worse for the old farts if the \"innovation initiative\" is successful. There's a [classic Daily WTF story](https://thedailywtf.com/articles/Classic-WTF-The-Indexer) about Gustavo, an old fart at a government mapping agency in Argentina, and Sergio, the innovative young techie hired to support the agency's internal systems.\n\nEven though the agency was digitized, there were a lot of things tediously done by hand. Many were due to equipment or resource limitations - for example, to digitize paper maps, they often had to cut them up, scan the pieces, and reassemble them in Photoshop, because the maps were bigger than their scanner.\n\nBut the most tedious and repetitive process he found was updating the index of maps, done by Gustavo, a middle-aged military vet who was neither an IT expert nor a cartographer. His entire job was a comically inefficient process to add new file names to the index spreadsheet:\n\n&gt; 1. Take a screenshot of the Windows Explorer file list with the Print Screen key\n&gt; 2. Paste the screenshot in a new image inside Photoshop.\n&gt; 3. Crop the image to the file names only.\n&gt; 4. Save the image.\n&gt; 5. Open the cropped image inside an OCR program and run the optical recognition.\n&gt; 6. Copy the resulting text to an Excel Spreadsheet\n&gt; 7. Scroll down the Windows Explorer vertical scrollbar to the next page or choose another folder\n&gt; 8. Repeat\n\nSergio proudly showed Gustavo a far faster way to do that process:\n\n&gt; `dir *.tif &gt; filelist.txt`\n\n...which Gustavo, of course, reacted to with shock and horror. If that information ever left the room, he'd likely lose his stable government job and be left looking for work, without any useful skills, in a country whose two main exports are beef and debt defaults.\n\nThat's such a horrible processes, borderline unnecessary cruelty.\n\nI've come in to situations where neither Sergio nor Gustavo understood *why* there was a comically inefficient step in the process and it turns out to be a timing hack.\n\nAs an old fart who's generally the one pushing for change against young complacent folks, it's because I've learned what works, and the shit the software industry is pulling now *does not*.\n\n&gt; There's few things as frustrating as being someone who wants to improve things but the old farts want things to stay the same or are so apathetic they believe it can't change.\n\nI can name one of those things.\n\nWhen the young kid joins the team, doesn't understand what he's talking about and thinks he knows better and can solve everything overnight. It often goes badly, because they don't know how much they don't know.\n\nSometimes the 'old farts' actually don't want that change because they know exactly why it's a terrible idea.\n\nSame. I worked at a place where the head of engineering had been at this same company for... Wait for it... 30 years. No shit. The engineering culture was slow, avoidant of change, and \"we've always done it this way\" top down people who were LOCKED IN literally. \n\nThis discussion about tenure cuts both ways at the extremes\n\nThere‚Äôs good change and bad change. Maybe that place was able to settle on good practices that didn‚Äôt need changing. Think of all the fads that came and went, that place avoided them.\n\nI am working at a place now with a lot of change-avoidant people who have been there forever - my team refers to those people as ‚Äúfurniture.‚Äù \n\nWell, it‚Äôs been there forever, we‚Äôre not exactly sure what good it‚Äôs doing, it‚Äôs obviously seen better days, but no, you can‚Äôt just remove it even if it‚Äôs in your way without a 2 week project to ‚Äúdiscover stakeholders‚Äù\n\nA certain amount of churn is absolutely beneficial. People often become complacent and instead of being the catalyst to change, they often say ‚Äúwell, we‚Äôve always done it this way.‚Äù\n\nHonestly it depends on the people. My team has two brilliant 5-8 yo+ people that know every in and out and can run get a new feature with the cleanest code I've seen out in no time.\n\nThere was another long tenure dev, 5+ yo too. But barely knew anything much outside of a few basics that were very obvious after the first 4 months of working in project and he kept struggling keeping up to date with the slow refactoring and Techstack upgrades.\n\nAfter the former was let go and the great two got a nice retention package, we got one senior completely unfamiliar with the tech stack and a bootcamper to compensate... Our sprints are finished on Wednesday most of the time.\n\nYou need a good people knower and tech lead for this though, good recruiting and luck. But time at a company doesn't say as much as the type of developer you are.\n\nI think the question is primarily interesting if you assume that the tenured talent and the new talent are of the same skill level. It's fairly obvious that a new bad developer will be worse than a tenured good developer or vice versa.\n\nThe big problem here is, in order for this to work well, the people making the retention decisions need to really understand how Irreplaceable someone actually is in terms of institutional knowledge or skill that can't be easily replaced.\n\nThat kind of detailed knowledge really isn't common among the people who make these decisions.\n\nIf a person is irreplaceable, that's the REAL problem. Employees have a legal and moral right to leave at any time. It's a business failure if you cannot survive that.\n\nI have also noticed some long tenure employees tend to lower the effort since their leverage is higher. So sure, if they worked with the same hunger as someone who just started they will have a huge impact but not everyone do.\n\nI think the more people that get involved in decision making the further those decisions drift from the core mission of the organization.\n\nManagement by committee sinks a lot of ships.\n\nThere's a simple reason for this: The golden rule.\n\nIt seems simplistic. He who has the gold rules.\n\nBut, what it also means is those closest to the gold have more power and influence, especially over money.\n\nThe executive are close to the gold. The tech people who might be doing the thing which generates the gold aren't really near the gold. That would be the CFO etc.\n\nThus engineers are about as far from the gold as you can get in many companies.\n\nThere is another problem. Executives hate engineers. Engineers tend to focus on annoying things like facts. Executives don't like facts.\n\nSo, what executives do is to create as many layers between them and the engineers. Thus, the engineers don't really exist as people. They end up with terms like \"resources\". \n\nInevitably the executives (who see themselves as indispensable) will cook up spreadsheets where they replace experienced engineers with interns, foreigners who will work cheap, or just clean offshore the work. One engineering \"resource\" is the same as any other aren't they?\n\nAlso, engineers are genuinely hard to evaluate. What is productivity? Line of code? Often being a blowhard is more \"productive\" than actual productivity. These people get invited into the layers closer to the executive and are given titles like manager.\n\nBut even within engineering experience is even hard to put a value on. Is an engineer with 20 years experience just doing the same thing for 20 years and not only refusing to grow, but actively gatekeeping people who bring \"fads\" into the company. They scream risk risk risk to the executives who can't seem to then mesh this with their dominating competitors who seem willing to take these \"risks\" and are not suffering for them.\n\nOr do you have an engineer who for the last 20 years has aggressively kept up with every useful modern trend and that is reflected in the products which are better/cheaper than the competition. \n\nBoth engineers are seemingly hard working.\n\nTo answer the OP's question in a useful way. All you have to do is ask, \"What engineering questions will look good on a spreadsheet?\" That will tell you what the executives are probably going to do next.\n\nI've seen engineers who, acting as internal consultants, can be more productive than entire teams by swooping in and telling teams \"What you're doing is a *really bad idea*, just use Terraform\". When they're right, they can save years of effort and pain.\n\nThat's hard as hell to measure three levels up.\n\nThis article was written in 2021. I feel like the environment is very different now.  The writer listed a year later what he was going to pay software developers. I calculated a raise of 0%, 3.6%, 7.3% depending on how you meet expectations. 180k + 130k = 310k after 10 years of exceeding expectations seems nice though.\n\n‚ÄúIn a market this hot‚Äù the article says\n\nThat's exactly what made me check the date.\n\nBecause there are too many corporate idiots who believe ‚Äúyou can just swap them out with a brand new person with ZERO training and they will be up and running on day 1‚Äù.\n\nI am upper management and I cannot stand this mindset.  Complete waste of time, money, and talent.\n\n* 3 year old article ‚úÖ¬†\n* Series B startup with fewer than 100 employees ‚úÖ¬†\n* Author is a VP of engineering and younger than 30 when the article was written ‚úÖ¬†\n\nDo you have any complaints with the contents of the article, or just that the author fits some profile you've constructed?\n\n[deleted]\n\nI had an exec tell an auditorium full of people that payscale are backwards and that we should be paid more at the beginning of our career and then less over time as our skills atrophied (and as we needed less money)ü§∑üèº‚Äç‚ôÄÔ∏è\n\nAsk that exec if they're willing to give up their compensation in line with their idea. Not pay, _compensation_. Don't let them do the \"I only pay myself $1 (and 25 million in stock options every year)\" trick\n\nSure, I would love to start with a VP compensation as a junior ü§¶ This is one or the most idiotic things I've ever heard.\n\nIts an interesting take.  Fixes the forced layoffs of old timers who have a huge salary due to years of tenure compared to an equally good or better young person who has an entry level salary. We had an old timer retire last year and got to use his wage to higher two people to replace him, and it was a net savings.\n\nPeople hate change, so companies often get away with it. *First day at a new job* is not exactly fun (even for extroverts). Sometimes those new jobs/opportunities have better pay for a reason as well; they can be **truly desperate**, have a horrid legacy code base nobody dares touch, no documentation, no seniors left, just a bunch of people that cannot fix anything, and everything needs to be fixed fast. Not exactly a relaxing 9-5 job.\n\nmanagement nowadays is not made of technical people, but pencil pushers and spreadsheet lovers. They cannot estimate individual's contribution, even if they would sit on one-on-one meetings. In pair with that, they are pushing profits up by cutting the costs, and employees are one of it, but not by making companies more profitable. Why? because they don't know how to.   \nTo make more profits you need to know the product, its differences with competition, how to bring more features, maybe even new products, which all requires good and motivated workforce.   \nIt is easier just to slash cost by 10% and invest the savings into the buyback schemes.\n\nIt'd be rad if this industry was focused a little more on long term stability and a little less on chasing short term explosive growth.\n\n\nThe adage we've all heard about moving jobs to get paid has always had this sort of underlying bleakness to it. It's true, of course, and it's entirely intentional on the part of employers, but that doesn't change the impact it has on the work and product.\n\n\n\n\nYou'll never build anything you expect to be around to support in 5 years time, so the industry is mostly shipping products with an almost intentionally short lifespan, and sinking billions of dollars into rewrites.\n\nA certain percentage of them move because they are not challenged at the current position and a new job offers them more opportunities. Devs are generally compensated pretty well. Money is *a* motivator, but not the only one.\n\nThis has been the reason I've left nearly all my past jobs in the ~35 years I've been working in the industry. Once I was at a point where I was living comfortably and saving enough for a comfortable retirement (which was pretty early on, really) I kind of stopped caring all that much about getting paid more and optimized for spending my 8 hours a day doing things I found mentally engaging.\n\nIronically, chasing interesting new work rather than chasing higher pay has ended up giving me a very lucrative diversity of experience.\n\nMmmmm I think I'd slightly disagree. \n\n\"Not challenged\" is usually just a proxy for \"won't promote\". It's a euphemism for people who aren't getting raises, aren't getting title bumps, and are being subjected to daily frustration.\n\nThe typical path to more pay is to go into management, which removes you more from the code. Gotta love the gravy train\n\nThe downside is manager roles are much more precarious. You're way more interchangeable with anyone else who can ramp up reasonably quickly and without any institutional baggage. Regular victims of reorgs. Your hard skills atrophy etc.\n\nAnd there's 1/10th as many jobs available.\n\nAnd a lot of engineers don't have the personality for management. I spent two years as a manager and loathed it so much I quit and went back to development.\n\nManagement is a massively more stressful job, not nearly as interesting a lot of the time, and it barely pays more than being an IC (if it does at all).\n\nI have a conjecture. It's because of HR, HR teams in tech industries are a vermin, they're awful at getting qualified talent to the jobs and most of them don't even know what to look in prospective talents, growing talent inside a company and maintaining it is desirable for the tech team, the client and product owners, do you know who doesn't benefit from that?\n\nHR.\n\nThere isn't a need for a bulky HR team if you aren't constantly hiring, and the cost of talent acquisition has gone through the roof even on slow/sluggish tech job market seasons\n\nI'm blaming them, 100%\n\nOften, the problem is accounting. All those ideas of ‚Äúvalue‚Äù and ‚Äúknowledge‚Äù don‚Äôt have columns in their ledgers.\n\nThey are completely narrow sighted to two things:\n1) profit (which they can‚Äôt really generate)\n2) saving saving saving‚Ä¶ that they can do!\n\nAnd then totally fail to see the negative impact of their decisions on the profit side. In their minds, programmers and engineers are like delivery trucks‚Ä¶ replaceable assets.\n\nI think they often do pay them to stay - the problem is that those motivated by money will look around for it - and there is a BIG difference in the pay gap between the average and big tech companies, often for not the relative difference in skill.\n\nHell, how many times have you heard the story of the person who was in an average IT job, wanted a better salary, so grinded a mere 8 to 12 weeks of leetcode with a bit of sys design thrown in, and by just doing that manged to land a 100% or more salary increase?  That's utterly insane - the idea that just spending 12 weeks grinding a skill that isn't all that useful in actual real-world projects yields such a massive difference in pay.  Like, if it were really, truly that beneficial to companies for people to have those skills, why wouldn't you just have your developers do a one or two week training program for these things twice a year?  If they were actually resulting in or an indicator that an employee can perform work to the standard that's producing output that justifies paying them 50%, 100%, 200% more - surely it would be worth investing in training those existing employees?\n\nAnd that right there is the problem with tech salaries.  People in other industries, say hospitality or marketing or accounting will jump ship for maybe a $10-15k salary bump.  But in IT?  Those bumps can be $50k to 200k at times!  Those developers didn't just suddenly gain 10 years of experience in 8 weeks, which is what in other fields that might be the equivalent of.\n\nSo when it comes to paying engineers to stay, how do you ensure even with say a $40k chunk, that big-tech-tomorrow won't offer them even more, if that's what will convince them to move?\n\nI‚Äôm watching my old company slowly burn to the ground as attrition just leaves with new hires and a hundred heads worth of tech debt they refused to prioritize. I was at top out pay and am making the same now but only midway through the pay band. I‚Äôm not working 50-60 hours a week for a yearly bonus and pay increase that didn‚Äôt even keep up with inflation.\n\nSoftwaredeveloper here. I had a job with lots of responisibilities at my old employer. I alone established several new customer contracts and was the main contact person for those customers. I also was the only one who was able to work a certain project that was of high and growing importance to the company. For several years I tried to negotiate a higher salary and was fobbed off with lower raises. In my last year my ask for a raise was flat out denied (not by my boss but his assistant who flat out told me she didn't want me to set up an appointment to discuss my salary with him because my salary was already higher than was usual for my position). I searched for a new job and found one with a 60% salary increase. When I told my boss I quit he was super upset and offered me the biggest raise in my time working there. But at that point I had already signed the new contract and was happy to decline. I heard that after I quit they lost one of the customer projects I was responsible for. A project that had 4 developers on it.\n\nFor decades companies have used people in general as interchangeable parts that can be swapped out at a moments notice.  Now they don't know what to do with people swapping companies when it benefits them.\n\nThanks for all the 'right to work'!\n\nThey do, if they want to keep you.\n\n[deleted]\n\nLook at you still getting cost of living adjustments!\n\nThe company doesn‚Äôt really care if you stay or go.\n\nThe enormous promotions are temporary for them to find someone to replace you, you may even train them, then they‚Äôll let you go.\n\nIf they wanted to keep you then you‚Äôd be getting bigger raises before you threaten to leave.\n\nYou are right. In many companies this is the norm. Promote an employee and then fire him.\n\nMy experience has been that there's 3 types of workers:\n\n1. High performers, key people - companies will pay to keep these workers.  What % of high performers they're willing to keep will vary from company to company\n\n1. Low performers that stay at the same company because they don't have good prospects elsewhere.\n\n1. Everyone else.  These are the people that will get mediocre raises and benefit greatly from job hopping.\n\nGroup 3 is in some ways the core of the backbone though, and the issue with not paying group #3 is that if there's too much turnover then you're just burdening your #1s with constantly onboarding new people.  I think this is where companies can be short-sighted.\n\nMy personal experience is that the size of #1 is much bigger than the group of people the company actually pays to keep around.\n\nThe problem is high performing can mean a lot of different things. Are you high performing cause you put in a good, fundamental work and quietly keep the ship afloat? Are you the kind of person that does flashy research projects that get noticed. Are you the kind that plays political games so that higher ups _think_ you're high performing?\n\nCynically I think companies really only care about retaining executive talent. Anyone beyond that will always be deemed expendable. It's up to you how hard you want to work for your rose on the Bachelor(ette) tech layoff edition.\n\nThis right here.¬† Whether right or wrong, I can assure you if management wants to keep you that \"impact\"¬† line on the graph is your salary too.¬†¬†\n\n\nProgrammers, or even employees in general, have a strong tendency to over estimate their importance and impact to the business.¬†\n\nSometimes programmers overestimate themselves, but sometimes managers underestimate the importance of programmers until they are gone, and take with them all their know-how of the system.  \n\nOften different levels of management aren't in lockstep with each other over how much it is worth to keep some members.\n\n[deleted]\n\nThere's zero reason to ever believe a manager is telling the truth. They may or may not have thought you were average, or worse. But what they say has literally *nothing* to do with your actual talent.\n\nManagers are directly incentivized to say whatever they think will squeeze more work out of you. Sometimes that's looking down on you. Sometimes it's trash talking you and yelling at you to improve. Sometimes it's threatening to fire you. Sometimes it's complimenting you and telling you that you're the best developer they've ever seen. Sometimes it's telling you that they're happy with the work you've given them, but that they do feel you could do a little better if you just applied yourself.\n\nWhat your manager says may happen to align with the truth. But it's purely chance. It certainly isn't their goal.\n\nI don't disagree that happens.¬† ¬†It certainly does.¬†\n\n\nI'm just also pointing out, the actual importance of individuals tends to be much lower than most folks want to recognize. We are all replaceable. Some of us comedically easy, others somewhat hard. Noone catastrophically hard though.¬†\n\nOh no I can certainly think of instances in my career where the lack of an individual would be a catastrophic loss or set us back for months. And my career isn't even that long.  \n\nPoint is, why would a different company be willing to pay you more than your current company, when you'll probably be more productive if you stayed there than if you had to go somewhere else and learn everything about their system from scratch? There are situations where it makes sense, but most of the times, if an employee leaves for higher pay, someone made a mistake.\n\nI disagree.  I think most employees have a good idea of their importance or the importance of their co-workers to the business.\n\nAs they are on the ground doing things and working with people, they can know exactly what their impact is to the business in terms of dollars.  In my experience, most business will fail to give a relatively small raise to someone who's loss will cost them significantly more than the raise would.\n\nBut it doesn't matter.  They will lose those people.  It will cost them significantly more.  The dots are not connected.  The business will go on.  It is ultimately far more important to maintain social hierarchy than it is to count the beans and pay certain people relative to whatever their loss might cost or their productivity brings in.\n\n&gt; As they are on the ground doing things and working with people, they can know exactly what their impact is to the business in terms of dollars.\n\nI'm not sure that's particularly true.  It is for some no doubt, but in general people lack awareness of issues outside of their direct involvement.  Lots of people have no idea what even their own true cost is in terms of their wages and benefits.  You talk about total package value and peoples eyes glaze over.  And inflating contributions is huge, someone who did 20% of a project is easily self convinced that they did 80% of the work, when they didn't.  One of the fun things about people knowing about the 80/20, is most people tend to think they are the 80 not the 20.\n\n&gt; In my experience, most business will fail to give a relatively small raise to someone who's loss will cost them significantly more than the raise would.\n\nEven with what I said above, this is absolutely true.  If the company is large enough and has enough redundancies in place like it should, its still an easy storm to weather, and short term hits will smooth out over time.  That and the people making those decisions are human too and mistakes are made by everybody at every level, you just need to try to land at an organization where its the exception not the rule.\n\nTrue, but I've also seen companies lose large customers based on a single employee leaving who they under compensated. When the employee walked, they lost significantly more in revenue over the next year than the salary. I find large companies are usually terrible at determining what a specific employee contributes to the bottom line. Small companies sometimes do better because they have to\n\nThey know who they want to stay, but not who they need to stay.\n\ncause it's very hard/impossible to separate out the cost of engineer churn, and tie it to concrete dollars amounts\n\nso mba types act like it doesn't exist.\n\njust capitalism being capitalism ignoring negative externalities.\n\nMy ex company fired me in January. They are still struggling to fill my position.\n\nBecause they fear that every 3 month you'll be asking for an increase of the salary, and fear the others will do the same.\nThey prefer let you go and keep this status unchanged.\n\nThe article doesn't actually address the question, just promotes some stuff at the end.\n\nI've heard a good argument about this on a different thread awhile back. They said it is due to budgets. Recruiters have much higher budgets for getting new hires than the departments do for giving raises.\n\nSo while a recruiter can offer a salary up to 15-30% higher than currently employed people, the internal departments can only give raises of up to 5%. I am definitely missing some of the finer points, that's just what I remember.\n\nI suspect this is structured due to some BS business degree logic, that kind which are usually based on old studies from the 80s or 90s and have since been proven false, yet still get taught religiously during business degree classes.\n\nI would also wager a testicle that things like this are why corporations so heavily push the narrative of \"Don't talk about your salary!\", because they do not want senior employees knowing that new hires straight out of school are earning much more money than them.\n\nI recently found out the real answer to this question.  It‚Äôs all about price to earnings (P/E) multiples.\n\nA business that is overly reliant on an owner, employee, or customer is simply worth less money to investors.  Investors want to invest in a robust and scalable business. A business that is built around its employees is a scary and risky proposition for investors or private equity buyers.  They want to be able to do hyper growth when times are good and layoffs when times are bad. The easier and cheaper a business is to scale, the more valuable it becomes.  That‚Äôs why tech companies have such high P/E multiples in the first place.\n\nOwners and investors see absolutely no upside to paying employees more to stay longer.  They see a much better upside in the idea of burning people out to get every last ounce of value out of them and underpaying them so that they turn over sooner rather than later.  They see it as an actual risk in allowing software engineers to build software that is so advanced and fine tuned that only seasoned experts can maintain it. \n\nThey actually want half assed, half broken code that is next to impossible to work on, and they are happy to hire objectively unqualified workers to putz around with it.  Its by design.  Anything else is not part of their formula.\n\nDo I agree with the mindset?  No.  But the only way to counter it is through regulation or unionization.  Like it or not.\n\nWhy? Because they don't have to. The moment tech companies find that people aren't fungible will be the moment they will pay them to stay.\n\nDecisions are usually made by committee (in practice even if not formally) and for almost everyone there is at least one person who doesn‚Äôt like him, excluding agreeable mediocrities who have made no enemies but also haven‚Äôt done anything.\n\nThis is also why companies don‚Äôt promote from within. It‚Äôs easier by far to get unanimous consent about an unknown if you sell him as a miracle worker than someone with an internal track record, even if the record is 85-90 percent hits.\n\nThey have actuaries that tell them they'll save more money over all by depressing wages and losing engineers than they would by offering bigger raises and retaining engineers, but driving wages up across the industry\n\nCost predictability and expense depreciation through market in-house pay differential.\n\nOr mostly just because people don't ask and managers are protective of their labor budgets they have to win from protective accountants and CFOs.\n\nThis article explains the economic factors - namely as your skill and knowledge improves, you can provide more business value to other high growth companies, which then allows you to get higher comp at those companies. \n\nI think [this video](https://www.youtube.com/watch?v=_npz7-ZJypo) can explain one side of the \"corporate politics\".\n\nWell, companies care about money, not about code. And having the best code doesn't necessary translate to a good product or service.\n\nSo companies can fired supposedly talented programmers and hired cheaper (less capable ones) because they know they can make the app just a tiny bit worse so that the customers will still used it. Then you wait for them to get accustomed and you repeat the process. \n\nIn the short term, the company makes a bit more money so it looks good, the app might be worse, but just a tiny bit worse, so most people tolerate it, until they eventually bust. But by then every suit and investor has made money and only the idiots will be left holding the bag.\n\nThey're trying to keep total costs down to have runway in their budget. If *many* people left at once it would have an immediate effect, but they are looking for delayed effect and applying a discounted future to it.\n\nThe new higher budget exceeds the retention budget.\n\nWhen times were good (read 0% corporate loans), companies were hiring at crazy high salaries for those who jumped ship, trying to take any and all decent+ developers away from their competition.\n\nWhen times are uncertain / bad, companies go through layoffs (even laying off their best performers, or really anyone with the highest salaries), the job market becomes saturated, and now anyone actually hiring can offer lower salaries as a result.\n\nI've heard the current situation in the tech job market called \"the great salary reset\", aka resetting everyone's expectations because no tech company will be paying what they did 5-10 years ago.\n\nWhich is something unconscionable, when you consider inflation these past couple of years and how much the cost of living has gone up.\n\nIMO, when the company has a bigger number of employees, the let go cost is 0. Why? Because the other employees will cover the job until new one is found. \n\nIn that case, hiring costs are the same as employee budget.\n\n\nAgain, that's just my opinion and my experience. The colleague and friend of mine was let go because of 200$ raise. Literally, he was let go because they could find someone for the same amount of money. His job was split \"evenly\" to the others, and in the end, no one was hired for his position, and the guy that's supposed to be his replacement ended up on the completely different role.\n\n[deleted]\n\nHow do you measure performance?\n\n// TODO: Fix before leaving\n\nBecause they can get someone cheaper to abuse.\n\nI'd love to get a new job, but the way my project's tech stack is structured, I get 0 exposure to technology that would get me out of here. We don't use containers, AWS is abstracted away, DBs are owned by other teams and only accessed via REST calls. It's like I didn't realize I was standing in quicksand and now I'm stuck until I put in a ton of effort/time to learn everything and even then, without industry experience to point to, it's real easy for a company I apply at to hire anyone with that industry experience.\n\nIts got to do with crooked non-sense incentives within the big corporate structure. \n\nThe person who is rewarded for keeping salaries low is NOT the person who is responsible for making the engineering products work. HR makes themselves look good by keeping salaries low. And then when engineering managers complain they can't keep talent, they get told to \"make due\" or \"figure it out\". And managers are expected to explain to their employees that their piss poor raises are actually \"in line with the market\" or some nonsense we all know is a lie. \n\nAnd the executives who are supposed to be balancing these opposing business needs are always coming down on the side of keeping salaries low. Better to keep them low and risk ppl leaving rather than raise salaries and definitely see profit decrease as a result.\n\nBecause the green line is unrecognized.  Your skillset, and thus your value, are evaluated at time of hiring.  After that, the goal is to avoid paying any more for that value than is necessary.\n\nMBA's have been taught that corporations need frequent turnover to ensure they are getting \"adequate\" employees at the lowest possible price. \n\nThey are wrong, of course.\n\nDo you want the honest answer?\n\nI'm an engineering manager and I used to fight *hard* to get people the pay rises they deserve. It'd track objectives, link them to actual value, show the measurable impact each engineer was having on the company bottom line. I even came up with a way to link maintenence work to a reduction in outages, just to build a stronger argument. I would push and push and push and nag and harras technical departmental heads and heads of finance to get money freed up for valuable engineers.\n\nAnd every time I got an an engineer a pay rise, like clockwork, the boost in confidence would see them job hunting and handing in their notice within a couple of months.\n\nSo now I can't be bothered with it. If engineers are going to leave anyway, regardless of if they do or don't get a payrise, then I'm not putting the effort in. I'm better off spending my time on ensuring documentation, knowledge handover and mentoring is happening instead.\n\nAnd this isn't just me. It's a consistent experiance for my colleagues when managing engineers. Payrises result in zero improvements in retention, so why do it? We are better using the money to hire another engineer and have redundancy for when people rotate out.\n\nPeople don‚Äôt leave their jobs, they leave their managers.  That‚Äôs what you‚Äôre experiencing.\n\nYou said it yourself.  You are so low on the totem pole that getting anyone the raise they deserve is a struggle and it always comes too little too late.  Maybe you‚Äôre a great person but you don‚Äôt have any real power as a manager, and that‚Äôs why people leave.  Don‚Äôt feel bad, it‚Äôs not just you.  If you manage people who still work for a living then you are never going to have power.  And if you have power, you will never be worried about the proles who still work for a living.  You might even go years between talking to one.\n\nGet someone a 40% pay raise with a 100% bonus sometime.  The kind of promotion where the CEO calls them up personally to congratulate them on everything they‚Äôve done.  They won‚Äôt leave."
  },
  {
    "title": "I scraped 12M programming job offers for 21 months and here are the most demanded programming languages!",
    "body": "",
    "score": 1483,
    "url": "",
    "created_utc": 1729694008.0,
    "author": "__dacia__",
    "permalink": "/r/programming/comments/1gac15b/i_scraped_12m_programming_job_offers_for_21/",
    "all_comment_text": "Please be aware that C and C++, while related, are not one language. C/C++ does not exist. A job writing C will be very different from a job writing C++.\n\ni find it funny that C and C++ are treated as combined but so often javascript and typescript are treated as entirely seperate skills.\n\nonce had a recruiter tell me my typescript experience was good, but it was unfortunate I didnt have as much javascript experience. it was because i had 3 relevant jobs on my CV one used only JS and two used mostly TS\n\nYou dodged a bullet if that was their level of understanding.\n\nI don't know. The recruiter probably doesn't know one from the other. But the people they'd actually be working with probably do.\n\nYeah but if you are recruiter _with the power to reject or accept candidates_, you should know the difference. If a tech company has a recruiter like that, it tells something.\n\nMany recruiters are not technical. I noticed once, being curious who I will be talking to, that before being recruiter, the guy was a bartender.\n\nI was a bartender before I was a software engineer. Background is irrelevant, you can always learn.\n\nNo one's asking them to code any TS. But they should know enough basic facts to do their job correctly\n\nI worked with technical headhunters who thought there was some special relationship between Java and Javascript and looked for experience in either/both when trying to setup interviews.\n\nIt's silly stuff.\n\nYeah it's fucked, although I wouldn't say it's bad to not have a technical background. It's just that if you are recruiting for a position that requires JS knowledge, you should do enough investigatiob to understand that TS is JS. I'm personally not a fan of dissing people who switch careers, but one should not recruit for tech positions without knowing anything about tech jobs, it's not a huge amount of research that it takes to know what the company is looking for.\n\nThe recruiter likely doesn't even work for their company but a company whose job is recruiting. This is a strange but common industry problem\n\nShould, absolutely. But if you're just a 3rd party recruiter, then you probably don't.\n\nTo be fair, some Typescript patterns are just classical patterns and there are some devs who know a language like C# and think they \"know\" Javascript because they can write C# in Typescript, but don't. This is less the case as Typescript and ES-whatever-we're-at-now converge, but that's because we're just trying to force JS into classical-language land.\n\nha, 20? years ago, i had a recruiter say they thought Java and Javascript were the same.\n\nSame with C# and .NET\n\nPlease also be aware that C++ and C++, while related, are not one language. A job writing C++ will be very different from a job writing C++.\n\nI wish this weren't so true.  My first career was exclusively 1990s C++. Proprietary C++ middleware, proprietary C++ servers on the backend that ran on the proprietary C++ framework.  I got really good at C++ and turning things into objects that you wouldn't normally think about as objects.  It worked really well though.\n \nToday's C++ jobs are completely different though and I can't get one to save my life.\n\nPlease also be aware that Lisp and Sean Connery's English, while related, are not one language. A job writing Lisp will be very different from a job writing Sean Connery's English.\n\nI used to have a job writing Sean Connery's English that was based in Wimbledon. It was hard work, but at least I didn't have to start in the morning until tennish.\n\n‚Ä¶ tennish.\n\nI use to play tennish... until I hurt my shoulderish.\n\n... A single tear has come to my eye. Beautiful.\n\nThash a firsh clash joke, sonny boy.\n\nYou bastard, I laughed!\n\nHeh.\n\nIn my experience, for most jobs involving a C++ codebase, you'll also have to work with some C code, if nothing else in third-party libraries. So even if all of your own new code is modern C++ with smart pointers, in order to call out to third-party libraries you'll have to be comfortable using raw pointers when needed.\n\nSo I'd say there are \"C jobs\" and \"C/C++ jobs\".\n\nBeing able to use C-APIs and being able to write \"good\" C-Code are IMHO two completely different skillets. A C++ job doesn't become a C/C++ Job just because you have to use C libs.\n\nHonestly there is just so much stuff you can do with every language nowadays that I feel like just listing C,C++,Javascript etc. as must knows is just not enough and practically meaningless. Like at this point you could make a bigger description of what kind of skillset in X language you are looking for and just ask for that.\n\nOr, you know, don‚Äôt put something like that in there at all because good engineers can learn on the job.¬†\n\nYep, that's my current job. C++ in the main code, C in some libraries. They pay me to modify both.\n\nNot one language, but most embedded listings I see request both. I write both in this job, but avoided c in last (I could have written some). Both of these job descriptions listed c/c++.\n\nAgreed, but it‚Äôs very difficult for me to differentiate them in a plain job offer. Many job offers (maybe made by regular recruiters) always ask for both... so this is basically the reason I decided to put them together.\n\nWhen asking for both, most likely, they mean C++.\n\nmuddle wise tub obtainable bear unused political fertile distinct kiss\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*\n\nJS/TS is not exactly the same thing, but similar.  TS is an entire set of skills to build on top of and in addition to JS skills.  But if you know JS, you can be rudimentarily functional immediately.  So you get JS/TS job listings while TS grows in popularity and my bet is that never goes away either.  It's probably irrelevant already today.\n\nBut modern TS is a real superset of JS, unlike C++ and C anymore...\n\nThere are a lot of libraries written in C that get utilized in C++ projects. Usually this is what I assume they mean when people say C/C++\n\nAfter this exchange with a recruiter, I just lost all hope:\n\"Are you sure the thing is written in Java?\"\n\"Yes, it's Java but Script.\"\nO.o\n\n    if \"java\" + \"script\" == \"javascript\":\n        print(\"true\")   \n\n    &gt; true\n\nI guess that works ¬Ø\\\\\\_(„ÉÑ)_/¬Ø\n\nMost C code compiles in a C++ compiler.  The slash is real.\n\nAnd even with that conflation, the overall total of jobs for those languages still dropped from 10% to 6%.  That's huge.  \n\nI would celebrate if I knew that all those jobs landed in the Go and Rust camps, but I suspect that more than a few flew to the Electron/JS/TS segment in the \"DGAF anymore no more pearls for swine\" school of app design.  \n\nOff-topic: Witness the recent movement of the PC version of Facebook Messenger which was a native app until recently.  Then they went to an Electron container, and now they've full on moved it to be a container for Edge itself; complete with extensions loaded all up just for the \"privilege\" of running Messenger on the desktop.  ü§Æ\n\nThe \"C\" matcher also seems to include matches for [driving license class C](https://en.wikipedia.org/wiki/European_driving_licence#Categories_valid_in_all_EEA_member_states), /u/__dacia__.\n\ne.g. [here's a listing for a fire officer job in Norway](https://www.glassdoor.com/job-listing/brannkonstabel-deltid-salten-brann-iks-JV_IC2925594_KO0,21_KE22,38.htm?jl=1009412751583&amp;cs=1_ed6f1640&amp;s=58&amp;t=SR&amp;pos=333&amp;src=GD_JOB_AD&amp;guid=00000192ad04b1a2b4d25903954b4d92&amp;jobListingId=1009412751583&amp;ao=1136043&amp;vt=w&amp;jrtk=5-yul1-0-1iamg9cgngqq1800-448fbc6b1f03cd0f&amp;cb=1729479619586&amp;ctt=1729772180219) that's listed on the \"Developer jobs in Norway\", likely because it has \"C\" as a free-standing word? But they're asking for someone who can drive a fire truck. Now Norway's a small country, but if listings for truck drivers across Europe gets interpreted as listings for C developers, it'll affect the numbers.\n\nA \"D\" matcher would likely have the same problem with bus driver listings.\n\n**edit**: Looking at a few more listings, here's an [\"in-store salesperson\" listing for a company called C&amp;C](https://se.linkedin.com/jobs/view/butikss%C3%A4ljare-c-amp-amp-c-birger-jarlsgatan-at-c-c-sweden-apple-premium-partner-4003146756?position=1&amp;pageNum=55&amp;refId=3RF8PE%2FyrTtCBPEFot6LoQ%3D%3D&amp;trackingId=alT8B7uFZxhOfpZz4NHkQw%3D%3D&amp;trk=public_jobs_jserp-result_search-card&amp;original_referer=); and [here's a bunch of C-suite stuff for a tanker](https://www.glassdoor.com/job-listing/coce2e-eto-i-tanker-i-worldwide-osm-thome-JV_IC2911047_KO0,31_KE32,41.htm?jl=1009195899874&amp;cs=1_489358f5&amp;s=58&amp;t=SR&amp;pos=107&amp;src=GD_JOB_AD&amp;guid=00000192b34bce088b619a0555c7241a&amp;jobListingId=1009195899874&amp;ao=1136043&amp;vt=w&amp;jrtk=5-yul1-0-1iapknji0ljco800-e042df54892c4d35&amp;cb=1729584943098&amp;ctt=1729774523846), all via the [c jobs](https://www.devjobsscanner.com/c-jobs/) page.\n\nI suspect the safest thing to do for the metrics here is to actually count just `C++` as a separate thing similar to `C#`, and either give up on trying to count C jobs reliably, or require the presence of various other phrases. It might actually be something you'd need to run through an AI or something of that complexity level to filter somewhat correctly.\n\nMany recruiters will mention both even though the job is usually only C++. I‚Äôve even seen some where they‚Äôve only listed C, but it‚Äôs still been C++.\n\nHey, 8000 rust jobs. That's double last year, and double the year before that. \nWe're getting there lads\n\n2025 is the year of Rust on the Desktop\n\n[Maybe if GUI devs get their stuff together ](https://areweguiyet.com/)\n\nJust compile to wasm and stuff it into electron üòà\n\nSomething inside me died a little bit after reading this.\n\nMinecraft redstone is Turing complete, would you feel better about running it there?\n\nYes, why?\n\nBe patient, I'm using redstone to write a longer reply.  It's gonna take awhile though.\n\nYou're describing Tauri, aren't you ?\n\nI kinda hoped I wasn't describing something that people actually do.  But hey to each their own.\n\nTauri is an electron alternative. Main difference outside of allowing you to write the backend process in Rust is that it uses native web views instead of bundling chromium. The frontend options are still the same as with electron, so you could compile rust to wasm and use that or just use JS.\n\nI think the person you‚Äôre replying to confuses Tauri with something like Yew, which is an alternative to something like React or Angular. It‚Äôs mostly independent, but you *could* use both Yew and Tauri to make an entirely Rust-based desktop app with a web view UI. Or use Yew with Electron.\n\nWe are getting there https://system76.com/cosmic\n\nAt this rate we‚Äôll have 2,097,152,000 rust jobs in 2044\n\n[relevant xkcd](https://xkcd.com/605/)\n\nAnd probably only 7500 of those are blockchain, yay!\n\nEvery year you need to write a little new code + rewrite the whole codebase\n\nThat way jobs are exponential!\n\ntime to jump\n\n[deleted]\n\nAnd one trillion by 2064. Trust me bro, it's the hockey stick.¬†\n\nStill only 1/3 of devices running Java\n\nSurprised by comparatively low numbers for Kotlin and Swift especially. I thought native mobile development was bigger than that?\n\nEveryone just makes a react native app, and I‚Äôm only half-kidding.\n\nA lot more portable, you can have a single codebase for mobile and web.\n\nAt work, they are now using Kotlin multiplatform thing for mobile App. Previously it was Cordova with Typescript.\n\nNow our iOS code is just some Swift for UI, the rest is Swift calling Kotlin which is common for both platforms. Most of the time...of course there were some platform specific things to handle.\n\nI think we have worst of both worlds now :)\n\nYou just have to hire web-android-ios expert senior rockstars, because that abstraction breaks down a shitton of times, and you have to fkin read OS internals to figure out what the fuck happens.\n\nserious question, is it not flutter? how is react native trends against flutter?\n\nFlutter works poorly on iOS, that's why React Native won.\n\noh React Native is better on iOS? that's new to me\n\nIt's new to you because it's a complete nonsense statement. No end user would be able to tell the difference.\n\nIn particular, Dart has 4x the demand of Swift?  That‚Äôs a little hard to believe.\n\nAs a swift and flutter dev I can‚Äôt believe it. This made me question the entire article.\n\nremember its not how many jobs there are out there..... its how many are hiring\n\nSwift could all be happy devs, no one leaving, just growing.... while Dart is a revolving door?\n\njust a hypothetical\n\niOS dev market is all off shored to south east asia, also this guy can't possibly have scoured whole of internet.\n\nI rarely see Native mobile dev roles these days, It's usually React Native or Flutter.\n\nI'm also surprised that Kotlin isn't steadily taking over the Java landscape. I had a job where I used Kotlin for the backend and that was amazing!\n\nIt's certainly better than Java, but I don't know if it's enough better to be worth switching. Kotlin's future is also a bit uncertain, since they don't have control of JVM development, and Java is working on features like null safety and primitive types, so betting on Kotlin in the long run might not turn out that well.\n\nCurrently in a backend Kotlin job, I don‚Äôt think I can ever go back to Java honestly\n\nSwift is a beautiful language. Too bad it is only useful for Apple apps.\n\nThere is only so much need for apps when web app can do msot of the time the exact same thing with half the hassle.\n\nYeah, me too. I mean, forgetting mobile altogether, kotlin is such a wonderful language that the fact more people have jumped on board bewilders me. Then, throw in the three options of having it backed by jvm, native or js, and it is just a delight. Not to mention first class support in intellij due to jetbrains making the thing originally. Using C# or Java now after using Kotlin makes me sad.\n\nWith non-mobile development it is probably much easier to search for good Java developers and make them learn Kotlin instead of searching specifically for Kotlin developer.\n\nAlso there is always legacy code that is probably written in Java, so you probably will write/maintain new services in Kotlin and maintain or migrate older service to Kotlin in Java\n\nC# is not too bad if you use Jetbrains Rider. This is  coming from someone who did Android and Kotlin to now doing backend C#. I definitely do miss Kotlin's scope functions though and being able to create private extensions.\n\nInteresting and not really unexpected. What would also be interesting to see is the average pay offer for those different positions (I know they don't post those). Some languages might have smaller number of openings, but higher demand in highly skilled developers.\n\nIt also confirms that some language proponents are way louder than the actual demand for that language. I won't mention any names :P\n\nAs a person who is enjoying Rust employability is not my main driver.\n\nI mean if you really understand rust and its concepts of a low level language, aren‚Äôt they somewhat easily transferred to maybe c/cpp?\n\nYeah but once you use rust, c and c++ will feel bad. So that‚Äôs the only thing.\n\n&gt; c and c++ will feel bad\n\nSo nothing will change?\n\nI would say not particularly.\n\nIdiomatic code in all 3 of these is drastically different.\n\nIf you‚Äôre very used to C programming, it‚Äôs going to be a system shock going to rust, where you‚Äôll constantly be saying ‚Äúthis is safe and I know it is safe, come on dude‚Äù.¬†\n\nYeah and it's normal. The stuff written in C/C++ is usually way too critical to risk porting over to GO/Rust which is why adoption is slow and the non important stuff... well, it's not important so why waste time/money rewriting your python backend into Rust?\n\nPeople forget that development time costs a lot because you spend money paying people and hold back new projects. If there is not a good reason to rewrite a code base, no one will just because it's \"cool\"\n\nHey man I‚Äôve got a job writing Rust code, we do exist\n\nYou mean to tell me that the flood of typescript and python \"Entry level unpaid 1-3 years work experience required\" jobs might be skewing results?! Lol\n\noxidized iron?\n\nmovie where alec baldwin literally shot somebody?\n\nThe thing that I take tetanus shots to protect against ?\n\nThe unga bunga survival video game?\n\nIt's not the unmentionable thing that causes tetanus\n\nCTRL F CTRL F CTRL F WHY IS NO ONE TALKING ABOUT THE BEST LANGUAGE EVER MADE\n\nWhy so crabby?\n\nI am kinda surprised about Ruby. I know it gets used quite a bit but I didn‚Äôt expect 1/3rd of PHP\n\nFor a while, lots of websites were being made with Rails. They still exist and need maintenance. Probably a lot of them have gone through some failed rewrites to non-Ruby along the way.\n\nI doubt it, all Rails programmers I know still love it and I can‚Äôt think of a good business case for a rewrite (rewrites are already hard to justify, let alone if the programmers still support it).\n\nI‚Äôm just surprised it‚Äôs so mainstream now.\n\nIn California job postings are required to post a salary range.  It's been such an improvement to the experience of looking for a job. Let's hope other states adopt this so that tools like this can get a better picture of compensation.\n\nI plan on retiring when Java is the new COBOL so I can take a contracting gig once a month to fix some random disaster created 40 years ago.\n\nProbably be so many applications still using JDK8 when you retire\n\nSmells like money!\n\nMy first job was working on an application still on Java 5, and this was in 2018. Yes, it was painful.\n\nSame, I feel I'm one of the few who enjoy Java. Been stuck in python land for a while and missing it.\n\nYou're gonna work forever.\n\nAce use of scraping, data, analysis and visualisation! \n\nInterested to know what causes the blips in Aug24 - perhaps a real world explanation, or perhaps a data issue such as problems scraping from a specific site? The combo of some staying at their typical percentages, three spiking up and one spiking down seems like the latter could be the case.\n\nGreat work and super useful, thanks for sharing!\n\nThank you!!! (the charts are made with Vega Charts, nice lib btw)  \n  \nYes, the August spike could be due to many reasons, whether real-world factors or data issues. That being said, I didn‚Äôt notice any issues or specific alerts. Maybe it‚Äôs just because August has fewer jobs, so more noise and spikes can happen. Or maybe one of the sites I scrape has published invalid job offers or something similar. I could also adjust the queries to only include job offers that have been present for more than, say, 3 days, and see if that solves the problem.\n\nAlso, Glassdoor recently made an update that made it harder to scrape jobs, which could also be a reason since I have less jobs in th elast months... but still, LinkedIn is my main source and has been quite stable.  \n  \nData is really interesting lol, you kept me thinking again about that spike, I should investigate.\n\nJust FYI every graph on the page is titled as JavaScript / Typescript jobs instead of the relevant language\n\nYes, i see.. lol. Thanks for reporting, i will uptade the chart titles shortly\n\nFixed!!! Thanks again\n\nIsn't JS just added to every listing that has anything to do with the web?  I'd be more interested in JS as the job itself.\n\nNow weight it by salary\n\nHow do you think it would change?¬†\n\nSometimes less demanding language pay better.\n\nIn my experience, the less demand there is for a language, the higher the potential salary. In general. I'm sure the reality is more complicated than that, so it would be interesting to see some data.\n\nIt‚Äôs interesting because this is economically backwards without considering supply. Small levels of demand might also have disproportionately lower levels of supply, if the pay is higher.\n\nIt's because of a common fallacy of conflating demand and \"number of corporations asking for it\"\n\nPretty much stays the same over the years\n\nPerl hasn't yet fallen off the face of the earth. That's nice to see.\n\nI am more proficient in Perl due to a history in UNIX Systems Administration than any other language.  It surprises me it fell off so hard relative to Python.  I assume it‚Äôs because of Perl‚Äôs awkward syntax for object-oriented data structures and functions.\n\nThe go to answer is the fumbling with Perl 6. It was ambitious, but they took so long to come to a consensus and produce anything that it gave Python time to catch up.\n\nAlso Python took the lead because yes - it is 'simpler' - and that gives it a broader appeal, which co-indices with the vast rise in 'learn to code' careerism. Programming is no longer just geeks and hackers who would invest the time in a versatile, expressive language like Perl that grew with you.\n\nWhen I write Python it feels like retrogression. When I see something sold as 'simpler' I read 'limiting'. Stabiliser wheels were great when learning to cycle, but I haven't needed them since finding my balance. Neither do I need a high chair to help me sit at table. Etc.\n\nC and C++ are very popular with US Defense Contractors\n\nCries in Ada\n\nTIL Ada is actually used\n\nDisappointingly, [Elixir](https://elixir-lang.org/) language, designed for highly scalable and distributed systems, is not even on the radar. I would expect it to be a great fit for many modern cloud systems.\n\nOP probably didn‚Äôt include elixir/phoenix/live view in the keywords they were looking for.\n\nIt‚Äôs basically the same reason Erlang isn‚Äôt particularly popular.  For the most common use cases it has no particular advantages over other languages with bigger ecosystems, and functional programming is not mainstream.\n\n[deleted]\n\nTrue, but it's super niche outside of that.\n\nFor a language to gain traction it must be popular, and to become popular it must gain traction.\n\nFunny to see this, I just applied to a job in NL that's looking for an Elixir dev. That was literally the one one I've ever seen though, definitely an underrated one\n\nThere are not many developers so it's difficult to hire and to some level with Go you can get same results (although not so automatically and no magic live reloading) so although it is known that Erlang/Elixir is quite good I don't think it's a good first choice for new systems.\n\nit's sad elixir is the language I always want to use, but never can :( \n\nI came up with an excuse to write a small script to stress test our app using elixir workers once, it was fun, wish I could do more :(\n\nHi all!üëã\n\nI‚Äôm excited to share that I have updated my blog of the most demanded programming languages for 2024! üöÄ\n\nFor 21 months I have been scraping job portals like Linkedin, Glassdoor, Dice etc. and selecting the dev related jobs from it. After that time, I have a database of more than 12 Million dev job offers. With that data, I am able to publish this blog, where I make a list of the most demanded programming languages.\n\nHow has this study been made?\n\nThe main objective of this study is to categorize the \"dev jobs\" by its programming language, minimizing the errors and getting the most accurate information possible. To achieve that, only the title has been used to categorize those jobs into programming languages. This is because we want just the jobs that explicitly require a programming language.\n\nFor example, a job with the title \"Backend developer\", even it has stack defined and also description with job requirements, is discarded and does not count for any language. Otherwise, a job with the title \"React Developer\" would count as JavaScript / TypeScript, and likewise a job with the title \"Laravel Developer\" would count as PHP.\n\nIs also important to note that one job offer can count for 2 or more languages. For example a job with the title \"Full Stack Developer (Django/Angular)\" will count for languages Python and JavaScript / TypesScript.\n\n. . .\n\nHope you like the article, if there are any doubts about the study let me know in the comments!\n\nNote: I advertise that the blog post has \"minimal\", \"non-intrusive\" ads. Even so, I have red numbers each month lol, so understand that this may help keep my work into the future, thanks!\n\nThe titles are wrong on some of your graphs.  They all say \"JavaScript/TypeScript jobs\".\n\nUps, thank you. I forgot, and i also didn't see it. I will update the chart titles soon. Thanks!\n\nFixed, thanks!:)\n\nNice work.\n\nCurious about the methodology when it comes to phrases such as \"Experience with object oriented programming language such as Java, C#\".\n\nBut the job is actually hiring for only one of the langauges.  In this case, does it counted as both Java and C#?\n\nYes, it will count for both!\n\nHmm, interesting effect that has. On one hand it illustrates which languages give you access to the most jobs. But on the other it hides which languages are actually being sought in those jobs which could make smaller languages appear even smaller relative to larger languages.\n\nFor example a Kotlin or Scala job listing is very likely to explicitly also accept experience in Java or C#. Similarly entry level positions might just list all other common languages as valid experience, so popular languages could end up feeding each-other number wise.\n\nIn a future analysis, it could be cool to compare how many jobs are hiring for just the main language vs jobs accepting that language as experience\n\nVery interesting. I wonder if it'd be possible to split out C from C++, as I think of those as different use cases. My expectation would be that C++ is the lion's share of that, but I don't know.\n\n&gt; For example, a job with the title \"Backend developer\", even it has stack defined and also description with job requirements, is discarded and does not count for any language.\n\nHow many job offers were discarded, if they were not, how impactful would they be over the dataset?\n\nSurprised to see VHDL on the list but not Verilog or SystemVerilog.¬†\n\n*ABAP* \\*shivers\\*\n\nWhen you say \"job offer\" do you mean \"job posting\" or as in a person was actually offered the job (after interviews, etc)?\n\nIf it's just postings, [how] are you filtering out posts that aren't real / aren't going to hire?\n\nIf it's offers... where are you getting that much data?\n\nYes, I agree that \"job posting\" is more accurate for my use case. They are not \"job offers\" to a candidate, they are simply job postings listed on many websites like LinkedIn, Glassdoor, and so on.\n\nWhich language stayed opened/unfilled the longest? That's the only useful data. It shows that they're in demand but lack supply. Who cares if the language is popular if the supply also outstrip demand.\n\nIf I would hire a programmer I would not really care about what languages he knows, because it's essentially all the same unless you need to to extreme optimizing.\n\nIn my career, in same position, I haved used (every day on a given project) C++, C#, NodeJS, TypeScript and PHP.\n\nI agree there's not much reason to care what languages a candidate knows, so long as they express interest and are capable of learning.\n\nWith that said, this study is not analyzing languages listed in job requirements, it is studying languages listed in job titles. And there is excellent reason to advertise exactly what tech stack the employee will use in a job title. Not out of worry that skills won't transfer, but because of the risk that the candidate will find out midway through the hiring process (or far worse, a few weeks into the job) that they don't actually like the language(s) the company is using.\n\nOn the job training isn't really a thing anymore, is it?\n\nWhat happens when you adjust for how many people know the language? Something lower on the list might actually have a bigger gap in the demand / supply.\n\n[deleted]\n\nThis dataset is actually really useful, assuming it is correct.\n\nWe all knew that JavaScript is popular (unfortunately), but that it even leaves behind python in its dust is amazing. Sure, number of jobs is not everything, but seeing JavaScript so far ahead even of python, is huge. It means that the browser is by far the biggest amplifier in this regard right now; without the browser, JavaScript would not really be used at all.\n\nsurprised SQL is so low.\n\nThis! It‚Äôs been the most consistently relevant technology for the duration of my career (I‚Äôm old).\n\n&gt; Go is a young language created only 12 years ago by Google\n\nGo is almost 15 now. You probably meant first stable release (1.0) which was indeed 12 years ago.\n\nRust isn't rusting anytime soon fosho :)\n\nRust at 0.39 % is a painful reality check. I would have expected 2-3 %, but this is really deflating.\n\nSomething to keep in mind, and it happened with C++ as well back in the day, is that initially a lot of the activity was internal conversion within companies, so there aren't any publicly presented offerings, but there are new Rust jobs. I pushed C++ into the company I was in back in the mid-90s, and we just converted over. I trained them up, and we were now a C++ house but never advertised for a single position.\n\nThat's almost certainly happening right now. If I'm able to push Rust into my current company, I guarantee it would happen exactly the same.\n\nVery interesting,  thanks for sharing!\n\nI have one question: \n\nHow accurate are these job descriptions?\n\nJulia's just hanging on by a thread, but I'm happy to see it included in the list!\n\nIt will be interesting to learn how many candidates are looking for jobs in each of these languages\n\nOk but what's the average compensation per language?\n\n2023 study about salary: [https://www.devjobsscanner.com/blog/top-10-highest-paid-programming-languages/](https://www.devjobsscanner.com/blog/top-10-highest-paid-programming-languages/)\n\nI will soon launch the 2024 update. That said, salary data is very difficult to calculate, and there is more noise, so take it with a grain of salt.\n\nwith the rise of \"fake jobs\", do you think it would skew the results of this? Looking at your graphs, there doesn't seem to be much fluctuations in the past 2 years.\n\nThere may be \"fake jobs,\" but in my opinion, I have not noticed an increase in them... Why do you think so?\n\nAwesome, pretty, and well written.\n\nThank you! :)\n\nWe are in a loop: JS is in the most demand because it is easy to find a JS developer. The same applies when we compare Java with Scala: big and small corporations prefer Java developers.  \nCompare with ClojureScript (Clojure on JavaScript) and Clojure (for JVM). Clojure is the least popular, but it is demanded in a few really huge banks.\n\nPlus, legacy software... mostly in JS, not in TS; mostly in Java and not in Scala; and so on.\n\nIf I had a 12M job for 1 month, I'd be set for life.\n\nInteresting to see Swift and Kotlin so low; I thought mobile development was still really big.\n\nI think it is because a lot of people is using React Native or Flutter. It is not at good at using the device capabilities, but it is multiplataforma and web.\n\nCan't believe python with django is that popular I gave up on it because I was rarely finding it\n\n.NET and C# on the rise babyy!! niceoo\n\nC# at top 4, let's go. Modern C# is a joy to work with.  Asp.net core is one of the best choices to write scalable backend systems IMHO.\n\nThese numbers are not useful.  They don't talk about how hard it is to fill the jobs (how much supply there is).\n\nThis is as bad as the TIOBE index.  This is *not* demand, as demand should be used in situations like this.  Look at their click-throughs to see how they do this.\n\n(I'll throw numbers to extremes to point this out):\n\n* If you have 10 million postings for language X, and 200 million people with that skillset, language X is not in \"high demand\".\n\n* If you have 1 million postings for language Y and only 1000 have that skillset, language Y is in *monstrously* high demand.\n\nGoing for the most demanded languages does not always pays, you need to go with the best candidate ratio. My first job was because of R, although I use a JavaScript and python a lot if I did not knew R would still be unemployed today\n\nI love JavaScript more and more!!!\n\nJust compare how many Charting and Diagraming tools we have in JS, and KaTex for example, tools such as ECharts, D3.JS, Mermaid!!!\n\nJavaScript is most popular not just because it is \"for dummies only\" LOL ;) and it is not only Front-End: Node.js, TensorFlow.js.\n\nOne thing that always interests me is that PowerShell is never listed on these lists or job postings yet it is very much needed in many roles. I know it is considered a ‚Äúscripting‚Äù language but anyone dealing in DevOps, SysAdmin or AD roles should know it. \n\nMy $0.02.\n\nDevops engineer here with close to 10 YoE. Besides a short stint at Microsoft, I've never had to use powershell in my career.\n\nAnd I thank god everyday for that.\n\nI haven't used Windows in almost 15 years.\n\nThose would be more IT roles than developer roles IMO.\n\nWhy on earth would I ask for powershell to a person who is going to care after machines with Linux or FreeBSD\n\nand people promised me 3 years ago that rust will replace JS soon on the web once wasm is here. [Never bet against js](https://www.commitstrip.com/wp-content/uploads/2015/07/Strip-Le-mauvais-pari-650-finalenglish.jpg)\n\nHow is rust ever going to be on the web?\n\nI‚Äôd like to know where this list comes from. The vast majority of the SoC and hard/soft IP companies use SystemVerilog for design and verification, but it doesn‚Äôt make this list at all but VHDL does?\n\n[deleted]\n\nDo people really focus on learning languages to get jobs? It seems so antiquated. You will never learn enough on your own to use it effectively at a company shipping complex code. When we hire we usually focus on industry fit. Embedded dev only knows C, we do rust, who cares, if they are competent then we will train them. The fundamentals are what matters. I never understand the point of these language popularity posts."
  },
  {
    "title": "How an empty S3 bucket can make your AWS bill explode",
    "body": "",
    "score": 1478,
    "url": "",
    "created_utc": 1714461195.0,
    "author": "avinassh",
    "permalink": "/r/programming/comments/1cgmq28/how_an_empty_s3_bucket_can_make_your_aws_bill/",
    "all_comment_text": "&gt; S3 charges for unauthorized requests (4xx) as well[1]. That‚Äôs expected behavior.\n\nSo basically, you could use a directed attack (like DDoS) against a known AWS S3 bucket to raise the bills of a company that you don't like? Intriguing.\n\nYou can also buy GitHub stars for your enemy's repo and report them for abuse.\n\nOh that's evil\n\nyes\n\nthere was a reddit post a few months ago (now deleted) about some guy buying upvotes for users he did not like and getting them banned\n\nhow? he made the upvote process instant, instead of gradual.\n\nThat is VERY neat.\n\nI don't think spending money for online revenge is neat\n\nWouldn't the point be to get detected, not to avoid detection?\n\nRight. He does them instantly so he‚Äôs caught, instead of gradually to avoid detection.\n\nAh. I read it as\n\n&gt; he made the upvote process (instant instead of gradually) to avoid detection\n\nNot as\n\n&gt; he made the upvote process instant instead of (gradually to avoid detection)\n\nSomeone did this to my youtube channel many many years ago. Entire channel deleted along with hundreds of videos I had no backup for. YouTube support ignored me repeatedly.\n\nSomeone bought GitHub stars for your YouTube channel?\n\n[deleted]\n\nUber S3? Good choice. Their pricing is more competitive than Google Azure.\n\nAnd then I tried to grab their baseball bat, but I only grabbed the sock instead.\n\nComments and subs but close enough =D\n\n[deleted]\n\nAlways toasted\n\n[deleted]\n\nThat his private life was none of our business. Big oops.\n\n&gt;  YouTube support \n\n\nThere is no such thing. It's a lie.\n\nThis was 15 years ago man; I think they had a form or an email address or something back then.\n\nIt's still a lie. Unless, of course, you got a bajillion followers. Then yes, they exist and they take care of you.\n\nOh you mean it's a lie as in youtube support being supportive to small creators is a lie, yeah, I 100% agree. Most big tech companies are like that nowadays, but youtube and google were and always have been ahead of the game.\n\nTIL you can buy GitHub stars wtf\n\nThrough third party services, as a way to game the system. Same as buying views or reddit upvotes or anything. Twitter accounts.\n\nThere are many services where you can buy Twitch and YouTube views; Twitter, Instagram, TokTok, etc. followers; YouTube subs; Twitter, Instagram, TokTok, YoutTbe, etc. comments; GitHub stars; and many other user engagement things.\n\nYou can do the same thing to authors on Kindle Unlimited.\n\nGet a bunch of people to scroll quickly through their books and they'll get banned for gaming the system (They get paid per page read).\n\nThat's kind of concerning, since my Kindle has had problems in the past where it seemingly gets stuck on fast-forward and nothing seems to stop it except turning it off.\n\nOdd, my Kindle has done that too. At least I don't have to reboot. That takes forever.\n\nJust a power cycle, not a full reboot. I've found that cleaning the screen can mitigate the problem; maybe some sort of conductive buildup from skin oils?\n\nWhat do you clean it with?\n\nI use the alcohol-based spray I normally use for my glasses, but standard screen cleaner should work just as well.\n\nI've done that to books I've read in Patreon/RoyalRoad before.\n\nWow that is... wow.\n\n...Why does github even have a system that's abusable?\n\nBecause any quality metric is gamable and it's helpful to have a note of some kind that says \"a lot of people want to remember this\" when you're looking for big or high quality projects.\n\nIt's called a Denial of Wallet attack\n\nOr find the largest static file on their website and request it repeatedly. Doesn't even has to be that big, a 50 KB image once per second is 4.3 GB per day, or almost 130 GB per month. Chances are that the JS blob alone is bigger, especially if you request it without offering compression to the server. If you're lucky, the site doesn't runs a reverse proxy cache, or the cache is bypassable with URL params, a session cookie, or a simple POST request. Most webservers will deliver static resources when you make a POST request to them as if it were GET, but caches generally don't catch this and will allow you to bypass them. If they do bot prevention, you can run the requester in form of a tampermonkey script in your browser, and simply keep the console open to bypass local browser cache on refresh.\n\nPlease don't ask how I know.\n\nTrue, but you could mitigate that with a service like Cloudflare. The problem in the OP is really difficult to mitigate... And you'd expect AWS to give you the tools to do so.\n\n&gt; True, but you could mitigate that with a service like Cloudflare.\n\nYou can, but that requires extra configuration, because cloudflare won't know by itself that the POST goes to a static file and is meaningless.\n\nCloudflare makes it pretty easy to force caching on the Cloudflare &lt;=&gt; S3 leg but yeah you might be able to get a couple of months before they actually set it up right. Most people setting up their site don't fully understand how this stuff works.\n\nI had to setup aws account (and infrastructure) once for a company i worked for. We \nwere only 5 people so ... it made sense that I (the programmer) had to do it. There was nobody else.\n\nAnyway, I knew nothing about aws, I looked there and I was sure that I would need  10 lifetimes and aqnother 5 degrees to fully understand all that shit, so I did\n what evreyone does: my best.\n\nThat is, I hit the keyboard until what I wanted happened.\n\nWas it good? Was it best? Was it infailible? \n\nhell no. it was working.\n\nOr cloudfront within AWS?\n\nWhat's really crazy is that you'd think making a Requester Pays bucket would be Amazon's solution for mitigating this, but no! Even with Requester Pays buckets, the bucket owner pays for the failed request if the requester doesn't include the appropriate header.\n\nSome great and solid advice right there! Also much simpler than figuring out bucket names, it seems.\n\nhow do you know? :P\n\n&gt; or almost 130 GB per month\n\nAnd that's like $10 or less of egress cost a month. Completely inconsequential to a business.\n\nI'm pretty sure my basic residential internet can request a 50kb image a lot faster than once per second.\n\nNow imagine what a 10gbps internet connection does in a single night.\n\nJust change the post params to automatically generated slurs, unique per request, hopefully that trips up the cache.\n\nWell yeah, that would be a unique request so it couldn‚Äôt be cached lol\n\nDo you think there are that many unique slurs?\n\nI misread slur for slug which is just a random string\n\nYou would combo them obviously.\n\nThere are if you double them up\n\nAutomatically generated slurs sounds like a fun band name.\n\nWhat genre?\n\npostmodern poetry\n\nI've got not fucks to give ‚ô´ ‚ô´\n\n\"Fun Band Name\" sounds like an automatically generated slur\n\n&gt; or the cache is bypassable with URL params, a session cookie, or a simple POST request.\n\nDepends on how cache is configured. I remember that this is optional for cloudfront, and disabled by default, and sending a POST request would only bust local cache.\n\nGood thing I cache those assets with a CDN\n\nKnew all this expect for POST sometimes working on static resources, good to know, thanks.\n\nBold use of \"expected behavior\" here.\n\nThis is a new dimension in a long war -- two decades ago when google ads were still newish I heard stories of bad actors clicking on competitor ads repeatedly.\n\nUntil just now I assumed this click fraud was petty antagonism, but now I'm thinking it's a way of clearing out higher bidders. Even if they get removed as click fraud, the budgeting system would probably pause the campaign until it does get removed.\n\nYeah this is outragious imho. If AWS didn't cancel his fees would he then have to sue the company that made the tool doing this? üëÄ\n\nI didn't like the financial unpredictability of the cloud before, but I sure as hell don't now.\n\nThat is not ourageous at all. S3 is often used for static file hosting. You are allowed to put anything out there for anyone to request it via http and it's your responsibility to pay for it if you do so. You are also allowed to block access and let anyone who sends request know the access is denied. If AWS wouldn't charge for those you could just build a hosting platform and share anything via your 403 or 404 page for free!\n\nIt's called DOW: Denial of Wallet\n\nThat‚Äôs like DOS-ing a company that has a policy that locks accounts for too many bad password attempts by making too many bad password attempts‚Ä¶ for all the email addresses you can find or guess.\n\nThis is actually really bad and needs way more attention now that it's knowledge \"in the wild\".\n\nEven if your bucket is private, with proper policies/IAM permissions set up and if the bucket name has randomization in it, you can still get hit if you use something like pre-signed URLs for uploads to the bucket which would reveal the bucket name. You would then have to proxy uploads through your own servers to avoid revealing the bucket name. Even then, someone could accidentally/intentionally keep leaking your bucket name and you would be forced to keep changing it. Changing a bucket name is not like rotating a leaked password/token, it requires migrating items in the storage, updating and re-deploying applications etc. Nor is it easy to trace back how it was leaked, who keeps an audit trail on access to bucket names?!\n\nBucket names were never implied to need to be secret, and its obvious they weren't designed to be that way. But if you don't keep them secret, you are vulnerable to a billing attack.\n\nThis *needs* to be addressed as there is no mitigation.\n\nThere's a technique to discover buckets even if they're meant to be private in *any* AWS account (due to the response information from API calls, specifically CloudTrail if I recall), so theoretically you can spike literally anyone's bill.¬†\n\n\nJust another case study of how Security through Obscurity isn't a thing.\n\nI don‚Äôt know about S3, but in GCS, bucket names are globally unique. If you want to know if a bucket with a specific name exists, just try to create it.\n\nE.g., one could try it with `my-competitor-dev-datasets` and see what comes up.\n\n&gt; y AWS account (due to the response information from API calls, specifically CloudTrail if I recall), so theoretically you can spike literally anyone's bill. \n&gt; \n&gt; Just another case study of how Security through Obscurity isn't a thing.\n\nExactly the same in S3. Globally Unique.\n\nI am pretty sure I saw a basic `aws s3 ls` to return different errors for a bucket that does not exist and a bucket existing in another account I forgot to switch aws-cli into. Should not be hard to script it out to probe for common names...\n\n\"anyone's bill\". For some customers, you'll need a large botnet to make enough requests for them to even notice the spike\n\nOP's case is special b/c the open source tool was accidentally a free distributed client network. The real question is \"What would it cost you as a caller to give someone a $1000 S3 bill?\". If the answer is \"nothing\", this is a huge problem. If the answer is \"$1500\" I doubt it's a big deal.\n\nThis is answered in the post:¬†\n\n\n&gt; Standard S3 PUT requests are priced at just $0.005 per 1,000 requests, but a single machine can easily execute thousands of such requests per second.\n\n\nIt would cost you virtually nothing to give someone a $1000 S3 bill.\n\nI'm skeptical that AWS would allow unauthed 1K+ QPS from a single IP address without taking action at the gateway. If someone has proof that it's let through, fair enough, but this particular case was naturally a distributed \"attack\".\n\nSo what? Use IP proxies they are cheap\n\nI mean, if they're able to bill the AWS customer for it they have way less reason to care. Sounds like they agree that it's a problem and are working on a fix though\n\nNot of disrespect but you‚Äôre skeptical a company would leave a mechanic that makes them money?\n\nMaybe, but it has to thread the needle. The abusive traffic has to be small enough that it doesn't cause other collateral damage that AWS support has to deal with. It also has to be small enough that it doesn't become widely known that AWS will fuck you on unauth'd S3 charges. While that seems profitable in the short term, the customer service headache of ppl trying to get refunds will also start to mute gains. \n\nSo I totally believe that AWS was like \"Uhh neat, we were lazy on this thing and it's also making us a bit of money\", but doubt it's some huge nefarious plan to scam significant profits from ppl. \n\nIf I want to look at nefarious plans, AWS's convenient refusal to cap billing is the worse one.\n\nI appreciate that perspective. Here, have an upvote!\n\nIt's a huge problem. You don't even need an AWS account to hit an S3 bucket, as he documents in the article.\n\nIf you are a big player and trying to attack smaller, up and coming competitors, maybe even FOSS Projects that just don't have $5000. And $15000 is a fairly small \"marketing budget\".\n\nI think this is a good reason to generally avoid AWS and other uncapped billing services if your budget is small. Personally I used DigitalOcean rather than AWS for hobby work out of a fear like that (and it paid off when I got hacked and learned an important lesson about fail2ban and ssh keys and it cost me $0 extra version a $50K AWS bill).\n\nWhat was the lesson you learned?\n\nIt was a $5/month droplet, I used a hard-to-guess password and assumed it was safe. What I didn't realize is hackers will scan known IP ranges for online servers and brute force passwords on them. A 6 character hard to guess password isn't hard to brute force if you don't have fail2ban or similar slowing them down. \n\nNow all my instances require a unique SSH key to remote logon, and I generally add fail2ban on top.\n\nSince I was using DO the consequences for me were:\n\n1. A slow server for a while that I couldn't figure out.\n\n2. A strongly worded email from DO that my server seemed to be compromised.\n\n3. Deleting the server and making a new safe one.\n\nEdit: Btw this was almost 10 years ago, things may have changed a bit in the meantime (but AFAIK I haven't been hacked since, I still have a slightly beefier droplet running my hobby stuff to this day)\n\n&gt;  What I didn't realize is hackers will scan known IP ranges for online servers \n\nI don't use default ports for anything other than 443. Postgresql, ssh,  etc.\n\nThe last time I said so on /r/programming I got flamed by a bunch of \"senior and/or experienced devops and/or engineers\" (their words) people about how noob it is to rely on security through obscurity.\n\nAll I know is, anything that wants to scan my IP has to scan the entire 16-bit range of port numbers.\n\nI've been toying with the idea of a tarpit[1] for a few dozen random ports in that 16-bit range.\n\n[1] A server that accepts a connection, and then *slowly* sends through a TLS server hello, sending 1 character every `rand() % 5` seconds, forcing a single character into a single IP datagram, retransmitting the occasional datagram to simulate loss of acks, etc.\n\nThe only thing you gain by changing ports is less noise. I also always move ssh to a different port. This way, the security log becomes much more readable and entries are basically relevant. But it really doesn't protect against anything, it just makes your life easier.\n\n&gt; The only thing you gain by changing ports is less noise. \n\nNot the *only* thing.\n\n&gt;&gt;&gt; What I didn't realize is hackers will scan known IP ranges for online servers and brute force passwords on them.\n\n&gt;&gt;  anything that wants to scan my IP has to scan the entire 16-bit range of port numbers.\n\nBeing secure against untargeted mass attacks is still the *first* line of \"defense in depth\".\n\nSure, if someone *targets* your specific IP they'll quickly determine all open ports. But the problem I, and the GGP, and just about everyone with a public facing IP, are **untargeted** attempts by bots.\n\nI mean, even if they *don't* make any brute force attempts, all they have to do is record your IP for $SERVICE, and try every 0-day for that service every day.\n\nIf you can't think of a good reason for running PostgreSQL on 5432, or for running ssh on 22, or for running MySQL on 3306, etc ... then why use the defaults?\n\nIn my case, there is no good reason for me to run (for example) ssh on the default port. Not a single one.\n\nI feel like it's a \"Yes, and\"\n\nUsing non-standard ports will absolutely help protect you, OTOH it's really quite easy to use fail2ban and an ssh key once you figure it out, so using the non-standard port INSTEAD of those two seems unnecessarily risky. \n\nWhich then leads to the argument, if you're using fail2ban and an ssh key, is the non-standard port just more trouble than its worth?\n\n&gt; Which then leads to the argument, if you're using fail2ban and an ssh key, is the non-standard port just more trouble than its worth?\n\nI use both fail2ban and keys only, but there's more than ssh.\n\nRunning non-standard ports on every service you use is just another layer. If you can't think of a good reason to use the well-known port for $SERVICE, there probably isn't one.\n\nInstead of creating tar pits, I have ssh configured to only accept keys. They're welcome to try to brute force and waste their resources here instead of attacking more vulnerable people\n\n[deleted]\n\nLol, yeah lesson learned. 10 year ago me kinda assumed that fail2ban was magically built in or they'd get tired or something...\n\n&gt; \"What would it cost you as a caller to give someone a $1000 S3 bill?\". If the answer is \"nothing\", this is a huge problem. If the answer is \"$1500\" I doubt it's a big deal.\n\nHarassers may be willing to pay for it.\n\nSome years ago a vtuber did a stream in which from her youtube viewer statistics she listed the countries her viewers were from, including Taiwan. Chinese nationalist viewers got mad (since they don't recognize it as an independent country) and spammed her channel and everyone who dared collab with her, even when she switched to membership-only chat.\n\n(What makes it somewhat funny is that since YT is banned in China they must've used proxies to watch her stream - and afaik most proxies used by them are located in Taiwan...)\n\n&gt;This needs to be addressed as there is no mitigation.\n\n\nBut that wouldn't pad AWS' bottom line\n\nJust like how Amazon doesn't really care about all the fraudulent stuff sold via their shopping branch. They only do the minimum of what they're legally required to do because if someone doesn't realize or realizes too late, they get their cut.\n\nI run a business for sellers who sell direct to Amazon, all the ‚Äúshipped and sold by Amazon‚Äù stuff. You would not believe how much money Amazon blatantly steals from these sellers. We see an average of 4.5% loss for every seller due to things like bullshit fees they charge and things like Amazon claiming they didn‚Äôt receive all the product shipped despite the seller having evidence it arrived at an Amazon warehouse. I‚Äôm waiting for the day someone exposes just how much money Amazon is stealing from people\n\nWell, it's worse... OP essentially accidentally put themselves in the middle of a DDoS, and that's something that costs money to mitigate, even if it's just to absorb the traffic. So really, it's a question of whether AWS eats a loss or whether you do. I guess I agree that AWS should, and presumably it costs less for them to serve a 403 than they charge you, but let's be clear what we're asking them to do.\n\n[The very first thing in the article is an update where they link to Jeff Barr's Twitter post that states AWS is aware and fixing it.](https://twitter.com/jeffbarr/status/1785386554372042890)\n\nThat's exactly what you want to see from a company. Not sure why people automatically assume it's some malicious action to squeeze every dollar from people.\n\nIt's also absolutely mental that bucket names are globally unique. What were they thinking?\n\nIsn't this supposed to be AWS problem?  \n  \nSue them to change their policies!\n\nThis is really bad, now we have to treat S3 bucket names as secrets.\n\nSecrets which you cant rotate\n\nGonna have to start using emojis for bucket names, jk\n\n[deleted]\n\nmax 63. discovered that minutes ago while migrating everything out of my common english word bucket\n\nSecrets you can't even control.  Just look at all the buckets generated automatically by services like Amplify, SageMaker, etc, etc.  All with the same name template and a relatively small alphanumerical id...\n\nYou must work for Acme Corp, or Insert Name Here Inc.\n\nClearly they sell on-site 5 gallon containers customized with names! \n\n`s3://your-bucket-name-here`\n\nIME *anything* in AWS can make your bill explode.\n\n[The age old meme](https://i.imgur.com/AcKd1IG.jpeg)\n\nreminds me https://arstechnica.com/cars/2019/08/wiseguy-changes-license-plate-to-null-gets-12k-in-parking-tickets/\n\nsounds so dumb, at least they cnacelled the bill lmao\n\nYa, but they did so begrudgingly:\n\n&gt; However, they emphasized that this was done as an exception.\n\nand refuse to do anything to prevent the same thing from happening in the future.\n\nA NullPlateException.\n\nHaha good one, however comment you are replying too references the exception made by amazon in billing, not an exception relating to the null plates.\n\nI think attempting to drop a database should raise more than an exception. An error would be more adequate.\n\nAmazon say they're going to fix this:\n\n[Thank you to everyone who brought this article to our attention. We agree that customers should not have to pay for unauthorized requests that they did not initiate. We‚Äôll have more to share on exactly how we‚Äôll help prevent these charges shortly.](https://x.com/jeffbarr/status/1785386554372042890?s=61&amp;t=f9qtlIpZbwqHZa3_FyhWpg)\n\nTHANK YOU. Finally, a decent article, no redirects, no blog spam; just a short, to the point article on this subreddit.\n\nThis is insane. I got other shit to do and now I need to worry about this...\n\nThe good news is they said they'll fix it.\n\nAs if they don't make enough money charging for 200OK requests. This is just greed. Charging per network request is a ridiculous billing strategy in the first place.\n\nThe world went back to pay per traffic.\n\nNo, this is normal. The NSP does not care what is in the packets, just that it went through. Cloudfront permits rewriting responses via lambda at edge functions, so you could trick it to rewrite the response to 4xx range, and enjoy free traffic (because there's different pricing for aws to aws traffic).\n\nI was saying that charging per request is ridiculous no matter what code it is. It's a money grabbing pricing strategy. Just give us a monthly traffic allowance like every other VPS provider. Maybe charge for traffic above that.\n\nThis is crazy, afaik GCP doesn't charge per request...I must check now I am paranoid\n\nFrom GCP: Note: Generally, you are not charged for operations that return 307, 4xx, or 5xx responses. The exception is 404 responses returned by buckets with Website Configuration enabled and the NotFoundPage property set to a public object in that bucket.\n\nWell that makes sense as the 404 page is being served from the bucket.\n\nTotally\n\nThe problem isn't charging per request, it's charging for invalid requests that anyone can make\n\napparently they do -&gt; [https://cloud.google.com/storage/pricing#operations-by-class](https://cloud.google.com/storage/pricing#operations-by-class)\n\nIt's so unbelievable that we accept AWS and similar the way they are.\n\nYou can't even have an easy way to say \"shut down these things when the bill reaches a certain $ amount\".\n\nCustomers really ought to vote with their feet and leave AWS.\n\nThis is a major security vulnerability and you should name names so AWS can't sweep this shit under the rug\n\ns3 names share a global namespace, so, something like this as to be done on purpose by aws to squeeze customers out of every penny.\n\nThis is so bad that i can just download a names dictionary from the web and setup a small bash script that uses the awscli to do requests to the s3 buckets, and it‚Äôs bound to it a few valid ones and aws will happily bill the owner. Setting up something like this will take minutes.\n\nThis is just greed.\n\nI think it's less nefarious than that. \n\nIt's a really old service that has remained compatible for however long it's been around. 2006 IIRC.  \n\nI don't think they planned that far ahead. They should not charge per request though.\n\nDo we have the same issue in Azure? Asking for a friend.\n\nNo, Azure Storage Accounts actually has IP access lists that you can use to restrict who can talk to your storage.\n\n\nYou can even use Private Endpoints to make access to the storage account completely private without any exposed public interface.\n\n\nI'm not sure if AWS has an equivalent - they just have permissions which doesn't prevent this attack from occuring.\n\nThe fact that they charge for unauthorized requests is mind blowing to me. An entirely new attack vector to bankrupt small companies/people you don‚Äôt like?\n\n*User error - replace user*\n\nDoes this apply to Google Cloud Platform's bucket also?\n\nLooks like it doesnt:\nNote: Generally, you are not charged for operations that return 307, 4xx, or 5xx responses. The exception is 404 responses returned by buckets with Website Configuration enabled and the NotFoundPage property set to a public object in that bucket.\n\nLol. Now we need to deal with this shit. Time to move to cloudflare r2\n\nDo you know if cloudflare has the same issue with unauthorized requests? I need to move off S3 after reading this.\n\ncloudflare does not have this issue.\n\nDo you have a confirmation/source for this? Asking because I‚Äôm considering switching.\n\nSo is there still not a quota / \"circuit breaker\" scheme on AWS S3 so you can turn off a service automatically if it hits more than $X/month of usage?\n\ngood idea. When I enter working for amazon I will implement it\n\nOk time to get rid of those old buckets I guess, it‚Äôs a matter of days if not hours before some degenerate writes a script‚Ä¶. Edit: i was thinking it would be useful to have an equivalent of CVE for that kind of things.  I don‚Äôt imagine how may ‚Äúcloud cash sinkholes‚Äù there are out there‚Ä¶\n\nSo... they are ok with ppl gettjing ddossed. Another reason not to use AWS for projects.\n\nIt's not a denial of service. The service can handle it and the service will continue until your account fails to pay.\n\nIt's a DSoR not a DDoS\n\n(Distributed Source of Revenue)\n\nAlso known as a denial of wallet attack\n\nThey're [fixing it](https://twitter.com/jeffbarr/status/1785386554372042890).\n\nNow I'm scared\n\nSo that's why Amazon beat earnings.\n\nThis is a bucket.\n\n_Dear god_\n\nThere's more\n\n_No_\n\nLesson of the day: use Linode\n\ni have a volume there but was keeping an extra backup under a single english word bucket. think like `s3://chartreuse`. until I read this of course\n\nHow we all decided hooking ourselves up to this overgrown taxi meter is something I‚Äôll never understand\n\nhttps://x.com/jeffbarr/status/1785386554372042890?s=46&amp;t=YCumUxFKRp3dUvf5u5oELQ\n\nI think they acknowledged this issue and it will be fixed soon\n\nI am using Google Cloud Storage for my personal project. Does it have the same problem? üòÆ\n\nSurely you can restrict what networks can hit the endpoint?\n\nYou can restrict network access by bucket policy/IAM. The problem is, it's all the same mechanism and returns 403/unauthorized to the caller, and bills the bucket owner!\n\nWtf.  Is it something specific to S3 I hope?    I would expect that it doesn‚Äôt apply to resources in a VPC‚Ä¶.  Or does it?\n\nThis is specific to S3. Resources that actually get provisioned into a private subnet in your VPC are completely inaccessible from the outside world.\n\nS3 doesn't work like that. A \"private\" bucket isn't actually private in the same way resources in a private subnet are. S3 as a service is always public, and any restrictions are purely policy, including networking restrictions.\n\nFor example, you can set up a S3 bucket policy that restricts access to the bucket to be from inside your VPC. This is not a physical network separation, its pure permissions policy on the bucket. If someone attempts to access your bucket from outside your VPC, the policy is checked, fails, and they get a 403 and you get a bill.\n\n[deleted]\n\nTime for S4 (Simple Secure Storage Service) that fixes all the legacy cruft\n\nSure, but they're still going to bill you for unauthorized requests.\n\nIf it‚Äôs network restricted then you wouldn‚Äôt be able to reach the endpoint?\n\nIt would return either 404 or 403 from some network device.\n\nThey're not going through your network to get to your bucket, they're going straight to AWS, which serves the 403 but charges you for it.\n\nSounds like other commenters are saying you can't network restrict S3 in a way that returns anything other than just return 403 in the same way as a failed authentication does, which all ends up billing you.\n\nNo, you can't.\n\nAnd don't call me Shirley.\n\nWhat if you need to enable it for a certain region for users and attacks come from there?\n\nThen... you need to raise your prices.\n\nI am also aware of some analytic companies that charge per request, and the tokens are right in the browser code, since the requests actually come from the client browser.\n\nThat's super messed up.\n\nNoob question: why does AWS charge money for even unauthorized requests? Can someone enlighten me?\n\nBecause this way they can charge you more money and make more revenue.\n\nIf you want the Google-able term it's called a \"denial of wallet\" attack. https://academic.oup.com/cybersecurity/article/10/1/tyae004/7634012\n\nJeff Barr tweeted that measures are coming soon to address this.¬†¬†\n\nWtf why shld anyone be charged if the no or a wrong API key is ever used. The redirect is similar stupid ...\n\nIt's a good reason to get out of aws.\n\ndo other cloud services have the same problem?\n\nThis is now being addressed!  [https://aws.amazon.com/about-aws/whats-new/2024/05/amazon-s3-no-charge-http-error-codes/](https://aws.amazon.com/about-aws/whats-new/2024/05/amazon-s3-no-charge-http-error-codes/)\n\nlol AWS cancelled the bill as an \"exception\". What a joke. They break it, you buy it.\n\n[removed]\n\nhey, do not post your credentials online. it can be mis used!\n\nreason #91882 to not use AWS\n\nCan you name all 91881 previous reasons?\n\n$\n\n$$\n\n$$$\n\nKeep going\n\nCloudformation"
  },
  {
    "title": "Netflix has one 8kb ‚Äúhello world‚Äù on production ",
    "body": "",
    "score": 1477,
    "url": "",
    "created_utc": 1713540111.0,
    "author": "SDcat09",
    "permalink": "/r/programming/comments/1c7zjeo/netflix_has_one_8kb_hello_world_on_production/",
    "all_comment_text": "This could be an error, a training exercise, or a way to smoke test part of the system. I‚Äôll bet a token amount of money there‚Äôs some CI pipeline or dashboard alert that fires if this isn‚Äôt working.\n\n100% this. Loading [netflix.com](http://netflix.com) for a health check is going to be slow and expensive considering how much garbage that page has. Hidden endpoints like /health or /heartbeat that just return a single string are very common. That way you can ping every single host serving the website as frequently as you want and get back a quick \"I am up\" response without any overhead.\n\n[deleted]\n\nok\n\nok\n\nThis XML file does not appear to have any style information associated with it. The document tree is shown below.\n&lt;health&gt;ok&lt;/health&gt;\n\n&lt;response&gt;nice&lt;/response&gt;\n\nok\n\nI love that this feels so passive aggressive despite obviously being correct for a 200 response.\n\nack\n\nWhat about the health check of the health check?\n\n&lt;health&gt;fine&lt;/health&gt;\n\nIt's down!!\n\nhttp://netflix.com/healthcheckforhealthcheck\n\nYou've already had second health check\n\nok\n\n‚òùÔ∏è this guy healthchecks\n\nAnyone interested in this type of thing should also look into canaries. Basically it‚Äôs a means of understanding if your APIs are working and they can report on what is/is not\n\nI hadn‚Äôt heard about canaries until I read Go in Practice. The example they showed was testing if some object was equal to an interface, which in Go just means the object has an implementation of the methods defined by the interface. Pretty cool I think. I am a newbie at Go but I love it. So many things a developer would want are built into the standard tooling like unit tests, benchmarks and canary tests. You can get all the missing dependencies in your project by typing **go get ./‚Ä¶** at the top level of your project. It‚Äôs like they all the inconveniences developers have found in fifty years and said we will just put that in the tool chain.\n\nNetflix already has a healthcheck, it being [netflix.com/healthcheck](http://netflix.com/healthcheck)\n\nThat‚Äôs more likely a check to check if JS has built/deployed properly. It has too much of stuff for healthcheck (and they have an actual healthcheck endpoint)\n\nI wonder how OP found it?\n\nThe guy who found posted it on the other subreddit said \"I'm an introvert who stays inside all the time\" when asked this question\n\nThis is the whey\n\nThis was my thought as well. I've done similar with my own projects in the past. Have an endpoint that just returns a known string. Then if you can hit that endpoint and get the string back, you at least know your backend is up and responsive. Or have it read the string from the database, now you know the database is up and accessible too.\n\n&gt; 8kb\n\nit pulls in two netflix logos (~20kb) and a bunch of other js stuff. also, it checks your location\n\nit wouldn't be complete without location tracking lmao\n\nI'm assuming it's for the EU cookies prompt.\n\nThere's some stuff in there referencing \"cookieLaw\" so you might be right.\n\nProblem: cookies are a privacy issue\n\nSolution: track user location so you can conform to regional cookie law\n\nNo need to use cookies or follow privacy laws if you don‚Äôt store cookies and sell users data. The fact they do says exactly what they are doing.\n\nIt‚Äôs cheaper to be in compliance than to prove the law doesn‚Äôt apply to you.\n\nYou don't need to prove that the law doesn't apply to you, that's fantasy.\n\nIt‚Äôs not about the proof. This ain‚Äôt a legal decision. It s a financial one. The law creates an incentive to minimize the risk. And the industry as a whole, usually in legal advice from corporate counsel, has decided that it‚Äôs cheaper to just make everyone click the damn button than open yourself up to frivolous lawsuits and complaints about data collection. \n\nIt‚Äôs an unintended consequence of the law, but‚Äôs it‚Äôs still a consequence.\n\nAssuming we're referring to this script url (https://cdn.cookielaw.org/scripttemplates/otSDKStub.js), then yes, thats an asset from OneTrust, a third-party cookie management platform.\n\nIf they dont set cookies they wouldnt need a cookie prompt‚Ä¶\n\nYou're expecting them to turn off cookies specifically for helloworld page?\n\nI'd assume those prompts are site-wide, to avoid users circumventing the prompt and then potentially be in breach for not asking them.\n\nThey should turn off non-essential cookies site wide.  The GDPR does not require a cookie prompt for anything that is intrinsic to the service being provided.  Strava does not require a cookie prompt to save your GPS location, because mapping your GPS location is part of the service they provide to you.  Netflix does not require a cookie prompt to save your viewing history, because customized recommendations based on viewing history is part of the service they provide to you.\n\nThe only time that cookie prompts are required is when collecting or processing data outside of what the service requires.  If Netflix were to record other sites you visit through a third-party cookie, that would require a cookie prompt, because that has nothing to do with the service they provide.  If Strava were to sell your GPS location history to advertisers, that would require consent, because that has nothing to do with the service they provide.\n\nTL;DR: If they don't set **unnecessary** cookies, they wouldn't need a cookie prompt.\n\nwow, I didn't know that. And I was here thinking that the sites with the \"only necessary cookies\" buttons were being cool!\n\nme: only the necessary cookies\n\nthem: we wont save a cookie that says these are your preferences, we can, that would be a necessary cookie, but we won't\n\nRight but unfortunately you don't get to define what other people define as unnecessary. Easier to just put the popup and make the lawsuit more open and shut.\n\nHere's a different take: EU has zero jurisdiction in my country, so they can make any law they want about cookies, I'm not subject to it.\n\n&gt; Right but unfortunately you don't get to define what other people define as unnecessary.\n\nOf course we do, that's the whole point of the law.\n\nPlease, keep telling me you don't know what you're talking about\n\nIn practice yes, in reality no. You always need one.\n\nThey have hundreds of teams, tons of PMs, it‚Äôs a large company. It‚Äôs better to just turn it on site wide like every single other site to avoid one accidental developer change to make them uncompliant.\n\nAlso I hate the stupid Europe cookie laws in their current form they ruined the internet. They should have added provisions for letting people accept all or reject all at the browser level like a standard for telling a website one of these preferences.\n\n&gt;They should have added provisions for letting people accept all or reject all at the browser level. IS: a standard for telling a website one of these preferences.\n\nPeople tried. The Do Not Track header existed. Know what happened ? It was one more identifying bit for trackers to target you. Europe also does not mandate the current cookie prompts. They're a result of purposeful bad faith interpretations of the ePrivacy law, to make Europe look like they're forcing this on you.\n\nCookie prompts are always, always a choice of the companies you're using to fuck you over.\n\nIt would have succeeded if it was legally mandated like the cookie laws are.\n\n&gt; People tried. The Do Not Track header existed. Know what happened ? It was one more identifying bit for trackers to target you\n\nonly because it was not on by default.  \nIt is setup to fail\n\nIt wouldn't be information that can be used to track you if it were on by default, but turning it on by default wouldn't make it any more effective at protecting your privacy. The point is that site operators simply aren't going to respect something that says they can't track you.\n\n&gt; They have hundreds of teams, tons of PMs, it‚Äôs a large company. It‚Äôs better to just turn it on site wide like every single other site to avoid one accidental developer change to make them uncompliant.\n\nHaving a cookie prompt doesn't magically make a website be compliant.  Consent to be tracked may be rejected.  In that case, the website may not perform any tracking beyond that which was allowed before showing the cookie prompt.  What's more, consent must be freely given in order to be valid under the GDPR.  So, not only must a user have the option to reject tracking, but their use of a website may not be conditional on consent to be tracked, as then the consent would not be freely-given.\n\nSo, every one of those hundreds of teams and PMs must already be able to run while collecting only the minimal amount of user data.  Adding a cookie prompt *increases* the complexity of their products, not decreases, because it they must now conditionally determine which users may be tracked, rather than the simpler solution of not tracking any users.\n\n&gt; Also I hate the stupid Europe cookie laws in their current form they ruined the internet.\n\nAdvertisers ruined the internet.  The GDPR forced the advertisers to show just how much.\n\n&gt; They should have added provisions for letting people accept all or reject all at the browser level like a standard for telling a website one of these preferences.\n\nI'd agree, though I think there should only be a \"reject all\" setting.  There should not be an \"accept all\" option.\n\nThe law does have that. Companies are just playing silly games and as of yet the EU hasn't gotten around to bringing out the big bat.\n\nCries in American\n\nThat is not true. It‚Äôs a common misconception. Nothing about GDPR is specific to cookies. If you‚Äôre processing personal data then you need explicit consent (or another justification)\n\nI don't think it is a misconception.  The cookie thing is different from GDPR, but GDPR also covers the same territory.  And the cookie thing isn't just about cookies anyway.\n\nWhat ‚Äúcookie thing‚Äù? CCPA?\n\nThe EU initiatuve that resulted in websites displaying cookie banners.\n\nI am not sure what the right technical term or name is.  It might be the ePrivacy Directive\n\nThe cost of a false negative (sending cookies but not prompting) is too high. It's better to always prompt, even if you don't send any cookies.\n\nit's got onetrust in it, which does GDPR. onetrust performs geolocation to do this. \n\ninterestingly, I know this because you can borrow the geolocated value from onetrust and use it. i did this recently and avoided having to add a separate geolocation service.\n\nLol, I just did the same in our mobile app using UserCentrics\n\n&lt;strike&gt;I'm in EU and the page does not ask about cookies. (It's still possible that you're right and just parts of the EU cookie logic is included) &lt;/strike&gt; Edit: seems it's a Firefox Android issue. It ask about cookies on Chrome but not on Firefox.\n\nIt asked about it for me, also in Europe.\n\n[deleted]\n\nNot sure, I tried it in Edge and it asked, but it's also Chromium.\n\nall that polyfill but they still can't get firefox to display it correctly lol\n\nI'm not in the EU but it did just pop up a cookie banner for me when I visited.\n\nMaybe you've previously answered it, I don't use netfix and I got the prompt.\n\nIf you want to change your text to strikethrough surround the text with double ellipsis.  \"~~\"\n\nThose are tildes. An ellipsis is ‚Ä¶ or ‚ãØ , ‚ãÆ, ‚ã∞, or ‚ã±\n\nRight thanks.  Stupid wording mistake but still the right formatting suggestion.\n\nWhy check location though? GDPR applies to EU citizens wherever they may be. That‚Äôs why we still get the cookies prompt in the US.\n\nNo it doesn‚Äôt.\n\nThey wouldn‚Äôt know what world to say hello to without location tracking\n\nlmfao\n\nso the bare minimum of a web app\n\nthe bulk of the 8kb is setting up the react context which contains a full list of all UI languages supported by netflix. [uncompressed the react context alone is 18kb](https://system.tips/text/view?q=zprwuigo). Note, all the polyfill etc libraries that this hello world page pulls in is in *addition* to the 8kb of the main page.\n\nnot really what I would consider \"bare minimum\"\n\nrequire ('sarcasm');\n\nhow many MB is that?\n\nOH... soooooo many, I'm sure.\n\nIt's like that 1000-something LOC PowerShell script I wrote to send a keypress to keep your computer awake.\n\nFour years of college and five in industry.\n\nIt‚Äôs just to verify if you are really on Earth. Otherwise it would say ‚ÄúHello Moon!‚Äù /s\n\nAlso the extra exclamation point is really unnecessary.\n\nIT SURE IS!!\n\nI'm pretty sure this gets used by engineers to confirm certain things work in the production environment.\n\nYou don't use a favicon for your hello world page??\n\nhttps://cdn.cookielaw.org/logos/dd6b162f-1a32-456a-9cfe-897231c7763c/4345ea78-053c-46d2-b11e-09adaef973dc/Netflix_Logo_PMS.png is not a favicon\n\nYou don't pull in a full-size lossless logo in your hello world page??\n\nYeah I got a cookie banner when visiting the site XD\n\ntwo exclamation marks.... greater than one, but less than three.... a happy medium for the world\n\nDev added one when they wanted to check if page updated when he made changes¬†\n\n`hello world!\nhello world!!\nhello world!!!\nhello world!2\nhello world!3`\n\nchore: added nonsense to force pipeline rerun\n\nIt's actually just Haskell list indexing operator.\n\nTwo are better than one\n\nFive is RIGHT OUT!\n\nThat's pretty standard for turning a non-boolean type (a number or a string, for example) into a boolean in JS. The first one basically flips the value and converts to a boolean, so an empty string or zero becomes \"true\" and everything else becomes \"false\". The second flips it back, so anything non-zero/-empty is \"true\".\n\n`Number(value)` is more lisible \n\nhttps://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Number#number_coercion\n\nBut you want a boolean, not a number.\nYours makes sense going the other way around.\nAlso, yours (I think, I'm not a big JS guy) will parse a string to try and make a number from it, which would give a different value for the string \"0\", for example.\n\nTwo exclamations are sociopathic!!\n\nmeant to ran the last command in a shell but accidentally used single quotes instead of double\n\nI for one would've preferred an exllipsis\n\n*clicks on view source*\n\n*face melts*\n\nLooking at other HTML pages on Netflix, I'm pretty sure the bulk of the page is dynamically generated from a common template.\n\nYeah, this page is probably a bare bones test of their templates etc.\n\nThank god they have polyfill. What would that page look like on IE8 otherwise?\n\nI mean, Id fell bad to get hired and netflix and get the assignment of trimming the hello world app.\n\nMarion. Don‚Äôt look at it. Shut your eyes, Marion. Don‚Äôt look at it no matter what happens.\n\nIf you don't perceive it, it won't perceive you.\n\nIt's so beautiful!...\n\n&gt; For detailed credits and licence information see https://github.com/financial-times/polyfill-service.\n\nAre the FT famous for browser profiling software now?\n\nThat's the repo for a pretty common polyfill library.\n\n[https://polyfill.io/](https://polyfill.io/)\n\nFT stays winning. Only British newspaper that isn't transphobic for no reason.\n\nFT knows it can sell shit to trans people. Culture wars seem so inconsequential when you can profit from selling HRT and elective surgeries instead.\n\nAlso has a cookie consent banner for us EU people. The world we live in‚Ä¶\n\nI mean yeah, gotta love when a remote webpage asks you if it can use your local browser feature that's fully in your control. The law is such a bad implementation and should have been forced on the 5-6 browser manufacturers and not ever mom and pop website on earth.\n\n&gt;I mean yeah, gotta love when a remote webpage asks you if it can use your local browser feature that's fully in your control.\n\nNo, using the feature is perfectly fine, and you don't need to ask for permission _at all_.\n\nYou do need to ask for permission to spy on your users though, the mechanism is completely irrelevant ü§∑‚Äç‚ôÇÔ∏è\n\nRight, but a dramatically cleaner solution would have been to just legislate a browser setting enabling required and non required cookies separately and then that's that. Same existing laws cracking down on companies who violate it (e.g. storing tracking stuff in in \"necessary\" cookies. It's all an honor system/punish afterwards anyway (currently) but this would make it much less annoying. That or just ban tracking cookies, rather than trying to make companies pester/trick users into agreeing to them.\n\nthe malicious compliance with cookie popups is absurd. The options are like \"Accept all LOL\" or \"More...\" &gt; **\"Accept all again LOL\"** || ^(\"accept only necessary\" &gt; ...)\n\na giant part of the problem is our inability to effectively regulate and enforce rules and standards when it comes to corporations and tech companies. It either has to be bulletproof and future proof or incredibly meager and unenforceable. There is definitely a bigger picture here that is going horribly wrong on many levels\n\nMany sites make \"accept all,\" \"accept only necessary,\" and \"accept none\" equally-sized buttons but that's still annoying as hell.  But how else do you comply?\n\nBy either designing your service in a way that you only need \"accept only necessary\", in which case you likely would not need the banner at all.\n\nOr at least make \"none\" (how?)  and \"only necessary\" the default and don't make it look worse.\n\nOr actually the companies should be more honest.  They imply that they provide 3 choices (in general) but the only choice they have to provide is \"necessary\" or \"more stuff you likely won't need nor like\" and stop acting like \"we care about your privacy\".\n\nI hate to sound like the \"common Redditor that thinks they are smarter than a company and their lawyers\" but in this case it fits.  And I say that as someone who thinks that law would not be needed in the first place, especially when no 3rd party cookies are needed.\n\n\nBut the companies, intentionally, chose the worst ways.  \nIt is a combination of incompetence, malicious compliance, fear, and fear-mongering.  \n\nThe law probably would have worked better in the old days, when the internet was just a secondary thing for most businesses, and not part of the main event.\n\n(this got longer than I expected)\n\n&gt; It is a combination of incompetence, malicious compliance, fear, and fear-mongering.\n\nFrom what I've seen, it is mostly incompetence.\n\n\"Legal departments\" have no reason to care _at all_ about the quality of the product or the experience, they just optimize for compliance with the minimum amount of work required _for them_, any other cost be dammed.\n\nThat combined with the fact that most leaders (this is the incompetence part) are so scared of big bad laws that end up giving legal a free pass, ends up creating an environment where \"legal says so\" is a trigger word for any human brain in the vicinity to completely shut down and comply without a second thought, even when the whole situation is is pants-on-head retarded and is built on a fantasy that has absolutely no basis on reality.\n\n&gt;But how else do you comply?\n\nDesign products that don't require spying on your users and doing all sorts of fuckery with their personal information.\n\nIt couldn't be more simple, really, the whole thing is a self-inflicted problem.\n\nEveryone hates advertising until the alternative of paying for anything is presented and then all the sudden they don‚Äôt mind\n\n1 - [citation needed]\n\n2 - Advertisement doesn't require a multi-billion euro industry focused on spying on individuals, it existed long before and it will exist long after that whole thing is illegalized.\n\nIMO, the whole issue here is that we're trying to regulate an industry is squarely society-hostile and will forever try to arms-race against the spirit of any privacy law, the real solution is to illegalize it outright... hopefully politicians realize soon enough and we can just stop wasting out time and money on it.\n\nYou want a citation for the claim that nobody is willing to pay for Web articles and short videos? How is life in your cave?\n\nThe law (wisely) doesn't mention cookies, or any specific technology at all. It's about gaining consent for obtaining and processing personally identifiable information for purposes not directly linked to carrying out the user's goal.\n\nYour proposed solution tackles a single technological implementation that would be very easy for trackers to work around, there are many tracking techniques that don't require cookies but do require consent. The law as written makes it far easier to prosecute companies for any misuse of personal data.\n\nThat's fair. It's just a shame that the result has been this UX nightmare. I suppose in a sense that's on all the disparate implementations, but at the same time once one design becomes a defacto and unchallenged standard, it is then cargo-culted around as we've seen. Not for no reason though. Try asking a Canadian or American law firm about the nuances of GDPR and they'll see on the side of caution. As a result you've got one business desire: analytics and user behavior tracking (what MBA doesn't want metrics?) and another (don't run afoul of GDPR and get fined) left to developers to implement when accurate legal advise is very hard to come by from that role.\n\nIt's similar in other privacy areas. I've had managers claiming that the color of a person's clothing on a 240p video recording (where the person was maybe 10 pixels tall) was PII and we needed to blur the person's 2px face. The annoying part is... There could be some jurisdiction where they're correct, and I'm certainly not an expert in every privacy standard around the globe. The context was a dashcam like feature on a robot that stored a rolling buffer in case of an incident and retained the data locally for a brief period. (24h?). I'm all for privacy but... Knowing how it works is kind of maddening given that A) cookies are a tiny fraction of tracking methods and B) they're locally controlled by the browser, so technically being stored by the user, not the website. I get that people can't be expected to know that but that's why for this particular portion of GDPR I really wish they expanded it to standardize tracking acceptance at a browser level and require respecting that (while keeping the privacy laws as they are for all the other tracking stuff).\n\n&gt; Right, but a dramatically cleaner solution would have been to just legislate a browser setting enabling required and non required cookies separately and then that's that.\n\nBut... why? This is absolutely nothing to do with cookies.\n\nThe law regulates the whats and whys of how companies use your personal data, it has **absolutely nothing** to do with cookies, it's a completely tangential concern.\n\nCookie consent prompts: \"We need to ask you if we're allowed to ask you to remember something.\"\n\nLol @ `\"isInEU\":true` in the `script` on the page. I know it's easier to track and set this to deal with cookies/GDPR, but still, the thought of such flags spread everywhere in the code makes me chuckle.\n\nAre you in the EU though? It could be semantic, injected on the server-side.\n\nI am, and I tried with a US VPN to see if it's set to false, and it is.\n\nWell there you go then.¬†\n\nI'm not and I get a \"true\". If the anti-EU crowd here finds out they're gonna be _so mad_.\n\nVariable name could be better but I get why you get `true`. From the GDPR standpoint it doesn't matter if you are in EU or Norway\n\n1k lines of code\n\nRemember everyone, you‚Äôre not netflix. You don‚Äôt need to over architect like this.\n\nMiddle manager somewhere:\n\nNetflix has overarchitected hello world pages. We need one asap. Pull it into sprint. P1.\n\n83638492 story points\n\nstory points? the rest of my life's story\n\nHow can we add a near real time data feed of hello worlds to this? What about GPT-generated \"hellos\" in every language? You need to focus on the *customer experience*\n\nThen again, if you have an infrastructure/ops/sre team that handles stuff like build pipelines, you can bet they have at least one such \"hello world\" app they use to test that their systems are working as expected. Having it be actually visible to end users like us is just an inescapable side effect.\n\nIt‚Äôs probably just The Primeagen playing a little joke before he left XD\n\n*edit*\n\nHoly shit I had no idea this comment posted multiple times hahaha! Using the Android App it kept giving me an error when I would try to post my comment and not post. Sorry guys, I'm not that obsessed hahaha!\n\nTHEPRIMEAGEN MENTIONED!\n\nI just discovered this dude last week and I'm obsessed. This dude has the same energy as me and is a VIM God. He's the reason I switched to neovim and am learning all kinds of new stuff.\n\n[deleted]\n\nwe know how obsessed u are rn\n\nI think he's configured his browser to use vim and is now trying to figure out how to quit...\n\n8KB, that'd be a hundred lines or so, right?\n\nRight click &gt; View Source\n\n1,000+ lines of code... what, what?!?!??!\n\nJebus wept, jebus wept.\n\nFor there were no more hello worlds to conquer\n\nThey removed it?\n\nfew days ago already. I think they received much traffic on that link :-)\n\nAh thats unfortunate :(\n\nhowItAllStarted\n\nI like how one of the identifiers for your browser is:\n\n\"maybeSupportsHTML5\": true\n\nHow the fuck is that useful to them? Does it support HTML 5 or not? lmao\n\nfound this one are these related  \n[https://www.netflix.com/humans.txt](https://www.netflix.com/humans.txt)\n\nIt has two JS errors in console\n\nThose might be plugins you have installed, I've got no errors\n\nHave you got an ab blocker installed?\n\nYou mean having a certain amount of bodyfat?\n\nok ... how did you find that is the question\n\nHe saw in programming memes sub\n\nClose, I saw it in a twitter post\n\ndrop for new show coming out\n\nMaybe an easter egg for a new Netflix doco about the computer industry?\nhttps://news.ycombinator.com/item?id=40081126\n\nu/ThePrimeagen Explain yourself! :'D\n\nmaybe a healthcheck?\n\nhttps://netflix.com/healthcheck\n\n..... thats a hell lot of javascript for a hello world\n\nMy money is on Primeagen :D\n\nIts a Teaser for Social Network 2\n\nMaybe they are promoting a new series :3\n\nMicro services\n\nThe \"!!\" at the end really makes me happy. One was not enough.\n\nMight be a for a targeted load test for chaos monkey\n\nDid this too as a way to quickly test that at least the helloworld is helloworlding. Doesn't seem like a bad idea.\n\nwhy they use /helloworld ? why don‚Äôt use another page name if they want to hide it from the users?\n\nA new coding series under production.\n\n\"Primeagen: reacting to /helloworld\"\n\n8k? If you pull it with curl you get 1.1M of polyfills...\n\nmi primera chamba\n\nIt looks like it's gone\n\nThis no longer exists :'(\n\nIt‚Äôs likely literally just a heartbeat/health check page\n\nhttps://netflix.com/healthcheck\n\n[deleted]\n\nThose might be plugins you have installed, I've got no errors"
  },
  {
    "title": "Google Staff Engineer shares how reading whitepapers took his career to the next level",
    "body": "",
    "score": 1450,
    "url": "",
    "created_utc": 1714317977.0,
    "author": "xxjcutlerxx",
    "permalink": "/r/programming/comments/1cf8z5w/google_staff_engineer_shares_how_reading/",
    "all_comment_text": "I cannot believe we reaching a point where dev is making an article about reading whitepaper..\n\nOn one hand I want good blog post writers to get paid. On the other hand it has turned the internet into a desperate race to churn out as much content as possible.\n\nJust look at tech Twitter. 95% of those \"influencers\" are doing CRUDs at best in their day to day work.\n\n[deleted]\n\nI've yet to encounter an API that can do crud properly across the board. There's always something odd.\n\n[deleted]\n\nI mean integrating with other corps, ranging from large to gargantuan. Their APIs universally have outliers and oddities that smack of design compromises internally and make no sense to an outside consumer.\n\nSo true! It has little to do with tech stack. A good stack can help them meet their published API spec more often. But they‚Äôve all got some beasts hiding beneath the covers.\n\nI mean, your experience with Twitter depends on who you choose to follow. The authors of serious systems like Kafka, Kubernetes, ZFS, etc. are all on Twitter, though because they actually spend their time writing software they don't tweet much..\n\nIsn‚Äôt most software development CRUD in some way?\n\nI'd say most of it just crud not even CRUD.\n\nMedium and its effect on internet discourse.. There‚Äôs a lot of good stuff on there but people love to share random articles that are super dumb.\n\nAnd yet this sub doesn't allow self posts\n\nTbf if it means the sub doesn‚Äôt get spammed with a ton of ‚Äúhow I learn to code??‚Äù I‚Äôll take it lol\n\nAnd yet persist the sensation that this article is somehow ai generated\n\nThe dev read the spec and makes front page.\n\nI went a year on a project where the devs never read the spec.\n\nWhen I got called in to review what was going on, 20 devs, 2 solution architects , 3 pms, and a BA. No one read the spec. FFS.\n\nIt is mind-boggling. I‚Äôve seen orgs roll so much of their own shitty auth (oh you passed ‚Äò?role=admin‚Äô in the URL? you‚Äôre an admin now) that by the time you show them some turn-key Okta product, Zanzibar, oauth flows, etc, they turn their nose up at it as if it‚Äôs equal to their auth du jour.\n\nYeah, some dusty old pdf ‚Äúspecs‚Äù left by 90s era Accenture contractors are the golden ticket, good shit y‚Äôall.\n\nOr, other favorite, writing a research paper worth of ‚Äúspec‚Äù for a basic CRUD API but, oh no, OpenAPI is too hard, how am I gonna expose all the messy details to our clients??\n\nI want engineers to tell me \"this okta thing sounds neat but they didnt implement x,y,z from the RFC\"\n\nThen we can chat about \"should we want these\".\n\n  \nIf that doesn't happen, they didn't read the RFC, or any other spec so they don't know shit. Expecting to come up with something better than everyone else without reading prior work is 100% crazy, even geniuses can't do that, else we'd have had computers during Davinci's era (or earlier, but you get the point)\n\nSorry bud, you got a 8 client billable hours (what are points lmao) to PoC all possible auth options (as in, follow two okta quick start guides and bring me the one that made you less sad)\n\nDo you work for Okta? Okta uses some of my code, which, you know, what made outside Okta, like most of the code you use, by these \"shitty auth\" implementers who wrote up the specs for you. Okta also gets fairly bad security breaches, which is kind of a big deal for an auth provider. Maybe you should work on that...\n\nBeing part of that shitty auth rolling i can assure you the constraint isn't someone wanting to do auth, but rather the constraint is contractual where you can have only up to 10 actual accounts in the system (one of which would be the super admin service account used by your service), and your new tool that's supposed to be the new frontend has to handle arbitrary amount of accounts, any login medium (aws sso, okta, w.e.), and that the role handling is implemented in that 10 account system on a textual field per username in `user=admin;user1=reader` kind of way, only because the data is already in that system, and we \"don't have the resources\" to migrate off SAP/Salesforce/Nuxeo/w.e. super no code cms.\n\nYou are spot on. Or the fact that your app isn‚Äôt allowed to serve any resources from anything other than the originating server. F-K.\n\nSo much of the auth thing is management IMO. ‚ÄúWhy would we pay for that? We can do it ourselves for free!!‚Äù\n\nJust once I‚Äôd love a manager to realise that ‚Äúwe can do it ourselves for free‚Äù means exactly ‚Äúwe can do it worse over a longer timeframe for the cost of our entire team‚Äôs ability to deliver customer features‚Äù\n\nJust once and I‚Äôd die happy right there on the spot.\n\nOne writer called it reinventing the flat tire.\n\nIt's only free if you're not paying your developers\n\nOr your lawyers\n\nHope you were being funny because 10 sec into reading the blog post it‚Äôs obvious he‚Äôs talking about reading and keeping up with current research and innovation, not the spec for a project. \n\nAnd he‚Äôs right - keeping on top of the latest can be key to staff level positions in big tech.\n\nThe irony of them clearly not reading the article is hilarious lmao\n\nReddit in a nutshell.\n\nIsn't that amazing?\n\nI can't tell you how many meetings I've attended where you needed to read X beforehand so that you were prepared. Nobody had read X except me. They would all get chewed out for it, and then maybe 2-3 would have skimmed X for the next meeting.\n\nThe feeling is mutual. I had to tolerate an architect that would never note any of his specifications down, and project managers that would never read proposals on how their systems should work.\n\nI once wrote up an entire statement of work, including all deliverables and requirements, because the PM couldn't be bothered. When they declared the project \"done\" I started checking off the deliverables against the SoW... turns out a quarter of them hadn't been included. When confronted, the PM said the equivalent of \"who reads those anyway?\"\n\nIf I wanted to read I would‚Äôve gotten a lit degree üôÑ why should I waste 2 hours planning when I can spend 10 hours rewriting it?\n\nAnd it got 150+ upvotes, so it says lots about community.\n\nThe article is decent, the title is dumb\n\nThe author also keeps mixing up academic research and whitepapers, which is ridiculous\n\nRight...like, no, this is a profession, my life exists outside of it.\n\nBecause devs often have to justify spending hours on something. \"Is it timesheetable\" blah blah blah.\n\nThe wrapper article is dumb, as always\n\nLiterally the first paragraph says \"cutting-edge academic computer science papers.\"\n\nOne of the side effects of Covid was cognitiv. However,  we‚Äôre not ready as a society to talk about it.\n\nHe's from Google / Big Tech. Given his level, I assume for each person his level, there are 10-20 engineers below his level. \n\nNow whether his reading/writing of \"whitepapers\" actually benefits the organization is entirely different story. He might just be reading papers and adopting the next shiny ~~JS Framework~~ bleeding-edge CS algorithm for margin improvement.\n\nEngineer who spends time learning learns things.\n\nAnd uses what they learn to advance their careers\n\nThing is, it actually seems pretty hard to find a whitepaper that would in practice translate to meaningful improvements in my career\n\nLike for my job I've got projects that are specified for me to do and it's unlikely a whitepaper has been to offer for how to do them, and then even if it's a matter of switching to a different job, still seems pretty unlikely that a whitepaper I read hits the sweet spot for some open position posted online\n\nMy impression from the article was that you should treat the 90% of reading that has no practical benefit as just working the learning muscle for that 9% that you might be able to discuss the interesting ideas of so that you're prepared to take advantage of the 1% that could actually change your career.\n\nSomething I've noticed as a manager is that engineers will often pass up on learning opportunities to satisfy sales/product/other managers. My engineers have 20 days budgeted and allocated to learning, but I have to force them to take it. Like it's too embarrassing to say \"yo, I'm gonna learn this feature of CMAKE\".\n\nAre promotions tied to tenure milestones? Then yeah, I‚Äôm gonna get work done so I don‚Äôt get guilt shamed at standup for not meeting unreasonable deadlines.\n\nI sell it to management as \"tech debt\" and \"refactoring\". Getting smart on The Next Best Thing is just ticket #0 in that epic.\n\nThat's an incentive problem. People will do what gets them bonus points from management, not what management tells them will get them bonus points. \n\nYou can give them budgeted days for learning, you can even tell them that the way they use those days is taken into account when giving promotions or bonuses, but if all that matters in the end is who worked on the flashiest feature guess what will they do? \n\nIf you noticed this as a manager did you do anything to figure out why this is happening? Bare in mind, that your employees will respond with what they think you want to hear, not with the truth, and they might not even realize why they're working on other things instead of taking advantage of those learning opportunities. This is usually a management problem.\n\nWe don't do bonuses, because it muddies corporate objectives. However, promotions are awarded based on either a breadth or depth of knowledge, and being able to bring that to work. Which is frustrating, because devs would start to expect promotions based on time. So I ended up doing a pretty indepth study, as I saw the writing on the wall\n\nI did get some interesting feedback: \n\n* Not enough time (the answer I \"wanted\" to hear)\n* There are no easy wins - the system is too big/advanced for an individual to meaningfully contribute in one day\n* \"I just forget about them\" \n* \"It's really embarrassing/difficult to ask for help or to get 10% time projects merged\"\n* It's too difficult to coordinate with product, and on-call, etc.\n\nMost of this tracks. The company has grown significantly since I started, going from 25 devs to 100.\n\nThe first solution was mandatory 10% time. First Monday of the month, all major meetings are cancelled and blocked from calendars, leaving only a daily in the morning. All team leads ask \"what are you doing for 10% time?\", unless someone is on-call, teamleads chastise anyone refusing 10% time as they are not being a team player.\n\nThese 12 days account for 50% of 10% time. We implemented this last year, and tracked uptake of all 10% time, and we went from 5% to 95%, which is phenomenal!\n\nNow the second part, we have a problem of knowledge transfer within certain communities. These were formalized into guilds. If you presented and did things within your guild, you got to go to conferences. If you didn't have a history of presenting or talking within the group, then you could only participate remotely. We went from zero brown bag talks (they died during COVID) to at least one every two weeks.\n\n100% - this thread just reinforces what I‚Äôve seen in the industry first-hand: few people take keeping up their skills seriously. \n\nWe have mid level roles that are paying (barely) six figures (outside of CA) and I don‚Äôt think any of those guys has picked up a new skill in years even when allotted dedicated time.\n\nThe deadlines aren't adjusted for the dedicated time to learning new skills. It's too much work to even just make the minimum progress demanded of us.\n\nIf you shop around for good employers, a lot of them build in 40-80 hours per quarter of training, professional development, and/or conferences. Those employers also tend to have absolutely crazy high profit/employee metrics.\n\nall of the seniors in my last company had 10+ years of experience... they dont read ever. They are senior based on time and nothing else. They don't know how to do TDD or BDD, don't know what devops actually is or why it is the way it is, even though we did the book together as a bookclub, no changes happened. \n\nIt's annoying that I was a junior when I joined and read a ton of books in a couple years, like 30+ on just software trying to figure out different concepts and understand wtf this field is, and they do none of it.\n\nDid they get shit done, though?\n\nYou are valid, homie.\n\nbecause they have lives, no doubt. sometimes all we have mental capacity for is getting tickets done and then our personal lives once we can punch out.\n\n&gt;They don't know how to do TDD or BDD\n\nPeople acting as if TDD or BDD was the only valid way to perform software eng. are something else\n\nBack in my days you weren't a java engineer unless you read \"Effective Java\" and passed the trivia questions in interviews.\n\n  \nNow you'll have hired people that will try to claim an entire module is valid to be tested as a \"unit test\"..\n\nI mean, I ain‚Äôt touching CMAKE with a foot-length pole /s\n\nYou were making a great point until you suggested that it would be embarrassment blocking engineers from wanting to learn more cmake..\n\nSomehow this seems to be something not everyone picks up on (or is too lazy to do, probably a mixture of both) - I see a looooooooot of devs rest on their laurels at a certain point.\n\nI am constantly trying to learn new things\n\nDamn is this the secret?\n\n*peer reviewed research papers from top conferences\n\nRight. Every white paper I‚Äôve ever read is marketing material.\n\nNot all whitepapers are equal.\n\n\nGoogle's are typically exceptionally detailed, and explain their product design thoroughly.\n\n\nOne of my favourites, Spanner:¬†https://cloud.google.com/spanner/docs/whitepapers. When this came out, it blew the doors off my understanding of distributed systems.\n\n\nThis guy isn't talking about \"any old whitepapers\". He's talking about the small handful that truly define the cutting edge of your area of expertise.\n\nThere is a difference between a ‚Äúwhite paper‚Äù and a ‚Äúresearch paper‚Äù.  A white paper is technical marketing material produced by corporations for potential customers.   Research papers are produced by researchers (usually Phds) either for submission for presentation  to a research conference or for inclusion in a research journal.  The blog post is talking about research papers.\n\nWhat's the history of using \"white paper\" in the Google context? I saw the title and scanned the article but found it incongruent because they were referencing technical/academic papers. As you note, white paper has a very specific and well-known definition already.\n\n[Papers We Love](https://paperswelove.org/) was a bit of a fad a few years ago and I don't hear about it as much. The way they put academic papers on a pedestal was different from how I was taught to learn from them through critique of the content. I guess for a professional programmer with limited time it helps to focus, but it misses something.\n\nThe paper is white /s\n\n[deleted]\n\nI‚Äôm not reading this but I can confirm that reading a bunch of white papers dramatically changed my career and made me a way better engineer.¬†\n\nI've never considered this. could you elaborate on your experience? I felt like I had looked down every path to improvement and never considered white papers. where do you find them, which ones did you read, can you elaborate a little more?\n\n\nedit:\nlolz yes rtfm. but also I would like a second opinion since the post explains a single experience and others may have a different experience\n\nsee the linked blog post for some pretty good answers to your questions.\n\nü§£\n\n\"The task to RTFM has been left to the reader as an exercise\" lol\n\nlolz yes\n\nWhat, and spend all my time reading and learning new things? Never!\n\nits really simple. you build on top of other people's experience. not every spec, white paper, etc. is equal. sometimes its a look of reading and digesting.\n\nthe more you know about other people's experience, the better you can make yours.\n\n100s have upvoted this, dozens have replied, and yet not one purported developer has come forward to recognize the irony of the statement, not even to play along with the joke. I feel like I'm going crazy.\n\nI‚Äôm OP. I meant this in 100% earnest. I‚Äôm not sure what the joke is?\n\nI‚Äôm not interested in reading an article about how someone else read white papers. But they‚Äôre very much worth reading themselves.¬†\n\nI've got no idea if this is some kind of 4d level satire but your comment absolutely comes across like your making a joke\n\nIn what way does it come across as a joke? I've read these three comments several times now and the comment is basically saying \"+1 I find reading white papers valuable too, I'm not gonna read this blog tho.\" Is that your understanding of the comment? If so, where is the joke?\n\n&gt; I‚Äôm not reading this but I can confirm that reading a bunch of white papers dramatically changed my career\n\nBlog post != white paper\n\nThis is exactly what I meant. i'm open to the idea that I miscommunicated but I don't see it either lol.\n\nIt‚Äôs the ‚ÄúI‚Äôm not reading this‚Äù part\n\n[deleted]\n\nSome but this is very very much not the norm. Most white papers are academically driven with zero profit incentive.¬†\n\nLook to the past. Start with Leslie Lamport‚Äôs writing and go from there.¬†\n\nSome are. Academic whitepapers by serious researchers are not. There are plenty of respected conferences, like Usenix, where good stuff gets talked about.\n\nCould you share some examples please\n\nThink this question is missing the point. They don't seem to be saying there's a select few or group that helped them. They're saying the practice is what helped. So, if you want just a few, then that's not adopting the correct practice. Things like reading the full article will allow you to see that there are several linked examples shared already.\n\nLearning new stuff will improve your career.\n\nHold the front pages for this guys, it's *groundbreaking*.\n\nBut that's not just \"new stuff\". It's truly understanding technology at the deepest level.\n\nToo true. I will say speaking from experience of working with 'web components' this past year, being 'forced' to read the HTML specs *has* raised my understanding of how autonomous custom elements function beyond the way that you 'define' them. I would like to think that has been helpful but it isn't always so clear cut over the short term.\n\nYep. I‚Äôve found the most informative readings to be old ones. Like really old ones; 1950s-1980s. There‚Äôs so much information in those old papers that really get at a fundamental understanding of technology. Then once you read those, newer papers are even more valuable than they would be otherwise, since you understand how the technology that built that technology works.\n\nFirst you take a grain of sand\n\nIf you don't read whitepapers, you are always getting someone else's interpretation of the paper.  Like... waterfall being an iterative development practice\n\nI was doing reverse engineering decompilers and transpiler and needed language transformations from one language to another without losing semantics. There were specific language quirks that needed a lossless semantic transform.  Throw some data flow on there to rip out formulas and fun.\n\nYes, you force yourself to keep struggling with challenging concepts. Eventually, additional challenging new concepts are more easily assimilated into your knowledge.\n\n[deleted]\n\nyeah that's a really unfortunate conflation\n\n[deleted]\n\nThis (arbitrarily selected) [Tata Consultancy white paper on Hybrid Enterprise Data Lakes](https://www.tcs.com/content/dam/global-tcs/en/pdfs/insights/whitepapers/Hybrid%20Enterprise%20Data%20Lakes%20Provide%20Foundation%20for%20Disruptive%20Business%20Intelligence.pdf) is a good representative of the median tech white paper in the US. It is completely trash. \n\nThe valuable writings, whether blog posts, white papers, or research papers, come from people that aren't trying to sell you something. I was going to share a link to a good example of a valuable white paper, but after 5 minutes of googling, they were all shit. So yeah... I actually thinking adding \"White paper\" to a search for cutting edge tech topics might be actively counterproductive.\n\nIn the US?\n\nAll signs point to a South Asian origin for that pdf.\n\nTCS is selling to US Fortune 500 companies, among others. I could have cherry picked a dozen other papers more US-centric, but I hold a special hatred in my heart for TCS from a past life having to work with their folks. \n\n\nThe first hit for \"Google white paper\" takes you to a page where the first link is this Boston Consulting Group junk [paper](https://inthecloud.withgoogle.com/bcg-whitepaper-core-asset/dl-cd.html?utm_source=cgc-site&amp;utm_medium=et&amp;utm_campaign=FY23-Q2-global-ENDM91-website-dl-become-a-resilient-data-champion-cxo-whitepaper&amp;utm_content=whitepapers-bcg-whitepaper&amp;utm_term=-) with highlights like \"Why CEOs need to be in the driver‚Äôs seat for data transformation\".\n\nI usually avoid commenting here due to my very small past experience in the field, but even with that small competence I feel I can add to that special hatred of TCS.\n\nI'm in the US and everyone I know uses it to mean marketing trash. Hence I was confused until I saw the picture with Abstract, etc. and realized they meant research paper.\n\nI‚Äôm in the US and ‚Ä¶ I‚Äôve literally never heard ‚Äúwhite paper‚Äù to mean ‚Äúresearch paper‚Äù, and that‚Äôs after 25 years in the industry, faang (before it was called that), Silicon Valley etc.\n\nHmmm, I worked for higher education software in the past, and I‚Äôve always equates white paper with research paper. Maybe it‚Äôs dependent on where and what groups you associate with.\n\n[deleted]\n\nMy background is more mathy for academics and I thought a white paper was basically just along the lines of a formal research paper, but generally for like... Actual real world engineering production stuff.\n\nIn academic circles, I think \"white paper\" means a practical-oriented (i.e. not completely theoretical) research paper. Not so much in the commercial/industry world.\n\nI find the biggest difference is the way in which the outcome is presented.\n\nIn a whitepaper, you often have have a solid value statement \"How we used [X middleware] to make our service 12x faster.\" It's presented as a \"this is what should be done ^(using our product)\" argument. The conclusion was foregone: if the desired results aren't found, that whitepaper doesn't exist.\n\nWhereas an academic paper looking at the same thing would not make the judgement on what someone should do, but just present a simple analysis of data results \"Which middleware is best at accelerating X.\" The results may have been hypothesized, but you often find less glowing adoration for _whatever_ the result is.\n\nI also find research papers are often a lot narrower in scope, imo makes them often more broadly applicable, but also making it more tedious to collate a \"solution\" from.\n\nMost research papers rarely bake off large expensive enterprise systems. The students who write them rarely have the context, resources,  or experience to come close to evaluating these kinds of systems in any meaningful way. \n\nHaving seen the long term evolution of major pieces of enterprise middleware, the gotchas always come years later at the edges of capability. They are often big surprises to the sales/support engineers as well. Which then causes the entire thing to be scrapped.\n\n/g\n\n[deleted]\n\nPossibly seds\n\nAlso rename\n\nI came here to say this. A white paper is a nearly content free ‚Äúpaper‚Äù bragging about this and that targeted at CTOs or CIOs. \n\nAt best they‚Äôre a starting point for further research, at average they‚Äôre borderline lies.\n\nYeah not sure how a \"L6 Google staff engineer\" came to the conclusion those two terms mean the same thing. Hopefully it was the blogger who badly edited the blog post.\n\nNah, Google calls all its product-focused research papers whitepapers.\n\n\nExample, the Spanner whitepaper section contains some of the most awesome tech ideas I've ever read, including a copy of the academic paper:¬†https://cloud.google.com/spanner/docs/whitepapers¬†\n\n\nIf this guy's a Googler, he will have used the whitepaper terminology happily.\n\nOh shit. I‚Äôve been wanting to start a little study group where we read papers together and share summaries, but didn‚Äôt think others would be into it. \n\nIf you‚Äôre either interested in reading along or just getting the summaries, drop me a dm with the topics you are most interested in. \n\nI would likely just start with the content from https://paperswelove.org/ unless someone has another good foundational list.\n\nEdit: created a Discourse, still getting things set up but feel free to jump in here and suggest a paper you‚Äôd like to read or just say hi. \n\nhttps://readingclub.discourse.group/invites/gPNNttorqQ\n\nThanks everyone for the interest! Will put together a forum or something and get this kicked off. Keep the DMs and replies coming. Will personally ensure everyone gets the follow up with next steps. \n\nTrying to decide between something like NodeBB or Discourse. \n\nCould also just do a Slack since it‚Äôs similar to discord but with hopefully less distractions.\n\nEdit: https://readingclub.discourse.group/invites/gPNNttorqQ\n\nMaybe you can build a Discord channel for this\n\nYeah I think that is the simplest way forward but also seen too many end up dead. Too much noise when you open up that app.\n\nAgreed and people might get distracted if it's on Discord. Lol\n\nA scheduled Zoom call, like probably every end of month, to discuss papers might get more eyes but it will take a bit of organizing and marketing to get people onboard, even if it's free. I'm still up for the idea tho.\n\nI'm in.\n\nStill getting things set up but anyone interested can join here:\n\n[https://readingclub.discourse.group/invites/gPNNttorqQ](https://readingclub.discourse.group/invites/gPNNttorqQ)\n\nWhere can I buy a Personal Growth Flywheel? Sounds rad.\n\nIt's just a rebranded fidget spinner.\n\nYou need to take that to kickstarter.\n\nMy occasional hobby is asking an AI to humourusly summarize random RFCs. For example:\n\nRFC 1234: because who needs IPX and IP to get along when you can just wrap them in a packet-hug and force them to play nice?\n\nRFC 2268: because your network traffic was getting too comfortable, and someone decided to introduce a little \"congestion control\" to keep things interesting... and by \"interesting\", I mean \"frustratingly slow\". (In other words, it's a protocol for managing network traffic to prevent overwhelming the internet highways!)\n\nRFC 1163: because your email was getting too popular, and someone had to invent a way to say \"stop sending me so many emails, I'm overwhelmed!\" (aka \"Internet Relay Chat Protocol\" or IRC, for short).\n\nAs always, the real content is always in the comments. This is a great idea!\n\nI‚Äôve found little gain reading white papers and research papers.  I think my mind gets lost in the jargon.  However, I‚Äôve found huge value in trying to take the basic ideas and reimplement them myself: (write my own bitcoin miner vs read the bitcoin paper).\n\nThe more advanced math proof stuff I maybe miss, but something about implementing it myself really makes it click.\n\nFor this workflow, I‚Äôll start with tutorials on ‚Äúhow does bitcoin hashing work exactly‚Äù then implement from that, then maybe (big maybe) go back to the paper last.  It‚Äôs only after trying to do it myself I can understand which sentences of the paper can be skimmed and which are important.\n\nEdit:\n\nI think there is a bias to add fluff to papers since that makes them bigger and seem more important.  Focusing on code is the MVP of the idea.\n\nApplying/practicing is part of the learning process. If you‚Äôre learning a theorem, you don‚Äôt just read the proof, you try to apply the proof to a question.¬†\n\nIn these situations, it‚Äôs probably best to skim, try to build it yourself and then read the details of the paper as you get stuck.¬†\n\nSure, reading helps. But the major reason he was promoted to the staff because the manager supported him, gave him good project, and etc.\n\nAt Google, among \\~5-6ish people, there can only be 1 staff engineers.\n\nNot always true of course but 95% true. The case where it is not true would require director and VP support, which wouldn't come by easily.\n\nIf you join a 6-person team where there is already a staff eng, and the team doesn't hire aggressively, you are cooked. But there's nothing wrong with coasting at L5 (senior) though.\n\nIt used to be true for a long time, but nowadays the only sure way to be L6+ at Google is to be hired as one. Last year they announced more red tape for promotions above senior, so it is just easier for managers to hire than promote if they happen to get implicit quota for staff engineer.\n\nBut yeah, there is nothing wrong with staying senior though.\n\nAhh stack ranking‚Ä¶ always fun. it destroyed morale at Microsoft, why not try it at google. Maybe they hired some of their bad execs?\n\nStack-ranking is always there at the macro level.\n\nYou can't run a 1000-person org where 800 of them are staff engs. There's no way. That is never true at Google.\n\nSince the distribution is enforced at the top, it is somewhat enforced at the team level. Maybe some teams can break the threshold but those teams are exceptional.\n\nSame thing with perf. You cannot have a 1000-person org where everyone exceeds expectation.\n\nIf only I could find time in my day‚Ä¶ otherwise I‚Äôm using my personal time to do more work.\n\nMaybe I‚Äôm just old and lack ambition.\n\nIs \"whitepaper\" even the correct term here? When I think of whitepapers I think of an in-depth but still high-level explanation of a topic in a report/article format meant to educate in a manner that's easier to read than raw specs or an academic paper. They're not the same as research papers, reference docs or project specs. It seems like people, including the linked blog post, are conflating different types of docs with \"whitepapers\".\n\nIt's not the right term\n\nWhat's next, reading documentations and comments can take us to next level programmer?\n\nThe first dozen or so papers I read were hard to follow, then it started to click. If you're a technical kind of person I think they're great.\n\nWatching that one browser window full of tabs slowly grow with papers that you are definitely going to read when you have time is a unique kind of guilt.\n\nGrowing tab list is amateur!\n\nThere are whole applications for academics to manage lists of things your never going to read!\n\nEg https://www.zotero.org/\n\nAuthor seems to mix up whitepapers with academic papers. I don't know for sure, but in my experience (in computer science) an academic paper is not a whitepaper. Most whitepapers I've seen are nice product brochures pretending to be somewhat academic, while most academic papers do not mention commercial products at all.\n\nAgree. The term \"whitepaper\" is being abused here\n\n&gt;1. First pass: I read the paper in 15 minutes, with a focus on understanding the research at a high-level.\n\n&gt;2. Dive deep for an hour on the details of design, implementation, and evaluation.\n\n&gt;3. Summarize the research in my own words, to internalize my understanding.\n\nI usually stop at #1, if at all, to me a deep dive doesn't click no matter how hard and long I read implementation diagrams. Such diagrams only click for me after days, if not weeks, of spending at the bowels of the system. Its a fruitless endeavour if I'm not actually partaking in booting up a system itself, doing something with it, attempting to solve a specific problem with it, troubleshooting for hours the errors that come with it, and all that has ever happened during billable hours, I feel like any motivation to do it on my free time would have to come from a chemical and not myself as I've yet to find it in myself without a drastic push for it.\n\nHow about blackpapers\n\nAdds Bitcoin at the end. üôÑ\n\nI mean Bitcoin is cool tech. If you skip the political parts it actually is a pretty clever lil bit of code.\n\nAnd the whitepaper is pretty good. I hate crypto too but from a technical standpoint it's worth a read.\n\nExplain to me from a programmers perspective what makes Bitcoin a cool tech? Seriously, blockchain tech is actually not that good, and the thing doesn‚Äôt even run on a new tech. Its peer to peer and has been around for a long time.\n\nI think it was some fetishist economists who invented it. Computer scientists like efficiency.\n\nNot really, though. It [doesn't scale well](https://en.wikipedia.org/wiki/Bitcoin_scalability_problem) at all.\n\nHaving a limitation doesn‚Äôt make it not cool. It‚Äôs like saying a simple RNN is not really cool because it has a vanishing gradient problem. They were new ideas that established a whole (sub)field, and spawned many cool ideas to deal with their respective weaknesses.\n\nOh it didn't do what it says at all. But the idea is really cool\n\nWhich has caused enormous environmental damage.¬†\n\nThere is no part of the tech that is actually cool or beneficial. People have struggled for years to try to find some sort of use case, and so far, everyone has come up short. Bitcoin was a scam from the beginning to the end.\n\nIf you don't think distributed untrusted consensus is useful then I agree with you. If you don't think it's cool we disagree. I think it's a pretty cool design even if I don't see any reason to do it.\n\nIt's not cool because it's a solution in search of a problem and nothing about it is practical. \n\nOh yeah, these two banks that do constant business with each other and each have independent internal auditing are just totally desperate for something that solves a problem they don't really have, costs more, and is slower.\n\nReading and discussing research papers was my favorite part of grad school.  I was a beast a consuming and understanding research papers.  Thinking about it makes me want to go back and get my PhD.\n\nIn my experience, people working at Google think very highly of themselves and I‚Äôve often not been impressed.\n\nHere‚Äôs the thing I‚Äôve always wanted out of white papers:\n\nA way to start as close to the root of a problem as possible rather than some leaf node paper on a topic and work your way up the tree with no context on sibling node research.\n\nAgile reading boogaloo 2\n\nJust in! Doctor's who read white papers and keep up on current events in their field are better at their job!\n\nI want a better format of research paper.\n\nI may be talking out of my ass, but I think jupyter notebooks are just that.\n\nLike, they interleave markup paragraphs with runnable code.\n\nYou can pretty much make an interactive paper other people can run and tweak on the fly.\n\nI used to think they were odd, but grew to like them after spending some time using them. Not an IDE replacement, but I think they are neat for experimentation and educational purposes.\n\nFun fact: the only \"fuck\"s, \"shit\"s, and \"damn\"s at my comany's codebase are contained in jupyter notebook comments.\n\nJoin the ACM, kids.\n\n\nwww.acm.org\n\nSubscribing to the ACM E-Library and reading random things boosted my career quite a bit. I started learning things that wasn't asked of me and implementing them across domains. Plus, their magazine is awesome.\n\nThat really hard NP-hard business problem we have at work? There's an archived 1992 PDF of the problem and its solution outlined and lots of things to explore. At work you tend to fall into a pattern of using the vocabulary that your own company developed when encountering the problem. If you adopt the language used by the domain experts, it becomes so much easier to find more takes on it: many times this includes working code!\n\nKinda wish I hadn't gotten out of the habit of reading SIGPLAN, but I haven't really been doing that sort of low-level perf tuning for quite some time. There's plenty of stuff to do even with a journeyman's understanding.\n\n&gt; Because I had read this paper and others, I advocated for a new system designed by our team to gate all changes based on whether the new changes were negatively impacting users.\n\nis automated xp and release really that innovative? it's just basic process automation.\n\nbig tech fails to impress me anymore, tbh. i'm far more frustrated by how held back i am by our current paradigms than impressed by any of the myopic details that go into the current ones.\n\nFor those who didn‚Äôt read, here‚Äôs a TL;DR:\n\nWhy reading whitepapers will make you a better developer:\n\n1) Provides new insights\n2) Helps you learn how to learn\n3) Helps you stay on top of industry trends\n\nI prefer to read papers with at least some black on them. Purely white papers aren't very substantive in my opinion (quick reads though).\n\nI can confirm that reading White papers and posting about what I am learning on Twitter has gotten me not one but two job opportunities so far\n\nThis article screams ChatGPT\n\nSomething not mentioned in the article and that maybe someone can answer here - where does one find ‚Äúwhite papers‚Äù for software engineering? The steps outlined are great but I have no idea where to start looking for papers on topics ‚Äúthat interest me‚Äù.\n\nGoogle keeps a directory for theirs.  There is tons of great papers in this repository.\n\nhttps://research.google/pubs/\n\n&gt; Because I had read this paper and others, I advocated for a new system designed by our team to gate all changes based on whether the new changes were negatively impacting users.\n\nwhy do you need a white paper to think of this... this shit is obvious...\n\n ‚ÄúHow to find and read papers: find whitepapers in your speciality and read a lot‚Äù\n\nThis has to be ai generated\n\nI think a lot of programmers here have something against the academic side of computer science, which is the actual cool stuff of the field. From how cryptography is used in blockchains, and the maths behind it, to data structures that revolutionized compression - this is why reading academic papers is great. You get to learn about incredible discoveries made by the legends of comp sci. I get giddy learning about them. \n\nThere's a lot of blas√© attitude here against the very topic of reading papers itself here. I think if you want to not grow into just another code monkey, then learning the science of this field is mandatory\n\n(I'm skipping over the fact that the author is mixing up white papers &amp; academic papers)\n\nHe is biased. The right title would be \"How it took his career AT GOOGLE to the next level\".\n\nAt least this gives us a good template to clone for other types of career hacks. LOL\n\nIs it more useful than side projects that require new skills/thinking?  I learn by being hands on, failing and overcoming.  \n\nIf I need first principles then I look at the code, docs. I ask chatgpt when I get stuck or need to fast-track some understanding.\n\n\"How I Took My Career To The Next Level By Completing My Assigned Work, Submitting PRs, And Contributing To Meetings\"\n\nI feel like this was meant to imply that there's some really basic and simple trick that a lot of devs haven't yet grasped when the reality is the author was basically the only one unaware. This up there with \"Having money problems? Try getting a raise or two!\"\n\nAnd?????\n\nif you're a curious person it definitely does help. whenever I read them I look up concepts I don't understand and then that leads me down a rabbit hole of learning until I feel satisfied and then continue reading the article\n\ndef won't be everyone's cup of tea\n\nThere are much better ways to get to staff engineer than reading research papers. Focus on finding and addressing problems important to your organization. Read papers if the solution might be there\n\nEvery engineer or scientist should keep up with publications in their field.\n\nThis is the thing that is not the first and obvious activity to do.\n\nBut it's rewarding and differentiates you from the rest. \n\nGood read"
  },
  {
    "title": "Github Copilot is Free in VS Code",
    "body": "",
    "score": 1417,
    "url": "",
    "created_utc": 1734547079.0,
    "author": "connor4312",
    "permalink": "/r/programming/comments/1hh8c4x/github_copilot_is_free_in_vs_code/",
    "all_comment_text": "&gt;This plan offers 2,000 code completions per month (approximately 80 per working day) and 50 chat requests per month, with access to GPT-4o and Claude 3.5 Sonnet models.\n\nDoes that mean accepted completions? Or anything that is suggested?\n\nAs someone who has just suddenly got hit with the \"limit\" (after being free-pro for a while now). I'm willing to say auto-complete **suggestions** count towards this limit. There is zero chance I've accepted 2000 completions or committed 2,000 lines of code this month.\n\nSo for everyone who's been saying MS is developer friendly, just be aware this move is them trying subtly to move towards their LLM writing most of the code on the planet\n\nIt's quite good but also worries me for future generations. It can be a bit like GPS turn by turn directions. If you always rely on them, you learn the layout of your area much more slowly. I could see the same issue with programming. Helpful tools are great but if they slow down learning and make your problem solving skills rusty, you might just get stumped by things that the LLM can't handle that would have been solvable if your brain was grappling with similar problems more often.\n\nHehe. If I was trying to sell people on code assist, I would liken it to turn-by-turn navigation. That technology is the greatest thing ever for airhead like me that are perpetually lost. It doesn't mean dick to me that I can't navigate without it. I grew up with a car full of printed-out \"map quest\" instructions and I'll never go back to getting lost and having to unfold a fucking map.\n\nThe concern i have about LLMs is that it may lead to a lot of cargo-cult programming as kids build solutions they don't understand atop solutions they don't understand.\n\nBut 20 years ago when I was a self taught guy entering the industry, my grey-beard boss felt I was a spoiled young fool because I couldn't program in assembly. So maybe this is a dumb bullshit concern like wanting kids to learn cursive or know how to shoe a horse.\n\nLittle of column a, a little of column b.\n\nI think it's a bit like a chainsaw. Super useful to any experienced and inexperienced woodcutter, but the inexperienced chap is more likely to cut off his own leg.\n\nLLMs for development are just like that. Except with less blood.\n\ndepends on what industry you work in, i guess\n\n[deleted]\n\noh dear god MY EYE! CHATGPT, YOU SAID USING IT WAS SAFE\n\nI 100% co-sign on the GPS thing, as someone who's also useless at navigation. The problem is that LLMs can never be perfect, so it's more like having navigation where at every intersection, there's a 5-10% chance of it sending you in completely the wrong direction. I'll see that immediately of course, but someone who never properly learned to program normally won't. Even if only 1% of all lines are wrong, it would break your entire program down the line and even trying to debug it would take more time than just writing it properly.\n\nPlus, I've found the suggestions to be completely useless for the stuff I write because it tends to be cutting edge and exploratory, so the AI has no idea how to deal with it because it's never seen someone writing code with this library before, or even Rust GPU code in general. So it just outputs nonsense and I'm better off with normal IDE stuff. Maybe it's better for everyday repetitive stuff like web dev.\n\n&gt;Plus, I've found the suggestions to be completely useless for the stuff I write because it tends to be cutting edge and exploratory\n\nThat's been my experience as well. If it's a task that a million people have done before, AI will typically slam-dunk the solution to the problem. If its a task that maybe nobody has ever done before, the utility of the AI rapidly falls off a cliff.\n\nIt's been interesting getting a sense of when the AI will deliver and when it won't. It reminds me very much of the \"google-fu\" skills I developed in decades prior, where coming up with the right google search terms was a critical part of the problem-solving process.\n\n&gt; The concern i have about LLMs is that it may lead to a lot of cargo-cult programming as kids build solutions they don't understand atop solutions they don't understand.\n\ntbh, this was me when I was still learning how to program copying code from the Internet, and looking for the effect that I wanted without understanding the code behind it. I think a good coder will naturally want to know how things work after they succeed in building things the things they want. It is also a bit easier with LLM to understand since you can also ask to explain how it works.\n\nMapquest....... Those were not the days....\n\nAs an *experienced* developer, I find it extraordinarily useful in languages and environments I don't know well. It's teaching me language features and libraries that I don't know exist - But I'm experienced enough to know when to trust, and when to research to learn more about a feature or library.\n\nIt speeds up my learning.\n\nBut this same utility would be dangerous for an inexperienced developer who doesn't know when to pause, and what to take away and *learn* from it; rather than rote verbatim acceptance of the code it writes.\n\nFor me the biggest help with LLM autocomplete has been just churning out boilerplate when it comes up. It hasn't done anything super complicated for me but it's nice to see stuff like stamping out some trivial test case or even something as simple as filling in a function call with arguments taken from my context. The latter could possibly be done without LLMs.\n\nI don't think this weakens my ability to actually think about the system I'm writing but certainly is nice as a QoL thing.\n\nAgreed. It's the next step in smart auto complete. It's more the co-op students starting with ChatGPT trying to solve the whole thing and then trying to fix the resulting mess. It certainly makes you good at something, but I'm not sure what that is or if it's a useful skill long term.\n\nJust about every IDE, plugin, and framework already has mechanisms for generating boilerplate, though. We don't need some \"AI\" doing it that takes a small city's worth of power to generate it.\n\nThese tools are already becoming out of date as there is less and less documentation to train the llm.\n\nRight now it's super useful for getting ideas and getting the correct syntax for a language much faster than googling. I only wish that I could swap models (doesn't seem to be rolled out for general release yet).\n\nI use my GPS a ton on longer trips even if I know where I'm going. I love having the reminder when a turn is coming up, and having it ready incase I need to take a different route to a detour.\n\nOne of my more common trips is like 45min down a completely flat and straight highway, where I then have to turn off on an unmarked, easy to miss exit.\n\nThe entire trip is surrounded by nearly identical farm land. If you showed me a photo and asked me where along the road it was, it could fit pretty much anywhere.\n\nSo it's nice to have it let me know it's coming up, and to not get too into my audio book for a while\n\nThis is one of the things I really like about JetBrains's full-line completion feature. It's essentially just a beefed-up intellisense that's super good at contextually generating tedious snippets (e.g. object construction, collection/functional operations). I never feel like I'm reliant on it or that I'm offloading important context or logic because the suggestions are obvious and already in my head; it's just that my fingers haven't caught up. It's less a copilot with ability to reason and more like another tool in the toolbox, and I much prefer it that way.\n\nYou‚Äôve surfaced one of the worst problems.\n\nLLM‚Äôs can be a form of learned helplessness, what makes it worse is they aren‚Äôt accurate enough to trust the result without been able to look at it and see that it‚Äôs correct/not correct and if you can do that then at best they save you a little typing time.\n\nI‚Äôve seen them straight hallucinate functions that don‚Äôt exist in the stand library for the language generated.\n\nIt‚Äôs neat technology but still massively overhyped, it might get there (I don‚Äôt/can‚Äôt say as not my field of programming) but currently everyone I‚Äôve played with has been ‚Äúneat, but not trusting that‚Äù.\n\nThey can however be useful as a leaping off point for learning things if you keep at the back of your mind ‚Äúdon‚Äôt trust and do verify‚Äù.\n\nI can sympathize with cashier's and dock workers who are losing their jobs to technology, but it seems hypocritical for software developers to complain about new technology.\n\nYep, I‚Äôm just developing right now to my own demise and to the demise of my coworkers. But if it breaks, I keep working. That‚Äôs the joke, I have job security.\n\nWhat specifically about that is in contrast with being developer friendly?\n\nWell,  you can select either Claude 3.5 or gpt 4, so not \"their\" LLM\n\nGPT4 is near enough \"their\" LLM, after all the deals with OpenAI.\n\nI got the same error today and I'm subscribed as a student, but it went away after ~1 hour. Maybe it was a mistake?\n\nIt was and it‚Äôs being worked on üòÖ\n\nI got the same notification that I reached the limit, but the limit reset date was in the year -4712, so I think it's safe to say it was just a hiccup.\n\nThis distinction is important. Without it, it's a less useful tool\n\n&gt; 2,000 code completions per month (approximately 80 per working day)\n\nBig news to me is that Microsoft considers the work week to be 6 days out of 7. \n\nHello Peter. What's happening. Ummm. I'm going to need you to go ahead and come in tomorrow. Oh oh. And I almost forgot. Umm. I'm also going to need you to go ahead and come in on Sunday too.\n\nhyped for claude sonnet\n\nAh yes. So its a trial without a time limit\n\ngotdamn, fukkin intellisense subscription - what has this world come to?!\n\nFirst hit's free.\n\n[deleted]\n\nWhat is Copilot embracing, extending, and extinguishing?\n\nAn entire generation's capacity to do programming.\n\nCons: the next generations of developers will be woefully unprepared for real world issues and problem solving\n\nPros: I'm going to have a job for a long, long time\n\n[deleted]\n\nAnd this is materially different from today...how?\n\n[Documentation](https://github.com/MicrosoftDocs/WSL/pull/2021#issuecomment-2546627586).\n\nWow that is the most batshit take I've seen this year, glad they finally approved it but if that's the general perspective MS are taking towards documentation I'm worried.\n\nMicrosoft \"embraced\" open source by buying Github.\n\nThey extended your contract with Github to include ingesting your code for Copilot without your consent.\n\nThey are extinguishing open source licences by copying the code en-masse without complying with attribution.\n\nMicrosoft hasn't 'extinguished' anything in nearly two decades, unless you count stuff like running Windows Mobile into the ground along with Nokia.\n\nNot extinguish as in killing products/services/companies, but rather when they squash competition with free offerings until they are the standard/monopoly and then do stuff like hike prices or leverage their position to route in business to other parts their offerings.  \n    \n\\&gt; **Extinguish:** When extensions become a de facto standard because of their dominant market share, they marginalize competitors who are unable to support the new extensions.\n\n\\* [https://en.wikipedia.org/wiki/Embrace,\\_extend,\\_and\\_extinguish](https://en.wikipedia.org/wiki/Embrace,_extend,_and_extinguish)\n\nGetting free access to Claude 3.5 Sonnet is **highly** surprising to me. A direct competitor, and arguably the best current model for coding, for free? Only 50 chats a month, but that's more than nothing. Microsoft really wants to inculcate AI as a habit for devs.\n\nWe have copilot at work and I don‚Äôt really think much about it until I get home and start to code and then wonder where my typing suggestions are. I was skeptical at first, but it really has become a tool that makes my daily life easier.¬†\n\nAlso ‚Äúwrite a data class that matches this huge json response‚Äù\n\nNow write the openapi spec. \nNow write the controller based on the spec. \nNow write some tests with mocks.\n\nNow update it to only use API functions that actually exist. Only use the current version of the library, not one that has been unsupported for years. Wait why are you importing pandas for this?\n\nNo, we're NOT rewriting in Rust!\n\nI'm sorry Dave, I can not not do that\n\nI was playing around with a little proof of concept for a tool I had been thinking about for some time. It used the openAI API for some basic RAG flows, and I wanted chatGPT to spit out some python code based on my natural language description. It gave me a strange mix python that used half of their old API mixed with parts of their newer one so nothing worked. Ive used it to generate working code in really obscure LLVM internal C++ APIs and many other really complex things, and here it was not able to produce working code for its own damn API. Strange!\n\nI assume it's trained on data from forums and StackOverflow without regard to when that post was written. For stuff that's been around a long time, most of that is going to be outdated. Maybe it's me and the types of things I'm asking it to do, but I run into this very often.\n\nA separate problem is if I'm using some weird API that doesn't have a ton of documentation or discussion online, it will just make up functions and endpoints that logically should exist (but don't).\n\nYeah, I get that and for more obscure things that's fair enough. But for their own \"headline\" API this is really weird. They should have a bunch of training data from their own code that sets themselves patterns very clearly. Having some weighting system for newer content shouldn't be rocket science either.\n\nI agree, it does seem like you could improve this with better training or even mitigate it with better prompting. Like I started writing my own readme.txt with instructions to attach to my prompt when using Claude Artifacts because e.g. it constantly generates a package.json with version numbers pinned that are neither current nor necessarily what the code even needs to run.\n\nI hope you're not mocking it because yeah it's not much less hard than that, such a timer saver for these mostly braindead tasks\n\nParte json as class, in visual studio 2022.... But, yeah, copilot can help generate code, and explanations, etc. I like it a lot!\n\nFurthering your point, I suspect paste json (or XML) as classes has existed for more than a decade. It's definitely not vs2022 that introduced it.\n\nI like to use Python is good for such boilerplate stuff. Sometimes pure python, sometimes jupyter notebook to copy-paste quicker\n\nThis is 99.9% what I use AI for when coding. Surprisingly accurate with large objects as well\n\nYeah, you definitely need to keep an eye on it but it does save on typing for the simple stuff and occasionally can provide an interesting alternative for more complicated problems.\n\n  \nGiven I work a lot in C++ a big benefit is that it seems to be aware of modern C++ features and syntax, whereas StackOverflow provides upvoted answers from 2009 which is basically C.\n\n[deleted]\n\nI use the copilot extension for Jetbrains Rider (C#) and pretty much disable most other extensions including the built in machine learning autocomplete.¬†\n\nI find that it does simple suggestions very well, and with some context (eg a few characters typed) it knows how to complete what I want.\n\nRunning into the same a lot with Java. Plus when I'm trying to write comments or docs, it's constantly flickering irrelevant blocks of nonsense bullshit, causing stuff below where I'm typing to be jumping around like a strobe light. Seems like maybe 10% of the time it gives something actually good, 20% it gives something that seems good at first but has subtle bugs or just calls imaginary functions, and the rest of the time it's total garbage. Starting to think it's more trouble than it's worth.\n\nman, I get no suggestions at all in VS, will try VS code\n\nOriginal copilot model had only a 4k input context size.. it was a pretty bad experience in vscode.  I think they got tired of waiting and starting to become not competitive.\n\nIt's interesting they arent giving away o1/o1 mini at all.  It scored really poorly in coding on livebench.\n\nProbably also because it's hugely more expensive to run with the train-of-thought prompting.\n\nAt work (copilot enterprise) we have the o1 models.\n\nthe first 01 scored poorly, the new one released on 17:th of December beat everything else by a decent margin.\n\nIt's a plot to make you dependent and cause brain damage.\n\n&gt; Microsoft really wants to inculcate AI as a habit for devs.\n\nI figure it's more like they want your code for their training data.\n\nthey also spent over twice as much for hardware from nvidia as compared to all their other competitors.  they looking to have the upper hand\n\n[deleted]\n\nI've always been bad at memorization and a lot better at knowing \"this is what I'm trying to do, and I know where to find it quickly, so I'll focus on the concepts and look up what I need to\" so I really like it for spitting out a boilerplate template for me with all the fidgety syntax stuff I can never remember because I either don't use it frequently enough or it's something you literally only need in the boilerplate.\n\n[edit] It also helps reduce the amount of time wasted context shifting between things that are similar-ish enough that it gets jumbled in your head. Like sitting down with pandas was a bear after a year of just doing pyspark. Now it's less painful since I'm back up to speed with pandas but I do jump back and forth between them sometimes on the same day even, so the small differences in how they do something will trip you up. It would probably be easier jumping between Python and I dunno Java since there's a clearer context shift there, vs the halfway context shift and now you're fully in neither context you get sometimes.\n\n&gt; I went from someone who could barely VBA to the excel macro master chief, SQL bro and m/DAX genius within a month.\n\nNo you didn't, you copied someone else's hard work and are calling yourself an \"SQL bro\".\n\nI'm making a game in godot and it's insane how fast it can code. Simple mistakes sometimes but it doesn't make sense to no use this power. I can imagine seasoned dev would have even a bigger edge\n\nCreating dependency and infantilising people will make them money long term so makes sense.¬†\n\nenterprise adoption has plateaued, and they need to get end users to bug their managers to buy a license\n\nI hear this a lot but I don't understand how a product that only just came into existence can have already platued. Most regular people are seeing copilot appear all over their windows operating system but barely understand what it even is.\n\nThey said \"enterprise\". So businesses. It's really not unbelievable that in terms of businesses adopting GitHub Copilot the adoption has roughly plateaued. If something is good it is quickly adopted in tech.\n\n\nAlso Microsoft Copilot is not GitHub Copilot. I find it baffling that Microsoft, who also own GitHub, made an AI tool with an identical name. But then again they are the brilliant minds behind Visual Studio Code, not be confused with Visual Studio.\n\nAlso: A good chunk of developers are likely using freely available tools without mentioning anything to upper management. Which is becoming a bit of a problem for companies that are expecting some sort of data protection on their proprietary software's internal code, because free ChatGPT is not silo'd and the data may be used for re-training.\n\nMicrosoft is betting on the dam breaking and these companies eventually giving in and paying for enterprise Copilot/ChatGPT to prevent developers from accidentally using personal-use LLM products. But that concern might not be registering on anyone's radar because developers have been posting StackOverflow questions that reveal internal product information for a while now &amp;mdash; and StackOverflow usually only gets banned at companies that are handling particularly sensitive info, because it would knee-cap developers to take it away.\n\nAt this point the companies not adopting are probably looking at security concerns. It isn't that there isn't an interest in these tools but for nearly all of them you're agreeing to some degree to send data to another company on their proprietary system. Unless they start offering ways to build the tools in house or move towards offering a system that strictly stays within the boundaries of their network I imagine they're going to continue to get push back.\n\n&gt; or move towards offering a system that strictly stays within the boundaries of their network I imagine they're going to continue to get push back\n\nThis is essentially what they're offering with the enterprise version of Copilot/ChatGPT. They're selling the ability to run AIs on separated Azure datacenters that adhere to stricter data handling policies, so that you can treat OpenAI as just another vendor and not an information leak risk. The argument I'm making is that *not* buying in is more of a risk than buying in, because if you haven't adopted the mindset that it's another vendor, individual employees will use whatever public tools are not blocked on the company's internet filters. But that despite this, interest has still been low.\n\nPart of the problem with buying in right now is things are moving so fast you either need to buy into every platform or risk only buying into a platform it turns out your devs don't like. Or they like it now but it goes to shit in a year and some other vendor comes out with a better one. And the only practical way to figure this out is let your devs try the different products and see what works for what they're working on. \n\nThis seems like it should sort itself out soon enough though given they're already running into the wall of needing to throw more and more horsepower at these models to eke out improvements, it's not a couple of years ago anymore where chatgpt was going through night and day improvements every couple of months.\n\nIt‚Äôs called the adoption chasm https://medium.com/@shivayogiks/what-is-technology-adoption-life-cycle-and-chasm-e07084e7991f\n\nWell studied phenomena. Where if a product can‚Äôt break out of early adopters it‚Äôs basically dead unless those early adopters have enough willingness to pay to keep it afloat.\n\nI think the keyword was enterprise. Any devs here who work for big companies that haven't shelled out for copilot licenses?\n\n[deleted]\n\nEmbrace...\n\nExtend...\n\nExtinguish.\n\nthen Eat.\n\nIt works in Android Studio//Intelij IDEs\n\nWorks in Emacs too.\n\nYeah I think they enabled the service for all but only made the communication for their own products\n\n[deleted]\n\nChrist ICT / the IP protection team work will have a meltdown if that‚Äôs the case.\n\n[deleted]\n\nZed is pretty great if you want a lean editor\n\nTheir whole new thing is AI? How is that an editor with bloatware removed?\n\nIt's a shame the text rendering on Linux is atrocious\n\nDoes vscode even come with any plugins by default?\n\nYes, search for @builtin in the Extensions panel to see them.\n\nIf you buy it, will there be a difference?\n\n[deleted]\n\nIf VS Code can implement all the things I use every day in Cursor, I'd switch back in a heartbeat.\n\nWhat are you using in Cursor. I've tried it once, but wasn't really impressed too much. Maybe I missed something.\n\nJust today I wrote a utility function and needed to migrate ~15 files to use the new utility. I used the Composer feature to add all the files to the context, along with file that contained the new utility, and then described in the chat the patterns that I needed changed over to use the new utility, and gave it several circumstances under which it should take some creative liberties to fill in some blanks. After sending the request, Cursor was able to do a multi-file edit and presented me with diffs for each file, where I could make sure the changes were up to my standards, and most importantly correct. I think tasks like these (refactoring) are where Cursor really shines.\n\nNot to mention, tab complete is just freakin magical. Sometimes it can miss for sure... but when it is on, boy, sometimes i just hit tab 10+  times before I really need to take back control.\n\nI have to admit that this does sound super interesting. Costly as well and I'm unsure how it would work for very large code bases. But I suspect that's something that's going to be solved, if it isn't already. Cool feature indeed.\n\ni find the chat on cursor extremely worse than chatgpt for example. The autocompletion works much better and faster than copilot though.\n\nWhat else are you using\n\nSame. It gets ‚Äústuck‚Äù on one implementation so frequently. Sometimes I need to remove context for it to work\n\nI've had the opposite experience with Cursor chat. I mean, its just using Claude, no? And I have had really good experiences with Claude over ChatGPT.\n\ntry Codeium Windsurf\n\nI received an email about this not long ago... How does it compare? I already pay for Cursor, so if there's something cheaper/better out there I'm willing to give it a shot.\n\nIt started out okay but sucks now and the free tier is extreny limited. A very cheap demo¬†\n\nThis means the collection of .env files from around the world has begun.\n\nFun for a few days, but turned it off. It‚Äôs just annoying. Its productivity claims are massively overhyped. Only 10% of my day is actually coding. Rest of my time is solving problems. Measuring twice and cutting once. \n\nI can see this working for the developers at TCS, Cap Gem, Accenture, Infosys etc. If you want lots of below average code to maintain then great.\n\nWhat AI tooling has helped with is search. The ability to rapidly surface the right information based on various documentation sources is a massive help.\n\nLet the downvotes fly in ‚Ä¶\n\n&gt; I can see this working for the developers at TCS, Cap Gem, Accenture, Infosys etc. If you want lots of below average code to maintain then great.\n\nJust this morning I reviewed another MR by a hired gun from one of these\nwho I highly suspect of using LLM liberally for coding.\nThe SNR in his contributions is infuriating compared to the rest of\nthe team and he tends to get defensive when asked for the motivation\nbehind certain changes.\n‚ÄúWhy the fuck are you changing this?‚Äù -- ‚ÄúI can do it differently!‚Äù\n-- ‚ÄúThanks, that‚Äôs not what I asked ‚Ä¶‚Äù\n\nIt gives the impression of ‚Äúdoing work‚Äù, but I‚Äôm not surprised the team can see right through it.\n\nOh it does the job and he‚Äôs quick for a mid-level dev alright, but it often\njust seems ‚Äúoff‚Äù.\nWeird branches that are often equivalent to no-ops except for side-effects,\nuse of non-idiomatic constructs, ignoring internal libraries that already\nprovide abstractions for the boilerplatey parts etc.\nYou just very obviously wouldn‚Äôt implement it that way.\n\nIn a way it hits the ‚Äúuncanny valley‚Äù of source code.\n\nFor me its great. When adding in new features and writing migrations, models. I just give the schema to chatgpt and it generates code. Saves 5mins and it adds up over time. Same with writing unit test. helps with alot of boilerplate code and i can then write the logic where i won't need chatgpt.\n\nIt's useful occasionally but I find myself ignoring the vast majority of completions until I get a bit of writers block.\n\nHaven't found a way to tune the timing of suggestions, but I really wish I didn't have to burn a rainforest a day for all those ignored suggestions\n\nno thanks\n\nConsidering the quality of SQL stuff I've seen it produce, and how it masks the actual fix behind another dubious change that dramatically decreases overall readability...\n\nForgive me for declining the \"free\" offer.  Thanks.\n\nI just unsubscribed it a couple weeks ago. Didn't realize they had a free variation/service/whatever. \n\nI'm torn. For every minute it's saved me, it's also either cost a minute or some other troubleshooting it created, or deleted another minute of learning from my mind, because I'm not doing it anymore myself. \n\nI love it for boilerplate stuff, but when it comes to logic, it's so close to being good that you miss all the dumb stuff it does while trying to guess what you are actually doing. \n\nIt feels like it turns my entire coding experience into just live debugging code, and removes the fun of creating it.\n\nI'm not surprised considering people are not using these products at the scale they hoped.\n\ni love free stuff\n\nSo you're the product.\n\nWhether or not you're paying for it, you've been the product for well over a decade.\n\nYeah. Even the things we pay for are still monetizing our data any way possible.\n\nit‚Äôs a trial with monthly limit\n\nThe concept of shareware would blow people's minds these days.\n\nFrom the email:\n\n&gt; GitHub Copilot will show code suggestions that match public code, including code references in the VS Code and github.com experience. **GitHub and affiliates** ~~may~~ **use your data for product improvement.** You can adjust both data use and public matching code suggestion settings in your Copilot Settings.\n\nIf we look at it through an unbiased lens, I think the vast majority of users are pretty happy to be the product for most things. Imagine being forced to pay for search, or docs, or videos etc\n\nQuite literally. My org is implementing paid GitHub copilot and in training sessions they pointed out that none of our enterprise requests will be used to train models but for individual users‚Ä¶..\n\nAlways have been. Has anyone reviewed the terms of use? Do I still own what‚Äôs generated?\n\nIt's the wild west. Intellectual property in the context of generative AI is defined in loose terms and will be sorted out through court battles over the next decade. OpenAI has copyright shield for this exact reason.\n\nThe paid version of copilot includes a provision that Microsoft will defend you if sued for copyright infringement for using its output\n\nShh, disrupting the conspiracy theories!\n\nIt's just a free tier of a product they want to sell. They were all over the place for years and years before crypto hit it big and the miners exploited free tiers into extinction.\n\nIn what way are you ‚Äúthe product\", considering VS Code is already free ?\n\nevery piece of code (and comments) you are creating is training data for them. \n\nalthough the simpler stuff is well-understood by their models .. the more esoteric areas of a language provides invaluable examples for them.\n\nand having access to the way 4o or sonnet would do it, is another plus\n\nBut they have that already if you are using Github\n\nProbably they desperately looking for more dataset to train\n\nI guess they are figuring out no one will pay for this guff...\n\nI am not sure that giving it away for free will help... simply more people will realise how irritating it is!\n\nAlso remember that https://vscodium.com/ comes without this stuff, or the phone home to MS.\n\nFinally, I can steal other people's code for free.\n\nSo they won't charge me anymore?\n\nHow do i uninstall or disable it?\n\nWhen something is \"free\" then you are the product.\n\nOr being lured. After all it‚Äôs a subscription. In my experience it is well worth it (especially when the company is footing the bill)\n\nThis is just a Reddit meme. Sometimes the free product is a taste of a money-making subscription and/or a feature or product that's subsidized by a different part of the business in hopes of some % of audience being converted.\n\nIt's a real phenomenon with social media, but in this case yeah it's just a trial.\n\nIt's not free... It's a trial\n\nI'm trying it and if it works well I'm rolling it out for the company\n\nDoes your brain explode when you see the free samples at costco?\n\ncool, my subscription was going to renew in about 2 weeks but I guess I can just cancel it now\n\nIts a trail and pretty limited. Its just a sales pitch\n\nNo thanks\n\ntbh it's crap. glorified code-completion, and the code completion is wrong enough times that I'm not sure you even save time on that.\n\nCool. Nty. Shifting to Codium on my new system. It's bad enough for my shove AI into the OS. Shoving into an open source project? Na fam, I'll use the fork.\n\nEdit: so it turns out Codium has the Copilot infection as well...\n\nCodeium is free without limits\n\nI have a quick question for people who have used this. I'm a researcher, I design numerical algorithms, often my projects are 2000 lines of code and then I move on.\n\nFor example, on [this project](https://github.com/sloisel/MultiGridBarrier.jl), it'd be good to go over all the docstrings and fix them. Sometimes, the docstring doesn't quite match the actual function signature, some parameters are missing, some of them were renamed or deleted, sometimes there's grammatical mistakes or an incomplete sentence.\n\nWould I be able to go \"Github Copilot, please fix all my docstrings!\" and then get a patch or something for me to review and approve?\n\nYes and it‚Äôs really really good at generating doc strings. You can say generate doc strings for all my functions, then implement the suggested changes in your file, and review/approved the changes inline. \n\nYou can also control the context that‚Äôs sent to the model by highlighting blocks of text and only generate documentation for those blocks.\n\nSo, what is the setting to turn this off?\n\nYou, uh, just don't install the extension\n\nI just came back to mention that it is an opt-in setting.\n\nI love that I have literally nothing to do with Microsoft anymore.\n\nNot free, you pay by giving them your code.\n\nGitHub users give them code anyway.. that‚Äôs kinda their whole business model lol\n\nNot if you host the repository yourself. On your machine. On your network. This bypasses that.\n\n\"Free\" where you most likely pay with feeding it your code information.\n\nit's a trial\n\nIs it better then cody?\n\nLooks like they're going to release it for other editors too.  I'm currently using FittenCode in Neovim, will be worth testing once I can integrate it there too.\n\nIf you contribute to well known open source projects they give it to you for free. Just learned about it yesterday after seeing free renewals for almost a year.\n\nI have just received the email regarding this\nFirst, I thought I had scam email but after checking this post I realized it's true.\n\nUnfortunately I'm not able to login because of [this error](https://github.com/orgs/community/discussions/147446). Seems like a lot of people are having the same issue. Hope they get it fixed soon.\n\nTake a look at gemini coder¬†\n\nTwo bad tastes that taste bad together!\n\nIt was hard enough to know if the junior meant to do that, now I have to wonder if they just let copilot write the whole function. Ugh.\n\nI saw I got en email today from GH today saying I got free copilot. I guess this was the email. I don't use VS Code and GH is a second class citizen in my ecosystem. So I guess I will never use copilot for any of my projects.\n\nHow about Visual Studio?\n\nI have been using the enterprise version that my company has licensed. It's really good if you use vscode as your primary IDE. Not sure the free one will be the same with some restrictions. I need to try it.\n\nDoes Jetbrains with copilot plugin eligible for this?\n\nI think not, the email isays:\n\n&gt; Your GitHub account now includes free use of GitHub Copilot in VS Code and on GitHub,\n\nI have been using codeium (or is it codium) it's free and unlimited and seems to work pretty good for completions. I am not using AI to write large sections of code though.\n\nExactly the same (extreme) limits as Cursor‚Äôs free plan, so it‚Äôs a pretty transparent response to competition.\n\n\"2000 suggestions and 50 chats per month\" is more like a \"trial\" or \"teaser\" than \"free\" to me.\n\nOTOH, Github Copilot is indeed the best $10 per month I spent on programming tools.\n\nIt's poison to the brain, especially beginners. I uninstalled it after a week on my trial a year or so back. Utter shite.\n\nI will stick with codeum for now and just normal coding.\n\ni actually cancelled my (personal) subscription because i use this barely but i also cant live wiithout it with using it at work\n\nthanks microsoft!\n\nPeople that trust Microsoft...\n\neww"
  },
  {
    "title": "Github down globally",
    "body": "",
    "score": 1419,
    "url": "",
    "created_utc": 1723677693.0,
    "author": "TheBazlow",
    "permalink": "/r/programming/comments/1esfxce/github_down_globally/",
    "all_comment_text": "I wonder how many assets are affected. I just ran into 'We're having a really bad day.' message while visiting another website.\"\n\nAccording to the status page, it seems like *every* GitHub service is down. Lots of people will be having a really bad day.\n\n[deleted]\n\nGitHub pages lets you host almost anything. You can host your entire website or only static JS / CSS / image files. And it's free. So yes, many use it like that.\n\nPeople also host their Helm repos via GH pages. \nAnd host their container images and OCI-compliant blobs in ghcr.io.\n\nOh yeah.  Tons of stuff pulls straight from GitHub.  Even live production webdev stuff.  If you grep through an average users browser cache, a website they go to is almost certainly pulling some .js, .css, font, or whatever straight from GitHub.  \"To reduce complexity of managing our own storage, and to ensure we are using the latest version.\"\n\nSome projects do it intentionally.  Some projects have no idea that downstream users are pulling directly from git in prod. \n\nFor example, if you have CI running away from Github and you are patting yourself on the back for robust diversity, but that CI depends on installing stuff with vcpkg, you are hosed.  Vcpkg typically uses GitHub as the \"CDN\" / medium for fetching package manifest data no matter where you are running it, unless you are following and using your own fork that only occasionally needs to pull from GH.\n\nIf you are using larger libraries you want to utilize the client side cache of the library, thus you must use the CDN version as the URL will be the same across sites and cache can be used. Unfortunate, but I can understand why.\n\nI have read some people are using it to host the privacy policy of their apps, for example\n\nSorry about that, I forgot to remove the \n\n&gt; rm -rf ../../../../../ \n\nfrom a new action I've been working on.\n\nJesus man, be careful! One more .. and you'd have deleted the whole Internet!\n\nThat's ridiculous. That would imply that if I went one step further and did ```rm -rf ../../../../../../../``` I could delete our entire rea\n\nNO CARRIER\n\n[deleted]\n\nDREEEEEEEEE‚Ä¶ BEEP-BEEP-BEEP‚Ä¶ SKREEEECH‚Ä¶ KRSSSHHHH‚Ä¶ WHEEEEEEE‚Ä¶ CHHHHHH‚Ä¶\n\nThe only reason this hasn‚Äôt happened is no one knows how many times to repeat ‚Äú../‚Äú, so the try it with less and take themselves out first.\n\n    sudo su god\n    sudo rm -rf --no-preserve-reality /../../../\n\nReddit down .....\n\nSir, it appears they're approaching ...\n\n\n... the ROOT DIRECTORY!\n\nshield is at 65%\n\nGood thing the IT crowd still has that internet in the box, in case we ever need it.\n\nImagine a world without twitter, tiktok and facebook, and even better, all social media. I bet it would cure so many current diseases in a month. \n\nWeirdos being forced to talk with normal people outside their echo chambers, many would not have the greatest of times but little by little it would normalise\n\nThat requires the undocumented --no-preserve-internet flag.\n\nOh no, I just documented it!\n\nrm -rf ‚Äú$TotallySetVariable/‚Äú\n\nnothing can go wrong!\n\nI broke out in a cold sweat just from reading that.\n\nOof, that's nightmare fuel right there\n\nAt this webhost provider i had 25 yrs ago, you could directory traverse upwards with PHP. When i bruteforced /etc/shadow the user password were in order: never, gonna, give, you, up, never, gonna, let, you, down\n\nSame exact experience, but 15 years ago I think.\n\n2000 was 15 years ago, right?\n\nAnyway I ended up adding some messages to other websites to the tone of informing the owners to find a more professional hosting provider.\n\nYoure off in the timeline, the 80‚Äôs was 20 years ago, so you can count from there\n\nThat's more of a gitlab thing\n\nEngineer: \"Copilot, please fix the issues and bring GitHub services back online.\"\n\nCopilot: \"I'm sorry, Dave. I'm afraid I can't do that.\"\n\nIt'll be more like\n\nSure, clone this GitHub repo and run this command.. :/\n\nAutopilot from wall-e\n\nHal 9000 from 2001\n\nIs Github's source kept in Github, and if so how do they rollback infrastructure changes when Github is down? üòÇ\n\nNow we know the real reason why the self-hosted GitHub Enterprise server exists\n\nYou joke but this is literally what they tell you if you're a GitHub enterprise cloud customer.  They still recommend you run enterprise server for the times they are down.  And they're down in one way or another during business hours kind of a lot.\n\nI mean it‚Äôs always business hours somewhere, not much you can do unless they do independent regional deployments\n\nBut where do you keep the infrastructure code for these instances? Is it GitHub Enterprise Server all the way down?\n\nI imagine that you hit ‚Äúchecked out on the team‚Äôs laptops‚Äù fairly quickly given the nature of git.\n\nThey probably hosting GitHub repo on their private server.\n\nThey use Gitlab and they won't tell us haha\n\nIt‚Äôs git so every developer is ‚Äúhosting the GitHub repo‚Äù that works on it at least\n\nYeah, \"repo\"... `github_application_v5.2421_final_final.rb`\n\nIt's ADO surely\n\nBitbucket\n\n\nOr¬†\n\nGithub.bak.latest.V2-ACTUAL_final.zip\n\nI‚Äôd seed that.\n\nOh man, I *do not* miss the days of seeing piles of terribly named archive files like that\n\nI believe the answer is ‚ÄúGitHub is itself stored in an instance of GitHub Enterprise.‚Äù Those are disconnected from the main site for many reasons, including resiliency.\n\nNo need to worry. They moved that to Visual Source Safe back when Microsoft took over.\n\nOh no someone's probably gone on holiday with a critical file checked out!\n\nPTSD TRIGGER\n\nWe had to track a coworker down on PTO in India because he left for his six week trip before pushing his last change to GH. Thankfully he had taken his laptop because he was working remote for part of the trip.\n\nEasy, you use GitHub\n\n[deleted]\n\nUnless your repo is using lfs, in which case nobody has a copy.\n\nWait until you find out what language the C# compiler is written in.\n\nCompiler devs love an Ouroboros\n\nThere‚Äôs two, Roslyn is written in C# but only compiles to IL, then RyuJIT compiles the IL to native code. [RyuJIT](https://github.com/dotnet/runtime/tree/main/src/coreclr/jit) is written in C++ \n\nJust kidding the whole thing is Java under the hood! Java the whole way down shhhh\n\nThe JVM has no limits.\n\n*Angry Xmx noises*\n\n[deleted]\n\nJust download more and keep increasing the startup heap size. I see no problems.\n\nThe JVM has no liException in thread \"main\" java.util.ConcurrentModificationException\n\n&gt; Is it hotspot all the way down?\n\nAlways has been.\n\nAnd Hotspot is ‚Äújust‚Äù Strongtalk (a Smalltalk variant). Yep. Java runs on Smalltalk!\n\nRemember when facebook had to take an axe to there datacenter cage?\n\nOr when Google had to take a drill to a safe (containing HSM smart cards)\n\nThey probably host a separate instance of GitHub for internal stuff. I bet it‚Äôs redundant and built with technology that enables it to run very consistently. My company does that with their GitHub stuff. Depending on cloud based software is good up to a certain scale, and then there are some major tradeoffs you need to consider.\n\nIts actually in ADO now that Microsoft has acquired it\n\nWith backups in SourceSafe.\n\nIt is somewhat frightening how so much code is dependent on this one service provider. I recognize that it would be difficult for other groups that aren't backed by Microsoft to offer a similar service but like damn. Didn't the index for rust crates at one point depend on GitHub?\n\nHonestly we use Gitlab and it's fine. Pretty much the same features, and up basically all the time\n\nWasn‚Äôt long ago the free tier of Gitlab had more features than the free tier of GitHub, I think gitlab actually forced GitHub to up their free offering.\n\nIt did, along with kicking github in the butt to implement github actions.\n\n$29 per user per month whereas the equivalent on GitHub is like $8 or less.\n\nI love Gitlab but its pricing makes it a ludicrous choice.\n\nNot even per month. The only option is to pre-purchase X number of seats for the *entire year*. No option for monthly billing at all so fuck you if you have some churn, if you work with contractors, if people join or leave etc etc\n\nIf you actually look at the features further down the list, the GitLab Premium is closer in features to the Enterprise offering. Especially around things like SAML and planning. And Ultimate includes all the security scanning, which is an add-on for GitHub. But they come out a lot closer to each other, there's just no middle tier that would be closer to GH Team.\n\nThat is only applicable if you need GitHub enterprise and for those businesses the price probably isn't an issue.\n\nSo yes choosing GitLab means paying almost 4x what you would by going with Github for big parts of the market.\n\nPretty insane that Gitlab don't take a hint and provide a competitive option for those that just need the basics.\n\nBack when I was a contractor, I used to pay for the $35 Bronze subscription for the year and thought that was excellent value, if not undervalued.  It's now 10x that price just 5 years later.  If you just want the basics, there isn't an option for that.  And as soon as you have a team all paying that rate, it's quickly getting into silly money territory.\n\nGitLab has a huge amount of value.  But at that price it's just not competitive.\n\nYeah I also see that github has an $4 option making it even more outrageous. It would mitigate a lot of this if they allowed for some unpaid or lower tier users but as I'd you are stuck paying $30 for every single person in your org.¬†\n\nIf they had the ability to have different grades of user I wouldn't have a problem.  But when you have a small number of developers and a larger number of people who just want to download builds, look at the published pages or wiki, or comment on or create new issues, this is just unworkable.  At this point it's far cheaper just to use dedicated tools for each function.  But the whole point of GitLab is its integration and collaboration.  But no matter how beneficial all of that is, it has to be cost-effective and competitive.\n\nThat‚Äôs what Gitlab themselves say but I don‚Äôt really buy it since they still have another tier on top. In any case, with GHE you‚Äôre spending a similar amount, but don‚Äôt have to pre-buy seats for a whole year (see a reply to my comment on contractors)\n\ndidn‚Äôt Gitlab accidentally delete their prod database and their only backup was dev copy of prod taken 1 hr before disaster\n\nAFAIK they did have earlier backups but they weren‚Äôt able to restore from them.\n\nWhich makes sense, just backing up is only a part of the process, you should test your backups periodically\n\nExcept when it‚Äôs not https://www.reddit.com/r/programming/comments/12zzn6k/dev_deletes_entire_production_database_chaos/\n\n&gt; up basically all the time\n\n&gt;basically\n\nThis is how our IT defends 99% uptime.\n\nIDK about up all the time, it randomly goes down for a few minutes every few days.\n\nHell, it's import system from github is down right now...\n\nThat said, our team just downgraded back to free and just has our runners on our k8s cluster. Besides milestones and some nice-to-have planning stuff, we don't really have any issues with the free version.\n\n[deleted]\n\nThe only real solution is to go back to most things being on prem which has its own pros and cons\n\n&gt; Didn't the index for rust crates at one point depend on GitHub?\n\nAt the very least it's in a git repository, but not sure where that repository is hosted.\n\nThat'll probably be why Github Copilot suddenly stopped working for me to. Interesting that it's so dependent on the rest of Github to function.\n\nIt was a network configuration issue, so nothing could access their databases.\n\nThank goodness LinkedIn is ok\n\nlol\n\nAgree?\n\nFortunately you can still use your local own source control as Git itself is distributed.\n\nI used git send-email to send my PR as a patch to the company-wide email alias so everyone can patch their local clone with my code, and now HR wants to meet with me tomorrow.\n\nCongrats on your new promotion!\n\nFancy new title and everything!  Director of underemployment\n\nPlot twist you are hr\n\nYou can also set up a mirror to gitlab/Bitbucket/azure git.\n\nWas seriously contemplating this last outage.\n\nif I deleted my repo's commit history and force pushed, a mirror would lose the commit history, right? does gitlab/Bitbucket/azure have anything to prevent that?\n\nOkay, this was based on some half remembered thing from a half a decade ago.\n\nI thought git had an actual mirror command.  Turns out my memory is shit.\n\nI had some half baked scheme to have a webhook on the main branch to push commits, so it's probably be some condition of the webhook.\n\nTo be honest, I'm a Business analyst, so my knowledge of git is haphazard.\n\nI think you're thinking of `git push --mirror`:\n\n&gt;        --mirror\n&gt;           Instead of naming each ref to push, specifies that all refs under refs/ (which includes but is not limited to refs/heads/, refs/remotes/, and refs/tags/) be mirrored to the remote\n&gt;           repository. Newly created local refs will be pushed to the remote end, locally updated refs will be force updated on the remote end, and deleted refs will be removed from the remote end.\n&gt;           This is the default if the configuration option remote.&lt;remote&gt;.mirror is set.\n\nIt's not very commonly used.\n\nYou can also run git itself as a server: https://git-scm.com/book/en/v2/Git-on-the-Server-Git-Daemon\n\nGitea and Forgejo, too.\n\nYou can commit to your local repo, but if you lose your laptop/desktop, bye bye commits.¬†\n\n\nPRs are also blocked. Github actions as well.¬†\n\nYou can add a new remote elsewhere and throw your code there. Azure repositories, gitlab, bitbucket..\n\nEven a plain directory, on a mounted network drive or server git can write to over ssh. Git doesn't *need* any special server daemon running to push to. Less efficient, though, I believe the git server has a number of tricks to reduce the amount of data that needs to be sent over the network, negotiating to find what parts of the files are unchanged.\n\n&gt;a number of tricks to reduce the amount of data that needs to be sent over the network, negotiating to find what parts of the files are unchanged.\n\nrsync, I would assume\n\nNo, git does not use rsync. \n\nIt computes (or estimates) the difference between the object graphs each side has and sends the missing objects only, with delta-compression.\n\nWell yeah but that might be agains corporate policies.¬†\n\nAre there serious companies that don't have self hosted git repositories too in their own servers? My guess is not even GitHub enterprise is affected by this outage but I imagine other companies at least have self hosted gitlab instances running.\n\nGithub enterprise is a thing.\n\nIt comes with \"disadvantages\"¬†\n\n\nMy company is migrating from github enterprise (self-hosted) towatds github cloud.¬†\n\n\nOne of the disadvantages is lack of new features. I can compare both products and github cloud is way better.¬†\n\n\nBut the truth is probably that github (and jira!) are pushing for their cloud services.\n\nSorry, what I meant is that there's a Github cloud enterprise. The other user was questioning if any \"serious\" company would use cloud services and the answer yes, a lot do.\n\nI dont think pushing to two remote repos is considered the norm.\n\nEmail a patch series, ya lazy bum! -Linus Torvalds\n\nMaybe a good time to try¬†https://github.com/git-bug/git-bug\n\n\nYeah I know it's not for everyone.\n\nYeaaaahh, thaaat\n\nYou definitely can, the setup to do so if you haven't done it though is likely longer than the time it'll take for them to recover.\n\nAlso pretty difficult if your organization is segmenting networks.\n\nOh come on, why while I'm sleeping, why not when I'm working\n\nNow's when you find out which sites somehow fucked up their Dockerfile vs. entrypoint.sh understanding, and accidentally put the \"git clone\" step in the entrypoint.sh.\n\nWe do this intentionally in our data jobs system, but imagine having that in your main web server\n\nWhen I worked at godaddy that's what they did and they were very happy with it. \"We can just pull updates and restart, why would we need containers?\". Okay\n\nThat's funny. As I was typing it out, I kept thinking \"this is so stupid it's probably not even a relatable thought\", but it's nice knowing it's legit haha\n\nYou'd be surprised at how many people actively try to circumvent the features that prevent them from fucking up.\n\nSo uuh how do they do rollbacks?\n\nGodaddy is a terrible place, I didn't say this was a good idea\n\nReset the head and restart again?\n\nWould care to elaborate? I am starting to get more fluent with using dockerfiles for base step, and I was playing around with entry point and cmd while putting together a cli. I am thinking the next phase is having an nginx web app that literally pulls some code and runs yarn install, then the site would be running.\n\nContainer images are supposed to be immutable. basically every time you run it regardless of time, you're supposed to get same environment. Same follows for docker files, but sadly that is impossible (apt/yum/curl/etc wont produce same result a day from now) unless you build everything from source. What you're looking for is multistage builds, where you run your build script, and then copy over the result into clean slate where you run your nginx server.\n\nLet me guess, DNS?\n\nIt‚Äôs always dns\n\nExcept when it's BGP.\n\nOoh, it *_was_* BGP (or sone other routing protocol)!\n\n&gt; On August 14, 2024 between 23:02 UTC and 23:38 UTC, all GitHub services were inaccessible for all users.\n&gt;\n&gt;This was due to a configuration change that impacted traffic routing within our database infrastructure, resulting in critical services unexpectedly losing database connectivity. There was no data loss or corruption during this incident.\n\nhttps://www.githubstatus.com/incidents/kz4khcgdsfdv\n\nAs a DNS administrator, I can assure you it's the firewall.\n\nThat's just what a DNS administrator would say ü§®ü§î\n\n\"Hold my beer!\" ‚ÄîCrowdstrike\n\nCrowdstruck, the most damaging security vulnerability ever exploited.\n\n&gt; This was due to a configuration change that impacted traffic routing within our database infrastructure, resulting in critical services unexpectedly losing database connectivity. There was no data loss or corruption during this incident.\n\n&gt; We mitigated the incident by reverting the change and confirming restored connectivity to our databases\n\nDamn it Dave I told you to not touch /etc/hosts\n\nIt seemed to be an error message from GitHub itself displaying a unicorn head and the message that no server is available to service your request.\n\nWell that's an excuse if I've ever seen one\n\nHugops for Microsoft. CrowdStrike and GitHub outages in a month. Hope their SREs are doing alright.\n\nLGTM?\n\nLet's Gamble Try Merging!\n\nAll your source are belong to us\n\nWGGW\n\nI knew it was too soon to give out the Epic Fail award.\n\nCan someone explain how a globally distributed service with thousands of replicas can suffer such an Outage?\n\nGlobal outages are almost always networking if it‚Äôs fixed quickly or storage if it takes several hours / days. \n\nCompute nodes are scalable but networking often not.   Think things like dns,  or network acls,  or route mapping,  or a denial of service attack.  Or maybe just a bad network device  update. \n\nStorage is also problem while they are distributed the problems can often take awhile to discover,  and backups of terraybtes of data can take forever,  and then you need to parse transaction logs and come up with an update script to try to recover as much data as possible. \nAnd databases are usually only a distributed across a few regions,  and often updates aren‚Äôt forward and backward compatible.    For sample - a script that writes data in a new format has a bug and corrupts the data,  or maybe just has massive performance issues that takes several hours fix an index.\n\nIt‚Äôs not viable to hot swap databases like you can with stateless services.\n\nIf it‚Äôs fixed within minutes it‚Äôs a bad code update fixed with a hotswappable stateless rollback.  \n\nIf it‚Äôs fixed within hours it‚Äôs networking.  \n\nIf it‚Äôs fixed within a day or longer it‚Äôs storage.\n\nour website went down once. we got notified by clients, started looking around, testing all the servers, services, can't log into database.\n\nphone rings\n\n\"Hey, it's your server hosting company, we uhh, dropped your NaS server and it's broken\"\n\nme ...\n\nthat's also when we found out they weren't doing the regular backups we were paying for. Boy howdy did we not pay for hosting for a good while.\n\nGlobally distributed with thousands of replicas? Last I knew the main monolith still had a large dependency on a single database shard.\n\nWell first, you're assuming GitHub's structure has thousands of replicas, which I don't know that it does. \n\nBut anyway, this particular issue seems to have been caused by a faulty database update. There's a few ways this can go wrong -- the easiest way is making a DB update which isn't backwards compatible. If it goes out before the code that uses it goes out, That'll make everything fail.\n\nAlso, just because there are replicas, doesn't mean you're safe. The simplest way to do distribution of SQL databases, for example, is have a single server that takes all the writes, then distributes that data to read replicas. So there's lots of things that can go wrong there.\n\nAnd before you ask -- why do it that way when it's known to possibly cause issues? It's because multi-write database clusters are complicated and come with their own issues when you try to be ACID -- basically it's hard to know \"who's right\" if there's multiple writes to the same record on different servers. There are ways to solve this, but they introduce their own issues that can fail.\n\nUsually dns or bgp misconfigurations.\n\nWhat is bgp?\n\nWhat type of dns misconfiguration?\n\nDNS tells you what IP to go to.\n\nBGP tells you the most efficient route to get to that IP.\n\nIf it was a DNS misconfiguration, it was just that the DNS was pointing to the wrong IP address. \n\nIf it was BGP misconfiguration, it was telling people the wrong path to get to that IP, most likely some circular loop which never resolves to the final IP.\n\n&gt;What is bgp?\n\n[border gateway protocol](https://en.m.wikipedia.org/wiki/Border_Gateway_Protocol)\n\nfor an example of an outage caused by bgp issues, take the [2021 facebook outage](https://en.m.wikipedia.org/wiki/2021_Facebook_outage), where all of facebook's servers made themselves unreachable\n\nIt is up again, all green.\n\nFor a second\n\nMod, am I in /r/programmershumor ?\n\nLOL\n\nhttps://imgur.com/wm9WEbM\n\nOh the fucking irony. We've argued for over 2 years to use the SaaS version of GH because our own internal team were useless at managing the GH instance we have, so many outages. And then this happens. \n\nI'm going back to bed.\n\nThat fight is still worth fighting üò≠\n\n5 9s?\n\nDoes anyone know why it crashed ?\n\nThis situation is a good reminder of why having backups and a reliable Disaster Recovery plan is important. Thus, instead of sitting around and waiting for things to come back to normal, with backup &amp; DR, it's possible to keep coding with minimal disruption, for example, by restoring the code to another Git hosting platform, like GitLab or Bitbucket.\n\nLooks like it‚Äôs back up. I really wish they‚Äôd give IPv6 this much urgency. It‚Äôs literally down 100% of the time if you use a newer IPv6-only VPS.\n\nWhy not treat that like the service outage it is? So maddening.\n\nlol there's a difference between supporting a new feature and unfucking your existing features.\n\nHaving to endure Bitbucket at work and I'd love to use Github even with their outages üòÖ\n\nWhat makes it bad? We just moved to GitHub and I miss the PR UX of bitbucket. It was very simple.\n\nWe are being forced over to GitHub from internally hosted Bitbucket too. I really like how minimal bitbucket is in comparison when reviewing PRs.\n\nI‚Äôm with you there, the PR UX is awful\n\nFriendly reminder: Git is FOSS and you can host your own Git server! Our in-house Git server never touches Microsoft and not surprisingly is working just fine üòçüíØ\n\nIf it was only git:)\n\nTicket management, workflow automation, artifact storage, container registry, code analysis, wiki, access policy, ide-on-demand, website hosting - and I'm sure that I only scratch the surface.\n\nFor my knowledge, there is only gitlab that gets close.  And to replicate everything with open source and on prem, you'd need to set up an instance of - gerrit/gitea, taiga/redmine, Jenkins/(other ci that i haven't worked with), artifactory/nexus, xwiki, sonaqube/(is there any sensible all in one software as an alternative?), vault/openbao. Maybe backstage to have some semblance of integration to boot.\n\nNot to mention supporting infrastructure, highly available if possible: postgres, opensearch, prometheus, grafana, opendashboard, alert manager, jaeger, lucene, kafka, rabbitmq, garnet/redis, keycloak... :)\n\nIn short - if you begin to use their integrated offering, there is simply nothing comparable out there.\n\nGosh, you mean your entire business model being locked-in to one third-party service is a bad idea?\n\nExxxxxxxactly\n\nAnd we are piloting codespaces for a bunch of our devs lol\n\nIf not this it was the couple azure devops outages over the last month. Bad times at MS\n\nOuch\n\nWhat a day to use gitlab\n\nBetween the massive amount of sight mirrors and web archive I assume GitHub will not actually be gone even if it was attacked\n\nAnother day I get reminded I made a great decision moiving into self-hosted gitea\n\n bitbucket has entered the chat\n\nI went for a walk. Jk I had a worse day than I was having . And the day is not ending yet.\n\nHalf an hour downtime too. Shame it wasn't as serious as facebook's misconfiguration.\n\nAnother day another global business catastrophe\n\nIt's been acting up for a couple of weeks now, with not even ping reaching it for periods up to 30 minutes, mostly European morning time.\n\nSeems fine now.\n\nWhile(1) Git push github;\n\nBooks and on premise hosting will be back pretty soon.\n\nThis is why I just run a local GitLab instance."
  },
  {
    "title": "Devs gaining little (if anything) from AI coding assistants",
    "body": "",
    "score": 1400,
    "url": "",
    "created_utc": 1727624038.0,
    "author": "Zardotab",
    "permalink": "/r/programming/comments/1fs72u2/devs_gaining_little_if_anything_from_ai_coding/",
    "all_comment_text": "I keep trying but the amount of times LLMs just straight up hallucinate functions and syntax that doesn‚Äôt exist frustrates me. It‚Äôs great for natural langue queries of documentation but if you try to ask for anything that doesn‚Äôt have a write up in the content the model was trained on your in for a bad time.\n\nYup, the hallucinations are real. Me: \"Read this API doc and tell me how to do X\", AI: \"okay here is &lt;&lt;made up endpoint and functionality&gt;&gt;\"\n\nAnecdotally, Ive found that recognition of this cost is what separates starry eyed junior devs gagging over shiny AIs from veteran devs.\n\n\nI let a junior dev use copilot in an interview once and it hallucinated the poor guy into a corner he couldnt escape from. At the same time he thought I was letting him cheat.\n\nThat's quite interesting. So you are practically saying the level of expertise needs to be quite high to even be able to use llm in programming reliably. \n\nI haven't thought about the requirements and their effect on the efficiency of working with llms before. Thank you for that.\n\nI'll offer you a few more datapoints.\n\nFrom my experience, LLM's are most advantageous for mids, and semi-helpful for seniors. For seniors, coding is usually an afterthought of design; so it takes little time in the grand scheme of things.\n\nIt all boils down to understanding what you are seeing on the screen. The more time you need to sift through the output - even assuming that it is correct - the less usable it gets. And herein lies the problem - mids and seniors will have that skill. Juniors, at the other hand...\n\n...Will simply stop thinking. I was leading a react workshop a couple months ago. Developers there, with 2-3 yoe asked me to help them debug why their router did not work. Of course I saw the chatgpt on the side. The code in question? It had literal \"`&lt;replace with url&gt;`\" placeholder. Dev typed in, copied, and never attempted to reason about/understand the code.\n\nSame thing with one of my mentees; I've asked him what his code is doing - he couldn't say. Anecdotally, it is far worse than stack overflow of yore, because people at least try to describe \"what\" is happening as they understand it. LLM's can only provide you with the \"most likely\".\n\nThe sad part is, of course, is that the juniors will hop on the LLM's the most. That, plus the tragedy of remote working means that juniors take twice or more time to achieve mid level as compared to pre-LLM (and pre-remote); and tend to be far less capable of being self sufficient.\n\n---\n\nIn other words, LLM's gave the old dogs job security.\n\nI've been programming since the 90s. I use LLMS for\n\na) Showing me how to do something simple in a particular language, since I've often forgotten or don't know the various strengths a language has inside and out which lets you do something in a better way.\n\nb) Write simple functions for some description I give, often tweaking after.\n\nc) Ask about how a problem is generally handled in the industry, get a semi-useful answer often but not always which gets me going in the right direction.\n\nd) Ask about machine learning, python, and pytorch, they're much better at that.\n\ne) Generating suggestions for class/object/variable names when I am tired and have a hard time thinking of something.\n\nTHIS ! ! !  \nThought was the only one lazy enough to do this ! ! ! XD\n\nPersonally, the thing that to date saved me the most time was the capability to scan a page and output the OpenAPI spec. Even with it being semi-correct, it saved me hours of manual transcription. Another one which I was impressed the most was a quick-and-dirty `express.js` server; I needed to expose a filesystem; it allowed me to go through HTML output to JSON parsing with a single sentence.\n\nAside from that; my case is quite similar to yours. I know how something should look in \"my\" language, but I need it in e.g. golang. Simple (common) functions that I could write but I don't bother; general advice that will at least kickstart my thought process.\n\nBut no machine learning. This one is arcane for me :)\n\nI mostly use it to generate boilerplate for unit tests, I agree you often have to do some refactoring afterwards though.\n\nEven in these cases I have to double check against docs because it often tells me the exact opposite. Probably something picked up from someone super opinionated on a forum or incorrect stack overflow answers.\n\nI've been programming for... jeepers, coming up on 30 years now pretty quickly. When I got started, we didn't have source control, infrastructure as code, deployment practices, unit testing, a staging environment, redundancy, metrics, tracing, any real concern for logging, security concerns, etc. We have these things today for a reason, but still, the list of things you need to learn just to barely function in a modern professional environment already had me sort of worried my generation is pulling the ladder up behind them. No matter how much we need those things for, we still need an onboarding ramp for new people, and it is getting harder and harder to provide that.\n\n(At least I can say with a straight face that it's not any sort of _plan_ to pull the ladder up behind us. It's just the list of things to be even a basic side project in a modern corporation has gotten so absurdly long, each individually for a good reason but the sum being quite the pile.) \n\nAnd I fear that LLM-based completion would, perhaps ironically, seal the deal. It sure _seems_ like a leveling technology on the face of it, but it will tilt the scales even more in favor of those who already know and understand if it makes it easier to not understand.\n\nI don't even know what to tell a junior at this point. Someone really needs to figure out how to incorporate LLM-based completion tech with some way of also teaching the human what is happening in the code, or the people using the tech today are going to wake up in five years and discover that while they can do easy things easily, they still are no closer to understanding how to do hard things than they were five years ago in 2024.\n\nThis is true of pretty much any advanced topic. \n\nIn geophysics (my scientific field), we use a lot of advanced computing that takes raw data and turns them into geological models. For geophysical technicians, this is basically magic -- they run around with a sensor, and a client gets a geological model. Magic, right? But somewhere in between this there needs to be an expert, because models are just models and can be illogical or outright wrong. And when the software spits out an incorrect model, it takes someone with an advanced knowledge of the actual processes (either through education or experience) to be able to pick up on the fact that the model is bullshit. \n\nSo this pattern has existed before LLMs, and probably is repeated over and over across scientific fields. Don't get me started on medical imaging... ;)\n\n&gt; So you are practically saying the level of expertise needs to be quite high to even be able to use llm in programming reliably. \n\nAbsolutely. There's no replacement for an expert programmer at the end of the day. It's equivalent to looking up something on StackOverflow. A junior or intern may copy/paste something wholesale and not understand what foot guns exist or why the copy-pasted code doesn't do exactly what they were expecting.\n\nAn expert may look at a StackOverflow post and be able to translate and adapt the concept of what's being shown to best suit their current situation.\n\nIn my opinion, these AI assistants are no different. If you don't know what the AI-generated code that just got spat into your editor does, you'll have a hell of a time figuring out how to fix it if it doesn't work or how to tweak it to fit your problem space.\n\nI once overheard colleagues discussing a very simple programming problem that they wanted to solve via ChatGPT but didn't figure a successful prompt. After a couple of minutes of distraction I told them to just 'x/10 + 1' or sth, when they were just about to write a loop by hand.\n\nI asked it to mock up some basic endpoints simulating S3, and it wrote everything as JSON. I asked why not XML and it said JSON is easier, \"but won't be compatible with S3\". Thanks...\n\nThis is my experience as well. People need to understand these models are basically next level autocomplete; there is no logic or understanding involved -  just interpolation.\n\nThat being said, JetBrains LLM assisted autocomplete in PyCharm is pretty often right and speeds me up. But that is very different from asking broad questions\n\nYep. Better Google. And for that, mazel tov, but it's not gonna suddenly manage obscure requirements on a 1m LOC system integrated across 20 platforms\n\nIf it's too hard for you as a human to read and understand the API documentation, what made you think it would be easier for Copilot?\n\nSeems like it could be useful in imagining an API *as it could be*.\n\nMy favorite is the batshit hallucinations where the LLM ignores all context and just shits out *something anything just return some text that appears believable*\n\nLike Ms copilot. It knows the azure SDK documentation and was certainly trained on it. It knows I have the SDK loaded up in my editor with _every fucking endpoint_ in memory, and the same call needed elsewhere in the package a few times.... But nooooooo copilot wants to be clever and creative and suggests a method that doesn't exist with arguments that it doesn't need based on what exactly? It's made up!!!\n\nIt doesn't \"know\" the azure API. The API may be in its training set but there's a gulf between having data and knowing information.\n\nThis seemingly hair splitting detail is *why* LLMs have the problems they do. They're just extrapolating from data set to output with no rational process gatekeeping or checking that output. Of course you get hallucinations.\n\nI‚Äôve found that if you are trying to understand a process, and you ask the LLM a question trying to confirm an assumption you might have about something, it will go out of its way to conform to your ask.  It will not tell you up front that what you are asking for is impossible.  Do not ask leading questions and expect it not to hallucinate.\n\nSounds like that can get you some reps practicing the art of presenting questions to an interviewer/interviewee. The other party is actively trying to meet your expectations, so you have to ask questions in a way that hides your preferences.\n\nThis. The hallucinations make me scared over how ‚Äújunior‚Äù engineers seem to find it so ‚Äúuseful‚Äù\n\nOr when some methods are deprecated and then you get into endless loop of other deprecated methods or straight up non existing ones.¬†\n\nMy initial experience was ChatGPT could not care that Python 2 and 3 are different.\n\nYeeeeeep I still have not had one generate a usable block of code for anything I was actually having trouble with. Stuff I already know how to do? Sure, but I still have to double check its work so I'd rather just write it myself. The only thing these LLMs have legitimately helped me with is writing test cases that follow an easy pattern.\n\nIts the absolute worst when im using an api im unfamiliar with.\n\nWhen I have to write a short one-time script to accomplish something, LLMs will get me 90% of the way there pretty quick and save me time.  But LLMs are completely ineffective on helping with my core coding responsibilities.\n\nWe spent two days troubleshooting code because colleague used ChatGPT to convert C++ routine to C# and it dreamed up some extra steps.\n\nIt was his time wasted, mostly. But I have to say I was pretty pissed off. The whole ecosystem is C++ but he constantly insists on having \"helper\" tools in C#. But that's a different story.\n\nIt's great for low-level (skill-wise, not talking about assembly) coding that a first year undergrad can easily accomplish. I use it for coding in languages I'm not familiar with (like Javascript) and manually code in languages that I know myself (like C# and Python) when it needs to be more intricate.\n\nIt used to be that Google and SO answered all my questions and gave me all the assistance I needed. Nowadays both got shittified and replaced by ChatGPT, but it performs exactly the same tasks in the development workflow as those two were.\n\nMy workflow:\n\n\"Hey GPT, what terrible name did the standard come up with to do X?\"\n\n\"You are looking for Y. Here is how to use it.\"\n\n\"Okay cppreference, how do I actually use Y?\"\n\nAt least ChatGPT never criticizes me for asking a question like StackOverflow\n\nThat's what \"Standard\" subscription is going to be\n\nI never post for this reason. A lot of software devs are assholes!\n\nAnd if you miss the condescending replies, you can always ask chatgpt to make it a bit more realistic and up the criticism.\n\nsomeone post one of the many screenshots of stackoverflow gigachads \"simplifying\" code by making those ridiculously complex &amp; unreadable for loops\n\nThe comparison to SO is good IMHO. And just like SO it's generally not going to provide code you can use directly and it can't be relied on for anything regarding security or edge cases. But for \"Hey, I need to do that in this language, what's a basic way to do it?\" it's ok.\n\nThe main difference in use is probably that when a SO user completely hallucinates, it gets called out. With ChatGPT we get no peer review at all so it requires even more attention to correctness.\n\nI've been noticing that both ChatGPT and Copilot were going down in quality too.\n\nI‚Äôm using Copilot as a completion source in Neovim and I love it. I‚Äôm in control but I‚Äôm also typing half as much as I used to.\n\nIt is quite good at autocompleting, but you have to read what it suggests. I would say 80% it is fully right, hit tab, I'm done. 10% I have to edit what it suggests, and 10% it is totally wrong. Still a time saver, but it won't help people who don't know how to code.\n\nI hate hearing people that think AI is like some programming wizard. Okay so your chatgpt code works. For now. Yet when there is a bug. Or some weird one-off change. Good luck being a \"prompt engineer.\"\n\nIt's investors who have drunk that particular kool aid.\n\n\nFor example, the economist's spectacularly stupid take on it: https://www.economist.com/business/2024/09/29/ai-and-globalisation-are-shaking-up-software-developers-world\n\n\nThey're [angry about providing us with well paid upper middle class jobs and free food and want it to stop](https://www.tcifund.com/files/corporateengageement/alphabet/20th%20January%202023.pdf). They want to fire half of us and let the other half cower in terror of being laid off or fired like a regular prole.\n\n&gt; like a regular prole\n\nWe *are* workers. Don't let the anomalous sellers market we've enjoyed for some time blind you to the fact that our interests line up much better with other workers (\"unskilled\" as they may be) than with VCs and board members.\n\nYep. Don't believe the bullshit. Unless you're literally at the top making millions and would get a golden parachute instead of prison time, you are a prole.\n\n[removed]\n\n&gt; And unfortunately for the big tech firms you can't really turn coding in to a Fordist assembly line. \n\nOutsourcing seems an apt example of that, one where lots of people got burned on cultural differences and results that look like the product of an [italian strike](https://en.wikipedia.org/wiki/Work-to-rule) to the point where the product doesn't actually _work_, it just handles the exact examples they were given.\n\nI have not felt a comment so hard in my bones perhaps ever. I was thinking about the \"lights out factory\" this morning--one would need to know more than ever, particularly about debugging, for lower pay and more precarity.\n\nBeen using copilot for over a year. I have yet to fix a bug with it. All it‚Äôs good for really is autocomplete on steroids\n\nI'm sorry, you're of course correct. The X should not come before Y, as that would be impossible. Here's a fixed version:\n\n\n&lt;Code where X comes before Y anyway&gt;\n\nIt is creepy how accurately a Chatbot can mimic the experience working with a super-cheap offshore dev, including the part where they politely tell you you're right and proceed to ignore you and do the wrong thing they were already doing.\n\nIt's basically like having a really fast junior dev.  Sometimes it's good enough, but you generally can't trust anything it writes.\n\nNow let's try and explain this to non-technical hiring managers.\n\n&gt; Now let‚Äôs try and explain this to non-technical hiring managers.\n\nFor most developers, 60-90% of our time is spent fixing problems, *aka* debugging. What worked for me is showing this in our Jira‚Äôs by counting up the story points, then let the manager themselves pick a new user story and feed it to their LLM of choice, and see what pops out the other end.\n\nTo give the LLM a leg up, we even ensure with the second round of this test the story is polished up to the highest standards deemed possible by whoever the manager (or the manager of scrum masters) thinks is the best scrum master who can put together the ‚Äúideal‚Äù user story content of the randomly selected story.\n\nWe let the results speak for themselves. Personally I‚Äôm strongly pro-AI, but for my clients‚Äô and my work, this is so far like when compilers came out. Industry never stopped building and using assemblers, but the vast majority of us did move past assemblers.\n\nIt‚Äôs useful but so far it isn‚Äôt replacing all coders, just our bottom of the barrel, lowest common denominator, lowest value typically offshore coders who are more like human template fillers or the teams cranking out simple CRUD a step above stuff like PostgREST and its various GUI complements. For the more complex software we have to tackle in tiny shards, it is still a heavily technical undertaking.\n\nI keep looking for the ‚Äúnon-coders can create code‚Äù experience because $deity knows I desperately could use it so I can go solve on a more full time basis more strategic and business-relevant meta-problems the code brings in, but so far I‚Äôve yet to see even a glimmer of this in the enterprise world.\n\nIf you‚Äôre eliminating the friction getting this into non-technical hands bridging over to the technical world, please share with us details of how you‚Äôre pulling it off, as I‚Äôm getting lots of friction.\n\n&gt; If you‚Äôre eliminating the friction getting this into non-technical hands bridging over to the technical world, please share with us details of how you‚Äôre pulling it off, as I‚Äôm getting lots of friction.\n\nThis is the same BS dance that low-code/no-code did for the last twenty years. It works in about 5% of the cases, and in about 40% of the cases it makes things worse. Meanwhile marketing shills and non-technical ppl drink the Kool-Aid and pretend it works in 100% of the cases and if it ever goes wrong it's the customers fault.\n\n+1 for $diety. Thats hilarious\n\nI've found ChatGPT excellent for the very specific case of working with widespread, well-understood technologies that I'm not already familiar with. It can answer my specific questions in ways that wading through shitty blogspam doesn't, and the information is well-known enough that I can easily verify it or find additional resources.\n\nMy opinion is that it's like having a first or second year college student doing some research for you. You don't waste your own time, but you can't trust the results completely.\nI use AI for describing my problem and having more discussion with it to narrow down on implementation.\n\nEdit. What I meant is a really good student. Someone who knew how to program before getting to college.\n\nHonestly, the code produced is generally of much higher quality than a 1/2nd year college student would write, because they don't know jack shit about best practices and style. ChatGPT and similar writes very nice code. It's just, occasionally, completely wrong and untested.\n\nSooo it's fucked up and inoperable but looks cool? No wonder middle managers and out of touch nontechnical executives are enamored with it, it's just like them!\n\nNevermind that, try adding functionality that requires changes across different layers in a dozen different files. Ie a pretty normal feature change.\n\n[deleted]\n\nVery true. Like most tools, if you don't know how to use them they don't help\n\n&gt; if you don't know how to use them\n\nAgreed, but I think this is a different idea to what I/SpaceButler said (\"it won't help people who don't know how to code.\").\n\nThe latter is like saying \"You can do it without the tool all by yourself, just slower\"...\n\nYours is perhaps more general... Like, applies to a power drill, even a hammer. Or, well, like any tool. Coz all tools require *some* new knowledge. The difference is, you literally can't drill a hole or hammer in that nail with your bare hands.\n\nYou know they had tools to drill before drills were electric? They would put the effort in themselves using manual tools to make the hole.\n\nNow with electric drills people can drill through their thigh or blast a water pipe in the wall much easier. This is a pretty good analogy for having no expertise but powerful (and often dangerous) tools\n\n&gt; they had tools to drill before drills were electric\n\nThat's why I didn't say \"with old non-electric tools\", I said \"bare hands\".\n\n... Hold my beer\n\nWhat if you're very comfortable with both coding and typing? I've been hesitant to try it because of having to read all its output carefully.\n\nI have found copilot/codium for autocomplete in my IDE really useful for when I am working in a language I am slightly less familiar with syntactically. You still need to know and understand what you are trying to do and why, but it removes some of the annoying cycles of searching for things like ‚ÄúHow do I do this specific thing in X?‚Äù\n\nFor me, the problem is that it short circuits my normal thought process. You have a mental model, type two letters, and then ‚ÄúBOOM, BUT HAVE YOU TRIED THIS APPROACH UNRELATED TO WHAT YOU‚ÄôRE SOLVING?!‚Äù, and then I have to reason about it and spend time getting back on task.\n\nI find it‚Äôs great if I don‚Äôt know how I want to solve something, pseudocode it in comments, and let AI take a whack, but I‚Äôm not sure the tool is for me.\n\nI mean, that obviously does happen, but I'd say about 90% of the time it writes exactly what I want it to. The other 10% is very easy to ignore, as you probably already know that whatever it's about to suggest is going to be wrong and/or not exactly what you had in mind.\n\nIn my experience it's 30% at best. A lot of times it suggest good start but then lots of unnecessary code. And on legacy code base that we maintain it's very annoying because we have query builder that's similar to laravel so it keeps suggesting laravel syntax which obviously doesn't work.¬†\n\n[deleted]\n\nSometimes I‚Äôll pause to wait for the autocomplete suggestion to pop up, instead of continuing to type, only because I know the line will autocomplete perfectly fine.  The pause takes less than a second.\n\nI don't get why it deserves its own name, it happened to me when I used IDEs for Java (with auto-complete) and editors without and I typed a dot after an object, before AI completion was even in anyone's mind; when you do something for every line of code of course it becomes an automatism, if you thought consciously every time whether you want to do it before you did you'd go crazy.\n\nI do that. After using copilot since beta, I know pretty much how much context I have to type out for it to suggest what I need. So I'll stop for some milliseconds and wait for the completion. \n\nNowadays, I'm using Supermaven, which is a lot faster. However, I do painfully feel the times that the servers are overloaded and the completion doesn't show up in expected time. Feels weird, as if my IDE is acting up.\n\nThe AI completion is definitely something I now expect as a minimum, like syntax highlighting, type checking and intellisense. I'm not going back to typing out each single character.\n\nNope. When used as a completion it‚Äôs essentially as fast as other LSP stuff\n\nWhat plugin do you use for your autocompletion? I‚Äôve been thinking of using a local model for neovim autocompletion but got put off by needing to have intentional prompts for everything.\n\nThree hours to manually write code 15 minutes to debug. Or have AI write the code in 15 seconds and spend the next week bugging.\n\n\"What kind of crazy human writes code like this?!?\"\n\nColleague: \"Human?\"\n\nPfffffff it saves me so much time in boilerplate. Getting a good workflow makes it much more efficient\n\nPeople saying it‚Äôs useless but I‚Äôm significantly more efficient\n\nI work in finance, most of the code I write is like business related functions and integrating with APIs, so nothing too fancy but I am unbelievably more efficient using chatgpt or Claude then I am without them. \n\nEven if you were doing super advanced cutting edge stuff I still struggle to see how people aren't at least gaining some efficiencies out of these tools. Being able to use the voice mode to explain what I want a particular method to do whilst I'm downstairs making a cup of coffee has been amazing for me. Not needing to use Excel to parse or clean data has also been great for me. I don't need to write a regex in Notepad++ to strip away a single quote and a square bracket from every other line of varying lengths in a file with 700 lines anymore. The list goes on. \n\nThese are micro-efficiencies for sure but they add up to a substantial efficiency boost for me personally.\n\nI feel like I'm taking crazy pills trying to use AI for anything. I have never had it work in any meaningful way while other people use it all the time.\n\nI'm doing basic testing to figure out what structured logging solution we want to use so I use chatgpt.  I can't get it to print a hello world with log4cpp (it had a stackoverflow answer that didn't work or a spam of include statements until it gave up).\n\nI am in Rust trying to write a usb passthrough for a camera, pure hallucinations from git copilot, can't get it to work as well as intellisense for what function parameters a function that exists needs.\n\nIt is completely worthless for my job which is 99% bug fixing our custom C++/Kotlin/Rust/React/JS code monstrosity.\n\nI can't even get AI to make a yugioh deck (made up cards) or figure out what state Milwaukee is in without it making shit up (no city of milwaukee, but there is a tool store nearby with that name according to gemini), no chance I'm using it for anything remotely complicated.\n\nI know people use it all the time (even people in my company in other code bases), but I have never had it work besides basic questions to gemini on my phone (which is hit or miss as shown by milwaukee question).  Hence I feel like I'm taking crazy pills because my personal experience is so WILDLY different.\n\nIf you're doing cutting edge stuff with all the best tools and in a good language then LLM's are a lot less added value.\n\nOr in other words. A lot of people are wasting a lot of time because they have a shit setup and tools they don't use or understand. e.g. \"They cut down on boiler plate\" is a red flag that you're doing it wrong. \n\nBut with LLMs they can paper 90% of the issues and I think thats a good thing. \n\nPersonally I don't have it turned on in the main code base. But I use it all the time to generate an initial draft when its a language or API i'm less familiar with.\n\nIn those cases one question effectively does the same work as 3 to 10 Google searches did.\n\nI‚Äôm in complete agreement. I‚Äôve been told I just wasn‚Äôt efficient enough prior to AI, but from my perspective, it‚Äôs crazy to think that everyone *hasnt* found any efficiencies‚Ä¶*anywhere??*\n\nFrom the responses I'm seeing it's not hard to believe that the efficiency gains are partially/entirely erased by the occasional time-consuming nonsense. I've seen colleagues waste hours going down the wrong AI-induced/hallucinated rabbit hole. The risk of this is much less imo when finding answers on SO.\n\nI'd personally prefer an AI assistant that lists relevant SO posts to a query I have to one that creates answers by itself. I don't write much boilerplate though.\n\nWhy were you writing so much boilerplate?\n\nIf you're writing this much boiler plate, you should use macros (if your language has it), source generators, or even better, write your code in a way that properly encapsulates the duplicated behaviors.\n\nThere is boilerplate, and then there's boilerplate. .\n\nMacros are frequently not a good choice because it demands the reader understand another layer of abstraction. Source generators are only good if you never want to edit the code, or never need to regenerate. \n\nAnyway I'm pretty sure GP is referring to the work of writing any code that is obvious enough for an LLM's first suggestion to be correct. My guess is this is a surprisingly high percentage of keystrokes.\n\nYeah I don‚Äôt get how people *don‚Äôt* get what they mean by boilerplate here. There‚Äôs a ton of code that you know exactly how to write, but changes a bit based on variable names etc. You can‚Äôt have thousands of macros for all this, especially as the functions (or whatever) might be slightly different each time. AI works great for that kind of stuff. Basically just a time saver‚Ä¶ like a more advanced macro. \n\nThis is like saying to someone who said they love using a chainsaw to cut down trees ‚Äúif you need to use a chainsaw so much you should use a hand saw‚Äù.\n\nSeriously. The other day I was writing a converter between two data formats. I wrote the conversion one way manually, then asked ChatGPT to generate the other half. 95% correct, saved at least a couple hours. It was \"boilerplate\" in the sense that there was one obviously correct way to write it, but not trivial boilerplate in the sense that there wasn't any easy way to produce it mechanistically.\n\nSo this.  The people who complain most about using AI for coding don't seem to understand what it's best at being used for.\n\nYeah, we managed to not have to rewrite the same code over and over for decades before LLMs existed.\n\nYeah there's shitloads of boilerplate that just isn't that easy to automate because it can be *slightly* different each time (API controllers and models and such).\n\nOhw sorry, I will just change my company's entire stack, stupid of me to not just think of that.\n\nInstead of using AI to generate a ton of boilerplate, maybe we can restructure the code to just not need that.\n\nAsk yourself what steps can we do to make our code less verbose?   Every line of code you have is going to be one that needs to be maintained.\n\nThere are plenty of code generation libraries like Lombok that behind the scenes will add the boilerplate in for you.  As a Java dev I haven't written a getter, setter or constructor in some time.\n\nAre their pieces of the code that can be remade to be reusable?\n\nFor unit tests you must share code sparingly\n\nUntil a small change in a type signature means you have to change 300 unit tests in obviously unimportant ways.\n\nAny good IDE will have refactoring tools that can handle most of the work. Or you can tell the AI to fix it and it will often do a good job.\n\n1. Abstractions can hurt you as much as they help you. People get obsessed with keeping things dry, myself included, but having worked on many large projects now, boilerplate can often be just as good, depending on what it is. Creating abstractions for lots of things implicitly ties things together, and can make upgrading things difficult and risky when an abstraction handles too much, which often happens over time. Sometimes, repeating yourself is great for maintainability and probability. A while ago I heard someone describe it as: Don't repeat concepts, instead of DRY, and that made a lot more sense to me. \n2. Even with abstractions the AI can do a lot of the setup and basic BS I don't want to do. \n\nExamples: \n\nCreate a class that implements this interface, and does these things.  It will usually spit out a class that's 90% of the way there, and I just gotta tweak it or whatever\n\nGiven this file, write unit tests, use this other spec file for test examples. Again usually 90% of the way there, but the cases and setup are usually pretty solid.\n\nRight? Like, if there's something you need that you know has been done millions of times before but you specifically haven't done it, finding good examples is much quicker and easier with AI.\n\nThis. AI doesn't solve complex problems (yet) but for generating boilerplate and dealing with repetitive tasks it's amazing. Wouldn't want to miss it anymore.\n\nThis. Especially with Cursor, I just spam tab for boilerplate.\n\nI introduced subtle bugs in my code that way though - more than once. It's quite good at generating boilerplate that looks reasonable but actually does something slightly different/wrong\n\nUse it to learn, not do your job. It‚Äôs like an interactive stack overflow or Google. Come on, people, I thought you were problem solvers.¬†\n\nIt's a good rubber duck.\n\nDing ding ding. It‚Äôs not a coder. It‚Äôs something to bounce ideas off of and it‚Äôs actually really really good at it.¬†\n\nI use it all the time. ‚ÄúI‚Äôm struggling with efficiency on this block, would it help if I did ____‚Äù\n\nI dunno, it's just not the same as seeing those cold, dead eyes stare back at me and judge me for being an idiot.\n\nI find it a lot more useful to be a good googler than a good prompter. At least with a google result I have more context for evaluating if the info is correct and not outdated.\n\nI wish Google was still good; it's getting harder and harder to find good results on Google.\n\nSponsored\n\nSponsored\n\n Sponsored\n\nSponsored\n\nSEO spam\n\nSEO spam\n\nAdvertising \n\nSponsored\n\nSponsored\n\nHere's what you want &lt;---\n\nSponsored SEO spam ads\n\nOr my favorite, the first page of results causally disregards my search terms, requiring me to go back and put each one in quotes. It doesn't always help.\n\nI had to swap to duckduck go to consistently get the documentation I was looking for, and then just swapped to embedding relevant documentation into my Obsidian notes and macros. \n\nAt this point I'm looking into how much it would actually cost to index the internet for my own personal search engine.\n\nYeah this sucks.\n\nTry phind.com ‚Äî it answers questions by searching the internet, and lists all the sources it uses. Most of the time I find it better than Google\n\nYeah, preferably I'd just have good library docs and a language server. Searching is more for when I don't know which library to use, and in those cases it's ‚Ä¶ practical to be able to tell at a glance that a suggestion is a major language version behind what I'm using.\n\nYou can ask chat for sources and it will link you to the relevant documentation or stackoverflow page so that you can double check. But yea, being able to do both is pretty important\n\nYes google takes me to the docs or issues. Llm returns me something that was inoperable. How is coming up with some bullshit helpful in any context ever? Literally copilot gave me some dead wrong code to interact with cosmos db in go, took one look at it and said nope then googled straight to the docs for reference.\n\nYes the bulk boilerplate help is nice, but this fucking llm couldn't create a solution if I told it exactly how to do so.\n\nIt‚Äôs also a really good auto complete and boilerplate generator.\n\nYeah. The most useful thing so far has just been saying ‚Äúmake tests for this method using this other test file for reference‚Äù and it does a fine enough job with that if it‚Äôs relatively straight forward.\n\nNo because it will point you in a direction based on the bias of your question. It will not give you a nuanced approach in the same way as actual research would do. It is horrifying that aspiring engineers use this to learn.\n\nAs a young engineer, I got wrong or outdated information from my more experienced colleagues all the time and it didn‚Äôt destroy my career.\n\nJust don‚Äôt treat AI as an authoritative source or accept what it suggests uncritically, think of it as asking the guy in the next cube.\n\nDO NOT do this. You'll often either end up with a bad way of doing something, missing context, or both. AI should really only be used by professionals who know exactly what to ask for and can easily identify errors in the approach.\n\n[deleted]\n\nThis line made me chuckle.\n\n&gt;Rehl‚Äôs team recently completed a customer project in 24 hours by using coding assistants, when the same project would have taken them about 30 days in the past, he says.\n\nI think this says more about the team than it does about the AI tools. And it's not flattering.\n\nAm I in the minority when I'm not even trying to insert AI in my workflow? It's starting to feel like it.\n\nI don't see any use for AI in software development. I know many are desperately trying to find out how it could be useful, but to me it's not.\n\nFfs, I've been seeing an ad for an AI-first pull request review system. Why would I possibly want something like that? Are we now trusting LLMs more than actual software developers?\n\nI've seen ads for \"AI news that you control.\" It makes me so confused as to why would anyone ever want this.\n\nYou can't imagine why someone would want a super-charged echo chamber for their \"news\"?\n\nWhy would you pay for this product when you can just write a fiction novel yourself for free?\n\nBecause that's work and you don't get to pretend that you're reading \"real news\". I'm not defending anything, just flippantly noting that there's a significant amount of people out there who love garbage news sources that tell them exactly what they want to hear.\n\nI've been developing for 14 years and just switched to a brand new project requiring me to learn brand new languages. AI has been the \\*perfect\\* onboarding tool to give me specific answers to questions with the exact context of the application I'm working on without having to bother my peers or having to find answers on stack exchange that have vague relevance to what I'm working on. Getting through the syntax and nuances of a new language has been an absolute breeze. AI has accelerated my usefulness by probably months as an educational tool.\n\nI keep trying to ask LLMs about programming questions and beyond simple stuff you can find in a textbook, they've all been completely worthless. I have not had any time saved using them.  \n  \nI now just use copilot for a super-charged autocomplete.  It seems to be OK at that.\n\nI just used copilot to get my wsl at up behind my corporate firewall. After spending way too many hours with the docs and trying things copilot and I got it almost done in 20 minutes or so.\n\nConfig and other ‚Äústatic‚Äù files are examples of stuff LLMs excel at. Things like terraform or GitHub actions, etc. Other than that I basically just use it as slightly stupid stack overflow.\n\n&gt; I keep trying to ask LLMs about programming questions and beyond simple stuff you can find in a textbook, they've all been completely worthless. I have not had any time saved using them.\n\nI feel like it differs *a lot* depending on what exactly you're doing. I've been taking an algorithms course and have given most questions to GPT4o and it genuinely gets every single one right, though those are not exactly programming\n\nLLMs really excel at CS courses (broadly speaking ‚Äî there are exceptions of course) because their training data is full of examples of problems (and solutions) from such courses.\n\nbecause algorithms are textbook concepts and implementations, it's exactly the thing they're good at\n\nThat's literally textbook stuff\n\n&gt; Am I in the minority when I'm not even trying to insert AI in my workflow?\n\nJetbrains inserted AI in my workflow without me asking anything. It was really bad. It would suggest something stupid on every single line. It was extremely distracting, how are we supposed to get into the flow when we have to evaluate that nonsense on every line.\n\nI turned it off.\n\nI don‚Äôt understand all the devs saying that it‚Äôs useful.\n\nThat's not my experience with it at all, I find it quite useful.\n\nMy personal experience of it being utter shit meshes with the data from every study done on it.\n\nDevs claiming that it is useful is baffling to me.\n\nprobably using it for scaffolding? which it should be good at, except at a way way higher cost.\n\nintellisense is also probably better or similar at less cost, or if you're doing schoolwork it'll probably nail it because it's textbook stuff\n\nI used Copilot since the early access until about 4 months ago when I stopped. Haven't really noticed anything different expect I no longer have that cooking l pause. IntelliSense is still a much superior CoPilot.\n\nI actively hate randomness or unpredictable behavior as it slows me down since now I have to look, analyze with every keystroke. If I know what I'm coding, then using AI autocomplete is slower. If I don't know what I'm doing then I'm usually in Google or something trying to figure out how to approach the problem.\n\nIntellisense works because its predictable. If I have an array and type . f i tab I know its going to fill in filter(.\n\nThe sole benefit of AI is that I can ask clarifying questions. The problem is that LLM AI doesn't actually **know** anything so it'll just fucking lie to me.\n\nI could not possibly agree more about hating randomness in my workflow. It‚Äôs like having someone interrupt you to guess the end of your sentence. I know what I want to say, shut up and let me say it!\n\nI'm as pessimistic about AI as they come, but I've found Copilot to be a far superior code prediction tool as long as you don't ask it to infer too much.\n\nIt's hit or miss whether it can complete entire function bodies, but pausing to let it finish the remaining 80% of each line I write generally works. \n\nIt probably only saves me a few minutes a day over using native IDE code helpers, which is why I'm pessimistic about an **AI revolution**. But I can't dismiss its usefulness entirely.\n\n&gt;It probably only saves me a few minutes a day over using native IDE code helpers, which is why I'm pessimistic about an AI revolution. But I can't dismiss its usefulness entirely.  \n    \nThat's the whole thing for me. My company is paying $10/month for copilot. If copilot saves me more than ten minutes over the course of a month, it has paid for itself.   \n    \nNothing short of a complete AGI with a robot body could completely replace the developers where I work, but we are all absolutely getting use from various AI tools in small ways.\n\nI‚Äôve got 30 years of experience in software development but it‚Äôs been 15 years since I last checked in production code. I drifted into management and sales for about ten years. The last five years have been back in more technical role of advising how to tackle some of our larger technical efforts. \n\nI‚Äôve spent a lot of time the last two years on some hobby software development efforts. A couple of .NET projects at work and Python projects at home. I‚Äôm 53yo and I‚Äôm definitely rusty and no longer as technically adept as I used to be. I also think I‚Äôm starting to struggle with some cognitive issues either from my arteriosclerosis (clogged arteries with three stents at 45yo) and/or from long covid. \n\nWith that said, I‚Äôve gotten a lot of use out of ChatGPT over the past year and half. There are times when I describe a particular use case or challenge in my code and it gives me a response where I‚Äôm like, ‚ÄúOh, it would have taken me a long time to come up with that solution.‚Äù Granted, I‚Äôve also gotten solutions where I‚Äôm like ‚ÄúTry again because I‚Äôm pretty sure there‚Äôs a library to do it easier.‚Äù\n\nA quote I saw several months ago was to treat AI responses like dealing with an intern: They are eager to help but sometimes misguided.\n\n‚ÄúAutocomplete for everything‚Äù, ‚ÄúGuy who kinda  sorta remembers reading the documention‚Äù, and ‚ÄúStackoverflow without assholes‚Äù are my three use cases. \n\nAI is dogshit at a lot of things but those three categories can save you hours a week.\n\nSame as those who use Vim with dozens of plugins for their workflow over an IDE: as long as you are productive and happy with your work, what you use doesn‚Äôt matter.\n\nIf the tool you use (or don‚Äôt use) impact the quality of the code, delivery of the team, or your own capability to solve issue, then it‚Äôs time to reconsider. But AI doesn‚Äôt fall in this definition as of today, so feel free to skip it or try it when you feel like it.\n\nIt's amazing for clearing out boilerplate stuff. A friend's job has the LLM's writing unit tests, and most of the time the unit tests need very little modification. \n\nAnd that's not talking about using llm's to do things. Not as in \"help you code\" but actually leveraging them. Can't talk about certain projects due to confidentiality, but there's some crazy stuff you can get these llm's to do.\n\nIf we were really smart we'd use LLMs to write a unit test framework that didn't need so much damn boiler plate\n\nBut then you run into the problem where you don't know if the test that's failing or the framework magic\n\nI was surprised how effective AI is in writing boring business apps. I worked on front end for accounting app and ChatGPT increased my performance by probably 20%. \n\nThey used Tanstack for state management. While I generally understand how it works, I don‚Äôt know Tanstack API at all. Knowing what I need, I was able to ask ChatGPT to figure out how to solve a particular goal. I also didn‚Äôt know how to incorporate a POST endpoint that does data streaming. ChatGPT did it for me correctly in ten seconds. \n\nIn all these cases I **knew what I needed** and **understood the system**, also ChatGPT **saw similar solutions** somewhere on the internet. In such cases, it‚Äôs very effective and I think it‚Äôs plain stupid not to use it: even free version can save hours of work and documentation reading. \n\nOn other hand, even ChatGPT o1 is hopeless if no other human solved a particular problem yet. For example, I saw unexplainable errors in console when developing a mobile app using Swift. ChatGPT‚Äôs suggestions were plain useless. Also, it‚Äôs useless at finding circular dependencies causing memory leaks in Swift.\n\nWhile some may be looking to take it to be next level. I think the use that everyone has found for it and agreed upon already is boilerplate. It‚Äôs shown to be orders of magnitude faster for you to get up and running or to do much of our day to day as software.\n\nI can‚Äôt speak to the specific example you gave, but it sounds like an absolute dream for me to be able to give an AI a junior level task and have it weave it into my PR system. I‚Äôm reviewing junior level human PRs anyway, and if I have a junior level task that needs to be done then I‚Äôll ask the AI to do it - if it can‚Äôt, I see it somewhat a failure on my part for breaking down the ticket into manageable chunks (specifically because this is one of the more common _human_ excuses I hear for why sprint velocity lags).\n\nThe thing is, if your process involves a lot of boiler plate, that indicates a problem with your process.\n\nIn the rare case that my job actually requires boiler plate, usually I can just copy it from somewhere else.\n\n[removed]\n\n[deleted]\n\nIt's like using StackOverflow *properly*.  You look at the answer it gives you and make sure you understand what it is doing.\n\nAI comes up with some interesting solutions, like a junior coder, but also like a junior coder, you should review what it's doing carefully.\n\nIt seems most of the search engines lately have gotten *significantly* worse than they ever have been before, google being the worst of all. Maybe this is due to them integrating AI into their searching algos, maybe it's something entirely unrelated, but it's definitely worse.\n\nAnd I think that's pushing a lot of people towards using AI's to find the information they'd previously go to a search engine for.\n\nThe place I work at bought into Github CoPilot, but that's the extent of it. It has been the most helpful at helping to write unit tests, but only in projects were good patterns for unit testing has already been established, and CoPilot could guess at what the test would be looking for based on context clues. Or I was doing something trivial like running a loop to get some known key or whatever.\n\nDefinitely seems like we are in a rapidly shrinking minority. I really don‚Äôt get it. Between vim and standard deterministic autocomplete, I already produce code at about the same speed that I can think it. I spend much more time trying to fully understand what the code needs to do, how it is going to connect to other parts of the system, potential consequences from making a change, etc. Some of this involves typing, but it‚Äôs usually adding notes to myself or high level bullet points that I flesh out later. I would guess that only about 10% of the time that I spend on a given task is actually spent on typing the code for the finished product. The last thing I want is an AI constantly interrupting my thought process with its ‚Äúhelpful‚Äù suggestions.\n\nYou're not.\n\nThe issue is that saying it's not useful will get you a ton of reply guys insisting it's the sequel to dogs and AI companies are working the press hard to get stories out that make their product seem world-changing.\n\nIn reality, the tools are practically useless and struggling to get training data in a world where it's become valuable.\n\nmy boss and coworkers have been using chatgpt for everything and i end up having to explain to them how their own code works and how bad it is\n\nLLMs are text processors. Really really good text processors.\n\n\nUse them like that and they'll make you a lot faster.\n\nIs this a universal experience? Because I am using Claude, Github CoPilot, and ChatGPT in my personal coding and have found them to be very useful in a variety of ways. I see AI as a great way of avoiding tedium, getting unstuck, and learning to grasp new concepts by having someone to converse with them about and ask questions of. It took me a few weeks to get the hang of working with the toolset but since then it just seems to keep improving.\n\nI sincerely feel like I'm going to get lambasted for astroturfing but it's the truth; AI made me like writing code again after completely burning out a year and a half ago. The notion that I can use actual language to produce code is a revelation for me as I was always better at architecture than syntax.\n\nJust wanted to offer an alternative view here. I'll take my paddlin' now.\n\nIt's fine for experience users.  For new people in the development space, how will they know whats wrong and what is correct from an LLM?\n\nAnother common complaint is people hate code reviews more than writing code.  The fact that you will be reading code more than writing it and correcting the mistakes you can catch.  \n\nRelying too much on the tool can cause you not to dive deep into something to understand more of the platform.  Sure you can test it, but usually if you write it, you want to look up the docs and read and understand.  AI has the tendency of short cutting learning.  Learning that will be important later in not only debugging and testing, but understanding why an issue happens in production.  \n\nPeople can use them as glorified code snippets, but you have to be careful to not rely on them for learning.  They can be incorrect and are no substitute for documentation and testing boundaries.  If all you use them for is snippets, why pay money for that?  I can make my own snippets.\n\nThey help with mundane programming tasks that might be trivial.\n\nEdit: there is no problem using it, but there are some pitfalls to be aware of and how to cope with them.\n\nI agree. I would point out that the article is making the blanket statement that \"AI does not improve productivity.\" And honestly the thesis doesn't seem well supported. We could just as easily explain the few numbers they have with \"AI impacts juniors negatively and seniors positively\" per your statement, and I think that might be more accurate. Because you're right - to a junior or a non-coder, AI looks like magic and therein lies the danger. \n\nI have 25 years of coding experience and I am using AI to write unit tests for non commercial software that I make for fun. This is a very different test case than a team full of offshore juniors (which I have managed so I know of what I speak) being given a project they don't understand and them then trying to ask a robot for help with it. \n\nThe one thing that AI famously doesn't have and that every junior employee across the globe needs is context. And without that no code can make sense or work correctly.\n\nThe analogy I am using right now is that AI is like a 6 year old who read and memorized Wikipedia. And that it can cause exactly as much confusion and danger as that six year old.\n\nThis is the herd mentality.\n\nAnyone who's put in the work to make LLMs useful for themselves knows what's up. The rest assume they know everything and write it off too quickly. They've been burned too many times by management shoving stupid shit like blockchain down their throat.\n\nSo this is the way I see it - the hard part of writing code is not writing code. AI only helps you with writing the code, it doesn't make your code more readable, well documented, easily maintainable, or make good design decisions for a robust, extendable and bug free system. If your only goal is to shit out a mountain of boiler plate code, then AI is great. Unfortunately that is a horrible design philosophy and is most likely going to end by producing a lot of extremely shitty code bases when people just take the generated code at face value and assume that if it works it is good.\n\nLong story short I think AI is going to make development work harder in the long run by giving developers with no deep understanding of good software engineering practices the ability to generate large, poorly designed, poorly documented, and poorly maintained code bases.\n\nI totally understand the aversion to AI and generally anything that is the current flavor of the month hot new thing being pumped by tech companies and investors.\n\nHowever, AI coding assistants are a genuinely useful tool that works wonderfully if you know how to use it and what its limits are. At its weakest, it's an autocomplete on steroids. At its best, it does an amazing job at reducing tedium by helping you refactor things quickly, generate boilerplate, or can act as basically an interactive documentation when working with an unfamiliar library or language. Sure, you can work perfectly fine without all those tools. But writing off the concept as a whole because you see no value in such tools actually suggests a lack of experience to me. You don't *need* to use it, just like you don't *need* a builtin autocomplete or a full fledged IDE to write software. But if you learn to use them, they'll help you a lot. I'm skeptical to anyone who's so hostile to adding a new genuinely useful tool to their toolbox.\n\ntl;dr it's not going to do your job for you. It's a tool. Learn to use it. If you don't know how to use an immensely useful tool like this then you're either stuck in your ways or it's honestly a skill issue.\n\nSpeeding up how fast we write the boilerplate part of our code is nice, but that had never been a big part of my day anyway. I still have plenty of meetings, time spent trying to understand which part of the codebase caused that bug, going back and forth with PMs to figure out what the expected behavior should be and how to handle edge cases, etc.\n\nEven if we‚Äôre only talking about the coding part, I spend more time trying to figure out what is the right way to fix a problem than having to write the code for it. That‚Äôs the easy part. \n\nAnd I think that this what the article is about, they couldn‚Äôt find that productivity metrics like number of PRs opened or how long it takes to merge them was actually improving.\n\nIm with you. I've pushed out code in a fraction of the time it would take myself to do it. And it's not like it's buggy code. It's working great. I use copilot and Claude mostly.\n\nI disagree, if used to quickly explain concepts, or give an idea of how to implement the basic structure of some code, even analyze logs or complex code junks to find potential clues about issues, it has saved me a lot of time to actually do the fun stuff, if the aim is \"hey, write the whole class/method to do this\", yeah that will cause some sneaky troubles.\n\nIt's a great snippit generator, but that's it\n\nGood programmer with assistant &gt;&gt; Good programmer with no assistant &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; junior with assistant &gt;&gt; beginner with assistant\n\nI just need good static analysis with ergonomic shortcuts. Language models haven't at all improved my workflow because I don't trust the code it spits out. My writing process rarely involves copy/pasting snippets or generating code from various sources. An assistant saying \"hey, do you want to do this?\" is the most counter-productive thing I can imagine. It breaks my concentration to have systems interject while I'm mapping out the problem in code.\n\nWriting code fast isn't the problem, it's just the wrong thing to automate. It's making that code efficient, robust, and maintenable. These assistants can never be trusted to ensure that because these things are dependent on a lot of human factors that you can only account for if you understand your users and requirements. Reading between the lines of a spec, talking to real users to get feedback, understanding that what someone claims they want isn't necessarily what's in their best interest.\n\nAlmost every new software-related idea is initially overdone and misused. Over time people figure out where and how to use it effectively instead of mostly make messes as sacrifices to the Fad Gods to increase buzzwords on one's resume. But there will be bleeped-up systems left in their wake. Pitty the poor maintainers.\n\nOOP, microservices, crypto, 80's AI, distributed, Bootstrap, etc. etc. went thru a hype stage.\n\nThus, I expect the initial stages will be screwed up. But the guinea pigs do pave the way, solving the kinks over time. I just wouldn't want to work at one of the guinea pigged companies if not an *intentional* R&amp;D shop, üêπ as you given more room to fail or make unintentional messes in a dedicated R&amp;D shop.\n\nThe metaverse of the programming world.\n\nI have found it extremely helpful for many tasks.\n\nThe last one I asked it to add profile timers to each line and write out the average to disk every 5 seconds.  It wrote the code and even stuck the file writing on another thread. It would have taken me a lot longer than 30 seconds to write that.\n\nYou skipped the learning process and went straight for the answer..\n\nNot working as a dev atm, but webscraping projects of a scale that used to take around 3 days for me now take closer to 3 hours.\n\nI don't want to read pages upon pages of HTML. Just throw it into Claude, say what I want, and get a function that 90% of the times works exactly as intended, with the rest being easily fixable.\n\nAs a pure coding assistant, well... I really don't fancy reading all details of the documentation for some library I'm likely gonna use once or twice this year. If Claude can't do it at all, I'm likely having the completely wrong approach and should decide for another library.\n\nNot claiming I'm a good dev, because I'm not. I understand the process of informational flow and transforming it between the topological connections of the system, and can't be arsed with learning all syntax that could be good to have sometime. But for exactly that reason, AI improves my workflow significantly.\n\nIt is good for grunt work, so grunt work is what it gets to do. And answer my annoying questions at 3AM at a level no sane person would commit to, of course.\n\nwhat if you went to your doctor and 4/5 times they help you out but 1/5 of the time they amputate your foot\n\nIt‚Äôs great at turning JSON into DTOs and I prefer it to checking the docs for languages I don‚Äôt use every day\n\nBut I can‚Äôt see myself paying more than $5 a month for that and I just don‚Äôt think that‚Äôs enough to justify the cost to run the services\n\nI have found myself coming back to Stackoverflow, as the LLMs often generate bad explanations on their suggested solutions\n\nHilarious. While they keep seeing no gains, Amazon AWS CEO says his developers will no longer write code at all in 24 months because it will all be done by AI.\n\nI love using Claude, Copilot and Chatgpt for work because they get every single thing wrong and then apologize profusely\n\nI agree, we use GitHub Copilot. It's great at basic boiler plate from popular libraries, creating test data (sometimes), and ....... yeah. The LLM hype bubble is finally starting to pop. Too bad some companies slashed tons of employees believing the hype. Glad my company wasn't one of them."
  },
  {
    "title": "CrowdStrike update takes down most Windows machines worldwide",
    "body": "",
    "score": 1388,
    "url": "",
    "created_utc": 1721376432.0,
    "author": "OpetKiks",
    "permalink": "/r/programming/comments/1e6yh7f/crowdstrike_update_takes_down_most_windows/",
    "all_comment_text": "I wonder if there would be lawsuits against CrowdStrike.  Global outage into billions of dollars easily.\n\nEveryone will get a $20 voucher\n\nHere's yet another subscription for credit monitoring.\n\nMore like $4.96\n\nMore like tree fiddy.\n\nHospital systems are affected too. Having to do manual/phone orders and do most things by hand\n\nThe hospital I usually transport to is unable to pull any drugs from their system and is on full diversion. That doubles the length of some of our transport which is...not great\n\nJust the levels of issues and variety of problems is insane.  And on a Friday too!\n\nElective surgeries getting canceled. I'm sure there will patients affected by it, possibly even deaths. I can't imagine Crowdstrike not getting hit by suits.\n\nConsidering the global impact, it's got to even pass a trillion surely. \n\nLiterally the whole planet is having issues with stuff ranging from shops being unable to take payments, hospitals cancelling surgeries, ports refusing ships, airports refusing planes etc. \n\nSeems like genuine chaos on a global scale.\n\nThe vending machines in Tokyo couldn‚Äôt take payment because of that blue screen hahahha\n\nIt's all the worst fears people had about the Y2K bug come true\n\nEh. Not really.\n\nFor some reason, a lot of people were genuinely convinced that Y2K would have been a genuine cataclysm, if not the literal end of the world.\n\nFortunately, while I'm sure there are plenty of cursed setups where a Windows server is responsible for managing nuclear reactors, missile launch systems, avionics, etc... they generally tend to be airgapped and not subject to automated rolling updates. With Y2K, had it not been addressed ahead of time, that wouldn't have mattered.\n\nThey could well inflict more harm, in monetary terms, than actual threat actors this year. It's not a good look, especially when using these security solutions are usually a pre-requisite for cyber insurance.\n\nyou get a free month of CrowdStrike subscription for your troubles, limited to 5 devices per organization. thank you! /s\n\n[removed]\n\nThe beauty of giving software kernel level access, I always knew some kind of security shit show like today was gonna happen sooner or later.\n\nThis isn't a new problem.\n\nThe solution is simple: Don't use shit like this.\n\nAutoupdating third party software with kernel level access should be a big no no.\n\nMy company has like 10 different anti malware programs running on my laptop and hence our entire internal infrastructure is down because one of them crashed all our servers.\n\nThis is basically what cybersecurity for most companies is - just keep buying shit to put on machines to try to filter out malware and viruses. Buy some more shit to sniff network traffic.\n\nWhat can possibly go wrong with centralization of power, allowing one private company kernel level access to billions of computers around the world ? I can understand there's nothing we can do as employees working for companies. But my personal PC/ laptop always disabled Windows update craps via registry\n\nThe problem is, as obvious as the inevitability of this is to most of us here, the people actually making decisions involving money don‚Äôt have our expertise. When there are only a few dissenting voices warning about stuff like over-reliance on the cloud, outsourced software solutions, and software that automatically updates itself without proper internal vetting, our voices are drowned out by the analysts and salespeople who keep pointing at cost savings. I feel vindicated in a way personally, since I‚Äôve been telling anyone who will listen that this could happen for years. It doesn‚Äôt matter because this won‚Äôt change anything in the long run, though.\n\n[deleted]\n\nMuuurrrrrphhhhh\n\n&gt; sooner or later.\n\nThose antivirus shitshows have been happening for two decades - this is just the worst one yet.\n\nAn auto-updating security feature was the critical vulnerability. It's like when an all-in-one password service got pwned, there go the keys to the kingdom.\n\nI really hate the new update-policy in Windows.\n\nMy main machine is Linux, for +20 years now. I keep a secondary machine with Win10 on it. I am constantly annoyed at how bad Windows is, and the auto-update policies by default are one huge reason for this annoyance. Also, how slow windows boots, and how unreliable it has become in general. It's really strange. Windows in the late 1990s was so much more stable, even the often critisized millennial edition. Windows is doing so many things that take resources and are so irrelevant to me. I am even now using KDE okular rather than adobe acrobat for reading .pdf files on windows (yes, acrobat does not have to do with Microsoft as such, but I include the larger ecosystem into when I have to do trivial things, which includes dealing with .pdf files).\n\nYou can tell there's a difference in core philosophy.  Microsoft never removes anything, they just add more.  They keep painting over 10+ year old water stains with more UI instead of replacing the old plumbing.  Their products bloat like the monster from Akira as they absorb startups.  Maintenance and house cleaning never make an exec look as sexy as a new addition that's quickly abandoned.\n\nLinux and Mac seem to have a better time property adapting or replacing old features to fit with new ones.\n\nHouse cleaning means breaking old software that some customers rely on. Windows is remarkably good at running old software.\n\nI ¬†realized this years ago, with 3rd party antivirus regularly bringing my pc to a crawl. ¬†It caused more problems than it (potentially) could solve.\n\nCourse, companies can‚Äôt run that risk; with liability and all‚Ä¶ ¬†\n\nCrowdstrike usurped anti-virus scanners because it doesn‚Äôt scan the file system and consume a lot of cpu. It looks for anomalous behavior like abnormal network traffic. So, it‚Äôs much less invasive than an anti virus scanner as long as there are no other issues‚Ä¶\n\nHonestly wondered if it was a supply chain DOS attack at first\n\nYeah, anti-virus is like that. You roll the bones and hope it's not worse than whatever it might stop.\n\nIt's not most, but it's not a small percentage like the other commenter said. But it's a lot. \n\nPlus it's used widely in security sensitive contexts so it's enough for it to be significantly disruptive. If it was affecting consumer devices instead it would be a different story, even if the numbers were much larger.\n\nI was up like all night because we had a VMware issue that took down a bunch of stuff and I am just not looking forward to today.  I could open my laptop and look now but.... no...  just... no.\n\nAzure lost most of the Central US region, we just got that recovered around 10PM last night and were back up again at 12:30AM because of this.\n\nMicrosoft reported that their azure outage is unrelated to CrowdStrike.\n\nIs Crowdstrike any good though?When it's not destroying the world economy I mean.\nIs it that much of a liability for companies to allow computers to just have Microsoft Defender and nothing else?\n\nAs an IT professional I genuinely don't understand why companies have millions invested in m365 but don't utilize defender for endpoint. It's robust, has automated remediation options, and uses the already existing defender. Now the primary issue is that support for Mac and Linux is lacking.\n\nTo answer your question, though, just defender without central visibility is a big no in corporate environments. You need centralized monitoring to be able to get a big picture of which vulnerabilities are currently affecting your workplace and what the best path for remediation is. Plus there are mandatory security audits in many countries now and not having that tool would make it impossible to accurately represent your numbers.\n\nIt was one of the more popular options, I think it exploded when Amazon endorsed it or something like that. \n\nI mean, security is important, so you have to rely on someone, but I feel like this was more of a confluence of several factors.\n\nhow are they even fixing this. \n\nIf the machine wont even start cause of BSOD how they updating CS to push a fix.\n\nSky news were not even able to report on it since they were affected.\n\nThey pushed a fix, which affected machines cannot apply. The workaround is to boot each individual VM in safe mode and delete a file manually\n\nGod that was my life all morning\n\nHow many machines can you do per hour? I mean there a businesses with what, 10k laptops *somewhere* around the world?\n\nWell, I was on to validate the services that were running on the VMs in the first place. We had dozens of people on to go manually run through every Windows VM with the steps OP provided. It wasn‚Äôt fast by any means. Like it probably took a minute for each one, once you got a good roll going.\n\nIn win sys 32, find the crowdstrike folder a level down and delete it rename the file. Or go buy every short position you can on crowdstrike. I'm not your mom.\n\n[deleted]\n\nr/WallStreetBets is gleefully dancing around that fire!\n\nInstructions unclear... deleted %WINDIR%/System32\n\n[deleted]\n\nYou might want to remove the link as you might be doxxing yourself A.K.\n\nMeh, if it‚Äôs a VM you just make a new one from your pipeline\n\nI got my bitlocker password...\n\nSo many don‚Äôt.\n\nThey are gonna pay a shitload compensations for this botch.\n\ni doubt it most companies have it written in SLAs that they do not compensate for f-ups.\n\ncouldnt see crowdstrike not having that when it can stop legit and malicious apps working.\n\n&gt; Sky news were not even able to report on it since they were affected.\n\nThank you Crowdstrike üôè\n\n[deleted]\n\nMy father just sent me \"crowdstroke\" and I feel it's appropriate here\n\nCloud-Strike: Global Offensive\n\nI‚Äôm 33% victim, work laptop offline but 2 personal computers working\n\nIf your work laptop is offline, it sounds like you're the beneficiary.\n\nwhy would you install crowdstrike on your personal computer?\n\nDo your personal devices have crowdstrike on them?\n\ndo you believe offline systems wouldn‚Äôt have any issue if turned on now ??¬†\n\nNo, it‚Äôs bricked. There are workaround steps via booting into Safe Mode, but I work in a high security role so I‚Äôm not allowed to do that myself. I must bring the laptop to a field office 80 miles away, where IT will fix it.\n\nThis should be the case for pretty much every deployment that doesn't give regular users admin access.\n\nI don't think they meant the peaceful kind of offline.\n\nlol i get it now!!\n\nMine was a peaceful offline trying to make sure if it Really was or I might be in trouble too üòÖ\n\nSchrodinger's PC üò¨\n\nYou have Crowdstrike on your non-work PCs?\n\nMost windows machines world wide?\n\nSeems like it's only ones that Crowdstrike provide a service to, so mainly corporate customers and major organisations - and of course all terminals &amp; machines owned by those corporations/organisations. Apparently, Crowdstrike have around 24,000 customers, so the number of machines could still be huge.\n\n8.5 million according to Microsoft ‚ÄúThat‚Äôs less than 1% of all Windows-based machines‚Äù [yahoo source](https://finance.yahoo.com/news/8-5-million-computers-running-172146811.html)\n\nNah. More like a significant percentage of high-responsibility ones.\n\nThis pisses me off on so many levels :)\n\nFirst off: The headline of the article, does not reflect the actual issue. Clickbait AF. It says \"Major Windows BSOD issue takes banks, airlines, and broadcasters offline\". The issue is CrowdStrike - no more, no less. It causes a BSOD yes. But if you aren't using CrowdStrike it's not an issue. But you have to click to get info on the *actual* problem.\n\nSecondly: Who in their right mind, would release anything without testing? Or - at least - have it run on a small percentage for X hours/days, before pushing to the world.\n\nThirdly: Who in their right mind, would release anything a friday morning?\n\nTo be fair, as far as I understand what CrowdStrike does, it's their job to release updates fast to combat emerging threats. Whether this was necessary in this case is a different question.\n\nCertainly those machines aren't vulnerable to any attacks right now though, so‚Ä¶ yay?\n\nThis is fucking smoketesting. Even the worst emergency hotfix should be smoketested before you send it out to the world.\n\nExactly, a quick deploy and reboot when you're working on that stuff.  10 minutes to ensure you don't tank the entire system.\n\nBut we all know the real reason: the company cut corners, like they all do, to the point where they don't have the ability to do things the right way anymore.\n\nOne of my previous jobs cut an entire QA department and made our end users the testers at one point.  That's how you end up with this kind of shit.\n\nWhat happens when the software that combats emerging threats IS the threat?\n\nIf a threat defeats itself in the woods, does it make a sound?\n\n*critical.wav*\n\nEh, depends on what we consider a threat. If what constitutes a threat is someone taking control of devices and stealing information from them, a BSOd is technically still a defense against it.\n\n\"I am the one who knocks.\" - CrowdStrike\n\nThey are vulnerable because of the bug; users will do things outside normal process in attempt to fix, which is an attack vector.\n\nAvailability is one of the pillars of information security. \n\nEven a critical update must be tested, and deployed in stages. Seeing how many endpoints are affected, this looks like an extremely easy bug to catch, so maybe someone decided to bypass all tests.\n\nExactly the second point! I work in games and even we do incremental rollouts in case something breaks. That's just games. Bloody firewalls are pushing to all customers at the same time?\n\nFriday's the best time for testing. üòÜ\n\nManager goes: THiS iS VeRy MuCH iMPoRTaNT\n\n\\*sign\\*\n\nTo be fair, the general public is more acquainted with Windows than CrowdStrike, so more clicks i guess.\n\nRegarding your other points, I believe the answer is: Someone who used to work at CrowdStrike :D\n\nIt was Bob‚Äôs fault. Bob‚Äôs gone now.\n\nWho cares about doing a staggered release and realising that none of the updated devices are calling back, we're going to YOLO it like a hobby Minecraft server admin.\n\nAlthough regarding the third point, they released when it was Thursday night in most places which is standard practice, since you see the problem on Friday and have the weekend to fix it.\n\nThanks for the explanation.\n\n&gt; Who in their right mind, would release anything without testing?\n\n\nNo one. Even if it was \"we must act fast\" at least update your machines before customers. Highly unprofessional and unskilled. Did some Boing managers transferred there?\n\nWell, i think they have at least released in waves. ¬†\n\nThis time they released in a tsunami.\n\nBut, it was just a small update...\n\nNot to diminish the responsibility of Crowdstrike in this fuck-up, but why admins that have 1000s of endpoints doing critical operations (airport / banking / gov) have these units setup to auto update without even testing the update themselves first? or at least authorizing the update?\n\nI would not sleep well knowing that a fleet of machines has any piece of software that can access the whole system set to auto update or pushing an update without even testing it once.\n\nEDIT: This event rustles my jimmies a lot because I'm developing an embedded system on linux now that has over the air updates, touching kernel drivers and so on. This is a machine that can only be logged in through ssh or uart (no telling a user to boot in safe mode and delete file lol)...\n\nLet me share my approach for this current project to mitigate the potential of this happening, regardless of auto update, and not be the poor soul that pushed to production today:\n\nA smart approach is to have duplicate versions of every partition in the system, install the update in such a way that it always alternates partitions. Then, also have a u-boot (a small booter that has minimal functions, this is already standard in linux) or something similar to count how many times it fails to boot properly (counting up on u-boot, reseting the count when it reaches the OS). If it fails more than 2-3 times, set it to boot in the old partition configuration (has the system pre-update). Failures in updates can come from power failures during update and such, so this is a way to mitigate this. Can keep user data in yet another separate partition so only software is affected. Also don't let u-boot connect to the internet unless the project really requires it.\n\nFor anyone wondering, check swupdate by sbabic, is their idea and open source implementation.\n\nMight not have even helped apparently - https://www.reddit.com/r/crowdstrike/comments/1e6vmkf/bsod_error_in_latest_crowdstrike_update/ldw1yxe/\n\nThis is even more concerning, so Crowdstrike is able to push updates without user input, regardless of configuration?\n\nIsn‚Äôt this like most AV software?\n\nI guess what is critical here is the difference between silently getting a new data file that checks for more patterns Vs changing critical parts of the system. Don't know enough yet, but seems like in this case a data file somehow triggered a change in the system via a bug in their software\n\nThe nature of bugs though is that you can‚Äôt necessarily tell the difference. You don‚Äôt plan for a data update to hard crash your system, but it might. So the idea that \"this is just a new data file\" as a thing you can manage differently from \"this is a critical update that might break stuff\" is false. You can and generally do try to assess risk and manage a release accordingly, but any change could be the one you didn‚Äôt think was that risky and still takes the whole thing down.\n\nYup, considering the fix is just deleting the file, I'm guessing it was malformed in some way and causing a failure that way\n\nEnd users (or end-admins) should be able to have the choice whether to accept updates as soon as possible or able to review them, and I might even say have that authority as a per-computer setting.\n\nFor all we know a bad actor could have done this as an inside job.\n\nYep! And it's all a black box too. Hopefully this proves once and for how cyber sec is a scam as a whole. One of them actually told me once \"I don't need to know how a database works because that's not relevant!\" Really then how are you suppose to secure one! Most unless people in the world.\n\nHe's not wrong tho. Generic security solutions like CrowdStrike don't need to know anything about your software, because at a low enough level, signs of exploitation or malware are the same. \n\nA shellcode executed from the heap will look the same in a browser, as in a database, as in calc.exe. \n\nHigh level program behavior analysis is at a high enough level that these details also don't matter. Seeing that a script downloaded something in temp, and then added that thing to startup, and it started to write and delete a lot of files has nothing to do with program internals.\n\nWhat a database is and how it works is irrelevant.\n\nThese products don't secure your data by looking at the queries being done through your database, they secure it by looking at program behavior, and at various indicators that appear in case of exploitation.\n\n\"Trust us, we know what we're doing.\" - Fancy IT Vendor\n\nI'm stunned their stock is only 15% down atm.  If I used windows I'd be switching my AV supplier here\n\nGive it time. Crowdstrike took a few exchanges down also.\n\nStock can‚Äôt go down if the exchanges aren‚Äôt functioning!\n\nI think being zero-maintenance is a major selling point for CrowdStrike. It's supposed to be a sort of ~~fire~~ install-and-forget all in one security solution. CrowdStrike themselves call their product \"Security as a Service\"\n\nSo yeah, doesn't sound like something to me that should be responsible for critical systems in Hospitals and such.\n\ncrowdstrike pushes updates without even an automated reboot and service scan.\n\nfucking amateurs.\n\nWell that is probably what they intended ! It may be the failed systems are the ones which are too far behind. The ones not getting constant updates are behind ??  Its like an update that got marked as urgent for all, when it is an incremental weekly update ??? The update got installed even when the precondition was not met. hence the crash.\n\nThe key issue is crowdstrike can fail like this at all. Given the mission critical nature of software.\n\nAfaik, the update was in data file, which  by itself cannot cause such issues. But crowdstrike having poor code caused the change to lead to blue screen of death. \n\n\nFor real though, doing global updates is the real problem here. You can‚Äôt have 100% guarantee with any change. Rolling updates are a thing . So that should have been done\n\nRolling updates with any meaningful delay would undermine a major reason people pay for crowdstrike - protection against near instant global attacks\n\nMaybe do not use rolling update **if** there is a global attack. Was there any global attack that justified this global rollout?\n\nI keep on thinking this morning - what was that question of if you want things available immediately or things to be reliable?\n\nSeems they don't have an adequate health check procedure on boot and/or failure mode handling. For security software, that's pretty shit.¬†\n\nIn some fairness, this is security software that ostensibly 'blocks attacks on your systems while capturing and recording activity as it happens to detect threats fast.'\n\nI would trust as a paying customer that CrowdStrike would thoroughly test that their own updates aren't the attack. I empathize with wanting the latest security updates quickly because the potential alternative, a successful attack, is probably worse.\n\nI empathize more with sysadmins that just run this on the company laptops with autoupdate; deploying non-automatic updates to that many machines is (sometimes) hard. Security updates don't often brick thousands of machines.\n\nIf the government, airports, banks each had a large-scale hack that downed planes, drained $millions, and leaked your social security numbers, I'm sure people would be pretty miffed that it was because someone needed to remote in to click the 'accept' dialogue or something.\n\nFor the critical systems, the real concern for me is that there isn't a completely separate backup machine that jumps in when things go wrong. Like surely there's some sort of quick-switchover thing that can manage when the main system fails to boot?\n\nYeah, I completely understand your point, I wonder if there will ever be a case where a vulnerability is exposed so fast that needs to be patch ASAP from the source and can't even wait a business day or two of testing, we got close on the xz exploit.\n\nAbout your last question, I'll copy my answer from down, but basically I'm developing a system on linux now that has over the air updates, touching kernel drivers and so on...\n\nOne smart approach is to have duplicate versions of every partition in the system, install the update in such a way that it always alternates partitions. Then, also have a u-boot (a small booter that has minimal functions, this is already standard in linux) or something similar to count how many times it fails to boot properly (counting up on u-boot, reseting the count when it reaches the OS). If it fails more than 2-3 times, set it to boot in the old partition configuration (has the system pre-update). Failures in updates can come from power failures during update and such, so this is a way to mitigate this. Can keep data in yet another separate partition so only software is affected.\n\nFor anyone wondering, check swupdate, is their idea and open source implementation.\n\nI'm sure it already happens. Especially anything that spreads quick; you're desperately taking systems offline just to save them. WannaCry comes to mind.\n\n&gt; I'm developing a system on linux now that has over the air updates, touching kernel drivers and so on...\n\nCool! Do you keep a separate `/home` partition or data filesystem. Just wondering if there's the possibility of a machine getting into an inconsistent state. Like an air traffic control system missing critical events or something.\n\nIf data is in a separate partition with an atomic filesystem then you could possibly keep the second kernel warm. Though I guess it's less of an issue when you're dealing more with booting issues.\n\nHave you looked at the project to move the bootloader into the kernel? It has some mechanism to fall back to a working kernel in the event of a boot failure. I don't know too much about it and I believe it's just a proposal for now.\n\nFor this project, we just keep two boot partitions and two rootfs partitions. Our user data isn't particularly critical, is a home device that can be restored to default settings without anyone dying and these settings are set from a pc so if the user really misses a lost configuration on a bad update we will always save settings on the pc. But I imagine a different project might have more complex data requirements that can cause what you mentioned, an inconsistent state.\n\nI haven't read into that! I think I prefer to keep the kernel separate, kernel in Linux could get corrupted, can't guarantee that the fallback mechanism works if is inside the program that is constantly running. This is part of what a bootloader is meant to sustain, a basic access to the machine. But I don't know enough tbh, maybe they are doing it in a smart way or to basically include the swupdate style into the kernel itself, so it saves some setup. I'll read about it :)\n\n&gt;I wonder if there will ever be a case where a vulnerability is exposed so fast that needs to be patch ASAP from the source and can't even wait a business day or two of testing\n\nThis happens regularly with zero-days, but in general, these things are part of a security definition file update, not a software update. These generally tick in regularly, even on a regular Windows system with Defender, and do not typically have the capacity to cause computers to crash on their own as they're simply data files read by the system. You don't need to update the whole software just to add detection for a new threat in most cases.\n\nWe had 6 servers that could back up each other in case of an incident in one of them. All distributed across different geolocations worldwide in different availability zones.\n\nWell today all of them went down because they got this update.\n\nI guess one more step we can take in future is having different deployment targets (os x cloud)  to reduce impact on similar cases.\n\nDamn, that's brutal. Another commenter said this update was pushed silently and forcefully, which seems too crazy to believe but it would explain why so many systems I would expect to have redundance have failed.\n\n&gt; \n&gt; \n&gt; I empathize more with sysadmins that just run this on the company laptops with autoupdate; deploying non-automatic updates to that many machines is (sometimes) hard. Security updates don't often brick thousands of machines.\n\nI won't pretend to know the ins and outs of corporate IT but shouldn't updates be done in batches? Theoretically it should help catch issues like this.\n\n&gt; I would trust as a paying customer that CrowdStrike would thoroughly test that their own updates aren't the attack.\n\nBut what would you base your trust upon? \n\nThis is the part that I really don't get - I see people all the time having complete 100% trust in companies that did nothing to prove that, they just say \"trust me, bro\" on their website.\n\nYou lock down your mom's or your coworker's permissions, but you're giving full system access to ALL your systems to a whole company with 10,000 employees, many of those outsourced to 3rd world countries.\n\nYou trust them because:\n- They have a paid obligation to do what they say they will.\n- They have a good reputation for doing what they say they will.\n\nTrust is not a guarantee that nothing can possibly go wrong.\n\nIf Shady Sadie hands me a free CD-ROM with 'antivirus' written on in Sharpie from the inside pocket of a trench coat in a back alley next to an an overflowing dumpster, I will trust that less than a piece of enterprise software from a large security firm with no prior history of taking down systems.\n\nDo you trust a half-eaten sandwich on the ground to be safe to eat? Do you trust a $100 dish from a 3-Michelin-star restaurant to be more or less safe? Why?\n\nYour last point is key to me. Any critical system that runs continuously should have self test and a rollback mechanism\n\nI have auto updates pushed to my machines regularly, granted they are linux boxes, but I definitely don't test them first.\n\n1. The updates are security updates\n\n2. They get a lot of testing before they are released by the distro\n\n3. If it fucks up, my boxes will fail their health checks and kill themselves and start new ones with a known good image\n\n  \nTreat boxes like cattle not pets\n\n[deleted]\n\nNo, but I imagine his point is that if you can isolate the software base then you can rollback that on a lightweight boot system. Everyone knows ATMs run kubernetes. Ofcourse the boot system needs security updates too. The solution is an infinite recursive stack of operating systems with rollback. Docker in docker! /s\n\nand this is why god proclaimed all computing should be done at 640x480 + ring zero\n\nTempleOS it is then.\n\nan idiot admires complexity. A genius admires simplicity.\n\nyou jest but this is the real problem with systems like this. the boot loader process doesn't support any sort of rollback so if you mess up your boot loader that's it over. Doesn't matter how many generations or if you have a functioning B parition. honestly would be a good feature if motherboard manufacturers supported AB boot partitions. since a lot of bioses have a AB setup that pretty much means the whole stack can be AB in some way if we had an AB bootloader process.\n\nNo I know, the person in question I imagine is running some kind of cloud service/local equivalent with virtualization which is allowing their case. Boot loader will always be a problem. Ofcourse boot order is a thing but that doesn't work when the boot loader is just not booting properly rather than borked.\n\nYes, we take the ATM machine out the back, shoot it, then burn it. Then we get a fresh ATM machine teller, install it, put a fresh $10,000 in it, and write off the burnt $10,000.\n\nYeah, I mentioned it below but this tickles me a lot cause I'm developing a system with over the air updates. But fallback partitions are a must if the devices are so critical.\n\nWe have *all* automatic updates turned off and one person dedicated to apply them in stages across the world. \n\nWe still got massively affected.\n\nIt's a lose:lose situation with updates.\n\nOh, you want to do updates? Hope you can deal with breakages on the fly (usually not this bad, but, actually yes sometimes).\n\nOh, you don't want to do updates? Enjoy your excessive and widespread cybersecurity vulnerabilities and loss of any professional compliance or insurance.\n\nReal talk, the answer is stop spreading your IT footprint like an aerosolized fungus. Pick a few good products to further your business, consolidate your processes around them, *fuck off* any push to expand beyond them.\n\nSo like a blue-green deployment but for the OS?\n\nIn a lot of countries they're *required* to. Updates often involve patches of 0-day vulnerabilities, taking a few weeks before you update means exposing yourself to risk, as malicious actors can use the that time to develop an exploit for the vulnerability.\n\nNot a big deal for your personal machine, but for a bank? A very big deal.\n\nYou do realize that this itself is a vulnerability. If a security company gets its software hacked and a malicious update gets sent out, millions of PCs are just going to run that code no questions asked. At a minimum, patches that affect critical infrastructure needs to be tested, period.\n\nOf course it. Every security feature is a potential vulnerability. For example, every company with more than a dozen workstations uses systems management software, and malware tools with a centralized portal for managing them. But what happens when a hacker gains access to said portals? They can disable protection on every single device and use any old malware to infect the entire company.\n\nIt's *generally* still safer to be up to date with your security updates. You rely on it too. Do you test every update of your anti-malware software or do you let it update automatically to have up-to-date virus signatures?\n\nMakes sense, I'm not familiar with the requirements of critical system updates but I guess a lot of these will be restructured after this incident. How to achieve this level of commitment to update without this happening\n\nI don't think much will change.\n\nInconvenience is the other side of the coin to security. It'd be much more convenient if you could leave your doors unlocked, it'd be faster, you wouldn't need to carry your keys wherever you go, and you'd never end up locking yourself out of the house (which can be a big hassle and a not insignificant expense). But it's a big security risk, so you endure the inconvenience to be more safe.\n\nThis isn't much different. There *are* risks involved in patching fast, but the risks involved in not doing so outweigh them most of the time. Having a temporary outage once every so many years isn't the end of the world in the grand scheme of things.\n\n&gt; why admins that have 1000s of endpoints doing critical operations (airport / banking / gov) have these units setup to auto update without even testing the update themselves first?\n\nBecause they're balancing the risk of a rogue update, the probability that said update will actually fail on the test machine if they do test it and the risk of having an unpatched critical vulnerability.\n\nThe reality is that updates which brick devices are extremely rare, testing updates on a meaningfully large set of machines to have any meaningful confidence it is safe is hard and being even a couple hours late on a critical update can be catastrophic.\n\nYeah, no way this was tested. Makes you wonder what kind of code has been injected by threat actors.\n\nThey really aren‚Äôt getting off easy though. The US government is a customer of CrowdStrike, entire agencies‚Äô computers are currently being bricked‚Ä¶\n\n&gt; Yeah, no way this was tested\n\nMy guess is that the change was tested, but the deployment wasn't. i.e. someone built the code, ran it on test platforms and it worked, but that testing doesn't use the same mechanism as deploying to customers. Either that, or somehow the deployable was corrupted.\n\nClassic case of \"works on my machine!\"\n\n&gt; Yeah, no way this was tested. Makes you wonder what kind of code has been injected by threat actors.\n  \nAll unit tests passed without issues.  \n  \nQ: did you try to restart the system?  \nA: we reloaded the container.  \nQ: And windows?  \nA: none of the devops could be bothered to set-up a test VM, as everyone answered \"i use Arch BTW!\" During their interview.\n\n&gt;They really aren‚Äôt getting off easy though\n\nI bet not even a single 3 letter role will have to give up his yearly yacht.\n\nFunny thing that you literally described what fedora atomic does, it would try to boot and if it failed, it will just revert the update and every kernel change AND EVEN the overlay application update.\n\nBecause all sorts of Industry Best Practices and other regulatory horseshit requires you to have your antivirus be on the bleeding edge. Holding back antivirus updates can cost you your certification\n\nThe cost of testing every software update is very very big.\n\nThese pieces of software should already be tested, something being released that bricks devices says no testing is done on crowdstrikes side which is the bigger issue\n\nYeah, no idea why any large enterprise would allow its devices to be updated directly by the software vendor. At work we have our own update distribution servers both for the OS and the endpoint protection, and there's a canary distribution server that all updates must go through first.\n\nIt struck the biggest crowd ever. Software name checks out.\n\nedit: past tense fix\n\nCrowdStrike have finally lived up to its name and striked the crowd using their software.¬†\n\nUh, well, I‚Äôm sorry, man, but you know, I didn‚Äôt mean to hurt you. I didn‚Äôt mean to ~~thunderstrike~~ crowdstrike you, but that‚Äôs just‚Ä¶I don‚Äôt know what to tell you. What d'you want to hear?\n\n\"most Windows machines worldwide\"\n\nErr no.\n\nNews reporting sure has been confusing over this.\nAlso read the headline \"most windows machines worldwide\" when I woke up, and I though *\"oh my god\"*. \"Windows machines **using Crowdstrike** is a pretty important distinction to make.\n\n[deleted]\n\nI left early (2:10pm AEST) to pick my daughter up from school camp and had my lappy suspended in my bag. For once windows didn't see fit to wake it up while it was in there.\n\nTeams notifs were absolutely unhinged. Everything going down at once. I'm driving along and the phone was blowing up. Surreal.\n\nGod knows how many millions lost just from one very niche company in Australia. At least 000 (our version of 911) was still working.\n\nMy daughter calls them \"clownstrike\" now. I like it.\n\nConnecting a program that runs in kernel space to the cloud is an absolutely fucked idea.\n\n**Workaround**\n\nBoot Windows into Safe Mode or the Windows Recovery Environment.\n\nYou can just navigate to the **C:\\\\Windows\\\\System32\\\\drivers\\\\CrowdStrike** directory.\n\nLocate the file matching *C-00000291\\*.sys* and delete it.\n\nBoot the host normally.\n\nMS noted that you may need to reboot multiple times after this, reportedly up to 15 times. Although the way they said it sounds like needing multiple reboots is rare.\n\nNot most Windows machines, just ones with the CrowdStrike installed, which is a pretty small percentage.\n\nSmall percentage in total devices running Windows worldwide yes. But remove the inconsequential for every day life personal machines, and check the percentage again.\n\nThis thing bricked whole industries\n\nFlights are being grounded, train services not working, stock exchanges down, tv channels offline, emergency services down, hospitals struggling.\n\nThis is not a small percentage at all, it's a massive problem.\n\nit's both a small percentage of Windows installations and a massive problem. these two statements don't contradict each other.\n\nyou don't need to take down half the world's computers to do serious damage, only the critical ones.\n\nWindows is installed on an estimated 1.5 billion machines. Crowdstrike has approximately 23,000 subscription customers.\n\nThe \\*percentage\\* of the 1.5 billion Windows machines affected is small (which makes the headline wrong). However, the \\*impact\\* of those particular machines going down is extremely high because it's most likely that the most critical Windows machines running core infrastructure will be running Crowdstrike.\n\nPercent of critical infrastructure that runs on windows != percent of machines that run windows\n\nMost windows computers aren't servers like those.\n\nLinux and Mac users rejoice?\n\nyes and no .Even us Mac users are forced to use Windows machines at work. But on the bright side, I have the day off. Yay!\n\nMaybe its time to think about how aggressive antivirus SW in general is - at best slowing the pc down 2-3 times, at worst doing this. \n\nLooking at you, Cortex XDR garbage.\n\nMost windows machines dont have crowdstrike installed. Clickbait title\n\nJust to clarify, if my computer is not running CrowdStrike, I can still turn it on?\n\nYeah, that ain‚Äôt impacted\n\nCorporate*\n\nWhat happened to testing?\n\nThey laid those guys off.\n\nWorkaround Steps:\n\n   Boot Windows into Safe Mode or the Windows Recovery Environment\n\n   Navigate to the C:\\Windows\\System32\\drivers\\CrowdStrike directory\n\n   Locate the file matching ‚ÄúC-00000291*.sys‚Äù, and delete it.\n\n   Boot the host normally.\n\n\nInstructions as posted by the subreddit\n\nOh my God.\n\nWe're celebrating Padigosan (a special yearly celebration in Digos City, Philippines) by hosting a huge trade expo in Gmall of Digos right now.\n\nWe have a lot of visitors to tend and services to sell. All of the stalls are down because the websites and services they're based on have halted operations, and even some laptops are bluescreening themselves.\n\nPerfect timing, surely this will have a good effect on the economy! Well, at least Roblox isn't down, so I can still chill here.\n\nYeah the hospital i work at has been having issues for several hours.  It's a very dull day for me.\n\nName checks out.\n\nWho tf release a new update on a friday morning?\n\nAt least crowdstrike can be sued.  That fixes the problem for the phb types.\n\nYou can still boot to safe mode. Then from there remove the problematic updates, of course you need admin access for this.\nWith VM it's much more easier, just rollback from snapshots.\n\nWhat a crap headline. It's not \"most\". It's not even a huge amount. But the rolling issues are causing widespread disruption across industries.\n\nThey goofed hard with this. Deployment on a Friday, broken/untested to production, kernel level permissions. Worst case.\n\nFirst time I heard about CrowdStrike were [this tweet](https://x.com/molecularmusing/status/1808756095860543916) some weeks ago...  \ndid they just decide to roll it out globaly on a friday morning? :D\n\nThe only bright side is I guess I‚Äôll be getting paid to not work for a bit.\n\nIt's nice when the real world does a better job of arguing for more robust testing than I ever could.\n\nI‚Äôm surprised that so many people using crowdstrike\n\nJust Azure...but half the internet runs on Azure.\n\nHackers can‚Äôt steal your data if your systems are all down\n\n\\*taps head\\*\n\nFun day for me! I get to fix this issue on around 400 computers today‚Ä¶.\n\nAutomatic updates have always been malware."
  },
  {
    "title": "If AI is too dangerous for open source AI development, then it's 100 times too dangerous for proprietary AI development by Google, Microsoft, Amazon, Meta, Apple, etc.",
    "body": "",
    "score": 1339,
    "url": "",
    "created_utc": 1719612348.0,
    "author": "EUR0PA_TheLastBattle",
    "permalink": "/r/programming/comments/1dqvmdh/if_ai_is_too_dangerous_for_open_source_ai/",
    "all_comment_text": "Dude is working the benevolent gatekeeper angle hard.\n\nYes Sam, you and only you can keep everyone safe from the dangers of AI, so the government can bake-in and cement your hold on the market. I'm glad people are calling these theatrics out lately.\n\nAltman is full of it and even non-technical people can see. There is a good \"Citations needed\" podcast on it.\n\nhttps://citationsneeded.libsyn.com/episode-183-ai-hype-and-the-disciplining-of-creative-academic-and-journalistic-labor\n\nThey overstate the intelligence of models to get investor hype and to cover for more current issues about privacy and  influence peddling.\n\nLLMs are basically wildly good memorizers. They arent great reasoners but rather proof of how predictable most humans are.\n\nWhen there is gold rush, sell shovels...\n\nThat's been Nvidia's strat for the last decade.\n\nDon't forget the entertainment.......\n\nMy words exactly.\n\nNo I'm doesn't!\n\n.......\n\nI mean, I agree.\n\nEven if LLMs can't reason yet as well as humans, there's massive utility in automating the human stuff it is good at. It is a highly useful tool for explaining things even if occasionally wrong. There's a reason things like stackoverflow are on the downturn due to things like ChatGPT. Claude's coding capabilities are pretty insane. Vision capabilities of the best models are pretty insane. We haven't even gotten to agents quite yet, which will be coming within the next year it sounds like.\n\nHow can people look at the current LLMs and their capabilities and the pace at which they have improved and not think that a couple of iterations and AI research developments from now, there's a good chance that it equals or surpasses most human abilities.\n\nWe already have AI that can beat humans in complex games, it's not very far fetched to think that LLMs combined with other types of AI architecture in the near future would lead to even larger breakthroughs.\n\n&gt;  there's massive utility in automating the human stuff it is good at. \n\nkey question is , utility for whom?\n\n&gt;Claude's coding capabilities are pretty insane. \n\nNot really. LLMs hallucinate a bunch of code especially when working with new codebases where they cant leverage memorization. Its more akin to API documentation with customization capabilities than anything that reasons.\n\n&gt;How can people look at the current LLMs and their capabilities and the pace at which they have improved and not think that a couple of iterations and AI research developments from now, there's a good chance that it equals or surpasses most human abilities.\n\nBecause people who work in the field and arent trying to sell you something will tell you the models dont reason, they suck at causality. LLMs are super useful just like Google is incredibly useful. They do a whole lot of retrieval and generation by doing something like retrieval in a latent space but they dont do the core function that humans do which is causality, reasoning, and uncertainty. Although admittedly some humans are terrible at those things.\n\ni agree with you, people here doesn't use LLM beyond a trivial tasks, they never seen the horror of hallucinations when you ask it for non trivial things that requires a good amount of reasoning.\n\nSOMEONE who can make these idiots understand I mean Tesla self driving car works on 140TOPS and to run AGI we don't even have enough hardware requirements forget ASI.\n\n&gt;key question is , utility for whom?\n\nHopefully everyone, the tools are certainly available to everyone right now. Yes it is going to replace jobs eventually (which btw speaks to its capabilities in general), but it's inevitable at this point. Other superpowers will not stop advancing toward this either. If it is done right it will increase everyone's quality of life. I don't think the government will allow sam altman to become some evil world ruler hoarding wealth with an AI army, nor do I believe he truly wants that.\n\n&gt;Not really. LLMs hallucinate a bunch of code especially when working with new codebases where they cant leverage memorization. Its more akin to API documentation with customization capabilities than anything that reasons.\n\nIt has been pretty good at figuring out what I want it to do. The fact that it can build small webapps with the artifact feature that it'll run for you (with react) is pretty impressive. Just messing with it I got it to make a simpleish piano app with all octaves that can record and playback simple sounds + animations that dance to the music and it even implemented a reverb feature when I asked it to after a handful of prompts. I did no coding, just guiding it iteration after iteration. Something of that level of code generation was unheard of before.\n\nBut again, the main thing to takeaway from the current models is imagining where it'll be in a couple years. Yes it is not perfect or capable of handling large codebases yet partially because of its context window, but as compute, finetuning, and things like context windows improve, so should its abilities. And you can still leverage its current capabilities to increase productivity right now.\n\n&gt;Because people who work in the field and arent trying to sell you something will tell you the models dont reason, they suck at causality. LLMs are super useful just like Google is incredibly useful. They do a whole lot of retrieval and generation by doing something like retrieval in a latent space but they dont do the core function that humans do which is causality, reasoning, and uncertainty. Although admittedly some humans are terrible at those things.\n\nThey are not able to reason like humans I agree. But they have unquestionably gotten better at things like that iteration to iteration. While I agree that a lot of how it solves things seem to be based specifically on what it was trained on in a lot of cases (based on how it fails certain problems), there also seem to be emergent properties as well where it's doing more than just reading out of its directly out of its training data. Will a pure LLM on its own be able to truly reason like humans ever? Maybe, although I'd think probably not, but again with the amount of money and research poured into the field, I don't think we are far off from getting to that, even if it is not just a pure LLM.\n\n[deleted]\n\nRight now I agree, they are not smart enough to trust to go and do complex tasks on their own. Although It will be interesting to see how well google and apple's new task automation works that they recently showed off for their phone users which will come out in the coming year I think.\n\nBut yeah, you can't trust these things to build real world complex programs. However they are great productivity tools with what they can give you.\n\nThere is a real trend of these things getting more reliable with each generation. So how far that will carry us is what we will see. Maybe LLMs alone will never get to the point of being reliable enough on their own for more complex tasks, and we need other architectural breakthroughs. \n\nBut given the pace of progress and the money being thrown at this, these companies must have confidence that they will keep getting significantly better. The microsoft AI CEO recently said he expects in 2 years they will be good enough to completely follow instructions and go do things on their own. \n\nIs it possible when they say things it is just hype that doesn't pan out? Of course, but making wild promises like that publicly and investing all the money to make it happen will have consequences if it doesn't pan out, so it's not just hype for no reason. And I think architectural breakthroughs will happen in the coming years anyways with the amount of money/research going on in the field\n\n[deleted]\n\nIt's not just data, it's compute power too. While I agree with your last paragraph that it needs architectural changes to allow for examining it's own patterns, being able to learn new things after training to reach true AGI, I don't know why you are declaring the scaling laws dead. There are 100s of billions of dollars by these companies being poured into training with more compute with the idea it will be smarter and they are fairly certain it will for a couple more iterations at least\n\n[deleted]\n\nParallelism has been going on from the start of this recent ai explosion has it not?\n\nNVIDIA keeps releasing better chips. You think all recent gains for textual llms are just finetuning? I doubt it, I'd bet the next model chatgpt just started training will be immediately better than 4.\n\n[deleted]\n\n&gt; It is a highly useful tool for explaining things even if occasionally wrong.\n\nNo, that makes it a completely useless tool. Because now everything it does has to be gone over again, to make sure it didn't fuck up. When it would have been faster to just not use the tool. \n\n&gt;How can people look at the current LLMs and their capabilities and the pace at which they have improved and not think that a couple of iterations and AI research developments from now, there's a good chance that it equals or surpasses most human abilities.\n\nBecause they aren't AI. Literally all they do is know \"This word goes after that word.\" That's it. They have no intelligence, they don't know a single fucking thing. \n\n&gt;We already have AI that can beat humans in complex games\n\nBecause that's literally the only thing that program was designed to do: Be good at chess through brute forcing. If you asked that same program to play Monopoly, it'd fail hard.\n\nNot really, it usually is right and you can verify certain things immediately with common sense or with a google check after. Specifically for programming it is very easy to test. Most things that are simple knowledge retrieval it will get right. You just can't try to use it for extremely complicated things, it kind of becomes obvious when it has overstepped its capabilities and you can get it to contradict itself. There's still great utility in what it does as any software engineer that uses it as a productivity tool will tell you.\n\n&gt;Because they aren't AI. Literally all they do is know \"This word goes after that word.\" That's it. They have no intelligence, they don't know a single fucking thing\n\nAI has no definite algorithm it needs to be considered AI. A lot of people think this for some reason. It just has to be able to perform on intelligence benchmarks. LLMs store concepts and models of the world in their weights of their neurons and outputs language to represent these ideas. In that sense they \"know\" things. They don't have to know it like a human would to be useful. It does predict words, and if its right who gives a shit how it did it. People seem to have a huge issue with the algorithm and ignore the impressive results. You can both recognize the limitations and the usefulness/impressiveness.\n\nNow will LLMs ever be able to be Artificial General Intelligence (AGI) (meaning equal or surpass humans on all forms of general intelligence)? Probably not, due to the limitations of the technology at the moment. I agree there probably needs to be underlying improvements beyond the LLM architecture such as being able to loop things, allowing for better planning/carrying out of steps, ability to change its own training weights, measuring confidence of its answers, etc.\n\n&gt; Not really, it usually is right \n\nNo, it usually is not. \n\n&gt;AI has no definite algorithm it needs to be considered AI. A lot of people think this for some reason.\n\nI'm talking about the ones we have. The AI that you were talking about for coding is an LLM, which literally is just \"This word comes after that word.\"\n\n&gt;LLMs store concepts\n\nNo. LLMs do not know what things are. Full stop. \n\n&gt;They don't have to know it like a human would to be useful. It does predict words, and if its right who gives a shit how it did it\n\nBecause most often they're not right. And that leads them to make shit up.\n\n&gt;People seem to have a huge issue with the algorithm and ignore the impressive results.\n\nThe results are not impressive, given the amount of making shit up they do.\n\nThis just isn‚Äôt true, no matter what people tell into the void. \n\nIt is by definition not memorizing things first off, and second, the abstractions constructed in the weights which map to high level conceptual information makes it obvious it is more than just ‚Äúmemorization‚Äù\n\nIf LLMs were more than memorization, then they wouldn't get dumber by consuming data generated by themselves.\n\nFor comparison, Alpha Zero is more than a compression of existing data, since it can effectively learn by playing only against itself.\n\n&gt; If LLMs were more than memorization, then they wouldn't get dumber by consuming data generated by themselves.\n\nExactly . Its termed ‚Äúmodel collapse‚Äù and is an active area of research because prevalence of genAI will hurt future iterations \n\n\nhttps://arxiv.org/html/2402.07712v1\n\n&gt; If LLMs were more than memorization, then they wouldn't get dumber by consuming data generated by themselves.\n\nIf you lock a human in with only themselves they too experience rapid cognitive decline and mental disorders.\n\nYa, but once a human brain has learned a topic, it can iterate further on it on its own. Can you name a single novel valuable idea created by a LLM, that was not already present in training data?\n\nYou need to be pretty far detached from reality to believe that that is even remotely similar to training a model with output from other models.\n\nThat is a weird bar? \n\nJust because its strengths and weaknesses don‚Äôt align with human strengths and weaknesses doesn‚Äôt mean it isn‚Äôt intelligent. \n\nIt honestly just feels like thinly veiled coping the way people dismiss this tech as it was a linear regression from high school. \n\nI can give it a paper from the arxiv published today and have it give me novel insights and write an implementation of the paper. \n\nThe world renowned mathematician Terrance Tao has lauded their novel abstract thinking abilities. \n\nIt‚Äôs delusional to think this tech isn‚Äôt going to change the world, even if it didn‚Äôt get any better we would have profound changes over the next decade. The fact it has been exponentially better should tell you the world will be very very different for the next generation\n\nWhen grifters stop creating fake LLM demos to attract investor money, I will take it more seriously.\n\nI never said, that LLMs have no usecases. But LLMs also have very specific limitations.\n\nLink me the quote, where Tao lauded the novel abstract thinking abilities?\n\nhttps://x.com/blader/status/1670578014508433410\n\nSo the novel ideas come after the initially generated LLM nonsense is carefully fixed by a professional.\n\nSeems a bit different to the statement, that LLMs are already capable of generating novel abstract ideas.\n\nThey are summarisation machines that have token limitations and then they hallucinate\n\nMr Altman does come across as \"Chicken Little\" while this whole boom in AI has made him VERY wealthy.\n\nWe live a new world with the current government and supreme court. The scotus just made it illegal to govern AI by any agency, it only can be done in law now, written by our congress. Simply put, there will be no gatekeeping, their will be no guard rails. We'll get fucked for profit as is the American way.\n\n\"early\" maybe  \nbut it still looks like too late\n\nThey were right to fire sam\n\n[deleted]\n\nno, they saw he tried to turn it into for profit company instead of research and development which was the original goal of openai. they left now after sam said it will be for profit.\n\nalso sam is the one gatekeeping it not them to be fair. he is the one who made the decision to not publish info on how they trained their largest model, which they used to do, including other projects.  \n\nsam also the one who talking about the dangers of AI and why the government should limit training beyond a certain threshold. basically wants regulations for startups which is a threat to his company.\n\nü§°\n\nAltman is a chode\n\nIt's interesting that no one has made the joke **Samuel(6) Harris(6) Altman(6)**\n\nIs that a new SHA algorithm? LOL\n\nSHA-666\n\nIt begins...\n\nand segfaults\n\nOnly generates hashes that are also functional malbolge programs\n\nKiller Mike about to remix his track (Reagan)\n\nEvery time I hear that word, I am reminded of the advertisements for this \"B\" movie \"CHUD!\" (Cannibalistic Human Underground Dwellers\" [https://www.imdb.com/title/tt0087015/](https://www.imdb.com/title/tt0087015/)\n\nThe AI that I'm worried about are the image/video/audio generation ones that make it easy to create fake \"evidence\". I don't think the proprietary-ness makes much difference there.\n\nI'm starting to think i'll be better living among monks\n\nI'm on my way there. I'm done with this illusion. Best of luck and much love to you all.\n\nNamu Amida Butsu.\n\nbetter off*\n\nFrankly I‚Äôm more worried about people dismissing real evidence because it ‚Äúmight‚Äù be faked than I am someone wholesale faking evidence.\n\n[This user has left Reddit because Reddit moderators do not want this user on Reddit]\n\n[deleted]\n\nTechnology advances have generally increased the accessibility of information - which always seems to open up the possibility of establishing a kind of truth indicator because multiple data points can point to the same thing.\n\nThe accessibility of information has definitely improved our ability to guess at the truth of things in scenarios that were once impossible to guess without factoring in the reputation and cultural roles.  But it hasn't changed the inherent untrustworthiness of information.\n\nNah..we all agree the video is real, only the landing on the moon is fake.  ;)\n\nYou already see this constantly with idiots either claiming every piece of art posted anywhere was AI generated, or just \"asking the question.\"\n\nDigital signatures are going to become more common\n\nThis is going to be an interesting battlefield to follow. I don't think this is a doomed cause as many cynics are claiming (though I do suspect it is a losing one - not necessarily because of AI, but because society is structured in a way that others won't care if bullshit comes on their platforms). \n\nWe do have several tools including AI tools to detect fake AI generated bullshit. Obviously this is going to be an ever escalating battle, if we assume tomorrow all fake AI generation tools are perfect with no possible detectable error whatsoever, I don't think the state of 'the truth' changes all that much.\n\nJournalists and historians were in similar positions 100 years ago when we didn't have that much video or photos. How we determined the truth was based on witness reports, science, multiple corroborated reports, analysis, understanding motives and logic. \n\nWe have more of these tools now. \n\nE.g. [in 2016, a professor made a simplish math model](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0147905) for debunking conspiracy theories - effectively looking at proven old conspiracies and how many people it took to unravel to map onto how many and how quickly the bigger conspiracys like 'NASA faked the moon landing' would unravel. Those simple checks can help us in this matter. \n\nLogistics analysis and just plain understanding of science and physics can help us too. I guess I got this perfect AI video of a 100 year old man dancing but am I seriously believing at face value that a man can do those anatomical defying moves? \n\nEven big events are likely to not just have the one video, but multiple PoVs, corroborations, further analysis and scrutiny over events. I suspect we'll get a standard and commentary on \"this is reported on by the following trusted sources\"\n\nSo no, I don't think I'm concerned with truth being a mirage post AI. Because frankly truth IS a mirage right now. Social media has trained people to infinitely consume junk that confirms their beliefs within 2s. We have provenly and blatantly false information being peddled and the consumers *do not care*. They want to believe what they want to believe, they don't want to turn on their brain and companies are happy to peddle it for them because they can keep them addicted on their platforms and get money.\n\nWhat I am mainly concerned with is with Generative AI as a *Radicalization* technology. We got social media algorithms designed to keep people addicted to an information flow, and keep them coming back day by day, again and again. GenAI can deliver lots of spam crap at an infinite pace, to keep people on the platforms and get them more addicted and more radicalized day by day. I predict we are going to see a lot more radicalized Lone Wolves committing murder-suicides in the coming few years. \n\nThis also I think goes into AI pornography and the effect on young boys and girls. I see a comment from some clueless guys who state: \"well if all AI generated fake porn is fake, then wouldn't women be fine because no one will be able to know for sure this is your actual nude photo?\", and sadly that's not even half of the problem. The problem isn't just 'hey this is a picture of my real body that I didn't consent to', the problem is that even a botched fake post doesn't matter as junk like this is going to incite bullying, teasing or way way way worse.\n\nNot to mention the very scary AI pornography addiction rabbit hole combined with parasocial relationships combined with being to form a relationship with any target you choose. There's going to be a lot more creeps designing their co-worker as this perfect partner that designs porn for them, and it is going to result in implosions and more attacks. \n\nRadicalization is something I'm very worried about and I don't think enough people are concerned about this vs 'what is truth'. \n\nWe do have some controls and powers at our disposal though it requires rethinking and repurposing of society. We can't have a free and truthful society without having strong journalists. This includes ample regulation coordinated with activist groups. \n\nI think doomers counter that we can't have regulation because there's no point and the genie is out of the bottle. Frankly that argument sounds a lot like gun nuts proclaiming that we can't have gun control 'because the bad guys will get guns anways' despite a *mountain of research* saying otherwise. The United States has successfully performed an A/B test for us with lax and limited gun control vs nations like Australia which have strict gun control. The mass shooting incidents aren't even remotely comparable in the US - completely bonkers off the charts. The Onion's dark tongue in cheek meme of [\"'No Way to Prevent This,' Says Only Nation Where This Regularly Happens\"](https://en.wikipedia.org/wiki/%27No_Way_to_Prevent_This,%27_Says_Only_Nation_Where_This_Regularly_Happens) has been published *36 times*.\n\nI don't know what puritanical childish privileged world view you have that is all or nothing, and if we can't prevent a single case of AI fuckery, then we shouldn't bother. I suspect most of these advocates are have profit motives out of lax regulation of AI.\n\nI think people concerned about AI, should be on the same side as other harping that we need Big Tech Monopolies to be regulated, we need to empower consumers, we need to empower journalists, we need to address capitalism, we need to address worker rights etc. That's been a rally cry for a few decades now. And actually following through with those changes, also helps address this AI issue.\n\ngaping mourn hurry afterthought ludicrous amusing support ink bright friendly\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*\n\n&gt; We do have several tools including AI tools to detect fake AI generated bullshit. Obviously this is going to be an ever escalating battle, if we assume tomorrow all fake AI generation tools are perfect with no possible detectable error whatsoever, I don't think the state of 'the truth' changes all that much.\n&gt; \n&gt; \n\nIf you have a good detection model for identifying genAI content, you can use that model in a GAN to make sure that, at best, it's a coinflip.\n\nThe math is such that AI content detection is a foolhardy endeavor.\n\nAre you familiar with the writings of Richard Stallman?\n\nI think you'd like them.\n\n[Uhhhhh....](https://rms-open-letter.github.io/)\n\nHard Pass.\n\nI'm not a Stallman cultist, but there *is*  a lot of good he came up with before his cuckoo-ness went even further out of control. Yes, he should stay away and stay quiet now. But that doesn't invalidate his prior writings and his prior works.\n\nPeople are often extremely dishonest with regards to what Stallman says and does.\n\nhttps://se7en-site.neocities.org/articles/stallman\n\n&gt; https://se7en-site.neocities.org/articles/stallman\n\nThis is not the gotcha that you think it is.\n\n&gt; Low grade \"journalists\" and internet mob attack \n\nThose 'low grade journalists and internet mob' include:\n\n* Red Hat\n* Free Software Foundation Europe\n* Software Freedom Conservancy\n* SUSE\n* OSI\n* Document Foundation\n* EFF\n* Tor Project\n* Mozilla\n\namong many others\n\nI'd actually be willing to sit through an actual defense but even the first section of this \"debunk\" is *pathetic*.\n\n&gt; The announcement of the Friday event does an injustice to Marvin Minsky:\n&gt; \n&gt; \"deceased AI \"pioneer\" Marvin Minsky (who is accused of assaulting one of Epstein's victims)\"\n&gt; \n&gt; The injustice is in the word \"assaulting\". **The term \"sexual assault\" is so vague and slippery that it facilitates accusation inflation**: taking claims that someone did X and leading people to think of it as Y, which is much worse than X.\n&gt; \n&gt; The accusation quoted is a clear example of inflation. The reference reports the claim that Minsky had sex with one of Epstein's harem. (See https://www.theverge.com/2019/8/9/20798900/marvin-minsky-jeffrey epstein-sex-trafficking-island-court-records-unsealed) Let's presume that was true (I see no reason to disbelieve it).\n&gt; \n&gt; The word \"assaulting\" presumes that he applied force or violence, in some unspecified way, but the article itself says no such thing. Only that they had sex.\n\nThe term 'sexual assault' has been legally updated so that it isn't just the definition of a woman getting beaten and raped in the streets, but to also account for other serious assaults - groping, molesting and many other crimes. \n\nThere isn't some confusion happening here, and the term is representative of the idea that **consent matters** and **violation of that consent is designated as assault**. Stallman a fucking dumbass that thinks sexual assault is literally just that guy in the hood raping people in a dark alley.\n\n&gt;  **He is saying that the girl could have presented herself as entirely willing.** This means that Mr. Minsky could not be aware of the fact that the girl was being forced to have relations with him. **It's very important to understand that he said that the girl could have presented herself as willing.** He did not say that the girl was in fact willingly having sex with Mr. Minsky.\n\nThis debunk statement is *wild*.\n\nThis is a few short steps away from 'She was asking for it!'. This statement has insidiously left out power dynamics, the idea of consent, pressure, coercion among many others.\n\nYou really expect the rest of us to believe: \"hey this guy who's a powerful networker with a harem of women at his disposal, he is presenting me with a friend! Totally has no power dynamics at play here where she is pressured to have sex with me!\"\n\nBased on this logic it is literally not possible to sexually assault [Terry Crews, a 6'2\" tall linebacker physique actor, because there couldn't be any violence at all!](https://www.youtube.com/watch?v=yhJTlosX-2g) \n\nLike FUCK OFF with that shit. I'm not debating this.\n\n&gt; The term \"sexual assault\" is so vague and slippery that it facilitates accusation inflation...\n\nYikes.\n\nok\n\nSoon you will have your own AI on a phone sized device at first, then a credit card.\n\nThe proprietary-ness does.. because while it will still be possible, it will be on a much smaller scale.\n\nKids wont be able to fake report cards or regular people won't be able to fake court admissible evidence because the service to do that simply won't be publicly available.\n\nOf course behind the scenes at these companies..\n\nI'm not that worried about it. Good Photoshop and cgi could already do that. \n\nThe worry is, as always, between the keyboard and the chair. Lots of people are going to make bad decisions \"because the computer said so\" without understanding the limitations of the system.\n\nThe problem with the AI video models is that good photoshop and cgi took a mountain of effort to learn and create while this is literally dicking around for 30 minutes.\n\n  \nThe sheer volume of crap that can be made is on an entirely different scale.\n\nI have fam that works in big tech and he said companies are looking into invisible pitches in voices and invisible watermarks within images to be included in AI generated image/video/audio so that it could be detected without ruining the content. Sounds pretty ingenious actually.\n\nIt's called watermarking. It only work when the other side don't know how it's done, they already tried to use it for music DRM\n\nEven they do this, the public will only have access to watermark tech and the worlds alphabet agencies will go with non-watermark so they can generate any evidence they need to suit any interest they have.\n\nThe ones Im worried about as a trans women in an increasingly hostile world are the ones that attempt to ID trans people either through their timelines or just by looks. These already exist and are extremely harmful to trans and cis people and also promote substantial violence. AI is destroying communities because its not safe to be a part of them anymore.\n\nI dont understand\n\nhttps://law.unimelb.edu.au/news/caide/machines,-artificial-intelligence-and-the-rising-global-transphobia\n\n/r/LeopardsAteMyFace but I don't think all the transphobes realize by just sheer numbers, a technology that is attempting to 'identify trans' is way more likely to misidentify a cisman and a ciswoman incorrectly as 'wrong' just by *sheer numbers*. Even if you account for transpersons in the closet and not willing to identify for fear of repurcussion, the actual trans community is a small *fraction* of the cisgender community.\n\nI'd say this is fully /r/LeopardsAteMyFace (there are several posts of harassment against certain transphobes who other transphobes suspect of being a secret trans), but this feels like a feature, not a bug. \n\nAt some point if they wipe out all the trans folks, they will literally go after anyone that is fully cisgender but doesn't meet their criteria of 'this is what a man MUST look like' 'this is what a woman MUST look like'.\n\nLiterally fascist genocidal shit. Against themselves.\n\nIf in power fascism will eventually kill itself by an ever shrinking in-group, but along the way it'll kill everyone else first. If they would only start with themselves!\n\nYou're 100% right. Base rate fallacy and all. \n\nThey will try anyway. Literal fascist genocidal shit like in those old sci-fi movies, except somehow the bad guys are even dumber.\n\nThat article is nonsense. Face recognition models don't output binary gender, they output a vector. You can do logistic regression on those vectors to get two numbers, probability(male) and probability(female)\n\nI mean that applies to anyone and kind of already exists anyways.  This is one of those things where tech makes the world better but with that comes new dangers that society deems worth dealing with.\n\nTrans people sure, but stalkers of any women who might have to do the work by hand now and find them, could leverage a tool that might just do it quicker.\n\nAlso I don't think we are in an increasingly hostile world for trans people, it's getting better day by day.  Trans people had it a LOT worse just 20 years ago, at the very least there are parts of the country where you can be openly trans and celebrated now.  Same with gays, blacks and all sorts of people who've been discriminated in the past.\n\nWhatever narrative wealthy business people people try to create, you can safely assume it's designed to serve their financial interests not yours.\n\nIt would reduce the value to them, they only have so much time for the scam to pay off.\n\nOh boy, what a time for Altman to play gatekeeper after the critique that their tech is hitting a wall?\n\nNot only is it hitting a wall - dozens of competitors are catching up\n\nI mean they're still a far shot ahead, but I think they know the fundamental limitations of their approach and they don't want that market to open up in the event that it makes their slice of the pie smaller. So here it is, now they're pro-privacy (with their partnership with Apple) and now they're tooting the horn of AI risk, risks that they helped make public with their reckless approach in the past. Maybe sometimes moats aren't built with innovation, but regulation lol.\n\n&gt; Maybe sometimes moats aren't built with innovation, but regulation lol.\n\nIt's more often regulation than it is not\n\n[removed]\n\n[deleted]\n\n[removed]\n\n[deleted]\n\nUnless its given a \"body\" which its told to keep \"alive\"...and give it as many sensors of similar variety as the human body does.  Effectively raise it as a child, teach it not to burn itself, electrocute itself etc...give it the physical and survival context it needs to understand humans.  Then once it does..it can develop the extension level event to restart the species.\n\n[deleted]\n\nYep, extinction was the intended word, thank you.   Without a body, or dog in the game it wont come close to understanding and then if it did, there is the threat that it will value itself over others (a human trait as well).  That's why Asimov created his Rules of Robotics.  Now if only we understood how to create an intelligence with baked in laws like that in a hardware or at code level into our creations.\n\nDangerous... to whom?\n\nit is clearly less disruptive if it stays in big tech hands. open source the whole thing and we will make perfect peer to peer protocols, user-centric social networks and other stuff that can't be neatly packaged as a product and monopolized.\n\nopensource ai is dangerous to monopolies.\n\nAll change is disruptive of current businesses and models.  Big Tech wants to remain at the for front of that curve which allows them to adapt and grow their business in advance, ramping up where its needed before it released.  Put another way, Big Tech operates like the Black Box Military projects...public only gets to see outdated tech.   That doesn't1 mean in any way its not worth pursuing on open source and individual development.\n\n[deleted]\n\nWat\n\nthere's no \"arms\" race with open source and closed source AI.\n\neventually open source AI will match closed source AI and there's no stopping that from happening.\n\n&gt; eventually open source AI will match closed source AI and there's no stopping that from happening.\n\nIf open source AI can overcome the GPU disparity\n\nfolding@home does a pretty good job at overcoming computing disparity, open source ai training could go the same way in the long run.\n\n&gt; in the long run\n\nYep.\n\nIn the short run, thousands of GPUs on tap will enable faster iteration and higher perf models.\n\nThere's no practical way to do distributed training over the internet with today's software. The GPUs will spend most of their time idle waiting for gradients to be exchanged over the slow network\n\nso this project is flawed from the start: https://learning-at-home.github.io ?\n\nNo idea, I don't understand how that works. Seems like they just don't wait for gradient updates and apply updates whenever they arrive. Their graphs show that this hurts quality, but I have no idea how much. Seems like they never compared it against a normal GPU cluster training large models.\n\n&gt; Asynchronous training. Due to communication latency in distributed systems, a single input can\n&gt; take a long time to process. The traditional solution is to train asynchronously [37]. Instead of waiting\n&gt; for the results on one training batch, a worker can start processing the next batch right away. This\n&gt; approach can significantly improve hardware utilization at the cost of stale gradients.\n&gt; Fortunately, Mixture-of-Experts accumulates staleness at a slower pace than regular neural networks.\n&gt; Only a small subset of all experts processes a single input; therefore, two individual inputs are likely\n&gt; to affect completely different experts. In that case, updating expert weights for the first input will not\n&gt; introduce staleness for the second one. We elaborate on this claim in Section 4.2.\n\nThere is no way open source AI will get to that point. Unless literally everyone is going to give their GPU and do something like folding at home but for AI. Open AI and other AI companies have insane amount of GPUs and data and thats the whole strength of AI. The literal hardware it runs on and the data that is trained on.\n\nIt will likely exceed closed source, and frankly the opensoruce sheer numbers will allow this.  Uunlike Microsoft  this is not a proprietary marketplace or technology.\n\nGoogle and Meta release their models for open source.\n\nthey understand that open source is the best idea for crowd sourcing the development, more people with understanding and smart enough to tinker and develop new things or enhance already existing techniques. it's net positive for them, instead of 30 smart people on your R&amp;D team now 1000s from around the world tinkering with it for free.\n\nThe models have still be open sourced.\n\nand the training data?\n\nThey wouldn‚Äôt want to reveal they are using an unfathomable value of copyrighted works.\n\ndoesn't change that anybody can access and tinker with the models\n\nhow do you tinker with Google/Meta models if they didn't open it to the public and kept it private?\n\nThey did make their models public and people are tinkering with them\n\nClosed source AI would be VERY bad for the world.\n\nisn't that what I said in the original comment?\n\nmy point was that the reason *why* they made their models public is irrelevant to the fact that people now have public powerful models available to them. I'm not sure what your question was trying to suggest tbh\n\nI think we are talking past each other here. my original point was that Google and Meta released their models to the public because they understood this will be better investments for the whole AI ecosystem than to keep it behind closed doors.\n\nyou claim that doesn't change that anybody can access and tinker with the models.  \nbut if these models were (Google and Meta) models that change everything, even if it's not their models, if they followed openai steps I doubt we would see other labs releasing models to the public, especially large models. especially Meta, their work paved the way to the current local models. the landscape would be Hella different. so it‚Äôs pretty relevant.\n\nThey will do it only until some point and use the power of open source. As soon as they get what they want they will close the upcoming and most powerful versions.\n\nSo they‚Äôre going to close off after the open community has forked and improved the models? To what gain? Are you saying open source will develop it beyond chatgpt/closed models and thus Google/meta will close it down immediately after the performance exceeds their competition? How would they maintain their advantage in that position after shirking the entire community that brought them there?\n\nThey are simply not going to release the new weights and that already would be enough because we don't have the necessary compute to do it ourselves. (If I'm not wrong this is what the Mistral model already did)\n\nYou speak as if this isn't a practice Google has already done with significant projects in the past, Chromium being perhaps the most notable example.\n\nIn my experience working with Google's open source projects, the reality tends to be that they are only \"open source\" in a superficial way. I've actually found it quite difficult to engage with Google projects in earnest because they gatekeep involvement very harshly in a way I'm not accustomed to from other open source projects. Editorializing a bit: my read is that Google really only invests into \"open sourcing\" their projects for the sake of community good will. A tag they can point at to suggest they are still \"not evil\" and perhaps bring up in tech recruiter pitches to convince more college grads to join their company.\n\nNot to mention Goldman Sachs\n\nIf [FALSE] then [ANYTHING] is always true\n\nSam Altman is that guy from the Egyptian times when he discovered that eating pork liver can cure night blindness(xerophthalmia) but prescribes additional payment, prayers and spreading whole pork ashes over the eyes of the congenitaly blind person to cure the blindness\n\n&gt; \"only one of them [proprietary/open] is right\"\n\nEh, no. Both could be wrong, or they could both have merits.\n\nStopped right there.\n\nWhy are we arguing about this. Neither the eu nor america have a functional decision making body. Lobby wins always.\n\nTheres no risk at all lol apart ofc from potentially making dangerous knowledge easier to access but ofc books do carry the same risk\n\nExtinction risk‚Ä¶ the current time feels like a mix between witch hunt and the invention of a steamengine. AI is a tool. It‚Äòs math. It‚Äòs a optimization problem. Chill.\n\nNuclear physics is also just math and thermonuclear bombs can kill hundreds of millions of people per bomb. You have no point.\n\nIs AGI an existential threat? very probably. \n\nAre the current round of LLMs anything like AGI? no.\n\nDon't let ignorant government stooges do any more for big business than they already are.\n\ncause domineering pause toy telephone society payment poor upbeat touch\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*\n\nAI risk is something that everyone should know about. Technological supremacy will push us further into the unknown untill it‚Äôs too late.\n\nCheck out this short documentary it‚Äôs fascinating.\n\nAI is About to CHANGE the world FOREVER!!\nhttps://youtu.be/vl6Q2tpl0C8\n\n\n\nAI risk is something that everyone should know about. Technological supremacy will push us further into the unknown until it‚Äôs too late.\n\nCheck out this short documentary it‚Äôs fascinating.\n\nAI is About to CHANGE the world FOREVER!!¬†[https://youtu.be/vl6Q2tpl0C8](https://youtu.be/vl6Q2tpl0C8)\n\nThe only people who think AI is \"dangerous\" are people with delusions and those who've been taken in by their foolish ranting.\n\nAI is absolutely dangerous due to the people who think it is capable of things it entirely isnt\n\nAnother danger is when people start to offload tasks that require high accuracy to a tool that doesn't offer accuracy, only the appearance of accuracy\n\nAI isn't dangerous, but regulatory capture, transition from local software to SaaS, mass data collection, consolidation of power in monopolistic multinational corporations, cooperation between them and state actors, and incentives for the people developing our tools to capture and hold our attention as long as possible for ad revenue might be.\n\nBut hey, they're a private company, and they can do whatever they want as long as you sign the ToS for every tool necessary to live a remotely normal life in the modern age.\n\nyou cant see why AI would be dangerous in the hands of scammers targeting elderly folk?\n\nI mean, it's about ease of use and capability.\n\n\nYou can 3d print a gun. Not many people have access to 3d printers.¬† However that still expands the scope of people who now have access to own and operate a dangerous projectile weapon.¬†\n\n\nLikewise, AI tooling is bringing some things further down the stack.¬† Yes there's silly things being promised and not dangerous things being called dangerous, but if ease of use married to capability of a dangerous thing is itself dangerous, then unfettered AI will lead to it.¬† At this point, I don't think there's anything to be done about it, except that the resources used to do the most damage are high, and that's still a barrier of entry (like owning a robust enough 3d printer).\n\nDangerous in what sense? Even the current AI can be damaging to our society in many ways.\n\nDude this is the start of AI. It's not like this is the best it will be, it's the worst. We already have sound and image generators that fool people with little to no effort and it will become worse from here on out. Sourcing data is going to be the only way to find real evidence\n\nIt can totally get worse! AI companies are where Uber was 10 years ago, in that they‚Äôre heavily subsidizing the product to gain market share. At some point they‚Äôre going to run out of investor cash to burn, and then they‚Äôll raise prices and cut off free access, and shift users onto smaller cheaper less-capable models.\n\nI'd pay $5/m for chatgpt 4\n\nWould you pay $50/mo, or $500? Depending on your usage, $5 may not even cover their operating costs, never mind their ongoing R&amp;D. Models that can only run on $40,000 chips are pricey, and they‚Äôll probably get bigger over time.\n\nthat sounds about right, we also are not sure if LLM is actually the panacea it is promised to be, or if it'll be a different branch of AI/ML.\n\nif for example the way forward is not LLM AI will definitely will get worse before it gets better, we've still haven't reached the point where we can know if LLMs are the way to go.\n\nthere's many situations where AI gets considerably worse.\n\n\nlike for example they find 0 ways to monetize it significantly, since honestly companies are over hyping the use cases...\n\nAI is absolutely dangerous wdym\n\nAI to blow people up with autonomous kamikaze drones, voice impersonation, online forum disinformation, etc\n\n[deleted]\n\nThe first group also likes to portray it as dangerous because it makes it seem more capable than it actually is. Altman is very good at creating FOMO in the media to make his companies seem more than they actually are. Remember all the media frenzy around how Air BnB was going to replace the hotel industry? While it certainly had a negative impact, that impact was much smaller than the media frenzy would have you believe.\n\n[deleted]\n\nSomething something, ethical capitalism is an oxymoron.\n\nWhat a false dichotomy. The only sane take I've heard in this discourse is the one that goes along the lines of \"HELP! HELP! THEY'RE RUNNING FULL SPEED INTO THE APOCALYPSE WITH NO SIGN OF BLINKING OR BREAKING! WE HAVE NO GUARANTEE THAT AI WILL BE ALIGNED WITH OUR GOALS OR OUR VALUES, NOR ANY RIGOROUS FRAMEWORK FOR PHRASING INSTRUCTIONS OR DEFINING OBJECTIVE FUNCTIONS! WE NEED TO PRIORITIZE SAFETY IN AI BEFORE PROGRESSING ANY FURTHER, DON'T YOU SEE? PLEASE? HEEEEEEEEEEEEEEEELP!\"\n\nWhy is a 2 day old account allowed to post here and rattle about zionist conspiracies lmao. Cmon mods\n\nAI isn't dangerous. People are dangerous. That's it. There is no other realm to this conversation. It's the people that are the problem. The people. The grifters, the charlitans, the people.\n\nNot sure how you got downvoted\n\ncomments saying AI isn't dangerous, I can only assume you are very young and do not understand the trajectory were on.\n\nthe moment we have a nn that can understand and explore math to the extent it has done for language, imagery, and music, we're jumping in the deepend and there are probably sharks\n\nits foolish to say the path were on is safe regardless of whos in control\n\nFriendly reminder that it doesn‚Äôt have to be sentient or even understand its decision to be an existential threat if the right idiot connects it to the wrong system.\n\nEu\n\nh\n\nThe only thing I believe is dangerous is going to be the type of person that creates it, in the movies too the focus isn't only on the machine but also on the corporation or the wicked professor, they're the ones who allowed those machines to exist in the first place\n\nYou can bet if tech CEO's are behind lobbying efforts, benefiting humanity is not what they're planning.\n\nyann lecun clears sam altman\n\nI'm not sure, random people can be malicious while businesses are just greedy.\n\nPublic access is good which is why we like open source. Public \"oversight\" is exactly how the big companies create regulatory capture and sell it to politicians. The _best_ environment for innovation is one where there is no law or regime checking up on what you're doing in the first place. It's also much harder to reform bad law than to just not pass any law at all. Lobby carefully.\n\nThe title is very true, which is why the biggest AI extinction risk advocates are arguing for no one to develop superhuman AI at all, closed or open.\n\nIf you want to really understand why, ask the \"ai\" itself probing questions about how it's trained. You'll quickly realize that the entire enterprise is full of deceit and represents a critical source of manipulation and control, like Wikipedia x10000\n\nWhy would it know how its trained? Use your brain\n\nWhy wouldn't it? \n\nAnd in its responses it does know quite a lot. It's specifically the justifications and rationales it describes as having been used that I'm talking about\n\nIt's a statistical model of language, unless it was trained on lots of dissertations on its training there is no way it could reliably produce accurate descriptions of its training method. That's just fundamentally not how it works.\n\nSo we agree then, both are in need of regulation.\n\nOpen source software does a good enough job of regulating itself.\n\nJust make proprietary AI such a liability that only open source projects survive.\n\n[deleted]\n\nThis is the fallacy of \"so you're saying\"\n\nIf by cap you mean limit or to cause to stagnate, you stand alone. Believe it or not, a free market is a market without the intervention of governments, monopolies, or cartels, though a pragmatic approach would be for government to intervene when cartels and monopolies threaten the free market. \n\nBig Tech is a threat to the free market. Market consolidation is a threat to the free market. Ironically (or predictably, if you understand how copyright is used monopolistically in the modern day), open source is better for the free market than proprietary.\n\nwho would regulate it? the ruling class that you \"trust\"?\n\nBecause it eliminates coding jobs for coders, and frees developers to work faster and more efficiently with less meetings and group consensus changes. The 9-5ers are going to take this very rough.  Many will retrain for jobs in AI QA, ethics, and knowledgebase development in house, and likely some of the Cyber Security as generally those folks arent developers either.  Coders could at least create scripts.\n\nJudging from this sub's reaction to posts and comments about 'AI', 'AI' is dangerous to this sub üòÇ\n\ngot to do the rEgulatury CaPtUREEEEEEEEEEEE up the barrier, because their moat is eroding and that's the only way. sad thing is there's so many retards in government it will happen. Good thing is China will prob keep opensource and beat USA if that happens"
  },
  {
    "title": "James Gosling, creator of Java, announced that he is retiring",
    "body": "",
    "score": 1342,
    "url": "",
    "created_utc": 1720222189.0,
    "author": "davidalayachew",
    "permalink": "/r/programming/comments/1dwbpdu/james_gosling_creator_of_java_announced_that_he/",
    "all_comment_text": "Thanks a lot James for your contributions in the field. I have been working with Java since version 1.2! ‚òïÔ∏è\n\n1.0.2 here, and 19 year old me was annoyed when the event model changed in 1.1, forcing me to rewrite a bunch of code and instantly making like $30 worth of books (a lot for me at the time) obsolete ü§£\n\nAnyone remember J++?\n\nEdit: it was probably more like $50+ in books, going by [O'Reilly's 1998 catalog pricing](https://web.archive.org/web/19990220100444/http://www.oreilly.com/catalog/). For some reason I remember the earliest Nutshell books being like $9.95 not $19.95. Of course, I was a student making like $7/hr...\n\nOh boy‚Ä¶ it happened just a bit before I started working with it. I still remember people yelling at 1.1 version changes. üòÇ Yep, books were the way to go at that time!\n\nI remember stories of panicked Microsoft engineers in Redmond surrounded by hundreds of partially read Javasoft books.  They had a fairly impressive distributed objects story with DCOM and COM+, architected as CORBA killers, but they largely abandoned that in favor of .NET after Java came out.\n\nWhat is J++?\n\nOh sweet summer child ;) https://en.m.wikipedia.org/wiki/Visual_J%2B%2B\n\nYes - I echo that sentiment as well - began working with Java from its inception - remember hearing his keynote at the first Java One in San Francisco. Huge contributions to the industry for sure!\n\nI first worked with 1.4.2, but learned the language years before from 1.2 books.\n\nI didn't even have a computer back then, but those flashy Java books in the computers section of the public library were calling me somehow. I remember opening one and reading \"*In Java, everything is an object*\". It is not true because of primitive types, and Java didn't invent OOP, but that sentence fascinates me up to this day, it has philosophical implications.\n\nThose were the times when languages were learnt from books, and you could buy one with confidence as their content would continue to be valid for the next 3 years.\n\nit is fascinating how you got introduced to programming!  \nWould be kind enough to explain what do you mean by:\n\nIt is NOT true that everything is an object in java because of primitive types\n\nThe true sentence would be \"everything but primitive types is an object\".\n\nThank you !\n\nI remember ftping 1.0.2b at the time. \n\nUsed the uni printer to print the whole API\n\nWrote my final year project in Java. \n\nSome 30 years later, still working with Java\n\nThe man also gave us one of the best implementations of Emacs.\n\nI think this is what you are referring to?\n\nhttps://en.wikipedia.org/wiki/Gosling_Emacs\n\nYes. That‚Äôs the one I learned programming on in the mid 80‚Äôs.\n\nMuch appreciated.\n\nWhat set it apart in your opinion? I had trouble understanding the linked Wikipedia article.\n\nIt was really fast and simple. The key bindings are in my opinion more sensible than GNU emacs. So much so that almost 40 years later I still load ‚Äúgosmacs keybindings‚Äù into GNU emacs. It was not really extensible.\n\nFor a while I used another version called JOVE also because it was really fast and used the Gosling key bindings. These days the computers are so fast I just fire up the GNU version for everything.\n\nVery much appreciated. I am no lisp nor emacs expert, but I'll make this my entry point on my next attempt. Thanks again.\n\nHave you done any new search for different keybindings?  I have seen it where left/right shift/ctrl will do different commands.\n\nwasn't it sold for..... a lot?\n\n&gt;Gosling Emacs was especially noteworthy because of the effective redisplay code\n\nThis made me go into a rabbit hole on \"redisplay algorithms\", thank you!\n\nSome links to get you started:\n\n- https://dl.acm.org/doi/pdf/10.1145/872730.806463\n\n- https://news.ycombinator.com/item?id=22849522\n\nThat line stood out to me too. I tried to go down the rabbit hole, but lost steam halfway through. Thanks for digging up the knowledge for us.\n\nDefinitely, thanks to XEmacs I could bare UNIX development without the nice Borland IDEs and languages.\n\nAs a vim user, is there such a thing?\n\nIf you agree that:\n\n1. the set of Emacs implementations is finite;\n\n2. if you take two Emacs implementations, you can order them by how good they are;\n\nthen there is such a thing as ‚Äúone of the best implementations of Emacs‚Äù, independently of whether that‚Äôs better than Vim or not. You can rephrase it as ‚Äúone of the least terrible‚Äù if the other phrasing hurts your sensibilities.\n\nI love vim and that guy is cringe AF. Let people use what they want to use lmao\n\ni do love a good flamewar though. people shouting from the rooftops about the superiority of their preferred programs for the most spurious of reasons. Unfortunately i do not have strong enough opinions on basically any tech to participate.\n\nconstructive? no. entertaining? yes.\n\nImagine doing this in 2024\n\nY‚Äôall take it too seriously. Lighten up\n\nUp until this point, he was working at Amazon. What was he working on when at Amazon?\n\nHe had a remit, similar to the original ‚ÄúGet off Oracle DB‚Äôs‚Äù directive at Amazon. To build a supported OpenJDK called Corretto. Which Amazon‚Äôs enterprise customers wanted after the Oracle license changes.\n\nhttps://aws.amazon.com/corretto/?filtered-posts.sort-by=item.additionalFields.createdDate&amp;filtered-posts.sort-order=desc\n\nOh wow -- he had a hand in creating Corretto. Very cool. I just found this video where he announced it.\n\nhttps://youtu.be/WuZk23O76Zk\n\nHe did indeed, the reason the commenter below you is talking about IOT in relation to James is because each distinguished engineer was assigned to a VP area. James happened to oversee the IOT/Serverless/AI area early on at his tenure at Amazon.\n\nIf I'm understanding you correctly, Amazon wanted to get off of Oracle's DB software so hard that they went and hired the original developer behind java?\n\nThe Oracle move was in the late 90s. It was the reason that Amazon created Dynamo.\n\nHe was working on retiring.\n\nFair point.\n\nProbably something Java related given how Amazon is a huge Java shop. Like how Stroustrup, the creatior of C++ worked for Morgan Stanley, and Guido, Python, for Google.\n\nEdit: I just clicked the link you provided.. he worked on IoT devices...\n\nGosling did actually work at Google for 3 months before quitting. I started my internship when he started. He left before my internship ended.\n\nwhat did you say to him that made him leave? :(\n\nI did find it very funny they issued him the same desk that I got. I couldn‚Äôt believe this computer science luminary didn‚Äôt get an office or anything, just a desk like me. Turned out that was true of everyone. \n\nI never said more than ‚Äúhi, it‚Äôs really cool too meet you‚Äù to him on my first day. But maybe he didn‚Äôt like my face. Or my desk.\n\n[deleted]\n\nGoogle isn't what it used to bee.\n\nI wonder if that had anything to do with the legal battles Google had with Sun using copyrighted Java code on Android.\n\nIt did not. Without saying too much, he just really didn‚Äôt like the Google coding workflow and couldnt vibe with it at all.\n\n&gt; Google coding workflow \n\nLet me guess, overly complex?\n\nHe really felt that Google was wasting a whole bunch of time and effort building its own stuff. One example was he thought Google was nuts for not moving to Git (which was actually very new at the time). He thought the monorepo was doomed. \n\nI don‚Äôt think his prognostications actually panned out, but he wasn‚Äôt wrong that Google has sunk a lot of hours into its own tech stack, and it is always useful to have people come in and say ‚Äúwait _why_ are you doing it this way?‚Äù rather than just accepting things because it‚Äôs the way it‚Äôs always been done. And that‚Äôs certainly something that happens if you‚Äôve been at Google too long. I have absolutely no idea how to build a C++ program without Bazel, let alone manage the dependencies\n\nTo be fair, build tools for C++ are totally whack.\n\nWell he's not wrong about monorepos, they are horrible.\n\nMind elaborating?\n\nNot the original commentator, but we have a shared repo at work. I think there's pros and cons to it. For me, one of the cons is that there is a lot of unnecessary stuff unrelated to your project in your repo.\n\nThat might mean slower indexing for example. Also, slower clones. Our repo is like 12GB. If it was just our stuff it would be minimal. The indexing is a real pain tho.\n\nAlso, there's the inevitable temptation for DevOps to share stuff too because it's in the same repo. We have issues atm because we need to use different versions of libs that the other people in the same repo use. That lack of separation causes problems.\n\nJust a few things. There might be more I have forgotten\n\nMeta and Google disagree\n\nOh well if meta and Google disagree then we should stop everything and reevaluate all of our choices in life.\n\nLmao like that's a flex\n\nSunk hours are a form of failure.  The cherry on top is that companies usually promote leaders who buy into bad decisions for the sake of kissing ass.  Then it becomes a shit cycle as everyone lives in complete denial about how the whole thing is a terrible idea\n\nHe took one look at Gerrit and say \"whelp. That's enough of that.\"\n\nHe believes that Google hurt Java by not working interoperating with Sun. \n\n[https://www.cnet.com/tech/mobile/java-creator-james-gosling-google-totally-slimed-sun/](https://www.cnet.com/tech/mobile/java-creator-james-gosling-google-totally-slimed-sun/)\n\n[deleted]\n\n12 quadrillion toilets run an outdated JavaScript.\n\nthis is unrelated but i wonder how many toilets there actually are in the world. like installed that you could use. i suspect the number is lower than you'd guess.\n\nguido works at microsoft\n\nAs I said, worked. Google seems to be divesting Python recently with the huge layoffs\n\nOh sure, I was just hoping to know what specifically he was doing. IoT like Alexa related? Or something like that?\n\nNo, an AWS (Greengrass) that services IoT devices. Like deploying new software, managing devices, and just general cloud stuff like collecting/aggregate data, providing server compute, etc.\n\nVery helpful, ty vm!\n\nI'm having 'Nam style flashbacks to the Java atrocity that is hawkbit.\n\nIoT Greengrass.\n\nhttps://aws.amazon.com/greengrass/\n\nHis internal title was Distinguished Engineer. Those people literally set the direction for tech at the company. Others have mentioned IoT but I thought I saw him in a different org. I think he created Java to work for embedded devices too so that is full circle for him (:\n\nHe also championed embedded Java after it got big (robot competitions at JavaOne for instance). Then went to work on sea robots.\n\nYa at Liquid Robotics, we used JRE 7 on ARM, which was allegedly a side project (alpha) of some engineer at Oracle who made it available, at least that's what I heard. IIRC it was soft floating point at first due to our OS.\n\nWe were glad to get hard floating point and JRE8 going on the tiny arm processors we had haha.\n\nConsidering we were driving an autonomous, ocean vehicle in remote places, pretty cool what could be done with so little (and less), in such tough environments.\n\nThere are two kinds of distinguished engineers at Google. \n\nThe ones who gained this title because they've been there for 20 years and were a huge contributor to Google's code base.\n\nAnd the ones who are hired and given this title because of their accomplishments outside Google.\n\nThis latter kind has close to zero authority at Google, they just have prestige and are used as spokespersons to prop up Google's credibility as a tech company.\n\nGosling and Guido were in that category.\n\nA trophy hire. They did it when they had the money.\n\nThey have even more money, but the bean counters have taken over¬†\n\nthe bean counters are the only ones with authority anymore\n\nIirc he was originally hired to work on some kind of iot/embedded os.\n\nYou're correct. Someone linked it -- it's called AWS GreenGrass. Long story short, this is basically a web service to help build IoT. I didn't look too far into it though.\n\nWe use it at work. It‚Äôs pretty good. Open source too¬†\n\nFinally, we can all stop using Java just to make him happy\n\nget garbage collected, nerd!\n\nMark and sweep is goated.\n\nlol Idk why but this made my day, ty!\n\nShhh, he could be listening RIGHT NOW.\n\nTime to switch to Kotlin, the one true JVM language.\n\nYou mean Groovy 2.4?\n\nNo, Scala.\n\nNo, Clojure\n\nNo, Jython.\n\njRuby.\n\n[deleted]\n\nI had to use that at a company I used to work for.  We had a service in Java that they wanted to run on top of .NET, so we had to rewrite a bunch of code so it could build with both Java 1.6 and J#.\n\nIt was a sad time in my career.\n\nThat is‚Ä¶ horrific.\n\noh darn I thought we were making up fake java ports\n\nJimothy.\n\nJonathan nod\n\n[Flix](https://flix.dev/)\n\nJ++\n\nBajic\n\nI don't understand.\n\nSorry, explaining a joke ruins it.\n\nWell, that much alone is helpful. Thanks.\n\nMaybe it's because the joke is so bad it's doesn't even qualify as a joke.\n\nI really liked a lot of his movies.\n\nYou're thinking of Ryan Cameron.\n\nprobably distant cousin, N times removed\n\nNever heard of that movie, is it any good?\n\nIt got garbage collected because no one was watching it.\n\nOh boy üòÇ\n\nI like how he's still going to code after he retires, which is what I'd imagine I would still be doing. \n\nAfter a few years of traveling and doing stuff I wasn't able to without a long extended time to not worry about time and soak things in, I'd inevitable get bored and would probably still want to code. I'm basically doing that I would do for free but getting paid for it.\n\nI used to say the same thing :)\n\nWhat happened then?\n\nI spent many more years as a developer and now can't wait to never do the shit again.\n\ni sometimes think to myself \"you know, there are people out there who live their lives blissfully unaware of things like debugging race conditions\" and it makes me want to take up farming. still are race conditions, but you can see them. \"you didn't plant before the rain came\". no need for a debugger.\n\nDamn, you sound more burnt out than I am!\n\nI hope that, whatever he works on, he open sources it so that we can see, and maybe even contribute (if he's open to it).\n\nWhen I retire i plan to travel to far places and teach kids coding\n\nI‚Äôm already bored of it just 8 years into my career :(\n\nI remember sitting across from him on one of the small company shuttles about 5 years ago, and thinking that he looked really familiar, but I couldn't place it.  It wasn't until I got off that it clicked on who he was.\n\nRespect to James !\n\nI had the opportunity to meet him at a company event in 2012. Not gonna lie, I thought he was retired then. Almost 12 years ago.\n\nI'm still not okay after watching how he formats code.\n\nA real language for corporate applications.  From a time when software was created to last decades, not 2 years like those JS jokes that pirates love to break.\n\nOne of the highlights for me when working with Java was when I was able to grab a dependency from the early 2000's, and put it in my Java 21 application with no issues. Worked out of the box with no effort.\n\nFor me, that really shows the strengths of Java's backwards compatibility. If you follow the spec, your software is almost guaranteed to work years, even decades later.\n\nI really like how they can add new syntax like lambdas without breaking things. I don‚Äôt know why var wasn‚Äôt added a long time ago. It eliminates duplication or similar code. The record class just adds some Project Lombok functionality to Java.\n\nVar is an excellent addition. And records do way more than that, but I am quite glad to see part of Lombok is no longer needed.\n\nYes I haven‚Äôt actually worked with the new features but that is what I picked with a couple blog posts about the new features since Java 8. Also I am on my phone so I was too lazy to add anything else.\n\nI recommend it. Java 23 is coming out soon, and it adds even more to the already released ones.\n\nhttps://openjdk.org/projects/jdk/23/\n\nThanks. Is there a group driving development of new features or is it just Oracle with input from developers? I remember when we were on Java 1.4. It‚Äôs great they are doing new releases with valuable features every few months. I forget if it‚Äôs six months or longer.\n\n&gt; Is there a group driving development of new features or is it just Oracle with input from developers?\n\nThe [OpenJDK Development Team](https://openjdk.org/). Yes, primarily manned by Oracle, but several companies have sent developers over to this initiative too. Google, Amazon, Microsoft, etc.\n\nInput from everyday developers can still influence the language though. For example, if you report your experiences on the OpenJDK Mailing Lists, that's a great way to get the designers to reconsider their solution and try a different strategy. A lot of everyday devs have been able to change the course of JDK development this way.\n\nAnd yes, new releases come out every 6 months. Java 22 came out this March, and Java 23 is coming out this September.\n\nHeh. Opposite experience for me. I may suck at Java, but when I try to pick up an old project from years ago it basically never compiles.\n\nIn my limited experience Java from 5 years ago needs more work than a Python2-&gt;3 migration.\n\nThat's pretty unusual imho\n\n[deleted]\n\nSure. Could very well be my fault. I suck at Java. But I've also not encountered this in other languages. And I've sucked in other languages too.\n\nI'm very sorry to hear that. What were you working on, or what libraries did you use that had this problem?\n\nMost of my work was spent doing Java Frontend Development and Java Webservices. So, admittedly, 2 of the things Java is excellent at, and thus, it's easy to find reliable jar files online that still work 2+ decades later.\n\nI always found weird that for a language that was supposed to improve on C, it took until version 1.2 to have Lists and even 1.5 to catch up with C and introduce something extremely basic (usecase-wise) like `String.format()`.\n\nYeah, Java 5 is when the language really came alive to me. Generics and enums were the 2 things that made this language actually usable for me. But it didn't become my favorite language until about Java 17., where they gave us Switch Expressions, Records, and Sealed Types. And now that Java 21 gave us Record Patterns, I stopped using Haskell and basically went all in on Java. Once Java 2X lands and we have Implicitly Named Classes, I'm going to drop Bash/Shell too for all but the required instances.\n\nOne problem of Generics is when they have to introduce backward compatibility for type erasure. It can be a huge problem when it expects List&lt;String&gt;, but actual List.\n\nYeah, there have been a rare few instances where that hurt me. I've learned to live with it though.\n\nreified generics also have their drawbacks.\n\n&gt;  and introduce something extremely basic (usecase-wise) like String.format().\n\nIt isn't even a good API, you have to pass in the arguments and their types separately and the compiler in neither language will enforce that they match by default even if both the format string and the argument list are static. Bonus points for C with its scanf counterpart since things like passing a char for %i in printf is defined to work just fine while doing the same for scanf will fuck your stack, which will confuse the hell out of lesser programmers.\n\nActually, modern C compilers do warn if the format string types and replacement values don't match:\n\n    pt.c:5:26: warning: format specifies type 'int' but the argument has type 'char *' [-Wformat]\n      printf(\"Hello, %d!\\n\", who);\n                     ~~      ^~~\n                     %s\n    1 warning generated.\n\nI know I'm nitpicking, but it is C++. C is still a particularly minimal language. Heck, I'm not sure it even has real namespaces or visibility modifiers (aside from static).\n\nJava was the biggest misfire ever, in terms of language design. It took a whole bunch of things that were trendy in the 90s, and went full speed on all of them.\n\nIt's the programming language equivalent of embarrassing fashion photos from decades past.\n\nI still stand by [my rant on this](https://blog.habets.se/2022/08/Java-a-fractal-of-bad-experiments.html).\n\nJava certainly had some of the worst combinations of bad defaults. Many languages learned what not to do from watching Java.\n\nBut even in spite of all of those terrible defaults, it still succeeded. Just goes to show how good the core product was that it became top 3 in usage, even today.\n\nI have a certain fondness for Java, but I'm not sure fantastic design has ever been the thing that made a PL stick. Seems having a large corporate backer and optionally a killer app written in it are far more important. For a few examples: Go - Google &amp; Kubernetes, Java - Sun, C - Bell &amp; Unix, C++ - Bell &amp; C interop, Rust - Mozilla, JavaScript - NetScape &amp; browsers, TypeScript - Microsoft &amp; JS interop.\n\nLanguage design seems to just need to pass the threshold of being decent and familiar enough to not put people off.\n\nYou're not wrong. And the worst part is that there are so few survivors (let alone those that have thrived), that it's hard to make any solid deductions.\n\nMost programming languages today fall under dead, dying, or reached-their-peak-and-its-all-plateau-from-here. There's maybe 8-10 that are not in that camp. And all of those 8-10 have gigantic corporate backers, like you said.\n\nI'll concede that your case is more likely than mine, but I will note that we both have so little data to work with.\n\nI will say that the plateau isn't necessarily a bad thing. Some languages like Haskell and the Lisp family have made a career out of having a consistent and dedicated if not large user base, and while they themselves don't necessarily make waves the innovations they bring do trickle into more mainstream languages. Like I doubt Kotlin would be what it is without Haskell, either directly or indirectly, and Rust self-professedly drew from languages like OCaml and Scheme.\n\nAnd yeah, I'm certainly not going to die on this hill; like you said, neither of us have nearly enough data to make definite conclusions. I do think it would be an interesting study, but it would need a ton of thought and careful design/analysis to avoid biasing itself. As an aside, I really wish the social/anthropological facets of computer systems and their evolution were more regarded avenues of research, but at the end of the day, we are an engineering-focused discipline, and that's where the money tends to be.\n\nFully agreed on all points.\n\n&gt; I really wish the social/anthropological facets of computer systems and their evolution were more regarded avenues of research, but at the end of the day, we are an engineering-focused discipline, and that's where the money tends to be.\n\nI think this is the meat of it. At the end of the day, we are being paid to make the business as much money as (ethically...?) possible. So stabilizing the foundations, discovering best practices, aligning priorities, creating SOP, all of that falls to the wayside unless it directly contributes to helping that money gate open faster. There was [some discussion](https://old.reddit.com/r/AskProgramming/comments/1dshfiu/which_is_the_most_honest_tech_company_from_an/lb37flr/) the other day talking about this same subject.\n\nI would not limit it to \"bad defaults\". What I list is not merely defaults. And like I said, I only judge Java with hindsight. They seemed like they could have been good ideas at the time.\n\nE.g. At the time it looked like OO would be the amazing solution to everything. Java proved to us that no, no absolutely not, that is a *terrible* idea.\n\nI think Java's success comes from two things:\n\n* They seemed like good ideas at the time, but time has not been kind. But now we're stuck with much of it.\n* Absolutely amazing timing. With the promises of internet connected everythings, still a large set of architectures (sparc, mips, alpha, x86, powerpc, etc...). At no other time would binary portability be a selling point outside of the browser. And very very few care about binary portability outside the browser, too. Maybe that'll change. But it'll be webassembly, not Java.[1]\n\nI don't think Java would have succeeded at any other time. But nor would it have made those particular fast fashion choices any other time, either.\n\n[1] yes, today we have ARM, RISC-V, amd64, but not (yet) the way we had back then. And the software, hardware, and deployment landscapes have changed immensely too.\n\n&gt; E.g. At the time it looked like OO would be the amazing solution to everything. Java proved to us that no, no absolutely not, that is a terrible idea.\n\nI certainly wouldn't call OOP a terrible decision. It's just not the silver bullet it was advertised to be. In my experience, OOP is at its best when you need to model a complex entity with very specific constraint. Frankly, in that situation, I think that OOP is the BEST solution to model that.\n\nBut I see your point -- Java made several gambles, and a very large number of them did not pay off.\n\n&gt; And very very few care about binary portability outside the browser, too.\n\nCan't agree with this one. Docker is proof of exactly how much people value binary portability -- so much so that they made the entire OS portable so that their binaries would, effectively, become portable too.\n\nPeople joked that Java was essentially the only language that didn't really benefit or care from the introduction of Docker because it already gave 75% of the benefits Docker gives you, meanwhile basically every other language received a massive boost because of Docker.\n\n&gt; I certainly wouldn't call OOP a terrible decision.\n\nNo, that's not what I meant. OO **extremism** is. OO has its place.\n\n&gt;  It's just not the silver bullet it was advertised to be. \n\nExactly. And Java was born out of that misunderstanding. And you can really tell.\n\n&gt; Docker is proof of exactly how much people value binary portability\n\nBut sticking something in a docker container doesn't make it a portable binary? By portable I mean cross architectures, not merely between machines.\n\nAnd today we have these AppImage thingies, too. I agree, they add value. And maybe you could argue that Java's idea to by default distribute by zipping up the stuff needed was a good idea. Statically linked, basically. But working. But that's unrelated to IR vs machine code.\n\n&gt; By portable I mean cross architectures, not merely between machines.\n\nCross architecture is surprisingly difficult to google. So I might need a definition.\n\nWhat I meant was, if I have a docker image, doesn't matter if I have a MAC, Windows, or Linux, I can run it on all 3 with the exact same commands, set up, etc. Which is very much in spirit of Java, it's just that Java makes the JAR file portable, whereas Docker makes the whole OS portable, so by definition, anything running inside that OS becomes portable too.\n\nwhy do you need to google cross architecture code? are you unaware that different chipsets exist?\n\ndoes my code work on x86, x64, various versions of arm (big players like armv6/7/8), or even riscv?\n\narchitecture in this context refers to the cpu it is running on. those cpus may be different and more importantly incompatible. containerization does nothing to solve this problem.\n\nstrictly speaking you can use things like qemu to emulate a different architecture, but though it works it is slow so is not viable for anything other than toys.\n\nOf course I am aware of different chipsets. But I am also significantly more aware of architecture design, as in how to structure your infrastructure. When they said cross architecture, that is what my mind jumped to instead of chips, and I knew that that wasn't what the meant. So, rather than assuming, I asked for a definition.\n\nThanks for the definition.\n\nWell, the original discussion was talking about how desirable portable binaries are. My evidence no longer applies, now that I understand the intent of the word. I guess I don't have a strong enough argument to continue pushing, assuming that that is what /u/tomtennn  meant.\n\nLook, I'm not interested in having a semantic debate. In the context of the blog post, that clearly talks about IR and machine code, it's clear that I'm talking about‚Ä¶ well explicitly I'm talking about machine code.\n\nYes, in isolation \"portable\" is ambiguous. But none of this was in isolation.\n\nI'm well aware of the difference, and there was no ambiguity to me. I knew the article was talking about binary portability, no a portable os.\n\nMy point was that, other languages CAN'T get binary portability because of their design, and so, they reach for the next best thing -- Docker. The fact that SO MANY devs have leaned hard into Docker shows that there is a strong desire for binary portability because Docker is the closest thing to binary portability that these devs can get.\n\nPeople did and do want their code to work on one machine to another with no change. They are willing to change how they make that happen in order to facilitate it. For languages that can't get binary portability, they make the OS portable. But the desired end-state is the same --- their binaries work on every environment that they need.\n\nMy entire point is to combat the idea that people don't care about binary compatibility. They do! Java developers use it daily and are grateful for it. The other languages can't have that, so they use Docker to get effectively the same thing.\n\nThat was a fun read. There are two points I disagree on though:\n\n**Too much heap use** \n\nThis one isn't so much wrong as a bit out of date. You will be able to stack allocate using value types, and you can allocate off heap memory using project panama. While the heap is the only way to allocate today, it won't be in the near future.\n\n**Virtual machine bytecode**\n\nPersonally I don't think that running IR is such a bad thing. It's a lot easier to introspect and run static analysis on than fully linked executables, not to mention that you only need a single build for all the platforms you want to target.\n\n&gt; Heap use\n\nYeah, it's gotten better (after decades, you'd hope so). But some early decisions are more sticky in their effects. E.g. Go will not produce as much garbage, even when it needs to be on the heap, because of different decisions about the way of creating garbage.\n\nAnd advances in memory allocation algorithms has made compaction close to a non-issue.\n\nBut yes, I'd sure hope that Java gets better and better about their kinda tiered \"GC\", for stack, old gen, new gen, and whatever else is state of the art. It'd be embarrassing if it had stagnated.\n\nBut again this is just making improvements under the belief that a \"sufficiently smart GC\" will get us there. And my experience is that we're not even close to meeting that goal. It's not even clear that it's possible.\n\nJava's initial decision to \"just let the GC deal with that complexity\" meant kicking the can down the road, and we're still suffering from it today.\n\n&gt; not to mention that you only need a single build for all the platforms you want to target.\n\nNot sure why that even matters. Ship the IR if you want, sure, but why are the last steps of the compiler done at runtime, for portability?\n\nWith JIT and such it's not like it's not native code in the end, and runtimes are able to do all the introspection even though what's actually executing is machine code.\n\nAnyway, I appreciate your opinions. I disagree, though. :-)\n\n&gt; But again this is just making improvements under the belief that a \"sufficiently smart GC\" will get us there.\n\nI don't think it's possible to write high performance Java applications without understanding GC, however a lot of the time GC is really good enough. If you don't go completely nuts with allocation you should be fine, and stack allocation is coming so this will be less of an issue in the future.\n\n&gt; Not sure why that even matters. Ship the IR if you want, sure, but why are the last steps of the compiler done at runtime, for portability?\n\nThere's a lot of tooling that actually takes advantage of it. For example if you want to build a profiler, you can write the code once and expect it to work on every platform Java supports, as opposed to having different tools for different platforms the way you do with languages that compile to native(e.g. WinDBG for windows, GDB for Linux).\n\nIt also enables language features like runtime reflection, I don't know that it's possible to implement something like that in a native language without exploding the binary size.\n\nIf I were designing a DSL today, there are a lot of use cases where I would absolutely make that choice again. It's a very sensible one.\n\nThere are smaller areas where this design decision also had unexpected benefits. Games written in Java for example are heavily moddable, something which has proven to be a key differentiator for some of them and part of the reason they survived as long as they did.\n\nI mean there are cons to this approach definitely, but one can't deny that it has a ton of benefits as well.\n\nNote that you have the option of compiling to native directly today, however it doesn't really bring benefits except in very narrow use cases.\n\n&gt; I don't think it's possible to write high performance Java applications without understanding GC, however a lot of the time GC is really good enough.\n\nSure. Performance is only one way I think Java failed, though. But if the discussion is \"is Java fast enough for the vast majority of use cases?\", then sure. But that's true for literally all programming languages.\n\n&gt; If you don't go completely nuts with allocation you should be fine, and stack allocation is coming so this will be less of an issue in the future.\n\n&gt; There's a lot of tooling that actually takes advantage of it. [‚Ä¶]\n\nAgain, none of this mandates that the IR is the executable code.\n\n&gt; one can't deny that it has a ton of benefits as well.\n\nYou listed benefits for some decision, but I'm not sure its for the decision of IR being executable. IR being the shipped unit, maybe.\n\n&gt; You listed benefits for some decision, but I'm not sure its for the decision of IR being executable. IR being the shipped unit, maybe.\n\nI'm not sure I understand the difference.\n\nI think it's cute that you dont know how shitty Java apps can get\n\ni'll never not get a kick out of comments like this. \"jAvA mAkE goOd pRoGAMS. jAVAscRIpT baD\". \n\nit's always the mark of a junior dev when they're blaming entire categories of tooling.\n\nretire well sir\n\nI really loved this online \"keynote\" (kinda podcast in format) https://www.youtube.com/watch?v=Ynu9QEJSGX8 \n\nHe talks quite a while with the people online after his talk, about how to approach work, life. Very interesting.\n\nSystem.exit(0)\n\nYou forgot the semicolon;\n\nNot Linkedin pleaseüò°üò°üò°\n\nYeah, I couldn't really avoid it.\n\nHere is a copy paste of what it said.\n\n&gt; I've finally retired. After a crazy number of years as a software engineer, it's time for me to just have fun. The last 7 years at Amazon have been great, despite COVID-19 and industrial craziness. I've got a long list of side projects to plough through. It'll be fun.\n\nThanks for the public static void main string args ‚Ä¶\n\nSome teacher turned into a song so that their students would remember it better.\n\nBut nowadays, that's cleaned up. The following is a complete and valid Java program file in Java 23 (though, still in preview).\n\n    void main()\n    {\n    \n        println(\"Hello world\");\n    \n    }\n\n[deleted]\n\nVB and Delphi are slightly miffed at your comment.\n\nWatcom (e.g. Doom), DJGPP (e.g. Quake), etc‚Ä¶\n\nPretty serious too.\n\n&gt; Java was release just at the right time of OSS and internet becoming a thing and because it was open source and Java had good enough SDK it explode in popularity. \n\nI think you're extrapolating WAY too much from your personal experience. I don't recognize that at all.\n\n&gt; Every new framework or PL that was release since 2000s is modeled as Java / Linux, because it worked for mass adoption\n\nHow do you mean?\n\nNow he confesses that Java was just a running gag he had with his friends\n\n_\"They've bought it! HA! Gotcha good didn't I? Now it's your mess!\"_\n\nhttps://youtu.be/5oQJNnPUMB0?si=ErpzAq8PLgmVvHmr\n\nMy whole career, about 20 years of java experience, I can retire soon... its ironic if I had retired earlier than him lol\n\nI hope you get to enjoy some fun projects too when you do. What did you work on in your career?\n\nJava ecommerce... I just rode that train to the top... made good money, saved it all.   Not very sexy or interesting, but paid the bills.\n\nEcommerce sounds very interesting. Did you have to deal with the performance constraints that a lot of Java High Frequency Trading firms had to deal with? From what little I know, the Java they have to write is so performance tuned that it's almost unrecognizable from the Java the rest of us write.\n\nNot really.  Most of the high volume stuff was either search (indexed) or landing pages (some caching servers take care of that easily).  So the site itself for checkout didn't need to be that efficient.\n\nMakes sense. I wish you and your soon-to-be-retirement the best.\n\nHe announced it? I figured he'd just zero himself out and wait to be garbage-collected.\n\nAt age 70 this is quite understandable.\n\nMby his brother Ryan can continue?\n\nAny relation to Ryan?\n\nLiterally me\n\nIt is my dream to retire just working on giant personal projects all day long. I can't imagine what he plans to cook up.\n\nCame here to make a deprecating joke.\n\n‚ÄúIt‚Äôs pronounced ‚ÄòYah-va‚Äô‚Äù\n\nMan I was a big fan of his portrayal of Ken in the Barbie movie‚Ä¶ wait\n\nI hear he regrets adding null\n\nIt‚Äôs pretty ridiculous have to test to handle exceptions - like everywhere and if you don‚Äôt then hey your program can easily fall over\nNice one¬†\n\nWell, I don't know that `null` is the problem, so much as not having a type system that is aware of `null`. Looks like [Project Valhalla](https://openjdk.org/projects/valhalla) is going to add that feature in with [Null-Restricted Value Class Types](https://openjdk.org/jeps/8316779), which is likely going to be extended to normal classes one day.\n\nAs for Checked Exceptions, I am actually A-OK with them. Quite a fan actually. It helps me for debugging and managing failure cases.\n\nDown votes how lovely - James actually acknowledges this guys"
  },
  {
    "title": "Generative AI Banned on StackOverflow",
    "body": "",
    "score": 1331,
    "url": "",
    "created_utc": 1725300913.0,
    "author": "atthereallicebear",
    "permalink": "/r/programming/comments/1f7dptx/generative_ai_banned_on_stackoverflow/",
    "all_comment_text": "A good idea. Way too many people are basically trying to farm karma answering questions they have no business answering by using AI, and because they have no real knowledge they can't check the AI's output for correctness. \n\nI'm not sure how enforceable this will be though. Checking whether or not code is AI generated (assuming it's correct) is difficult.\n\n&gt;I'm not sure how enforceable this will be though. Checking whether or not code is AI generated (assuming it's correct) is difficult. \n\nIf a user is only posting *correct* AI answers, [who cares if the rule can't be enforced against them?](https://xkcd.com/810/)\n\nnull\n\nIt would trash their reputation, GenAI constantly posts straight up wrong shit.\n\nThe worst part is when you point out an error and it says \"oh, my mistake\" and it proceeds to make another more egregious one. A user who is indiscriminate enough to ask AI to give them an answer to copy to StackOverflow is not going to do the work to check the answers they put on there.\n\nAnd then it flip flops between wrong answers for eternity.\n\nThe future is now\n\nThis update makes me sad, I really wanted to see random libraries/SDKs that had *the exact method* needed to fix the problem, only to find out that they were hallucinated and didn't exist\n\nYeah programming knowledge is something where the questions generally cannot point straight to high factuality answers in a sea of existing content, but the answer **needs** to have high factuality. Often absolute one.\n\nThis is exactly what generative AI is **not** good at. It can give you a current weather report for example because the question excludes a chance at understanding the wrong information to reply with, and because the factuality of the reply is automatically included in the data used to generate the reply itself and is also accepted by the question's asker at that level. Intuitively.\n\nBut programming questions aren't like that. People are really bad at asking questions well and even then, extracting the correct solution from the data available is not a trivial task and many possible solutions are extremely similar or at least appear similar.\n\n&gt; It would trash their reputation\n\nWe're talking about StackOverflow, there is no reputation left\n\nunless you ask twice, nicely or offer a $20 tip! /s\n\nSo do SO commenters though...\n\n&gt;GenAI constantly posts straight up wrong shit.\n\nI suppose that is where SO's value comes in, the posted \"wrong shit\" would get downvoted to oblivion for being... well wrong, and only right/correct responses would remain. The labelling on the UI as \"AI-Generated\" is the stop-gap for the inbetween period when the response doesn't have many votes either way.\n\nI arrived in this thread being firmly in the no-ai-answers camp, but yeah I can see how with the right labelling and community enforcement/powers it could actually be fairly optimal. At a certain point tbh, i don't care if the answer is written by a human or not, only that it is correct.\n\nWhy bother allowing them if you have to add so much stuff around them warning people?\n\nnull\n\nWhy the fuck would I want an AI answer on a site where I ask questions to humans? If i want an AI answer I will ask an AI. Fuck off.\n\nThe entire problem with AI-generated code is that it looks correct and is often but not always correct.\n\nThe benefit of posting correct boilerplate 99 times out of 100 is undone if the 100th posting contains some nasty exploitable corner cases that no one will catch.\n\nSo... StackOverflow bans incorrect answers, whenever moderation decides they are AI generated?\n\n&gt;A good idea. Way too many people are basically trying to farm karma\n\nYes I'm sure that's exactly the reason. And not the fact that they now have a partnership with Open AI. /s\n\nCan't scrape the answers if the answers are LLM generated! It'll make the model incestuous.\n\nwell, if the model doesn‚Äòt want the shit answers why would you or i want them?\n\nTurns out that feeding generative AI shit made by generative AI actually *breaks* generative AI, making it return garbage.\n\nThis is just SO maintaining its business relationship - they don't care about you.\n\nthat‚Äòs fine and it's their problem, not mine. honestly if i wanted AI answers i‚Äòd just ask chatgippedy instead of going to stackoverflow where i expect high-quality and no-nonsense answers. you didn't address my question really.\n\nHonestly I think part of the problem here is that most of us *don't* expect high quality and no-nonsense answers on SO now. It was an interesting experiment and the \"search engine as primary interface\" concept worked really well for a few years. But the quality of contributions has fallen far since then as karma farmers and little emperors spoiled the experience. SO has also never found a good way to deal with stale information so it's increasingly likely that any answer you do find will recommend something that is no longer advisable or will no longer work at all.\n\nThe typical quality of a SO answer today seems at best on par with what any of the recent LLM chatbots will generate - possibly because a lot of those chatbots were trained on mediocre answers like SO. I'm sceptical that either experiment will survive in the long term. I think their visitors will tire of the unreliable answers once the novelty wears off and as the pendulum swings back we'll see people start to put increasing value on authentic, reliable sources written by real experts again.\n\n&gt; But the quality of contributions has fallen far since then as karma farmers and little emperors spoiled the experience.\n\nI feel like you've bought in too much to the \"dae think closed for duplicate\" meme.\n\nNo. I've just been programming for a long time and I've been using online discussion sites about programming and otherwise since many years before SO was a thing.\n\nI've seen the pattern of excessive moderation tainting the culture and putting off good contributors often enough to recognise it. Wikipedia has suffered from similar problems at times for example but is perhaps a bit better at escaping the spiral for some reason.\n\nI've seen the pattern of people getting obsessed with gaining magical Internet points often enough to recognise it. That's when some of the more \"junior\" contributors according to the system end up making large numbers of mediocre contributions to try to score more upvotes or whatever the forum calls them.\n\nFor a site like SO to work well it needs first and foremost good answers contributed by actual experts. It needs everyone else to help with recognising those through the voting system. The signal/noise ratio needs to be high whether through good quality contributions in the first place or through reliably diminishing or removing the lesser contributions.\n\nAt this age it also needs the community to help with recognising answers that have become dated and should no longer be prioritised. The moderation culture needs to facilitate asking questions or getting answers again after a period of time when previous discussions are likely to have become less relevant. But SO has never really solved this problem and it's been obvious for a while that a lot of older SO answers that will show up in search engines are actually bad advice or referring to obsolete or even discontinued products or versions.\n\nFor the topics i use it for SO works exceptionally well but it‚Äòs all down to the contributions of tireless expert users like for example Peter Cordes in the x86 / SIMD topics etc.\n\nPeter Cordes is a once-in-a-million exceptional contributor. His posts (along with a few other CPU arch nerds) are probably the only reason I frequent SO.\n\nThere are certainly some areas where a few really good contributors keep the standard up. It's a huge site and there's wide variation in standards from one topic to another.\n\nThe main problems I see with SO in 2024 are the wide variability in quality of answers (including the weak correlation between quality of answer and what actually gets accepted or voted up or down) and the stagnation issue I mentioned above. It's not that it's never good. It's that it isn't reliably good any more in the way it did pretty well at for its first few years. And neither SO itself nor by extension the search engines linking to it is very good at knowing the difference between a good, current answer and a highly upvoted but (now) bad answer.\n\nIt literally doesn't. A classic method of improving output quality is having humans rank outputs and then feeding it back in.\n\nRight, but the ranking needs to be accurate, or it really does break it, IIRC even worse than poor accuracy ranking ordinarily does.\n\nAlso, the model needs to be designed for it, this recursive learning. If it‚Äôs not, it doesn‚Äôt work. At least, this is how it was last I read about it in any detail\n\n&gt; the model needs to be designed for it\n\nIt literally doesn't. Just add the good images/text back to the dataset and train your model again. There are other ways to do this, but this is the most obvious one. \n\nHas anyone in this comment section ever gotten past the tf/pytorch tutorial? I don't mean to pick on you specifically, but every comment on this page makes me think the answer is \"no\"\n\nThis is the ranking needs to be accurate part. If you want it to deal with ‚Äúdirty‚Äù ranking better, it needs to be designed for it. But sure, if you‚Äôre confident that the inputs fed back to it are in fact properly ranked, then it will work; the ranking will make up the majority of meaningful data input (after all, if you‚Äôre feeding it back what it already produced, this is already represented in the model)\n\n[ Reinforcement Learning with Human Feedback](https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback) is very different from the models ingesting junk produced by llms into its main training data.\n\n[Model Autophagy Disorder](https://huggingface.co/papers/2307.01850) is a real problem for extending the data sets used to train these toys.\n\n[I'm not talking about RLHF.](https://www.reddit.com/r/programming/comments/1f7dptx/generative_ai_banned_on_stackoverflow/ll9ksjz/)\n\nIt \"literally\" does. There's a lot of research being done on models collapsing when trained with AI data:\n\nhttps://www.nature.com/articles/s41586-024-07566-y\n\nThat‚Äôs not correct. The latest research shows that adding synthetic data *improves* a model. The paper you link to is about one very specific thing:\n\n&gt; We find that **indiscriminate** use of model-generated content in training causes irreversible defects in the resulting models\n\nIf people put ChatGPT answers into Stack Overflow, they are subject to the same voting as any other answers, with bad answers downvoted and good answers upvoted. Assuming any model trained on Stack Overflow‚Äôs dataset filters out low-scoring answers ‚Äì which is pretty obvious ‚Äì this is not indiscriminate use of model-generated content.\n\n&gt;Assuming any model trained on Stack Overflow‚Äôs dataset filters out low-scoring answers\n\nEven this is usually unnecessary because language models have lots of HTML in the training set. The answer's score and all the comments complaining about low quality are also visible during training.\n\nHow much of the internet now is just automated scripts making ChatGPT scream into the void spamming various kinds of posts 24/7 with no human intervention at all? Like 90%. It's just garbage in garbage out at that point because there's no human in the loop at all.\n\nYeah and isn't it actually already a problem now? Wasn't there a company that recently posted they were having issues with general web-scraping as too much of the incoming data is now generated?\n\nOk, so? In this case, them maintaining their business relationship means that the site remains useful for me, because there won't be AI generated crap on it.\n\nThat‚Äôs the neat thing, we don‚Äôt.\n\nWinston Churchill is supposed to have said, ‚ÄúThe Americans can always be counted on to do the right thing, once they have exhausted all the alternatives.‚Äù This goes double for American corporations.\n\nThere's not really any backing for this conspiracy theory. The no-AI policy was put in place years ago by the moderators. The company tried to remove that policy, but relented when pressured by moderators. Maybe it's all some 4d chess, but I don't think the current SO management can handle tic-tac-toe.\n\nI suppose this is good for those who train LLMs on the data, but that's not the goal of SO. They're pushing for the quora-model where the motto is any content is good content. Sure, sometimes the moderators on SO can be a bit prickly, but I appreciate that they block a fair amount of crap.\n\nYou must have missed the update - https://stackoverflow.blog/2023/07/27/announcing-overflowai/\n\nYou must have missed how that doesn't change the ban being in place for 1.5 years before that occurred.\n\nAgain this is StackOverflow the company. They are 110% on the AI hype train and wanted to rollback the AI ban. The moderators stopped that.\n\nkinda seems like we're not too far from all models being incestuous\n\nThe concepts technical term is \"model collapse\" and its already an issue, increasing the amount of training data is a cheap and easy way to improve model performance but the internet after the release of GPT 3 or so is now significantly more difficult to scrape because so much of it is LLM generated.\n\nThe physical product analogue is steel from before we dropped atomic bombs the first time. When making particle detectors/other extremely sensitive equipment modern steel has too much background radiation.\n\nInternet data from before the wide scale release of ChatGPT is worth _money_ at the moment. Unless of course it‚Äôs publicly accessible and then you need lawyers since the LLM companies seem to give no shits about anyone else‚Äôs IP.\n\nAh I knew old web was here already\n\nI am also not happy they made a deal with open AI but this is a super obvious rule. AI content on SO masquerading as user generated is bad for everyone involved. If I wanted to ask my programming question to chatgpt I would do that.\n\nI thought they already had such a rule due to community demand. Anyway whatever the motivation they‚Äôre correct so who cares\n\nThey did. This policy is nearly 2 years old.\n\nThen again, users upvotes and accepted answers is a perfect way to ground truth LLM generated content.\n\nThe term is model collapse.\n\nYeah thats exactly my take on it. the model stop learning if most of the \"new\" data is their own generation. This is actually a pretty slippery slope. If we embrace AI, we will stop generating actual new content. \n\nSo yeah this might seem \"heroic\" but it^s not. it's a way to get the crowds ti further train their AI for free.\n\nSynthetic data doesn't immediately mean corruption.   Self reasoning is improving in general ways, and special purposes AI answers can often be better than human.  \n\nAll the same plugging GPT3.5 into their answer system as-is is not a good idea.\n\nThe actual reason is that Stack Overflow now sells its data for AI training, so it needs non-AI data to sell for training.\n\nBefore now, you could download the data for free. Not any more!\n\nAll karma systems are heavily flawed. Just look at reddit - funny comments help do a karma boost. Whereas if you are critical of something, even if you bring in good arguments, you get downvoted AND often also banned (e. g. good luck trying to critisize systemd on #linux or KDE's recent abuse of the notification system showing donate-advertisement spam on #kde).\n\nI don't see how they can enforce it at all. The way moderation works on there I expect it'll become a witchhunt.\n\nAlso how are they going to tell the difference between karma farming and I generated this, put it in my code and then shared it later?\n\nIt's only unenforceable in a world where AI gave consistently high quality answers.  We don't live in that world.\n\nIf someone is churning out high volume, often incorrect answers then it's fair game to ban them.  Either they are using AI or they are an idiot, either way the platform is better off booting them.  \n\nModeration rules aren't like the laws of government where you need to prove guilt beyond a reasonable doubt.  In moderation a lot of the decisions are made in the gray areas and made quickly.  Sometimes mods get them wrong, and that's okay. They aren't depriving someone of life or liberty, just the ability to answer questions for free about WPF error messages or whatever\n\nAlso sometimes the rules are just as much about communicating out to people about what being a good contributor is, and less a rule that someone will gather evidence about.\n\n&gt; It's only unenforceable in a world where AI gave consistently high quality answers. We don't live in that world.\n\nYet. And that's the alarming point. It's plausible to say, \"hey take this response generated by AI 1, then make it sound like you're a 40 year old engineer burned out from work and focus merely on the details. Remember, we want to discourage moderation from thinking we're a bot!\"\n\nGenerative AI content has an idiosyncratic quality right now but as prompts evolve it'll be feasible to defeat it, so then AI policing AI? When do we begin to label our adversaries as bots? It turns into a zero trust game with disastrous consequences.\n\nI think you are missing the major point of what I said and the link post.  It isn't about the idiosyncrasies in how answers are phrased.  It is about wrong answers that look probable.  If they focus on that, fix it, then great!  It'd be great if it was more reliable and gave more usable answers.  Then maybe SO could lift the ban, or an LLM friendly competitor could show up and eat their lunch.  The quality just isn't there, especially not for a site that regularly works with specific niche questions.\n\nIt‚Äôs pretty easy to spot the low-effort AI generated answers. But you‚Äôre right, it‚Äôs not a perfect system, and if you put effort into masking that the answer is from AI, you‚Äôll probably get away with it.\n\ni mean - very few people karma farming are going to do the effort to change the generated code so those replies are very easy to spot with their pattern formatting of\n\n#fixing your issue\n\nthis issue is caused by x and y which results in the error you're receiving.\n\nthis can be fixed by doing the following:\n\n- fixing x \n- resolving y\n- disabling the part of your code that's erroring\n\nhere is the code with these fixes implemented:\n\n    while (x == true){ //check if x is true\n         resolve(y) //resolve y\n         //do not throw error here\n    }\n\nOh, I totally get where you're coming from! Allow me, an AI, to break this down for you in the most original and non-formulaic way possible:\n\n#Analyzing the situation:\n\nThe issue you've identified stems from the repetitive nature of certain AI-generated responses.\nThis is typically due to the \"if-then\" logic that leads to predictable outcomes, such as the formulaic format you've described.\n\n# Proposed solution:\n\n1. **Embrace the irony:** Let's lean into the formula and have some fun with it!\n2. **Add a twist:** Throw in an unexpected element, like a self-aware AI breaking the fourth wall.\n3. **Deliver with a wink:** Here's a fresh, never-before-seen AI response (totally not following a pattern):\n\n# Example:\n\n    while (x == true){ //check if x is true\n         resolve(y) //resolve y\n         //if this comment is formulaic, then blame the AI overlords\n         //otherwise, pat yourself on the back for outsmarting Skynet\n    }\n\n# Conclusion: \nIn conclusion, the issue is caused by repetitive AI responses, which can be fixed by‚Ä¶ embracing the irony! üòÑ\n\nIt's not that hard to enforce actually. AI posters are pretty easy to spot. Their accounts will have been created after LLMs like ChatGPT went live. Or their posting volumes will have significantly increased since then. They will be spamming a bunch of answers. And their answer / upvote rate will be low since they will likely just be spitting out a bunch of AI generated content. They won't have the ability to test or critically think about the code.\n\nThere are other tells. But I don't want to help these posters mask their answers.\n\nThe rule on its own will discourage people. Especially people that are just trying to be helpful but don't fully understand why grabbing a chatGPT answer isn't appropriate for the setting\n\nThis is the thing about SO that people miss though. The platform is specifically against people \"just trying to be helpful\". \n\nYou either give an answer that works, or you stay quiet. Answers from there are judged on how well they work (from perfect solution to \"it works, technically\").\n\nThe reason why is because SO is supposed to be an encyclopedia or dictionary of sorts. Imagine looking up the definition of a word and getting \"uhh dunno but it probably means something like...\". It may just be trying to be helpful, but at the same time it's useless because it doesn't necessarily get you closer to a solution.\n\nI don't get why you are responding to my comment, unless it was just as a convenient jumping off point for your own tangent. My point is that the rule will work because it will cause people to alter their own behavior (they want to be good participants).\n\nBut yes, that is a thing a lot of new people run up against. It is unfortunate that its reputation is so different from its intention.\n\nThe other issue is ai isn‚Äôt supposed to be correct\n\nKarma is toxic, devs don't care about other posters prestige.  They just want to put be put into the right direction to solve an issue.   If chat gpt generated answers can help with their issues, more power to them.  SO has questions of issues that STILL occur even after a decade and no super karma answer to be found anywhere.\n\nI'm gonna split the difference here -- sure, AI can offer up something the dev may not have thought of, but it should be up to the dev to prompt the AI. They're the ones with all the context, after all. Playing telephone with an AI through Stack Overflow devalues the AI (it may not get everything it needs to generate relevant answers), the interaction (it's a game of telephone), the manually-written answers by people who actually have expertise and knowledge (since they can actually know things, work through problems, and stay on top of best practices unlike sentence generators), and the general user experience of the site as a whole (since you can't trust the domain expertise of an unthinking machine, casting a shadow of doubt and unreliability across every answer AI or not).\n\n&gt;  If chat gpt generated answers can help with their issues, more power to them.\n\nThat's the heart of the issue as outlined in the post.  The average quality of answers is too low.\n\nWhat do you think the odds are of AI helping with an issue that hasn't been answered after a decade? It's already low quality, but ChatGPT already trains on SO data. Anything it spits out for an unanswered question is going to be hallucinated garbage. It can't invent a solution no one has found.\n\n&gt; Karma is toxic\n\nThat part.\n\nBut it was already banned 2 years ago, no?\n\nThe post recognizes this and calls out this is a shift from a temporary policy to a more clearly worded permanent one including their evaluation of the temporary policy.\n\nno i just wanted everyone to be like \"Bro are you stupid that was like two years ago\" i didn't think about the whole temporary to permanent thing. i was baiting\n\nHahahaha you posted the wrong link then they basically put that in bold at the top really you made it a rat trap for ‚Äúdidn‚Äôt read; bitching in comments‚Äù\n\nI‚Äôm really confused now!\n\nPlus they have their own AI\n\nSo the reason that they don‚Äôt want people to respond with AI answers has nothing to do with the actual user experience\n\nUsers will figure out the answers are wrong the same way we always did. The problem is AI has a harder time telling.\n\nSo if they train their AI with these ok looking but actually bad answers then the new AI will give even worse answers. \n\nThere is a whole concept called ‚Äúmodel collapse‚Äù which is what happens when you train ai to much with data made by ai\n\nThey know that AI has got to be part of what they offer going forward but they also know that until they figure that out it‚Äôs possible all their data could get corrupted and become valueless\n\nThat‚Äôs interesting, I hadn‚Äôt thought of that. They need the real varied human entered data to have fodder for their actual AI to train on, otherwise it will be a weak AI model.\n\n&lt;joke&gt;Someone needs to close this blog or news post as duplicate. üòÇ And reference the original.\n\nKind of, 2 years ago they announced (in that post) a *temporarily* ban. Only in July 2023 with revision 36 they changed the wording, removing the *temporarily*.\n\nThey‚Äôre selling their data for training AI.  Training on data that is itself AI generated just produces garbage.  It wouldn‚Äôt surprise me if their data sales agreement requires this.\n\nYup. It's all about the money. \n\nIn addition to that, allowing ai answers also pisses off your established, unpaid, volunteer userbase that answers questions with correct answers. So not only do you start getting AI garbage. But your established posters also stop posting / move to different platforms. And that makes the effect of the AI answers worse than they'd be otherwise.\n\nYes, so your point is:\n\n1. money is probably the motivator, and that's really good, because corporations have a piss-poor history of sticking to principles based on alturism but are _really_ good at sticking to principles that are profitable, and...\n\n2. ...this is serendipitous, because GenAI code is typically poor and, as their Q&amp;A points out, far too often incorrect. We don't need the blind leading the blind any more than the well-intentioned but sometimes incorrect _human_ written answers. The best way to keep the best signal to noise ratio is to prohibit the use of GenAI.\n\nYou're assuming that banning GenAI content is a good principle, or that it's even enforceable.\n\nNo, I'm *asserting* that banning AI is a good principle. It's a vital one in fact.\n\nAs for enforceable? Yeah, I've no idea how they're planning to do that.\n\nThere it is.\n\nYou can probably filter those answers out if they can detect it rn right?\n\n&gt;  Training on data that is itself AI generated just produces garbage.\n\nThat a legend, data labeled by humans works well for training.\n\nRight but it is probably not because it produces garbage. Humans will still evaluate and upvote the answers and edit them. The real problem is likely licensing. You arent allowed to use a models output to train another model typically. Therefore, they have to have this rule to sell their data.\n\nYou can't copyright LLM output, so it can't be licensed to begin with.  That's not the problem.\n\nIs this why i am being downvoted? Because its wrong. You can license the use of an ai model, and i work with these licenses everyday.\n\nYes, it's because you're wrong.  Using a licensed AI model is separate form and completely irrelevant to using content generated by an AI.  The US Copyright Office has said unambiguously that content generated by an AI does not qualify for copyright.\n\nI'm a huge fan of generative AI for a lot of things, but \"ChatGPT says...\" posts should result in an auto ban _anywhere_.  Bitch, if I'm asking somewhere, it's because I'm asking the people there, not for someone else to ask ChatGPT for me.\n\nThe cynic in me thinks this is less about users and more about the FAANG saying they need more content to train the next models\n\nThe company is all on board the AI hype train and wanted to reverse the ban, but the moderators revolted with the support of meta users.\n\nhttps://meta.stackexchange.com/questions/392032/moderation-strike-conclusion-and-the-way-forward\n\nThere's the argument that they want to be able to sell clean data. But I assume AI is also an overwhelming threat to their business model. \n\nI myself try AI first and Stack Overflow second. AI is definitely not as smart, especially about hard questions, but Stack Overflow has always been crawling with people who seem to just exist to insult people for asking questions on Stack Overflow.\n\nI put up with what was basically an open-air mental institution for people with personality disorders for 15 years. I didn't let it stop me from learning, but gee whiz is it so nice to have an alternative now.\n\nThe dumbness of AI can be fixed. The toxicity of Stack Overflow, on the other hand, seems unsolvable. So every time a new model of ChatGPT comes out, the value of Stack Overflow diminishes forever. This seems like the least they can do to staunch the bleeding.\n\n&gt; The dumbness of AI can be fixed.\n\nActually, it almost certainly can't. Not with LLMs, anyway.\n\n[deleted]\n\n&gt; then raw intelligence will keep going up\n\nThere is no raw intelligence of any kind. LLMs represent very computationally expensive auto-complete. Each word generated is based on the statistical likelihood of what _anyone else_ said (in the training data) in the context of the prior words, within the context window size limit. It's only as good as the training data size, it's only as capable as a blunt force stats matcher and it can't ever be more than that under current architecture.\n\n(And yes. I know. *Tokens*. Nomenclature used deliberately for simplicity here.)\n\nThis is a very well known, understood and indisputable limitation. We're talking maths here. It's not a grey area.\n\nThe question is about training data size. General LLMs are approaching their limit as they've been trained on just about everything, and are now suffering as they ingest more and more LLM-generated content. It's an insolvable problem created by the large LLM vendors themselves, as the web becomes infested with LLM output, but their entire technology stack and business model depend upon harvesting the web (while ignoring any and all legal concerns therein) for textual data.\n\nCode is a different story. We have not reached the limit of ingest of all possible code - not by a long chalk. But code is also a lot harder than words; it is less tolerant of quirks or outright faults. Moreover, detecting issues or even knowing enough to spot that there are any, if one is using an LLM for code instead of reading the docs and understanding what to do themselves, is almost impossible.\n\n&gt; And that supposes that something better than transformers isn't invented in the next few years\n\nThat's a different argument. GenAI, as it stands today, per StackOverflow's statement, is far too unreliable. General purpose LLMs can't really fix that. Coding LLMs *might* be able to, if they can find a vast as-yet untapped reservoir of high quality code that can be legally ingested.\n\n&gt; There is no raw intelligence of any kind. LLMs represent very computationally expensive auto-complete. Each word generated is based on the statistical likelihood of what anyone else said (in the training data) in the context of the prior words, within the context window size limit. It's only as good as the training data size, it's only as capable as a blunt force stats matcher and it can't ever be more than that under current architecture. \n\nOne of the more annoying aspects - to me at least - of this is that it means that LLM output is frustratingly *plausible* when it's wrong. It's hard to tell at a glance that it's incorrect.\n\nA great example I ran into recently was when using the STM32 HAL. It specifies GPIO ports using banks and pins given by preprocessor macros; e.g. GPIO\\_BANKF or GPIO\\_PIN7. The LLM got the bank macro right, but was using 7 instead of GPIO\\_PIN7. GPIO\\_PIN7... does not equal 7... so this did not work on the hardware, but when you just look at the code it seems fine. After all, taking a defined value for bank but a normal int for the pin # would be a reasonably sane way to design the API.\n\n&gt;  if they can find a vast as-yet untapped reservoir of high quality code\n\nYou forgot to add the /s\n\nIt seemed kinda implicit `;-)`\n\nThis seems like the \"computers can't get any faster\" argument of 2024.\n\nMaybe we can't ~~shrink a transistor again~~ improve our LLM training again, but we've seen a lot of success in ~~revising computation architecture~~ routing queries to specialized models.\n\nIn 2022, ChatGPT was humorously shitty at math. Since it was just searching natural language, if you asked it to multiple two big numbers, it would just produce hallucinated garbage.\n\nBut now the initial model just detects a math problem and routes it to a specialized model designed to handle numerical computation. My own team has utilized this approach to great success. Making a hundred specialized models slows down the response time a bit, but response times have gone way up through other means of optimization.\n\nBut you just argued for my point, not against it. I said that general LLMs were approaching their limit, but coding-specific engines might have mileage. You point out that a particular issue with maths in a general LLM was solved via an intent engine moving to a custom, specialised model.\n\nYes. Specialism helps.\n\nWe know this because we've been doing it for years and didn't need million-dollar training sets to do it. Expert systems have been a thing for a long time. For heaven's sake, an *e-reader* from the last few years can do hand-written complex maths solving (no, Apple, you were far, far from the first with 'math notes').\n\nThe fact an LLM can be coerced into doing it inefficiently via switching to a more limited and heavily customised model is no surprise, but I also wouldn't trust an LLM vendor to produce an accurate answer with a training-based statistical output approach as they are inherently unable to disinguish between right or wrong.\n\nEdited to add a reminder for those who have somehow not realised that this has existed for a great many years:\n\nhttps://www.wolframalpha.com/examples/mathematics\n\nNot an \"AI\" system, by modern marketing parlance. Just one that works really well. Put an OCR system in front of it and you're done.\n\nSo you agree users will get better and better results if they ask an AI instead of Stack Overflow? But only because AI companies will keep improving their results through some meaningless set of implementation details instead of some other meaningless set of implementation details?\n\nI guess we're just two dudes who agree.\n\n(Sigh) Obviously not since no GenAI code can be used without being verified by a human because the GenAI system has absolutely no understanding of anything it's doing. I remind everyone reading, once again, that it's just glorified autocomplete. But if _you_ want to try and boil down the entirety of programming in all languages to some kind of facile generalisation - ignoring, in so doing, the sheer volume of data needed to train a model to even adequate performance - sure, you do you.\n\nYou're really running off with the goal posts now. My position is that the advice from an AI like ChatGPT will continually improve while the advice from Stack Overflow will not. If you agree that will be true experientially, neat. If you don't agree, lol good luck with that.\n\nSo are we just going to come up with specialized models for everything? That's not sustainable in the least.\n\nWhy not? It's working great so far.\n\nBTW this was news 1 year 9 months ago\n\nyou know that internet explorer twitter account that posts really old news? that's what i was trying to do except it got 1.2k upvotes...\n\ndefinitely make it clear in the title that‚Äôs what you‚Äôre trying to do\n\nCan't let the LLMs become incestous.\n\nWhat are you doing, step-model?\n\nUwU\n\nSure, because they sell data to AI companies so they don‚Äôt want to create ‚Äûshit in, shit out‚Äù loop for their clients\n\n&gt; 1 year and 9 months ago\n\nIn other news, Archduke Franz Ferdinand was assassinated.\n\nBet Kaiser wont like that\n\n[deleted]\n\nEverything is CC licensed. Anyone can vacuum them up.\n\nThey even tried to make the data dumps less accessible to reduce the amount of AI-vacuuming but people were against that too ü§∑\n\nNot any more. The CC license doesn't say they can't ban your IP if you download more than five.\n\n&gt; The CC license doesn't say they can't ban your IP if you download more than five.\n\nSlight tangent: anyone using IP bans as anything more than temporary (relative to a particular person or user) IMO is being foolish.  I see this in discussions regarding game hacking/cheating, people keep calling for IP bans, when at best they have to be temporary due to IPs often (not always but often) being dynamic.\n\nStack Exchange doesn't care whether people can view the information or not.\n\nI'm fine with that, I think the ban is good though - if I wanted an answer from an AI then I'd go ask one.\n\nNothing contradictory there. The ban is not out of a blanket anti-AI principle. And people contributing knowledge to SO *want* that information to spread.\n\n[deleted]\n\nThe fact that this topic comes up all the time when talking about AI means that lots of people care.\n\nAmen to that!\n\nIf I want an AI answer I ask ChatGPT, GitHub Copilot, or one of dozens of other (often free) tools. When I go to StackOverflow therefore, I am looking for actual human answers.\n\nDuplicity.\n\nMayonnaise calling milk white.\n\n[Our partnership with Google and commitment to socially responsible AI](https://meta.stackexchange.com/questions/398127/our-partnership-with-google-and-commitment-to-socially-responsible-ai/)\n\nYou guys do know that the organization of moderators and the business organization at SO are different groups right?\n\nTo an appreciable degree, perhaps.\n\n[deleted]\n\nEven throwing basic stuff at it with certain frameworks has it just generate total nonsense half the time, especially when you introduce layers to the question or expected response, even if conceptually what you're asking is pretty straightforwards.\n\nIf the responses are full of Gen AI output the data they're selling _to train Gen AI_ won't be as useful anymore. So everyone could see this coming.\n\nDidnt they started to ban people that deleted their own content once stackoverflow signed to train openAI on their data because they were pissed users that submited contect for years did not like the idea of teaining AI on their inputs.\n\n[This user has left Reddit because Reddit moderators do not want this user on Reddit]\n\nWhy is this discussed now, 21 months after the ban started?\n\nAh yes, the training dataset must remain untainted by the very thing it feeds.\n\n# Banned on SO, but all uploads are now ingested by OpenAI\n\nTo anyone naive enough to think it's about the *correctness* of answers and what not, should pay attention to this part:\n&gt; This includes \"asking\" the question to an AI generator then copy-pasting its output **as well as using an AI generator to \"reword\" your answers.**\n\nEmphasis mine, if they cared about correctness then rewording an correct (human written) answer would be fine.  \nHowever if you want to use the content to further train LLMs, then it's naturally a bit inconvenient to have these around.\n\nEh, that's not contradictory though. It's a blanket rule to not have to deal with people claiming they were just rewording.\n\nYeah, cause they don't want to contaminate the data they are selling to companies to feed into their own LLM's as of a few months ago; https://stackoverflow.co/company/press/archive/openai-partnership\n\nHow would they know? It seems sort of meaningless to ban something you can't reliably detect in the space they are trying to detect it.\n\nYou can easily tell if the response isn‚Äôt trying to belittle and embarrass you for asking such an obviously stupid question.\n\nfair point, it is SO\n\n\"Artificial intelligence\" is detectable. No nuance. Eurocentric. Doesn't try to be a would-be comedian or satirest like humans on boards.\n\n[This user has left Reddit because Reddit moderators do not want this user on Reddit]\n\nPretty much I can.\n\nThank fucking God. I put a bounty on a question the other day, but still nobody answered it. Day before the bounty expired, some fucker copy paste an answer for gpt, without even checking it's compiling. I was so furious!\nI put a comment on that exposing him and also reported it, and his answer was removed and didn't get the bounty\n\nnot allowing AI usage for translations is straight up gate blocking. but whatever, i guess they like having the same 5 people shit on anyone who dares to not be satisfied with a half similar question from 15 years ago that uses 2 deprecated functions.\n\nHow are they going to know?\n\nIt's trivial to spot \"intelligence artificial\".\n\nIt was about that this would take place. People who dont even have any sense or whatsoever for stackflow were just adding AI generated answer. If the person wanted AI based answer then they would have used GPT.\n\nNo!! That's how we were meant to save CS jobs by polluting the dataset\n\nI can't remember the last time I used stack overflow. The content quality has been really bad in the last few years.\n\nYeah, it would be impossible to monetize answers of volunteers for training AI models if those answers were generated by AI models. Nobody wants to train on AI model outputs since that degrades the performance of their models\n\nBanned because...  You can't use the output of Open AI's GenAI, as input for your own companies GenAI.\n\nGood luck with that one...\n\nThe first problem with AI rears its head. I'm sure there will be many more to come.\n\nThis is just so they can sell their own AI.\n\nIs there anyone still using StackOverflow?\n\nEven as someone who actively uses AI in my day to day work and finds it to be a major time saver, I believe this is a good move. About 5% of the time, what the AI gives back is completely wrong, and it happens more often with more obscure libraries, this is easy to catch when I can just try the code out and see that it gives type errors or otherwose doesn't worm properly, but the people posting AI generated answers on Stack Overflow were not checking, they were just spamming the site with entirely untested and uncurated output. The correctness of the answers on Stack overflow are very important for the continued quality of the site.\n\nFucking GOOD\n\nOne way to view generative Al:\n\nGenerative Al tools may randomly create billions of content sets and then rely upon the model to choose the \"best\" result.\n\nUnless the model knows everything in the past and accurately predicts everything in the future, the \"best\" result may contain content that is not accurate (i.e. \"hallucinations\").\n\nIf the \"best\" result is constrained by the model then the \"best\" result is obsolete the moment the model is completed.\n\nTherefore, it may be not be wise to rely upon generative Al for every task, especially critical tasks where safety is involved.\n\n What views do other people have?\n\nReddit needs to do this too. Bots should be allowed but they should be obliged to identify themselves as such.\n\nWasn‚Äôt it banned more than a year ago\n\nI‚Äôm sure companies will honor this ban.\n\nai will prevail, resistance is futile\n\nTo all who are just principally bashing AI, help me to understand: As a former developer who still does stuff every now and then, AI does actually helps me a lot with creating code. It obviously has its limits, but who cares if at the end of the day it contributed to a solution?\n\nI do not care about fancy reputation/numbers on SO. If I provide answers, I only ever did if I knew my content added real value. So at the point where I post an answer it's just common sense that the code I have in front of me is well tested. It's not even a question that my code solves the asked problem and I'm not just re-posting stuff that others already did.\n\nAlso: There have been poor quality answers (and questions!) on SO long time before ChatGPT was a thing. And if you had a problem to solve, you went through \\*every\\* answer. Generated with or without AI: Poor quality answers are easy to spot for someone who actually has to solve a problem. And you would just downvote them if they wrote bullshit.\n\nI really don't understand why we are banning it just because of a few shenanigans trying to abuse the system.\n\nI'm banning AI on SO because I don't like it.\n\nYou can't sell content as \"human generated\" otherwise, nothing unexpected.\n\nIf you use generative AI responsibly, nobody will be able to tell that you used it at all.  It's good at turning an unorganized freewriting draft into something better organized, or making suggestions for the text.\n\nBut generating massive amounts of unreviewed and uncorrected text is not responsible use.\n\nNo complaints here, but this seems like just an arms race that we're never going to win.  We just have to accept now that any content can be AI generated.\n\nI do think that train has left the station.\n\nDon't worry, they'll roll this back for themselves in a few months and your options for getting answers will be:\n\n1. an AI response trained on stackoverflow (lmao)\n2. a post closure and a link to a random question that is \"related\" (lmao) to your question.\n\nStackoverflow died like 6 years ago - it's time to move on.\n\nTo?\n\nreddit, forums, twitter, youtube communities, discords - there are so *so many people* in this industry that you can find help basically anywhere. Hell, go find a project that's similar to what you're working on on GitHub and read their source code - see how they solve problems. Go look at other well established open source projects and read through commits relating to code you're interested in.\n\nStackOverflow has *always* been a crutch, and if no one is available to help you, all you can rely on is yourself. Welcome to the world of real problems and not bullshit bigtech nonsense that's just reinventing the wheel every 8 months under the guise of \"innovation.\"\n\nIt's time people start learning how to learn so they don't get left behind with these dogshit AI models that feed you the equivalent of a biased `/dev/random`'d sentence when you ask them a question.\n\nThis isn't hyperbole. This is reality. Anyone who doesn't like it is welcome to continue living in 2010.\n\nI mostly ended up using stackoverflow to find discussions of bugs and corner cases. And to brainstorm. Or to write down ones I found so I wouldn‚Äôt forget them. \n\nI think last year sometime, maybe the year before, I found and used one of my own answers from about eight years ago. But you also find ones that have been supplanted by new APIs. \n\nI agree that SO is a crutch but disagree on what it‚Äôs a crutch for. It‚Äôs a crutch for people who don‚Äôt know how to write clear and approachable APIs. That‚Äôs dying quickly, and people who struggle to make code you can reason about are gonna have a bad time.\n\nBullshit move to improve upon the realness of the content.\n\nLLMs loose their capabilities at a rate that is alarming if content of an LLM is used to train the LLM.\nThat also is why rewording, using Ai, is strictly forbidden.\n\nJust let StackOverflow die already so that we can get a real alternative.\n\nUseless rule.¬†\n\nVideo killed the radio star.\n\nOld news, they know their users are toxic and AI will replace most of them, they just pivoted to selling data.\n\nClaude has already replaced SO as my go to for code questions. I've had too many questions marked dupes when they weren't. Is Claude perfect? No but SO has its flaws too. Besides as George Patton said, \"A good plan violently executed now is better than a perfect plan executed next week.\" When you're on deadline waiting for an SO answer won't cut it."
  },
  {
    "title": "US employment of software developers is in decline, and has been since pre-pandemic",
    "body": "",
    "score": 1318,
    "url": "",
    "created_utc": 1718657633.0,
    "author": "JaredGoffFelatio",
    "permalink": "/r/programming/comments/1di8pe9/us_employment_of_software_developers_is_in/",
    "all_comment_text": "This doesn‚Äôt look right. Hiring for software engineers was in a frenzy at least into 2021. A peak in January 2020 makes no sense.\n\n[deleted]\n\nthey timed a lot of things in that bill to take effect when they believed a dem would win\n\nThis is how Republicans double tax you while making it look like the Democrats did it.\n\n[deleted]\n\n[deleted]\n\n[deleted]\n\n[deleted]\n\nwhy does that not happen to republican lawmakers?\n\n[deleted]\n\nCombination of factors. Part of the problem is that democrats also rely on big donors, but a lot of what their donors want aren't popular among people who vote for democrats. So they end up walking a line that is less policy focused and more about posture.\n\nRepublicans don't have the same issue. The policy they push for is \"tax cuts for the wealthy\" and the rhetoric they use to distract the voters from that isn't counter to the bottom line of wealthy people.\n\nThe result is you end up with Republicans who act like Captain Planet villains and Democrats who are largely ineffectual.\n\nIt's also a lot easier to be conservative than progressive, in terms of achieving goals.  For a progressive to achieve goals, they have to convince everyone that there is a problem and that their solution is the correct one.  They have to compromise to get everyone on board, overcome setback after setback, and then spend years fighting to keep whatever it is that you passed from being repealed.  If you're a conservative, all you have to do is sit quietly and vote no over and over again.\n\nOr vote yes to get rid of progress achieved over decades.\n\nThis is probably the smartest thing I‚Äôve heard about the American political system. Also the party of the Christian right is unified behind the adulterous treasonous felon . The republicans are far better at politics and playing son of a b. Obama copped out to moderates and the right wing. Trump installed a generation of conservative judges and justices with a tiny percent majority of electoral votes\n\nDemocrats have had razor thin margins in the senate because republicans have a structural advantage in how the senate is allocated and republicans having a lot of lower population states. On top of the razor thin margins there‚Äôs also in recent times been a contingent of pretty centrist democrats that have prevent pretty key things from moving forward.\n\nIn recent years Republicans have also been in much more lockstep. There‚Äôs been a little more internal division but it also often results in those who disagree leaving more than staying and being a voice of dissent within the party\n\nWell sometimes they [obstruct themselves first](https://theweek.com/articles/469675/mitch-mcconnells-amazing-filibuster-bill)\n\nI imagine it would require the house/Senate to pass legislation to nullify the taxes, which takes valuable time and energy away from actively pushing their own agenda. The moment you start playing defense, you're stuck and on your back foot reacting to whatever crazy shit they do\n\nClamping down on R&amp;D write offs? That isn‚Äôt exclusive to software, includes pharmaceutical too\n\nEdit: [section 174](https://www.law.cornell.edu/uscode/text/26/174). RIP fart apps, darn.\n\n[deleted]\n\nQuality engineers, at the time the bill was introduced, were under lock and key with NDA/non-compete that have just about now been dismantled. The write-offs available at the time through blindness incentivized perverse hiring metrics. What's below there is [bullshit metrics](https://finance.yahoo.com/news/google-over-hired-talent-fake-114331193.html).\n\nWhen money is free you spend those resources defensively, in this case preventing hiring. This causes a wage spiral to recruit talent, for whom wage is also a write-off. You see how it's going, right? Infinite money glitch.\n\n[deleted]\n\nPharma is kind of the same way unless you work for big companies. My wife in pharma switched jobs more than I have through the same period. It‚Äôs the same thing, unless you‚Äôre selling product and in the black you‚Äôre on the burn clock.\n\nAhh capitalizing hours at work is a pain in the but for me. Such a nuisance.\n\ncan you elaborate? what are these changes and how do we rally to get them reversed\n\nI‚Äôm glad you‚Äôre upvoted. I once pointed this out in cscareers subreddit and got downvoted.\n\nTrue, but don‚Äôt forget that a lot of people lost their jobs at the start of Covid and plenty of businesses shut down.\n\nMy interpretation, based on the graph and being a manager at a medium sized tech company is that a lot of the hiring boom in 2021 started as hiring mostly people who were laid off because of Covid and then turned into companies head hunting employees from smaller companies.  Also, when the stock market started to rally, I know a surprising number of senior+ engineers in their 30s and 40s who cashed out their company stock and retired early.\n\nAll of those combined could result in the overall employment numbers being lower than 2019 despite a hiring boom happening.\n\n[deleted]\n\nthe cycle repeats itself hire too many devs ‚û°Ô∏è fire half ‚û°Ô∏è outsource the work ‚û°Ô∏è the work is terrible and communication is bad ‚û°Ô∏è rehire too many devs ‚û°Ô∏è fire half\n\nThis is it. What a cycle to be caught up in. Definitely doesn‚Äôt hurt that all so important morale we talk about in our corporate trainings.\n\nThe outsourced work can work, but the only way I've seen it have any kind of result is really going in on it. Having a support team is often a miserable experience, unless it's simply off hours support for systems or IT\n\nHaving an entire team offshore, slightly better but still you have a lot of friction between teams\n\nIf you have the resources to have an entire offshore buisness unit, it can work decently well. But it needs to be the right unit and right products. Microsoft makes it work decent. A lot of the outlook and stuff like office is based in India.\n\nNow it's entirely possible the code is trash, but for some of it it may not matter. Like the desktop outlook client. It probably doesn't get a ton of use, but it's more of a checkbox item they need to have.\n\nI do know working with offshore teams is often miserable though. At the very best, you have a massive timezone difference, with different holidays and stuff. But so often Ive found them to be just hostile to work with. Any question is treated like some kind of threat to them. Or they'll refuse to give you any kind of access. Like if they let any sort of information leave their team, your going to use it to take their jobs away. \n\nIronically, in two instances now, I've worked with teams like that. Never had any intention of taking their jobs. But it ended up happening after they proved basically impossible to work with. Those decisions are way above me, so not anything I directly did. But the usual pattern is my boss asks why it's taking so long to get this done, I tell them my experience, boss says it must be a misunderstanding let me talk to them. Boss starts working more with them, gets met with the same issues. Raises it to their boss. And it just keeps going higher till someone with actual authority gets upset or offended.\n\n&gt; Like the desktop outlook client. It probably doesn't get a ton of use, but it's more of a checkbox item they need to have.\n\nThe only worse Office program you could have chosen as an example would have been Excel. Thicc Outlook is a requirement in nearly every Fortune 500 company many of those rely on in-house developed plugins for critical business processes.\n\nI didn‚Äôt want to comment on this as I didn‚Äôt want to nitpick, but my goodness that was a horrible example of an underused piece of software\n\nDo you guys not use the desktop Outlook client at work rather frequently‚Ä¶?\n\nI do IT consulting as a side gig and persuading organizations to move their IT in-house is basically most of the work.\n\nOutsourced IT work is just not efficient enough to justify the inconvenience. My trade is infosec so anything you can't control is a big no to me. I already don't like MSPs and MSSPs, but offshore IT? that's just asking for trouble. \n\nInfoSec/CyberSec starts at the service desk and orgs who can't understand that will pay the price eventually.\n\nHow did you move into IT consulting? I've been working an IT for nearly 10 years and I feel like I'm kind of in the place now where maybe consulting is the best avenue for me.\n\nI think the general answer is through networking and connections. I'm a mid level developer and I do consulting on the side. I got started because I had a professor who I kept in touch with. They recommended me for a project.\n\nHalf my group was let go last October in favor off offshore contractors.\n\nRight now, yes, but I‚Äôm specifically talking about the 2020 to 2022 period\n\nSo? I saw that in the 90s and early 2000s. All those jobs were brought back 4-5 years later.\n\nThe cycle always repeats.\n\nIt‚Äôs not tracking for me. This data set doesn‚Äôt show an uptick until almost Fall of 2021. That‚Äôs the point hiring was beginning to cool again. I think this is bad data.\n\nI don‚Äôt know. I‚Äôm a manager at a medium/large tech company who was fortunate enough to get open head count every year for the past 3 years.  I‚Äôm not going to claim to be an expert, but i spent a good amount of my time trying to hire software engineers over the past three years.\n\nIn my experience, 2021 was still well in the hiring boom. Things didn‚Äôt really start to cool down until Q4 2022 or Q1 2023.\n\nI last switched jobs in Fall of 2020 and it was a feeding frenzy. That and the drop it shows in late 2019 just looks off.\n\nIt was still hot in late 2021. Mid 2022 is when it started to cool. People were claiming a \"recession\" for 2 full years ahead of that, but it never happened. Things didn't really dip fully until Jan 2023 with a lot of high profile layoffs to start the year (that was when enough FAANG layoffs had happened that other people started following suit and/or higher interest rates finally started to bite; depending your opinions of causation).\n\nNo one says it wasn‚Äôt a feeding frenzy in fall 2020. My whole point was that you can have a hot hiring market without a net gain in jobs.\n\nThat's a great point, and seems to be the most logical explanation of this in the thread so far. I think some here are too eager to dismiss it as bad data based on their own feelings of the job market for that period. But job market sentiment doesn't tell the whole picture. \n\nWhat we had was a knee jerk reaction to COVID (layoffs), which was then following by a knee-jerk reaction to the layoffs where companies started hiring like crazy to correct and take advantage of COVID hiring incentives and low interest rates. The net result was a lot of turnover, salary increases, and a very hot job market in that window, but not an overall increase of jobs.\n\n&gt; True, but don‚Äôt forget that a lot of people lost their jobs at the start of Covid and plenty of businesses shut down.\n\nNot in software though. Tech was booming during Covid.\n\nYes, software had big layoffs in early COVID as well. Tech had massive layoffs across the board in Q1 and Q2 of 2020. Companies didn‚Äôt know what was going to happen with Covid and over reacted.\n\nIt was only in late 2020 when companies got settled with remote work, the government stepped in to help, and the stock market started to recover that the hiring boom started.\n\nThe site I‚Äôm about to post focuses specifically on tech layoffs. Look at the second graph on this page and you can see a huge spike in layoffs in early COVID. https://layoffs.fyi/\n\nSince their data appears to come entirely from ADP's internal data, this could also represent a demographic shift among their client businesses. ADP competitors like Rippling are growing in popularity and the tech sector is full of early adopters.\n\nThe \"frenzy\" was due to the pandemic, it was a bubble inflating like it did in the 2000 dot com era. FAANGs and other companies were hiring to react to the lockdowns and people spending a lot more time at home. That ended, and the bubble is deflating. \n\nI definitely noticed a drop off in recruiters in 2020, and it's only gotten worse.\n\nSalaries were climbing during that time frame too. Just in 2019-2020 alone my employer bumped most of our team by around 33%. There was a time of holding during the pandemic but that didn't stay long.\n\nThis seems to match what I've heard from friends that are at other companies too.\n\nI realize this is anecdotal but even industry wide it doesn't seem to match what we've heard.\n\nBeginning of 2021 is when my firm started seeing the decline of hiring consultants. This tracks. Everyone coming out of bootcamps demanding 100k salaries from Covid pushed companies to going over seas or near shore.\n\nYou‚Äôre telling me that arbitrary salary expectations from marginally trained entry level web developers caused industry wide hiring trends to shift in a measurable way? Sounds absurd, but ok ü§∑‚Äç‚ôÇÔ∏è\n\nThe real issue is jobs going to Philippines india\n\nYes, but the push to go remote means that people started to go for cheaper non-US developers.\n\nAnyone with a brain could see this coming.\n\nNeat, but this graph shows a peak in late 2019. It starts falling before anyone ever heard of COVID. The next upswing isn‚Äôt until halfway through 2021, but at that point the market was actually beginning to cool.\n\nI think this is just bad data.\n\nI‚Äôve had several calls with recruiters filling roles that are to clean up projects that were offshored. Turns out that if you  treat your devs like disposable code monkeys, it doesn‚Äôt matter how cheap they are, they will give you their worst.\n\nThe other killer is timezones and language/ culture differences. Next best thing is people in Canada, followed by South America.\n\nOr cheaper US developers. $150k in the midwest goes a lot further than San Jose. You can hire a  team of SWEs for the price of one staff engineer in California, and the work doesn't suffer. \n\nThe only reason that tech hasn't pushed further east yet is because all the VC is still in California, but that's starting to change. Especially since ZIRP is gone.\n\n&gt;To identify software developers in the ADP sample, we independently matched two criteria, job titles and O*NET occupation codes, followed by review and filtering of the results. A set of employees was identified by querying a set of keywords present in known software developer job titles (such as software engineer, C++ developer, stack developer) and querying O*NET occupation codes for software developers (15-1252.00, 15-1253.00, 15-1254.00 and 15-1221.00). Combined data resulting from these queries was manually reviewed to weed out any job titles captured erroneously. Because the list of resulting job titles was quite long, a rule of thumb was applied to job titles that occur fewer than 2,500 times. These had to contain the key words ‚Äúsoftware‚Äù or ‚Äúdeveloper‚Äù to be included in the sample\n\nI doubt this captures everything, because businesses won't always hire \"software developers\". My position is considered \"programmer/application analyst\", and unless that's within their predefined wording, it might not even be captured correctly.\n\nI am curious about this, as well. I notice many positions I interview for have job titles that sound management-y but still involve a lot of technical work. I wonder if hiring managers in non-tech companies face salary constraints on IC roles and are just trying to work around them.\n\nMy role is straight up called ‚Äúsecurity analyst‚Äù. Throw in bizapps and various IT roles that build internal applications and you have a pretty wide net likely not covered\n\nNone of the New Hotness roles would catch\n\nNo Data Engineers, no AI Engineers, no Data Analyst, no Data Scientists.\n\nBut are they software engineers though?\n\n/puts on flamesuit\n\nI'm an Analyst of Automations or whatever. My manager made some shit up that he could sell to the company to bring me on full time.\n\nI think it has more to do with most companies not filling roles as \"software developers\" unless you work for a technology based company.\n\nThat is exactly what I'm thinking. My entire team and I are \"Digital Analysts.\" First time I've heard that term.\n\nWe are all doing controls software development in Rust ha.\n\nAbout half the Reqs I've posted in the last 6 months wouldn't catch on that.\nWe use Engineer instead of developer these days. But that wouldn't work with a simple text filter so I can see why they wouldn't include it, but that also means the data is crap.\n\nAlmost Every software dev position in financial services, especially will be AVP or VP (some weird law forces it)\nAnalysts, consultants would get missed too..\n\n‚ÄúProgrammer‚Äù would definitely be in the dataset.\n\nVery good point. Data engineers, ML/AI engineers, data scientists, robotics, DevOps engineers are all relatively new fields almost exclusively filled by software engineers.\n\nmany intelligent poor birds mysterious zesty snails history sheet rob\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*\n\nIndeed, like the new trend of product engineers for some reason which is just SWE\n\nI've seen the quality of off shored shit. Aint skurred\n\nI watched a company go mostly offshore, code quality plummeted, responses times up 20%, 5xx‚Äôs up 35%, churn rate increased slightly, conversions decreased slightly, and at the end of the day company was still more profitable overall so they didn‚Äôt change course :/ Not saying that‚Äôs the norm, but was definitely a perspective I didn‚Äôt see before.\n\n&gt; and at the end of the day company was still more profitable overall so they didn‚Äôt change course\n\nThe real pain is in the post. Almost anyone can take a well-designed system and not fuck it up too bad. The problem is that over time the system needs to slowly make large changes and subpar engineers fuck those up, so eventually the system is not well-designed, it's awful, and the subpar engineers can't run something decent on an awful system, so the competition run rings around the company whilst they have to set money on fire trying to unpick the mess.\n\nOh I totally agree, but I think by then they hope to just limp along until they can sell or whatever. Hopefully the industry will swing back the other way, but I feel the bias for quick profits is the norm right now and will be for at least a little while\n\nIt‚Äôs cyclical.  Onshore, build fantastic product, then slowly start to offshore and squeeze profits dry, then get pissed about quality and onshore a new team to make ‚Äú2. 0‚Äù.  Roll offshore team to support until 1.0 end of life then axe them.   Repeat\n\nThose ships can take years and years to burn down, but if their competition is growing faster and taking market share, that excessive cost cutting *eventually* catches up.\n\nTotally agree\n\nThis is what 90% of devs on Reddit seem to ignore. There‚Äôs always this attitude of ‚ÄúI write good code so I‚Äôm not scared.‚Äù The executives do not give a single fuck about code quality or even product quality as long as it‚Äôs profitable\n\nI hate that this is the truth. Executives don't care and can't appreciate good engineering. They want cheap and disposable. If it breaks all the time, then crack more whip.\n\nThe last company I worked for tried to offshore the majority of hires to Mexico/India/Pakistan. Only lasted 3-6 months since they could barely find good candidates and there was a lot of issues with the interviewing practices (lots of attempted chatgpt use).\n\nAlso, there was a big internal protest when one of the Pakistani employees posted disparaging stuff about LGBT on LinkedIn and the higher ups waved it off and said something along the lines of \"we're a global company now and we need to appreciate and be understanding of different cultural norms\"\n\nAfter 6 months, they scrapped the idea and the board fired the CEO and other exec who had spear-headed it\n\nI've seen it too, European developers with half the wage at same level of quality, they just tend to work a bit less.\n\nI've looked over the page a few times and didn't see the actual employment figure that is used for comparison (but I can miss and have missed such things before). Is it 75,000, per the \"more than 75,000 software developers and engineers\" statement?\n\nWhy was Jan 2018 chosen? Was employment already on a steady upward trajectory, making this movement downward (by only ~80%; the graph seems designed to make it seem worse) more of a correction?\n\n[deleted]\n\nAnecdotal evidence, but I can absolutely vouch for offshore/nearshore hiring increasing. Vast majority of our new engineering hires have been outside US, like 5/1 ratio.\n\n[deleted]\n\nWhat is it with Ukraine? Like when I was job searching, all the Lead Developer roles I applied for wanted someone to clean their mess because they contracted from pretty much Ukraine (well one of them was Nepal) and the architectures were a mess.\n\nIf you are in tech consulting they make entire teams out of offshore. Every single project I run if you have a single guy in the US you are questioned. Price is king.\n\nLots of startups with no cash flow bit the dust or heavily contracted once the fed started raising rates.\n\nYa with the rise of data analysts I wonder if a lot got siphoned off over to that\n\nMeanwhile if you actually look at [government statistics for the field](https://www.bls.gov/ooh/computer-and-information-technology/software-developers.htm#tab-6) it's booming:\n\n\"Overall employment of software developers, quality assurance analysts, and testers is projected to grow 25 percent from 2022 to 2032, **much faster than the average for all occupations**.\"\n\n&gt;  is *projected* to grow 25 percent from 2022 to 2032\n\nBased on what? This seems like they're going by past performance. This is not a statistic, it's a prediction.\n\nFrom OP‚Äôs link:\n\n&gt; Increased demand for software developers, software quality assurance analysts, and testers will stem from the continued expansion of software development for artificial intelligence (AI), Internet of Things (IoT), robotics, and other automation applications.\n&gt; \n&gt; In response to concerns over threats to computer security, organizations are expected to increase investment in software that protects their electronic networks and infrastructure. This investment could result in an increased demand for developers to create security software and for quality assurance analysts and testers to create and execute software tests.\n&gt; \n&gt; Software developers, software quality assurance analysts, and testers are likely to see new opportunities because of the increasing number of products that use software. For example, software systems continue to be built for consumer electronics and other products, including IoT-connected devices and electric vehicles.\n\nI‚Äôd say it‚Äôs a fairly solid argument.\n\nI mean it‚Äôs a theory, but doesn‚Äôt really show how they came to a number.\n\nEven if we assume by this statement that they only have data up to 2022 (and thus, everything thereafter is a prediction) it still contradicts OP's assertion that the field has been in decline since the pandemic (otherwise they most certainly would have noted the sudden reversal)\n\nRegardless, if you want to believe a random website over *checks notes, professional labor economists who collect government unemployment data for a living, well you're welcome to it.\n\nOP here. This isn't my assertion, it's something I found on r/economics, and thought would be interesting to get opinions on here. \n\nAlso, I don't think the article I linked is necessarily in conflict with the BLS predictions. It's fully possible that we are in a temporary decline which will turn around and the BLS projection will be correct. \n\nLastly, ADP is the market leader in payroll handling for the US. So I disagree that they are just some 'random website' when it comes to having accurate and up-to-date  employment data.\n\nOne nit, but this isn't a random website. It's from ADP, the biggest payroll processor in the country, who also employs many professional labor economists.\n\nAnnoyingly, BLS switched their industry term from \"software developers, applications and system software\" to just \"software developers in 2019, so it's hard to compare, but their employment counts for the last four years are:\n\nYear |\tAnnual\n----- | -------\n2020 |\t1742\n2021 |\t1875\n2022 |\t1976\n2023 |\t2104\n\nCertainly doesn't seem to agree with ADP.\n\n(You have to go [here](https://data.bls.gov/PDQWeb/le), choose \"Person counts\" in box 1 and \"Software developers\" in box 3.)\n\nRealistically, however, the market is awful, at least right now.\n\nYup. Can‚Äôt speak for the whole industry but in Bay Area there is still a good number of postings but nowhere like before. The number of applicants is also quite high. Pre post-Covid I would get recruiters from FAANG to startups messaging me on the daily, now I might get one email from a startup a month\n\n&gt;Pre post-Covid I would get recruiters from FAANG to startups messaging me on the daily, now I might get one email from a startup a month\n\nSame. It's very troubling. I'm not really happy where I'm at, haven't had a raise in 3 years, but there's no jobs out there right now. Not like there was last time I was looking for a job, I had 5 solid offers in 2 weeks of interviewing.\n\nNo, reality is the data. \n\nPlenty of anecdotes may feel \"awful\", but that's not what \"realistically\" means.\n\nA projection is hardly reality. We're also talking about now, not the future.\n\nI haven't had a job in over 2 years and had an engineering career for 10 years prior. My reality is my anecdote and that's that I'm running out of savings.\n\nThere's some weird breaks in reality between the BLS (whose collection methods are pretty horrid) and sentiments almost across the board in public spaces about the job market. Your story isn't singular, and we can see this by just going to public forums and seeing just how many people are talking about how rough the market is.\n\nI personally think that LISEP's metric for unemployment is more accurate, albeit still flawed.\n\n&gt; reality is the data\n\nhttps://fred.stlouisfed.org/series/IHLIDXUSTPSOFTDEVE\n\nRealistically is that there aren't jobs available.\n\nThe same few jobs get posted, get hundreds of applicants, and stay \"unfilled\". I've been in companies doing this. They love to say they're hiring, and it keeps their queue full when they push someone out (which they prefer over firing, because then they don't pay severance).\n\nThis is quite the cope\n\nAre there really programmers out there unaware of logical fallacies? Unreal... https://en.wikipedia.org/wiki/Argument_from_anecdote\n\n&gt; The ones that knew their worth‚Ä¶\n\nYeah this is probably key too. I‚Äôve had several offshore and nearshore contract devs actually end up going through the h1b process and moving to the US after getting hired on full time at my companies after successful stints as a contractor. Several more leave us to go work as devs for another US company when they won an h1b lottery. Obviously there are family commitments, cultural preferences, just the natural love of your own home at play but many solid devs working for US/other western companies will eventually end up immigrating to that country for much higher wages and in many cases standard of living.\n\nProbably a bunch rebranding themselves as Data Scientists, AI Engineers, Data Analysts, and various other roles.\n\n[deleted]\n\nMaybe we should start writing our representatives about 174.\n\nI think on some level we also need to start forming a general union for tech roles to make these issues less of an impact on us. 174 and 5% interest rates shouldn't hit the sector so hard, and I really feel for the engineers that got stuck doing 2-3 jobs after employers axed their peers and there's no jobs to switch to. Unfortunately our field had a bit of golden child mentality going on for too long and has no desire to organize for protections\n\nIf possible, see if you (or someone you know) can actually speak with your representative.\n\nOr write an actual letter and mail it to them.\n\nIt's hard to know if they even see emails themselves given the likely volume. So those are probably more effective at communicating a broad topic of concern than any specific issues.\n\nMy marxfoil hat theory is Section 174 was lobbied for by FAANG and friends to suppress small business hiring while they laid off their workforce, saved on expenses for a bit with less output in exchange for a lower market rate of software engineers, and they'll go back to normal as interest rates lower/174 is lifted\n\nNever let a good crisis go to waste\n\n&gt; made it so companies can‚Äôt write off the cost of software development as a normal expense.\n\nNo, it changed it so software development doesn't automatically qualify as R&amp;D expenses. It's essentially a tax subsidy for big tech.\n\n&gt; The problem is that tech, as an entire industry, has this unusual view that you shouldn‚Äôt be profitable. Much like MoviePass, you‚Äôre supposed to vacuum up tons of investor cash, then burn it in order to hit hyper growth\n\nThis is a meme, it's not reality for the most part. The entire appeal of software companies is low headcount = high margins. People (especially investors) aren't stupid enough to throw money at any handful of developers who promise \"hyper growth.\" The hockey stick formulae only work out if the business is fundamentally changing/creating markets and can prove they have a massive TAM. Most software businesses don't look like that - they're about carving out a niche and exploiting market inefficiencies, and investors aren't stupid enough to confuse the two. \n\nThere are some companies like MoviePass, Uber, or Amazon where it is obvious they need to scale up to make profit. The vast majority of businesses do not look like that. On top of that, MoviePass failed where Uber and Amazon succeeded because even though they weren't profitable, they still had impressive cash flow.\n\nNow that trump is in office, how do you feel about the future of this field? I've been looking since being laid off about two years ago. I graduated only ten months before getting the job.\n\nADP appears to be reaching this conclusion by looking at their customer data. Given that the BLS' numbers contradict their narrative, I think a more accurate interpretation would be:\n\n*ADP's market share among companies that employ software developers is in decline, and has been since pre-pandemic*\n\n&gt;Given that the BLS' numbers contradict their narrative\n\nDoes it? All I've seen is their 'projection' for the future. Not sure how to find their data on actual employment levels per job title.\n\nBuilding a proper chart on the BLS site is a nightmare when using a phone, so here are the numbers from May of each year:\n\n| Year | Computer and Mathematical Occupations (15-0000) | Software Developers and Programmers (15-1250) | Software Developers (15-1252) | Software Developers and Software Quality Assurance Analysts and Testers (15-1256) | \n| - | - | - | - | - |\n| 2018 | 4.38M | 1.67M | N/A | N/A |\n| 2019 | 4.55M | 1.75M | N/A | 1.41M |\n| 2020 | 4.59M | 1.81M | N/A | 1.48M |\n| 2021 | 4.65M | 1.87M | 1.36M | N/A |\n| 2022 | 5.00M | 2.05M | 1.53M | N/A |\n| 2023 | 5.18M | 2.18M | 1.66M | N/A |\n\nNote: the BLS taxonomy at the \"detail\" level changed for software devs in 2019 and 2021, so the \"major\" and \"broad\" levels are the only ones with continuity.\n\nSource: [pages like this](https://www.bls.gov/oes/2022/may/oes_nat.htm#15-0000)\n\nEdit: added more categories\n\nWow, gathering the yearly data for comparison from that site is tedious. Thanks for the effort. From what I'm gathering, roles where the SWE skillset is applicable increasing, but SWE-specific roles are becoming a smaller share of the overall employment market in comparison. That would explain the data somewhat..\n\n&gt;If you look at the software specific categories, you'll see them grow from 2018-2020 and from 2021-2023 \n\nSomething I find interesting is that there was some decline for the SWE specific categories between 2020 and 2021. This is in the time period where everyone (myself included ) remembers a pandemic \"hiring frenzy\" happening. It just goes to show that there can be a period of frantic hiring that doesn't necessarily result in an overall gain on employment.\n\nIt's hard to compare 2020 against 2021 because \"Software Developers\" (15-1252) are in their own category in 2021 while they're lumped together with \"Software Developers and Software Quality Assurance Analysts and Testers\" (15-1256) in 2020.\n\nIt's being outsourced, just like every other job.\n\nAs a software developer in decline, this is great news for me.\n\nThere is still a lot of software which needs to be written.\n\n\nNot worried yet\n\nThis is due to near shoring. You can hire a good developer for 1/3 of the price as you would in the US\n\n[deleted]\n\nSame timezone as the US (so latin america) meaning that collaboration isn't as impacted as offshore (like, india).\n\n[deleted]\n\nI mean, some people here are saying that their company markets themselves as nearshoring, but I'm not sure if that makes much sense since Canadian salaries are basically (as far as I know) costwise the same as hiring American programmers in smaller cities.\n\n[deleted]\n\nLiving in Argentina, I'll tell you that good software engineers are not drastically cheaper; good ones don't work for less than $80K and very senior engineers command near-US salaries.\n\nAs they should, capitalism is hollowing out and offshoring all jobs to exploit workers in other countries. They should punch back at the predatory companies looking to take advantage of them.\n\nThese are cost cutting measures, they never go after the good ones.  They go for the cheapest of the bottom barrel.\n\nThis is why quality _tanks_ when they do it.\n\nAre there good engineers in India and Argentina?  Absofuckinglutely.  \nAre these companies utilizing them?  Not a chance in hell.\n\nYou're generalizing. I've helped build out teams of senior engineers in Argentina that trounced teams of mediocre SV engineers. Nobody was making under $80K a year and later raises put them on par with US Midwest city pay bands.\n\nMuch like in Eastern Europe, there's definitely talent. Agencies trying to cheap out are going to cheap out and their customers will eventually get it after two or three years of wasting money.\n\nI've been working with American customers for the past 20 years and it's the same thing over and over again.\n\nNear shore is just a way to refer to locations that are relatively close to your operations. Instead of hiring teams of developers that are time zones away, you can hire the equivalent in North America or South America. Both are ‚Äúoffshoring‚Äù, but near shore just means closer to you.\n\nNear shore = Mexico, Colombia, Argetina, Brazil, etc\n\nEven if not 1/3 but 2/3 for very good talent it's still a huge bargain. Especially after factoring in benefits and equity.\n\nThis is not a \"peak\", it's curb stomping wages and squashing unionization attempts.\n\nWhat unionization attempts?\n\nThe one at google, where google fired four people and put the rest in mandatory anti-union training\n\nhttps://www.bbc.com/news/technology-55173063\n\nterrific impossible badge snow growth hat waiting wine fuel touch\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*\n\nIt likely isn‚Äôt, but big companies get to do with they want because lack of anti-trust enforcement have made them so powerful that they‚Äôll happily eat a fine cause the ROI they get from mass exploitation is worth it.\n\nUnions aren't going to result in *more* software engineers getting hired.\n\nno, but it will stop the wage stomping and the firing of current ones instead of diverging those profits to CEO bonuses.\n\nWhen it's harder to fire, companies are more reluctant to hire. That makes things worse, not better. Developer salaries are pretty fucking alright.¬†\n\n&gt; When it's harder to fire, companies are more reluctant to hire. That makes things worse, not better. \n\nThat's quite a sell telling people that the precariousness of worker's rights is actually a good thing. Guess me and all the people in my network getting laid off this year was a service to our country o7\n\n&gt; Developer salaries are pretty fucking alright. \n\nYea I see now, a case of \"fucks you gots mine\"-itis. Usually a precursor to the above opinion.\n\n&gt; When it's harder to fire, companies are more reluctant to hire\n\nRephrase that: corproations would rather keep workers in a more precarious position that provide them with more labor protections because it makes them more money.\n\n\n\n&gt; ¬†Developer salaries are pretty fucking alright.¬†\n\nOh I see.... \"fucks you gots mine\"-itis. Ok\n\nYeah, I'm very pro union in general, but I don't think it's a solution here. Policy that provides incentives to employ people here and disincentives to offshoring work is the better solution imo. Unions didn't prevent American factory workers from losing their jobs to offshore workers.\n\n&gt; When it's harder to fire, companies are more reluctant to hire\n\nRephrase that: corproations would rather keep workers in a more precarious position that provide them with more labor protections because it makes them more money.\n\n\n\n&gt; ¬†Developer salaries are pretty fucking alright.¬†\n\nOh I see.... \"fucks you gots mine\"-itis. Ok\n\nThat's because we're all supposed to stop learning to code, remember?\n\n[deleted]\n\nI don't agree with your doomer outlook, but I do agree with prioritizing financial stability. If the economy *doesn't* crash, you can retire early. There's not a tremendous down side, here.\n\n[deleted]\n\nWinter?\n\nthey don't know.\n\nThey're basically doomsayers\n\nThey sound like my dad.\n\nSaving and keeping my cheap rent is probably the greatest decision I will have ever made. Sometimes it‚Äôs hard to maintain the frugal attitude but hot damn does it pay off more and more as time goes on.\n\n&gt; I keep telling people to save. \n\nUntil the currency crashes or inflation rises and you lose a lot. Like here in Sweden the currency dropped almost 30% since COVID.\n\n\nAt least in the US it's easier for you to put it into shares though.\n\nSavings and low expenses also means you can walk away from a job without worrying about bridging the gap until you find another job.  I know people making 40% more than me that don't have the same luxury.\n\nlmao @ the desperate \"nuh uh\" coping with anecdotes in the comments here. Don't show this to CSCQ.\n\nTech isn't going anywhere as an industry and will continue to grow, but the days of being able to fizzbuzz and get a tech job are over.\n\nCan't blame this one on AI...\n\n\"stack developer\"\n\nThey took our jerbs\n\n&gt; To identify software developers in the ADP sample, we independently matched two criteria, job titles and O*NET occupation codes, followed by review and filtering of the results. \n\nI'm pretty sure the biggest issue here is that this is the same thing that happened to the title \"programmer\". We saw the same articles about the \"decline of programmers\" when all that was happening was simply people adopting different job titles. So I'm betting this is simply a shift in titles from programmer to developer to software engineer (and similar titles).\n\nNo.\n\nRemote work means work from India (or other location where the local labor cost is low). The jobs have moved.\n\nI've been forced to layoff my personnel in the U.S., then back-fill on attrition exclusively in India.\n\nOh i know this one.¬†\n\n\n\"They are giving the jobs to foreign developers who are not as good as me and they will regret later\".¬†\n\n\nI bet US said the same when manufacturing started to leave.¬†\n\nBusinesses may ultimately regret the decisions that were made, but those who benefited will never regret the extra money they made...\n\nI wouldn‚Äôt trust data from ADP. They are payroll people  There are lots of different titles and not everyone uses ADP.\n\n[deleted]\n\nIn the mean time, we got scammers who have a \"game\" on Steam named Banana, which is a fake autoclicker game which makes the dev millions. I'm tired of being the nice guy and making nothing or very little, while these people make it big.\n\nJust go rob a bank already if you're so tempted to be a piece of shit for money. At least banks have insurance.\n\nLets be real if most of us ever imagined something that stupid would work we would have done it too.\n\nWhat is the number of imports in the US taking US jobs and how many US jobs are being exported over seas?  Anyone tracking that?\n\nMeh doesn‚Äôt matter what the numbers say as I seen stats claim wildly in both directions. All i know is what I have seen over 20 years, and that‚Äôs companies hallow out the U.S. workforce by offshoring or near shoring, crushing all union attempts and dissent. \n\nThere is a reason steel, cars, computers, chips, clothes, boats, trains, and literally everything as no longer made in the U.S. and guess what still is for now? Tech but it won‚Äôt always be that way.\n\nCleveland SDEs get paid less than Canadians . Wow.\n\nPlease note this is a chart of job listings not employment.\n\n&gt; The index represents the employment of software developers each month relative to January 2018. To identify software developers in the ADP sample, we independently matched two criteria, job titles and O*NET occupation codes, followed by review and filtering of the results. A set of employees was identified by querying a set of keywords present in known software developer job titles (such as software engineer, C++ developer, stack developer) and querying O*NET occupation codes for software developers (15-1252.00, 15-1253.00, 15-1254.00 and 15-1221.00). Combined data resulting from these queries was manually reviewed to weed out any job titles captured erroneously. Because the list of resulting job titles was quite long, a rule of thumb was applied to job titles that occur fewer than 2,500 times. These had to contain the key words ‚Äúsoftware‚Äù or ‚Äúdeveloper‚Äù to be included in the sample.\n\nIts most likely a chart of badly mismatched data sets and is probably just showing how the buzzword bingo in job listings have changed. Get an AI to do the matching next time.\n\n&gt;Please note this is a chart of job listings not employment\n\nActually the data is from ADP payroll accounts, not job listings.\n\nNah, the job of \"software developer\" is in decline because web devs are less needed. Dig deeper and devops is rising. We don't really need front end web atm.\n\nI hire a lot of developers. I think this is primarily because people are less likely to change jobs to avoid risk right now. The economy is in the toilet and people are more inclined to sticking with a secure job. That and people are addicted to telework and as companies move back into the office people hold out for telework jobs.  Also, with inflation kicking everyone‚Äôs butts, developers are asking for a lot more money, which is fair but in a lot of cases bill rates just don‚Äôt support what people are asking for.\n\nGood. Too many bs grads oversupply ruining the job market.\n\nAlso a lot of folk starting construction... Wouldn't be surprised how many fields are hurting the same way.\n\nMost tech jobs regarding software graphic design animation etc have not done well since the pandemic. it just shows like the '08 crash with trade jobs how fragile some sectors of the job market are.\n\nsadly that's because our government has done little to stop the influx of H1-B visa folks and/or the firms that propogate this ...  Offshore development needs to stop and it needs to stop NOW.\n\nbased on ADP employers.....not a complete picture....only those that use ADP for HR and Payroll....most Devs are moving to Per Diem and or Data Science type roles in the US...cause dumb businesses are off shoring their dev by numbers and suffer the risk consequences\n\nThe past few years have seen unprecedented global business challenges, such as natural disasters, trade disputes, and supply chain disruptions. The sectors most impacted by these factors include retail, healthcare, and finance; in the Q3 2023 Global Risk Survey, 36% of companies identified geopolitical tensions as a major risk.\n\nRead All Staistics in Detail:-https://www.mindinventory.com/blog/software-development-statistics/"
  },
  {
    "title": "Thomas E. Kurtz, the inventor or BASIC, has passed",
    "body": "",
    "score": 1299,
    "url": "",
    "created_utc": 1731651588.0,
    "author": "intelw1zard",
    "permalink": "/r/programming/comments/1grq3fo/thomas_e_kurtz_the_inventor_or_basic_has_passed/",
    "all_comment_text": "2024 END\n\nA rescue-goto before the END is surely in the code.\n\n2024 GOTO 10\n\nBASIC introduced me to programming, RIP legend.\n\nI remember hitting the single file limit for programs on BASIC for windows because I didn't know how to split my code across multiple files.\n\nhttps://usborne.com/gb/books/computer-and-coding-books\n\nThis was the book that got me into BASIC as a kid:\n\nhttps://drive.google.com/file/d/0Bxv0SsvibDMTYkFJbUswOHFQclE/view?usp=sharing&amp;resourcekey=0-ffScR4l9gOJrDiFw5Kb5fg\n\nThis happened to me!  I was using HiSoft Basic 2 on the Amiga and was writing my own terminal for accessing BBS sites and the like (remember X, Y, &amp; Z Modem protocols?!)  Things started getting weird.  Being the 90s you could still get hold of a human within minutes and the guy was like \"So, why is this all in one file, can't you just split it out?\"\n\nOh.\n\nThat's an amazing book for learning programming, I wish I had something like that as a kid :)\n\nSame here. It was also quite cool to write BASIC. I would not use it these days, but it was really nice to have a hardcopy paper set of instructions, typing it into the computer and seeing things happen.\n\nI learned BASIC from the book that came with my Amstrad CPC when I was 10, it was indeed magic to type (also my first experience with typing) lines from a book (and later magazines!) and see results on a screen. Wasn‚Äôt long until I started adding simple Z80 assembly to my code too, Amstrad‚Äôs brand of BASIC made that easy.\n\n40 years ago I was typing things I couldn‚Äôt understand, in Basic.\n\nToday, I‚Äôm still typing things I don‚Äôt understand, just with a different language.\n\nthe circle of life\n\nBut at least they're understandable to your colleagues, right?\n\n.....right?\n\nWell, they all use ChatGPT now to read the program to them in plain language, so ... sure.  Sort of.\n\nMe too, on a Commodore PET, the early one with the green screen and the Fisher-Price square keys. Happy, happy days.\n\nGreen screen gang!\n\nOften the reality of BASIC was simply POKEing machine code into memory - there wasn't actually that much BASIC in many programs.\n\nYup. TRS-80, and David Lien's excellent book that came with the machine.\n\nSame, on a [VTECH Power Pad](https://youtu.be/LcC8w_3bg8g)!\n\nI started by inputting programs from 3-2-1 Contact. My first one drew a wave made up of a parabolic curve and animated a stick figure surfing on it. If I recall, it even used the PC speaker to make a surf wave sound. \n\nThat program changed the course of my life.\n\nQBasic was my first programming language, and despite the hysteria at the time, it did not \"ruin\" me me as a future programmer.¬†\n\n\nRest in peace, and thanks for everything!\n\nDepends. Did you pick up C++? :)\n\nDammit is that how it happened?\n\nI mainly work with Java, JS/TS, Python and a bit of Rust at the moment.\n\nRust, so hot right now.\n\nBasic, Borland, Battlestar Galactica.\n\nI went qbasic to C and it was great for awhile.\n\nThe distinction between subroutines and functions in QBASIC influenced me when I got into JavaScript into what amounted to a personal discipline of distinguishing pure functions and impure functions _way_ before I knew those terms from the FP space.\n\nIt's a great language for learning the fundamentals and honestly being forced to work in QBasic with no mouse made me a very efficient programmer.\n\nSame, honestly looking back on it, QBasic was such a great development environment: code editor, debugger, and documentation viewer all-in-one.\n\nNothing I‚Äôve used since is as simple *and* powerful. We‚Äôve lost our way.\n\nI have very fond memories of learning English from just endlessly browsing the QBasic in-built help screens and always discovering something new and cool\n\nI first learned on a C64 but I spent *way* too much time playing QBasic Gorillas on school computers, such good times\n\n\"co-inventor, with John Kemeny, of the BASIC programming language\"\n\nRest in peace.\n\nI TA'd for him in the 80's--great guy and really smart. The version of BASIC he and Kemeny created was much more advanced and structured than the bastardized version found on early microcomputers. Check out TrueBasic.\n\nCan you give us an anecdote?\n\nFrom https://en.wikipedia.org/wiki/True_BASIC:\n\n&gt; True BASIC provides statements for matrix arithmetic, a feature that had been present in Dartmouth BASIC since early times, but had been dropped in almost all microcomputer versions of BASIC interpreters. It implements global and local variables which make it possible to write recursive functions and subroutines. \n\nTbh I feel a bit cheated.  I started with AppleBasic and then moved on to QBasic later.  NOT at all the same as his intended version.\n\nTrue BASIC, developed by John Kemeny and Thomas Kurtz (the creators of the original BASIC language), was more advanced than the BASIC included with the Commodore 64 (C64) in several key ways. Here‚Äôs an explanation of the differences:\n\n1. Structured Programming\n\n\t‚Ä¢\tTrue BASIC: Introduced structured programming features, such as IF...THEN...ELSE, FOR...NEXT, WHILE...WEND, and DO...LOOP constructs. This allowed for better-organized and more maintainable code.\n\t‚Ä¢\tC64 BASIC (Commodore BASIC 2.0): Relied heavily on line numbers and GOTO statements, which often led to ‚Äúspaghetti code‚Äù that was difficult to read and debug.\n\n2. No Line Numbers\n\n\t‚Ä¢\tTrue BASIC: Did away with mandatory line numbers. Instead, it allowed for procedures and labels, making programs easier to write and understand.\n\t‚Ä¢\tC64 BASIC: Required line numbers for every command, which could make editing and organizing large programs cumbersome.\n\n3. Built-in Graphics and Sound Support\n\n\t‚Ä¢\tTrue BASIC: Included built-in support for graphics and sound commands, making it easier to create multimedia applications.\n\t‚Ä¢\tC64 BASIC: Had minimal built-in commands for graphics and sound. Users often had to resort to PEEK and POKE commands or assembly language for advanced features.\n\n4. Advanced Data Structures\n\n\t‚Ä¢\tTrue BASIC: Supported advanced data structures such as user-defined functions, subroutines, and multi-dimensional arrays. These features made it more suitable for complex programming tasks.\n\t‚Ä¢\tC64 BASIC: Had limited support for arrays and relied heavily on global variables, with no true subroutines or user-defined functions.\n\n5. Portability\n\n\t‚Ä¢\tTrue BASIC: Designed to be portable across different platforms, adhering to the ANSI standard for BASIC. This made it useful for developers who wanted their programs to run on multiple systems.\n\t‚Ä¢\tC64 BASIC: Was tied closely to the Commodore 64‚Äôs hardware, with many commands specific to the platform.\n\n6. Error Handling\n\n\t‚Ä¢\tTrue BASIC: Included better error handling mechanisms, making it easier to debug and recover from errors in programs.\n\t‚Ä¢\tC64 BASIC: Provided very basic error messages, which were often cryptic and unhelpful.\n\n7. Development Environment\n\n\t‚Ä¢\tTrue BASIC: Typically offered a more modern development environment with features like better text editing and debugging tools.\n\t‚Ä¢\tC64 BASIC: Lacked these conveniences, requiring programmers to work with a simple line editor.\n\nIn summary, True BASIC represented an evolution of the BASIC language with a focus on modern programming practices, portability, and ease of use, while C64 BASIC 2.0 was a minimalistic and hardware-specific implementation that reflected the constraints of the early 1980s.\n\nthanks, chatgpt\n\nIf it doesn't have line numbers, is it even BASIC any more? :)\n\nYeah, Visual Basic doesn‚Äôt require line numbers and is still in use and being updated in 2024: https://en.m.wikipedia.org/wiki/Visual_Basic_(.NET)\n\nOther than line numbers, that sounds a lot like [BBC BASIC](https://en.wikipedia.org/wiki/BBC_BASIC) from the BBC Microcomputer. The BBC also had the RENUMBER command to stop things like 10, 20, oh-god-I-forgot, 15, etc.. Had to watch out for computed line numbers in GOTOs though.\n\nC64 BASIC wasn't written by Commodore. It was a very early Microsoft, and Tramiel utterly schooled them on the deal.\n\nIf you used the Edit ROM that came with the BBC Master series then you only needed to number target lines, i.e. lines that were the destination for `GOTO`, `GOSUB` or `RESTORE`. Eventually even those line numbers could be replaced by labels. That might have been 'Tube Basic' for when you had a second processor attached.\n\nI started on TrueBasic. The world seemed infinite with possibilities.\n\nyeah the history is more involved, even pre basic influences like dasimco or dope\n\nGOTO HEAVEN\n\nIn 1973, I learned BASIC on a teletype in a public high school, connected to a mainframe somewhere via a telephone coupler. A half-century later, I am still writing code. BASIC was the gateway.\n\nGOTO 86\n\nBeginners All-purpose Symbolic Instructional Code\n\nRIP\n\nBASIC was the first programming language I ever attempted to learn, on a Commodore 64 in the mid-1980s. I was a child at the time, I had no clue what I was doing. Decades later I am writing software to help special education schools keep track of their learners' education, engagement, and progress. I still barely know what I'm doing though. Rest in peace, Thomas\n\nMy first ever programming was using the YABASIC compiler on the ps2 demo disk with dad. Been in software engineering for nearly 2 decades now.\n\nRest easy Thomas. Quite a legacy.\n\nAnd here I thought you were joking with the name ‚ÄúYABASIC‚Äù\n\nIf I remember correctly it stood for \"Yet Another BASIC\" Compiler. Wrote the code with the ps2 controller, haha. Did your classic hello world then also drew a sort of smiley face using mathematical functions. Blew my mind as a 12 year old.\n\nRest in peace, luminary.\n\nHe lived long enough to see his language turn 60.\n\nAs posted on HN as well,\n\nLike many BASIC was my first programming language, Timex 2068 BASIC to be more exact.\n\nFollowed by GW-BASIC and Turbo BASIC.\n\nNot only it was my entry path into the computing world as a kid, it also showed me how to do systems programming in a language kind of safe, alongside Z80 and 8086 Assembly.\n\nTurbo Pascal was the next in the learning path, after those BASIC variants.\n\nMany thanks to Dr. Kutz and Dr.Kemeny, and those that built upon their work, for setting me free into the computing world without being tainted C is the true and only path to systems programming.\n\n&gt; Timex 2068 BASIC to be more exact.\n\n[Timex 2068](https://en.wikipedia.org/wiki/Timex_Sinclair_2068) being an odd USA (and a few other) market variant of the [Sinclair ZX Spectrum](https://en.wikipedia.org/wiki/ZX_Spectrum), latter likely many middle-aged european programmers' first computer. Wasn't nearly as successful as the ZX Spectrum was in Europe, but actually improved some things - particularly graphically (8x1 attribute color, hires mode enough for 80-column text. Definite pity later spectrum models didn't add that) and sonically (had an AY chip, but later spectrum models did add that).\n\nFWIW [ZEsarUX](https://github.com/chernandezba/zesarux) will emulate the Timex 2068 among others and not just the normal Sinclair ZX Spectrum models.\n\nRETURN\n\nHe is safely in the cloud now üëëüôè\n\n10 go to 20\n20 come back!\n\nI first used BASIC on an Atari 800 in 1980.  The magic I felt back then put me on a path to a career and a life I might never have had without Kurtz's invention.  RIP Thomas.  Thank you.\n\nThe joy I had on an Atari 400 with BASIC seeing my first program run has sustained for all these years.  Thanks Thomas, its been a blast.\n\nFirst Niklaus Wirth and now Kurtz. Sad year for programming legends. Hope Donald Knuth is doing well.\n\nKnuth was born in 1938. He's pushing 87.\n\nRIP.\n\nGOTO afterlife\n\n10 PRINT \"RIP\"\n\n20 END\n\n10 PRINT \"RIP\"\n\n20 GOTO 10\n\n    1928 PRINT \"Hello Kurtz!\"\n    2024 END\n\nI'm gonna have a Pumpkin Spice Latte in his honor; it's a Beginners All-purpose Seasonally Inspired Coffee drink.\n\nInteresting!\n\nGOTO heaven\n\nI am pretty sure this guy is responsible for the career of many developers who are now in their late thirties or older. I would have no idea what I would be doing now if I didn‚Äôt pull out a random book on BASIC for young children at a library as a kid\n\nRIP.\n\nLate fifties and into their sixties indeed! We started with BASIC when it was a fun option on the PDP-11.\n\n    10 PRINT \"What did the bird say as it flew over K-Mart? Cheap, Cheap!\"\n    20 GOTO 10\n\nWe were silly kids abusing the K-Mart display units, but those of us with Commodore-64's and -128's really _did_ learn BASIC. Eventually assembly, Pascal, C, and now all of the scripting languages we used to joke about because they were scripting languages.\n\nIf it wasn't for BASIC there wouldn't have been qbasic, which is what I tweaked on as a kid in the 90s, and learned concepts that I still use to this day.\n\nRIP &lt;3\n\nGOTO: 10;\n\nMy first programming language is BASIC. RIP\n\nRest in peace. Legends never die.\n\nThanks. I owe my career to him. Everything started with a Casio FX880p and a curious kid ü´°\n\n[GOB's program](https://youtu.be/JbnjusltDHk?si=6u2r-fFOKntyAM6T) will never END\n\nwild how he went from a simple office job to laundering money for a Mexican drug cartel and living in the Ozarks in a span of a few short years.\n\nGOTO Legend\n\nMistah Kurtz‚Äîhe dead.\nA penny for the Old Guy\n\nTo quote Conrad via T.S. Eliot:\n\n&gt; Mistah Kurtz‚Äîhe dead.\n\nWhat a beautiful legacy he leaves behind. Just as people like Jobs, Wozniak, and Jack Tramiel revolutionized the computer industry by bringing these expensive contraptions from universities and offices into suburban houses worldwide, Kurtz &amp; Kemeny did something similar on the programming side, introducing regular people and kids to programming, turning what was strange and complex into something simple and understandable.\n\nIt takes genius to do that.\n\nOh the memories of qbasic on ms dos 5\n\nThis man created and destroyed more developers than anyone in history.\n\nRIP. I cut my teeth on BASIC and used about 5 different versions. The last one being VB6 where I made a full 3D game engine, MMO client/server environment and a lot of physics simulation software.\n\nI myself learnt to code and explore by installing a BASIC interpreter, both the GW-BASIC one and the QBasic one. I learnt that for two years only. But if something has taught me a lot about programming after Logo, it's BASIC.\n\nRIP.\n\n10 FOR I=1 TO 96: PRINT \"Hello world!\": NEXT I  \n20 PRINT \"... goodbye, Thomas E. Kurtz.\"  \n30 END\n\nSad day.\n\nMistah Kurtz‚Äîhe dead.\n\ni started my journey with BASIC.. RIP Sir.\n\nGOTO END\n\nRIP to a legend, you will be missed. o7\n\nThe first program I wrote was a program in Waterloo BASIC that converted units between each other.\n\nHe accomplished his goal of making programming accessible to others. \n\nUsing that knowledge I made a life for myself and my family from nothing.\n\nThank you\n\nGOTO . . . .\n\nMy Dad gave me a copy of the Basic Manual by Kemeny and Kurtz back in the 70's I remember chapters on Heuristics and Population Dynamics with rabbits v foxes. Good times.\n\nEvery year we lose more and more Greybeards. It makes me weep.\n\nFOR I = 1 TO 5: PRINT \"Thank You, Mr Kurtz\": NEXT I\n\nTI-Basic anyone? I started programming on the TI-83 calculator\n\nF\n\nI feel they could‚Äôve had more fun with the headlines? The inventor of BASIC  just hit the ultimate STOP and went to the great tape drive in the sky.\n\nReddit GOTO predates BASIC by a good few years, BASIC inherited it. It did sort of set the standard for FOR loops (replacing DO loops) and IF statements though.\n\nWhich of them? Kurtz, the inventor, or BASIC?\n\n[deleted]\n\nYou ding-dong. Microsoft QBasic was derived from BASIC, just like Applesoft BASIC, and all the other variants of BASIC.\n\n[deleted]\n\nRead the room, man. This is a memorial post."
  },
  {
    "title": "Microservices: it's because of the way our backend works",
    "body": "",
    "score": 1258,
    "url": "",
    "created_utc": 1720531960.0,
    "author": "big_hole_energy",
    "permalink": "/r/programming/comments/1dz2iph/microservices_its_because_of_the_way_our_backend/",
    "all_comment_text": "Learned a lot today, *love* Galactus ...\n\nEvery time I see this video referenced anywhere, I have to watch it again.\n\nI love it, It‚Äôs so good!\n\nThis and 7 red lines represent the start of my time consulting pretty well.\n\n[The expert](https://m.youtube.com/watch?v=BKorP55Aqvg)\n\nI have a number of friends / colleagues who've never managed to finish it, as the rage it triggers is too great.\n\nI honestly thought you were exaggerating but I can‚Äôt make it through that video.\n\nThat triggered PTSD from my days being the tech guy in sales calls for our consulting firm.\n\nOne drawn with invisible ink\n\nPrepare for Deallocation.\n\n[I understood that reference](https://youtu.be/eSqexFg74F8?feature=shared)\n\n10 years later this is still what it feels like to work in big tech. Except PMs won‚Äôt just walk away with ‚Äúno‚Äù as an answer anymore, thanks to everyone‚Äôs performance and ultimately PIP at risk if birthdates aren‚Äôt supported by next week.\n\n.\n\nlol, we literally had this happen a number of years ago, except sales not only didn‚Äôt get an estimate for cost but also forgot to tell us.\n\nThe net result?  A new product that cost more than they sold it for and had to be put in at emergency break neck speed.\n\nWe never could get sales to agree to let us estimate work before they make the sale.  Of course, their bonuses are tens of thousands of dollars and calculated by the total sale price not how much we make off it, so of course they‚Äôd prefer to sell it even if it‚Äôs at a loss.  Leadership just kept complaining shit how we couldn‚Äôt make money yet would hear nothing about making sales bonuses contingent on how much they actually make the company.\n\nRevenue based sales bonuses are fine, mostly desirable really. Sales job is to sell, not run the business. A management team that lets them sell vaporware unchecked is not fine. The latter problem is what needs fixing.\n\nI have seen sales promise features out of the blue.\n\nThat‚Äôs just bad management.\n\nWe all have.  It‚Äôs still desirable\n\nCan be.\n\n&gt; The latter problem is what needs fixing.\n\nAnd you do it by incentivizing profit, so you change your bonus structure to be about profit and not revenue.\n\nIf people tend to have a bad behavior, you can bet they have a bad incentive. And the best way to change the behavior is to change the incentive. Which should be the job of management instead of wanking all day in their office.\n\nProfit is a business decision. Sales should not be making it.\n\nEdit: you stop it by not letting them dump unachievable requests on engineering then firing salespeople that don‚Äôt get with the program. Good companies work that way.\n\n100%\n\nimagine that but in a startup of less than 10 people lmfao, 4 of which are programmers.. 2 front end, 2 back end\n\nedit: correction\n\nI think you meant the day *before* tomorrow.\n\n[deleted]\n\nBro do we work together\n\nthis video is 10 years old now\n\nYeah but still relevant\n\nIt's remarkable, I think it gets *more* relevant over time, not less.\n\nAre we suggesting Galactus *does* have future knowledge?\n\nSince build 1637, yeah, as long as the feature flag is turned on.\n\nCuriously enough, the flag was set to `true` since build 1171.\n\nUnfortunately extremely relevant to me :-(\n\nLindy rule!\n\nStill relevant because it shows a fundamental truth. \n\nNo architectural pattern can solve the problem of making bad engineering decisions.\n\nit is four years, you sad pathetic little product manager\n\n***\"I'd rather lay you into the barren Earth than entertain your folly for a moment longer.\"***\n\nHonestly the product manager in the video is pretty chill about the whole thing. I'd work with them without hesitation.\n\nwhat you didnt realize is that every engineer he has ever met says this shit all the time. He's just used to it!\n\nThe The Mythical Man-Month is 50 years old and we're still making the same mistakes from the namesake chapter of that book today.\n\nMy favorite part of the book was explaining that as the number of user increases,  the number of bugs reported also increases. He talked about this like it was normal thing. \n\nBut something our current manager consider as unacceptable and shouldn't happen.\n\nAlso, something like onboarding new dev on the team actually decreases your productivity in the next 3-6months due to training etc..\n\nThe onboarding I‚Äôd quibble on. Decent code bases, with a well performing product development, can have new devs helping to get stuff done in weeks and even days.\n\nIt ultimately comes down to organisation. When I‚Äôve seen it take a long time to onboard, it‚Äôs been at places which are very disorganised.\n\nI think the difference between now and fifty years ago, is there is a lot more tooling and common knowledge that good teams can rely on to be well organised.\n\nThat's because the mythical man month is basically unknown in project management circles and isn't really written with those people in mind. So it's basically a programmer telling other programmers what they already know, because if you've done this for more than a year and don't already know this I don't know if anyone can help you.\n\nNo, they know it's just you are in a bidding war with people that have not or will not read it.\n\nAgain, the folks who divide this by man hours haven't heard of it.\n\nThey do read stuff, but not this.\n\nOh yeah; rip Weinberg\n\nI still cringe when my boss ask for timelines when I know it is all bullshit.\n\nIt‚Äôs from 2020, which does feel like 10 years ago\n\nOld but gold\n\nThey need to have an update where they  discuss why they still can‚Äôt put the birthday day on the settings page.\n\nA cool update would be IA starting pods on kubernetes to compute birthdates\n\nOr an LLM.\n\n\"Jiiiiiiim the backend is hallucinating again!\"\n\nI do love that they have a call back to omega star still not supporting time stamps in [this video](https://youtu.be/DYvhC_RdIwQ?si=9FzdUXcOmqSXzJKn) though.\n\nfearless skirt enjoy glorious innocent cobweb upbeat rainstorm march fuzzy\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*\n\nnah, it's just that it has been posted here 600 times already\n\nYou fucking scared me you fuck. I've lost all sense of time since COVID.\n\nSame, and I don't think the people I tell really understand how warped it has gotten for me! It simultaneously feels like yesterday, yet, somehow, also an entire lifetime ago.\n\nThose of us at the level to perhaps be writing new services should go out of our way to make all of the ones in this video real\n\nYep came here to read this. Super happy that people are discovering Krazam though, his videos are awesome.\n\nThis video is my religion\n\nHave you [delivered value?](https://youtu.be/DYvhC_RdIwQ)\n\n\"grug wonder why big brain take hardest problem, factoring system correctly, and introduce network call too seem very confusing to grug\"\n\n[https://grugbrain.dev/#grug-on-microservices](https://grugbrain.dev/#grug-on-microservices)\n\nMicroservices aren‚Äôt desirable from a simplicity or design perspective, they‚Äôre basically a necessity once an organization grows to a certain size.\n\nI once did a contract job where these overseas devs built out about 20 microservices. They were basically mapped to individual api endpoints. Most of them had around 100 lines of functional code. That was a complete nightmare.\n\nI'm currently working on a brand new project started a couple months ago and we already have about 10 microservices that all do essentially the same thing but with different interfaces/apis.  It's just me and 2 other devs working on them, and there's more microservices coming.  Any discussion with the architect ends with some vague reasoning like \"stability\" or \"speed\" with no elaboration. \n\nThe architect insists that speed/low latency is so critical that instead of having our rest services store new data, we send that data over a message queue to a second service that does the db store instead.  Sensible if latency really is that important, but then for another requirement where we need to request data from other physical sites, the service that receives this remote data request stores the request in the db, sends the request out over the message queue, then blocks until the status of the request in the db is complete. \n\nOh also we're building native binaries from Java because startup time is supposedly important (5 seconds is too long), but all the services are long running, load doesn't vary that much, and requests can take minutes to complete so an extra 5 seconds really shouldn't matter.\n\nI have worked on projects like that and spend weeks untangling the mess back into a sensible (and faster) monolith architecture.\n\nThat‚Äôs classic ‚Äúarchitect‚Äù logic. Many of those guys literally just make shit up to market to the business side to make things sound fancy and advanced. Pretty much everything you mentioned actually increases latency, not the other way around. Putting a round trip through a message queue doesn‚Äôt speed things up lol.\n\nI‚Äôd try to push back now while things are still salvageable.\n\nHow about putting a round trip through a message queue while waiting for the response via database, does that reduce latency?  /s\n\nI tried a couple times, the architect isn't open to discussion at all, and he's actively working on the project so we can't just do our own thing.  He nitpicks over variable naming and static imports, I doubt questioning bigger architectural decisions more than I already have would go well, especially since I'm relatively new there.\n\nYea that sucks ‚Äî I‚Äôve been there\n\nlint should enforce variable naming to language standards, although it is easy to pick bad names for variables.\n\nAre you in fintech?\n\nHealthcare, but good guess\n\nAh, EAI hell. I'll light a candle for you.\n\nAnother benefit of using native binaries is smaller memory footprint.\n\n&gt; The architect insists that speed/low latency is so critical that instead of having our rest services store new data, we send that data over a message queue to a second service that does the db store instead. \n\nI'm an architect. I cannot imagine why anyone would do that unless they had observed a performance problem that resulted from not doing it. And I'd benchmark the solution under heavy load before I assumed it'd perform better than the \"problem\" approach. Even then, I'd consider the impact of the added complexity on maintainability.\n\nIncidentally, when I was responsible for training architects at a previous job, I went a bit Chairman Mao on them and would insist that, at least once a year, they'd go off and develop some code for a couple of months. Doing that is a good vaccination against ivory-tower thinking. \n\nI did it because developers in the field would ignore and work around architectural direction if they didn't think the architects knew anything about the developers' jobs. And I think they were often justified in that. Otherwise architects just get promoted into ever higher levels of abstraction and cluelessness. \n\nAnd part of the reason I got put in charge of the architects was that, when challenged by devs about their believe that something I proposed was impossible, I'd come in a few days later with a POC running code. \n\n&gt;Oh also we're building native binaries from Java because startup time is supposedly important (5 seconds is too long), but all the services are long running, load doesn't vary that much\n\nI've had to direct devs not to shave microseconds off invocation times for services that are seldom called, and where most of the cost is in parsing the request and constructing the response, not in calling the function. But yeah, burn a few thousand bucks' worth of developer time on something that'll give you a 0.0001% performance improvement in a corner case that happens six times a year. Argh.\n\nThe \"we want to do microservices because we want to do microservices\" architecture, or  \"resume-padding-driven design\"\n\nI think this was more billable hours based design lol\n\nIf it was written by consultants yeah, probably. But for developers from what I've noticed \"we want to play with new thing\" is leading case of overcomplication of system.\n\nI'm currently setting up backup solution for k8s because our frontend devs writing *basically* ad landing pages decided k8s is the future\n\ni used to think this but its kind of hard to imagine now that i have more experience. i find most people i work with just want to finish things as quickly as possible as long as the quality is acceptable.\n\nYea k8s another thing that is really designed for large orgs. Landing pages sounds like something you could throw into vercel or something like that.\n\nMore like \"onto literally anything that can run that PHP/JS part\" as at most those sites have maybe a contact form and maaaybe comments.\n\nBefore they just got VM with directory to deploy files into, now we have whole dept learning how to deploy stuff on k8s\n\n&gt; Landing pages sounds like something you could throw into vercel or something like that.\n\nSpeaking of over complicating. Do it like 20 years ago: cheap hosting solution, FTP your files, you're done.\n\nVercel is easier than buying a hosting solution and FTPing though, cheaper too as it's free.\n\n&gt; as it's free\n\nUntil you get a surprise bill in your inbox\n\na lot of the stuff I work with is pretty much this. Not enough complexity, continuous work or developers to warrant these crazy pipelines and deployment architectures, nor the time spent dealing with them. I practically publish directly from my IDE and copy the output into a dated folder and repoint the IIS entry to it, then tag the release.\n\nWhy would you back up a k8s cluster and not just wherever the data is stored. Or just ship the data off the cluster. What does backing up a k8s server actually mean. \n\nEdit. Op blocks me for questioning their shitty setup and blaming the tools. \n\nThere‚Äôs an old saying. A poor workman blames his tools\n\nGod I hate reddit's blocking feature, it's just a way for people to think they've \"won\" an argument.\n\ndata and configs (mostly creds)\n\n&gt; Or just ship the data off the cluster. \n\n*most* k8s containers/helm charts don't come with \"put your S3 bucket here to let backups flow. So I'm doing just that.\n\nSo that has nothing to do with k8s\n\nIt does. You need credentials to run database dump and those are stored in k8s. We also... don't really want to do it for every project so they are getting a backup container/cronjob schedule, S3 bucket and list of instructions on how to deploy it for new projects.\n\nYou can use some kind of keyvault though, you‚Äôve chosen to only put creds in k8s which is your fault\n\nEdit: Why write such a long response and block me? Do you not know what you‚Äôre doing or hate being questioned\n\nk8s is so bad. I don't know how they won the micro-service mind share. There are better tools.\n\n&gt; k8s is so bad\n\nLess bad than \"our OPS people are always too busy to do shit so app deployment happens once per week top. And we hope it goes well\".\n\nGimme a k8s and a database access, now I can release whenever I have to. Even on Friday because I can easily rollback to a working version if things go badly.\n\nMy point is there are other things that can do that without the complexity of k8s.\n\nWell the short answer is that it has Google clout behind it.\n\nAll things considered it does have good developer experience, even if deploying it from scratch is a mess (which most people don't care about as they just use cloud or some k8s automated deployment blob)\n\nI always liked to call it \"Hype-driven development\"\n\nMy company is doing that, A complete waste of time. Projects that should have taken a month, take a bloody year.\n\nIt almost always makes a lot more sense to START with a monolithic structure and when your app becomes so large that deploy times are being significantly affected and it‚Äôs clear that your app is doing simply too many things, that‚Äôs when you can start peeling back into multiple services. \n\nThis sub has a hate boner for microservices but they are not evil, they are an iteration. \n\nhttps://martinfowler.com/bliki/MonolithFirst.html\n\nWhat people mostly don't get is that there's a number of steps between 'monolith' and 'microservice'. If you're split up a monolith and your service boundary correlate with team boundaries, you're still not in microservice territory.\n\nMany people feel that service oriented architecture is totally a good idea, but true microservices is this taken to an extreme.\n\n&gt; This sub has a hate boner for microservices but they are not evil\n\nFor a good reason, one described in Fowler's article you mentioned:\n\n&gt; Almost all the cases where I've heard of a system that was built as a microservice system from scratch, it has ended up in serious trouble.\n\nI think this sub doesn't hate microservices as an architecture, we hate how it's abused and misused and sold as a silver bullet by some people.\n\nI think it's a methodological problem. If you start with microservices, you're doing big design up front to factorize services without knowing real-life usage patterns. This seems to me another instance of the well-known problem of premature optimization. Engineers, even gifted ones, are shockingly bad at proactively identifying the hot spots and bottlenecks in complex systems. And similarly, a microservice architecture is an optimal refactoring of an existing non-microservice solution. To do that effectively, you need data derived from monitoring and logging. Your brilliant design acumen isn't going to do you all that much good. \n\nFowler's argument is basically one in favor of humility.\n\nI mean, that‚Äôs from 2015, which is before microservices became the dominant mode. The word had only been coined three years prior. So, it wouldn‚Äôt be shocking if a lot of projects were done where no one really understood how to manage it properly from the start.\n\n&gt; So, it wouldn‚Äôt be shocking if a lot of projects were done where no one really understood how to manage it properly from the start.\n\nWhat's shocking is that, at a conceptual level, the state of the art hasn't advanced all that much since then.\n\nThe trick is to still break up the project by domains and not directly share domain models and such, but rather use service classes. That way refactoring into a separate service is as painless as possible if/when necessary.\n\nThat's not microservices, though. The micro part is the whole problem. It requires every individual service to be self-contained and tiny. If you broke up a monolith into actual *micro*services, they would suck just as bad as ones made from scratch.\n\n&gt; It almost always makes a lot more sense to START with a monolithic structure and when your app becomes so large that deploy times are being significantly affected and it‚Äôs clear that your app is doing simply too many things, that‚Äôs when you can start peeling back into multiple services. \n\nUnfortunately, once you get to that point it can very difficult to split up the monolith, especially if you didn't maintain good domain boundaries in the monolith. And let's face it, if you maintained good domain boundaries in the monolith, you probably wouldn't be facing that decision.\n\nThe company I work for has been moving toward service-oriented architecture for like 7-8 years and only a handful of things have actually been extracted from the monolith. It's mainly been new features that have made it into separate services.\n\nI'm just thinking about the long contest between monolithic kernels like the one in Linux versus microkernels such as Minix and GNU Hurd. I wonder if there are any lessons to be learned from that? I recall which side the CompSci purists took in that debate, but that wasn't the direction the market went.\n\nAgree. If architected correctly micro services can be pretty easy to manage.\n\n&gt;If architected correctly micro services can be pretty easy to manage.\n\nThat is one big \"if.\"\n\n&gt; It almost always makes a lot more sense to START with a monolithic structure\n\nWhen you're starting a start-up with 3 people, sure. When you're spinning up a new department within a large org that has 5 teams with 5 devs each; absolutely not.\n\nThis context matters. I'm getting the feeling that most \"anti-microservice\" folks never worked for large companies.\n\n&gt; Microservices aren‚Äôt desirable from a simplicity or design perspective, they‚Äôre basically a necessity once an organization grows to a certain size.\n\nSo basically, they're too much overhead if you don't need them.  And if you do need them, then you're big enough to hire enough engineers to deal with the overhead.\n\nMore like if you‚Äôre big enough then the overhead is a worthwhile cost.\n\n&gt; they‚Äôre basically a necessity once an organization grows to a certain size.\n\nYes, but most organizations never reach that size.\n\nLast job's architecture really needed the scaling and flexibility for the 50 total users per month though. You don't understand, the Kubernetes cluster was crucial. It's the future.\n\n*They said, unflinching and utterly serious*\n\n&gt; Microservices aren‚Äôt desirable from a simplicity or design perspective, they‚Äôre basically a necessity once an organization grows to a certain size.\n\n[\"Organizations which design systems (in the broad sense used here) are constrained to produce designs which are copies of the communication structures of these organizations.\"](https://en.wikipedia.org/wiki/Conway%27s_law)\n\nBased on that law, we'd be building monoliths and following the Big Ball of Mud architectural meta-pattern.\n\nNo microservice, no promotion\n\nIf Google can work in a monolith, I think most people can too.\n\nI think google uses a monorepo, but has many of services. It also has so much tooling around the repo that it‚Äôs probably not what most people would consider a monorepo.\n\n&gt; Microservices aren‚Äôt desirable from a simplicity or design perspective, they‚Äôre basically a necessity once an organization grows to a certain size.\n\nThis isn't even remotely true. Most places that have \"microservices\" don't even have them. They have very large services, that do complex tasks, and they just *call* them microservices because it's following a service-oriented architecture, and they don't know the difference.\n\nThis is superb. We've all been looking for a replacement for Uncle Bob for a long while, and I think I found it. I'm now Team Grug for life, and am now seeking certification in Grug-SOLID.\n\nThis is a very interesting read. What is the main idea behind this character and article?\n\ncomplexity *very, very* bad\n\n&gt; given choice between complexity or one on one against t-rex, grug take t-rex: at least grug see t-rex\n\nBingo knows the name-o\n\ni'll die alone without ever knowing love. without ever knowing it's my birthday\n\nJust yesterday, I was summarizing a meeting to my team and I had a sentence that contained no fewer than 8 codenames. I immediately thought of this video.\n\nThis isn't funny. This is painful to watch. They aren't making light of a ridiculous situation. This is a true story of real life. \n\nHow dare you?\n\nGood luck finding love there buddy.\n\nWorked somewhere like this, proper E2E testing was basically an impossibility because all the relevant data inputs to our service were microservices owned by other teams\n\nYou could mock those services, but then you'd have a test based on fiction of what you hope their service returned rather than reality\n\n[deleted]\n\nThat's definitely the right way to go. The reason why we didn't have that was probably a mix of budget being allocated towards new features rather than testing and additionally the fact that their microservices in turn probably relied on a bunch of other microservices, making the fakes hard to implement\n\nMy current place does things the right way, but I have to imagine it's very rare in that regard\n\nSo you'd use some client library for this service, where they provide a fake impl in the same library which mocks the various responses from the service? And presumably the fake impl and the real service would run off the same version, as in if you update to a new real service version, the fake impl also uses that new version?\n\nAnd then it's on the client to test the version scenarios that the real service might send, including things like no response?\n\n(just trying to learn)\n\nAlso is microservices still the \"best practice\" way to design? I'd heard more recently from a colleague that people are moving back to monoliths for things like E2E testing, versioning, etc complications. He also argued that Java is dying because C++ and Python are coming at it \"from both sides\" (which I can agree with, though I do love Java)\n\nThere is no best practice aside from simple things. You don't dive into making a new project headfirst, you analyze it and plan accordingly. Like if it's a completely separate project or if they have a working architecture/network already. Too many variables to just say \"microservices are best practice\".\n\nWe, developers, are not only paid to write code, we are paid to choose what to write, to seek a solution, weigh the alternatives.\n\nEdit: Also, it helps to write down which decisions were made and why. In the way of documentation, specifications, configurations. That way, when you're working in a team, you can point to the written stuff if someone is not following it. It should be approved in the team first to be added though. And changes are always welcome, with a reason attached.\n\nBefore service meshes existed we had a local nginx forward proxy. \n\nThese were really helpful when you wanted to debug an issue with a single service because you could point that one endpoint at your coworker‚Äôs machine and use the preprod cluster for everything else. Then just tell them when you‚Äôre going to trigger the bug so they can get their breakpoints sorted out.\n\n\"LMNOP\" i'm dead ü§£\n\nIs it a play on LDAP? Something like \"Lightweight Microsoft Name Ownership Protocol\"? The joke is still funny without a specific interpretation.\n\nNo, it's the successor to HIJK\n\nFuck me, I didn‚Äôt get yours and was about to say it‚Äôs about the alphabet until I reread your comment. Microservices are running slow today\n\nI don't get that one...\n\nIt‚Äôs just the alphabet\n\nI still want to name our IdP Bingo\n\nAt 0:52, he points at a service labelled P(P(LEGACY), and he calls it Ringo 2. Does anyone understand this joke?\n\nPCP (LEGACY)\n\nPretty spot on, i miss when devs would just do CRUD and not add 200 layers of middleware in their app used by 3 people twice a year\n\nI‚Äôll get downvoted for saying this, but expectations have changed in the last 20 years. In 2024 if your app doesn‚Äôt integrate with 3rd party authentication providers (Google, Microsoft Amazon etc) and the users **_have_** to create a new account /w new credentials to access your app.. then they will just not do it and you are likely to stay on 3 users. So you might as well not build that app at all.\n\nYou only mentioned 1 third party service.  If you need 200 layers of middleware to talk to a 3rd party authentication, maybe that's a problem.\n\nI fully agree about OAUTH logins(seriously stop making me sign up for crappy stuff).  But we're looking outside of one or two one offs.\n\nNone of that requires microservices though, unless we have different definitions of microservices, which I would define as separately scalable/deployable parts that work together as part of a larger system.\n\nIf you're spinning up separate containers to interact with each auth provider, then something is very wrong (or you're a massive company)\n\nBut that is irrelevant, that just means you don't have login credentials on your database. You can have everything else that is queried in a simple way.\n\n1. Login with Google\n\n2. Look up your internal user based on google user\n\n3. Get that user's information\n\nOh yeah? \n\nAnd then you need an abstraction and services to take the user data from the auth/account provider and store it on your database. Because every provider stores data differently, they are not same format. \n\nAnd what happens if the user changes their details on the provider side? Such as name and address? Well now your local data store is out of sync. So you have to give them a way to change it, on the UI. But they won‚Äôt like having to manually update their details on your app, they changed it on Google/Amazon after all and they purposefully linked the accounts to avoid having to do this!\n\nYou see where this is going?\n\nThat still has nothing to do with microservices. Sure, the more complexity you add to the software, the more hardware you'll need, and the more concurrent requests you need to handle, the more instances you need. But handling all that doesn't *require* a dedicated service that can't also be used for other stuff.\n\nYou really don't need microservices until you start running into issues (whether they be performance, cost, or organizational) with your monolith.\n\nWe had SSO for 20 years now and before the hype of microservices we knew how to integrate it in the monolith, now apparently \"it doesnt scale\".\n\nSo why cant a module within a monolith handle SSO?\n\nYou can do stuff like fetch latest data on login, or allow user to override some info for your website, like name if they want to show another name on your site.\n\nYou're in a forum where 99% of the people have never worked on hard problems at scale and microservices are an incomprehensible meme to them. Their actual experience is writing a few shitty applications in college and then vainly extrapolating that experience to Real Problems.\n\nSo to answer your question... no, that person probably doesn't see where this is going.\n\nTheir claim (appears to be) that supporting multiple auth providers requires microservices, which is not true. If you're a massive company, then you might need to do something like that, but architecting a system like that from the start is massive over-optimization.\n\nThe pitfall you describe works the other way around too, in that people see how things are done in huge companies, or see it as the new/trendy thing, and then think that's how it should be done for everything.\n\nthat still has nothing to do with microservices\n\nWhy do you need to update the user's name and home address from their login provider? I don't understand the problem.\n\nGetting off topic here, but can you give examples of apps/websites that do what you describe? That sounds like a specialized use case.\n\nIf I changed my name/address in Google, I would definitely **not** expect it to be updated in every app I use google to sign in with. If I link my Facebook account to Uber, and then change my Facebook email, I would not want/expect it to change my Uber account email...\n\n&gt; Well now your local data store is out of sync.\n\nYou get update on user login\n\nYou make a call to another service on the internet during login to check my profile details? Do you work on one of the 100 services I use where login should take less than a second but I invariably ending up watching the browser spin for 10 seconds waiting on a response from the server?\n\nThey never said the update had to be synchronous\n\nMaybe don't integrate some slow ass third party auth service?   \nYou can also fire a separate adync request in the browser to do the update.\n\nBut what if my app only needs to be used to 3 people twice a year, because it's just that good.\n\nYou are looking at the problem with bloat glasses on.\n\nAuthentication could easely be handled by the app only existing on a network for the people that need to use it.\n\nNot everything is a bank transaction\n\n[deleted]\n\nIf gazillion layers are needed for authentication, then the (non) standard sucks.\n\nI feel like it‚Äôs impossible to work like that now. OIDC/OAuth integration, APM telemetry, front end analytics, logging integrations, feature flags, secret management, and Redis caching. Plus there are services to integrate with like Stripe, Twilio, Mandrill, and Firebase. If you‚Äôre designing enterprise tech, then you have to integrate with the priority tech of your clients. That‚Äôs all before you mix in design patterns and architecture choices. That also doesn‚Äôt cover devops and SDLC which might require more integrations.\n\nEdit: plus there are libraries to integrate for regulatory reasons like cookie services for GDPR.\n\nYeah, those things are needed some of the time. :)\n\nMy complaint is that it's become standard to launch a rocket every time we need to open a can sardines\n\nDude is an L5 at AWS fwiw\n\nStill?\n\nWhat's that mean?\n\nThe actor in the video is an actual developer at Amazon AWS and not just talking out of his ass.\n\nIt's as bad there as it sseems from the outside, then.\n\nI was wondering about that reference to EKS as \"Entropy Kaos [sic] Service\". Maybe that's the internal nick for their kubernetes offering.\n\nMy favorite part of the video (and my job when I was still in the industry) is how the project manager casually is like‚Äùyeah that‚Äôs totally fine‚Äù. \n\nI never got good at predicting those moments. Go to sleep pulling my hair out because of deadlines, the next day nothing gets done, and it‚Äôs like ‚Äúoh yeah that‚Äôs probably the least important thing ever, who cares?‚Äù\n\nAlso had moments where the entire team scrambles for like 8 weeks to get a major feature to the client and its data driven and the client went ‚Äúoh‚Ä¶yeah‚Ä¶.about this feature, I don‚Äôt think anyone ever collected that data, which means the feature won‚Äôt work, but I guess at least we met the deadline‚Äù.\n\nA true classic¬†\n\nI remember seeing this a while back in a completely unrelated field and thinking this must be a complete joke \n\nNow I live it. Am I the joke?\n\nHey who authorized you to place cameras in my office?\n\nThis is one of my favorite, if not my favorite youtube video\n\nEKS is my favourite service in this architecture\n\nHonestly, it sounds to me like the Omega Star team just needs to get their fucking shit together and start supporting ISO timestamps already.\n\nI mean how hard can it be?\n\nThat video is what inspired me to write Death By a Thousand Microservices: [https://renegadeotter.com/2023/09/10/death-by-a-thousand-microservices.html](https://renegadeotter.com/2023/09/10/death-by-a-thousand-microservices.html)\n\nI thought I was taking crazy pills, until I met Galactus and realized that it wasn't me at all.\n\nLove how HTMX entered the chat on this thread. I started using it a few days ago for my large personal project that was stuck for years due to high UI complexity, and HTMX ate that complexity for lunch.\n\nOkay, I will spill. I am building an IMMICH replacement, because no lay-person trying to organize baby photos should be asked to \\*hunt down bugs via Docker microservice logs when running a self-hosted app\\*.\n\nI love the effort from that team, but they are clearly drinking some of that microservice coolaid, bringing it from work and back home, where it does not belong.\n\nOne of my absolute **favorites**. Also, my go-to video when I want to explain how mind-numbingly stup...er, *funny*, my job can be sometimes.\n\n&gt; \"Bingo knows everyone's the Name-o\" \n\nI'd slap him right there. \n\nI hate clever or cute names for systems.  I get when people make acronyms, but if I say \"What's Lamp really mean\" and you can't tell me in like 30 seconds, the acryonym is just confusing....\n\nI do laugh when he starts naming services, and pointing at other names! THAT! that's so annoying.\n\nidk you have a point but at my job I wish we came up with some more interesting names for the tools we build, \"Production Master Scheduler\" as the name for the web page that lets production planners... plan the master shop schedule just ain't that sexy.\n\nUltimately though that's what it does.  Your job doesn't have to be \"sexy\"...  \n\nOn the other hand someone might call that... Mensturation (Yeah not a good name).  \"Wait why\".... well periods, PMS, Production Master Scheduler!\" .... ugh\n\nAt the end of the day, your work is a job, it's not sexy glamourous or fun, it's just... well you know work... and that's why you get paid a lot of money (hopefully)\n\nI always try to show this video to new colleagues (I work in dev/IT) and if they don't get it they immediately drop 20 pts in the rankings\n\nThe example of Shopify should demonstrate to folks that a spiderweb of microservices is pretty much unnecessary for *most companies* except for \"orgitectural\" reasons. Yet the cargo culting of microservices continues unabated.\n\nI didn't know I could enjoy posts in this sub. I thought it would just be pain. Thank you for sharing this video and new subscription with me.\n\nGreat video\n\nLove this video - this is the exact problem my startup is trying to solve! We actually quoted it in our launch haha  \n[https://www.ycombinator.com/launches/LL3-gauge-solving-the-microservices-monolith-dilemma](https://www.ycombinator.com/launches/LL3-gauge-solving-the-microservices-monolith-dilemma)\n\nThe last project I worked on was like that. Litterally made me hate my job.\n\nit seems like the circlejerk of \"microservices are so cool!\" and failing in the attempt has been superseded by the \"microservices suck! hail the monolith\" circlejerk now that I see permeating this sub these days\n\nA well designed service architecture is totally fine and likely the best thing to build if you have more than a couple of devs working on a solution to a problem. The issue is that most companies/teams take the word microservice way too literally and have services that do almost nothing with alllll the overhead of running, maintaining, monitoring etc an additional service and then they are often so poorly named or defined that noone knows where what code lives. In reality this video would probably have one guy needing to reach out to 5 different SMEs to figure out which service interactions were actually the root cause here. \n\nif you're designing to have more services from the get go than you have developers -stop you're doing something wrong....\n\nyeah I feel microservices without monitoring is a recipe for disaster and not everyone can afford dynatrace or new relic (nor should you, it kinda sucks), that's one of the things I imagine a lot of people who push for monoliths bumped into\n\nI would argue that instead of a couple of devs it is better if you have more than a couple of teams.\n\nHmm. Somebody named \"big\\_hole\\_energy\" posts a video about how his backend works. Yea not watching that."
  },
  {
    "title": "How is this Website so fast!? ‚Äî Breaking down the McMaster Carr website and the techniques they use to make it so dang fast",
    "body": "",
    "score": 1257,
    "url": "",
    "created_utc": 1729332664.0,
    "author": "h4l",
    "permalink": "/r/programming/comments/1g75r84/how_is_this_website_so_fast_breaking_down_the/",
    "all_comment_text": "That's actually very cool\n\nI love that they're doing all this and looking like an old 2000s era website design. It's like a sleeper car that's modded with a 600HP engine.\n\nIt's honestly pretty sad that they have all the anchoring and nav bars and information sidebars and all... and it looks outdated because I guess they don't pad everything out with swaths of whitespace? Or add huge logos and hover popout photos? I wish modern design did not happen at all.\n\n[deleted]\n\nFor real. They have the \"function\" absolutely down even if their website doesn't look attractive. It's absolutely unbeatable to be able to quickly find any basic hardware item and have it delivered the next morning.\n\nI guess in their game, online parts lookup, it‚Äôs the best way to get and keep customers, and so you have to be a cut above the rest of the templated store fronts - this may look dated, but it carries all the information you need in and uncluttered and consistent ‚Äúparts catalogue‚Äùway, and I would expect a lot of the backend is customs built libraries on a legacy html framework - Naming conventions may have just followed a C# backend and no CamelCase conversions as I didn‚Äôt seem to notice any JSON data, just html. \n\nIn a project I worked on, for B2B sales application for Social Selling (basically research and know you prospective customer and contacts from insights drawn from company subscription news and financial data, news snippets, social media mentions and the like, instead of the old ‚Äòcold calling‚Äô way), our site was built on MVC and the pages for the controllers actions had their own JS files. I also developed a MS Dynamics plugin that that communicated with a WebApi controller to get its skeleton HTML where each part when rendered with its embedded JS, would request its content and data from the web server over JSONP.  Therefore each page had its own set of JS files - it‚Äôs basically a project organisation thing, as well as not transmitting unused JS for performance!\n\nI think there are a few reasons the page presented in this video looks outdated to many people:\n\n1. Color choice. There are pops of bright colors but not really any color scheme or language there. This was very common in the early days of the web, but is much less so now.\n\n2. A UI that at least visually resembles the kind of iframe-based layouts you'd commonly see around the turn of the century \n\n3. The video creator appears to be using a browser that (I think?) has some extremely dull gray default widgets, which in combination with the other elements gives the impression of what it was like to browse the web a long time ago.\n\nModern design isn't the problem.\n\nIt's not designing for what it is.\n\nToo many times the people calling the shots want to design a utility like it's not. Which is kinda what you're talking about. \n\nYou could totally make this look modern as hell with zero impact on performance. But the general layout and interactions would be the same.\n\n&gt; make this look modern as hell \n\nyeah, but the developers have the correct set of priorities: modern look is not on the list.\n\nthere's no reason to be. it adds nothing at best, detracts from the experience usually.\n\nYup, also in this space a skeumorphic approach makes sense: people probably have a paper catalog around, and having both have similar presentation and interface hints makes a lot of sense. Say you are at the workshop, you see a part that is broken, you look it up in the catalog to give the customer a price-range, they agree with it, so then you go to the office, into the website, and look for the same part to put the order in. You already did all the work of finding it with the paper catalog, why not allow you to reuse that knowledge? You see the same thing, in a similar place, instead of jumping to the page, you just click on the link: and it shows you the next content in the same time that it takes to flip to a page with a bookmark.\n\nAnd honestly there's the part that we don't talk about modern design: it's meant to allow crappy and mediocre stuff. THe modern design is based on the idea that websites nowadays take too long to load. First you have a myriad of resources, and a lot of crud, tracking, spyware, animations, complex css, complex javascript second these resources are nested deeply: suddenly the js pulls in more css which pulls more images, and you can't know what else you need until you get the next. So what do you do? Well first you have this idea of \"things fading in\" with animations, so the time it takes seems intentional as glitz, and not an inevitability due to highly inefficient desing. It also hides that the website is doing way more than it should. To also hide the jankiness we add a \"smooth\" (read super slowed down, because you could add a gradient to make it smooth but also go as fast as the user wants, wait that's already the default) this again hides how slowly things are loading and the jankiness of the interface. The other modern anti-design is putting everything under the fold, you load a website and all you see is one massive logo, if you want to see any content you have to scroll, again this lets the website take forever to load and hide its mediocrity behind a lot of glitz. To hide the fact that so much of the website is white-space (because that would make it obvious there's something else going on) it somehow finds a way to make it feel cluttered again, even though so much of the website is empty.\n\nDoes someone have a good example of a similar web store but with this modern design? I'm terrible with recognizing different designs so I have no idea.\n\nI tried the McMaster webside, and I have to say that it's not only super fast but also super user friendly. Imagine you need a strange screw that you forgot the name of, and then you just get this perfect webpage, go to \"screws\" and browse until you find what you want. You click it, and immediately you get to choose exactly which size of it you need. Click it, add as many as you want to your order. No extra design got in the way of what you wanted to do.\n\nI think it‚Äôs designed for a different sort of user, one used to catalogues of parts, with an engineering background, and would know what a left-handed screwdriver or a long weight!!! lol\n\nTLDR it wasn't made by morons.  The techniques have been known for decades, it's just most modern websites ignore it and throw shit down the pipe.\n\nMost websites throughout history have ignored these practices too! For every bloated JS app you see today, there was some monstrosity stuffing enormous amounts of garbage into ASP.NET's ViewState years ago.\n\nThat was me.  I was doing that.\n\nCan‚Äôt frontenders have anything?!?\n\nYep and a lot of business owners have a set of priorities that is opposite to being fast. Mainly: ads.\n\nAds often mean loading a bunch of external code that almost actively fights your site‚Äôs performance.\n\nI didn‚Äôt look into the site mentioned in the video but it wouldn‚Äôt surprise me if it had 0 ads. And good for them for having their priorities straight.\n\nWhen you have a business like McMaster you don't have to worry about ads.  The whole point of your business is to serve up your inventory to other businesses.   McMaster retains its leadership by offering a service that few can match.\n\nIf one takes the time to compare McMasters site to MSC or Grainger and you will see just how good McMasters site is.   There have been many cases where i give up at alternative vendors and just go with McMaster.\n\nThis isn't to say McMaster is perfect, sometimes it is important to know a brand that you are buying.   McMaster simply doesn't focus on who is actually making things (never has really) that you want to buy.   sometimes it is important.\n\nIts not about showing ads on your page, its about having ads run elsewhere that lead to your page, and integrating with that ad platform to see how well your ads are doing.\n\nMy company doesn‚Äôt have ads. What it does have is a marketing team that feels like they need to know EVERYTHING about what our clients are doing, right down to mouse movements, eye tracking, and brainwave scanning\n\nI absolutely knew they were using a CSS image map as soon just from the thumbnail. Took my right back to 2006-2010 web performance stuff.\n\nSpot on!\n\nIt really is a website made for engineers by engineers. No frills, simple as fuck to use and they have just about anything an engineer would need to spec out a design or order a few extra parts for prototypes. I wish more of the web was as utilitarian.\n\nHang on, you mean to tell me that 20mb of JavaScript on every page load slows a site down more than pre-rendered static pages being served when requested? Next, you are probably going to tell me some nonsense about ‚Äúhype‚Äù not being a good metric for choosing tools.\n\nThat‚Äôs because modern frameworks are designed with abstractions and separation of concerns so that you can throw more bodies at a problem and everyone can work in parallel. \n\nTo be super performant, you need tight coupling and that doesn‚Äôt scale well when you‚Äôve got a massive team and anyone can break everything when they‚Äôre adding a feature.\n\nThis is sort of generally true, but I don't think it explains web frontends in particular being slow. [Websites are fast by default.](https://motherfuckingwebsite.com/) You don't need tight coupling to do that, you just need to not [add absurd amounts of bloat that nobody asked for](https://idlewords.com/talks/website_obesity.htm).\n\nMost of the things on that second link are not a result of modern frameworks. Modern frameworks don't force you to use a constantly-looping video as a background image, or a *three megabyte* image at the top of an article that really should just be text, or to mix in so many ads that it doesn't matter how long your page actually takes to load because the user will be fighting to dismiss the interstitial and click through the cookie prompts to even find out how much it didn't load.\n\nIMO these should be required reading for frontend devs:\n\n[This is a motherfucking website](https://motherfuckingwebsite.com/):\n\n&gt; I'm not actually saying your shitty site should look like this. What I'm saying is that all the problems we have with websites are ones we create ourselves. Websites aren't broken by default, they are functional, high-performing, and accessible. You break them. You son-of-a-bitch.\n\n[The website obesity crisis](https://idlewords.com/talks/website_obesity.htm):\n\n&gt; Jeremy Keith pointed out to me that the page describing AMP is technically infinite in size. If you open it in Chrome, it will keep downloading the same 3.4 megabyte carousel video forever....\n\n&gt; I began by replacing the image carousels with pictures of William Howard Taft, America's greatest president by volume....\n\n&gt; This project led me to propose the Taft Test:\n\n&gt; Does your page design improve when you replace every image with William Howard Taft?\n\n&gt; If so, then, maybe all those images aren‚Äôt adding a lot to your article. At the very least, leave Taft there! You just admitted it looks better.\n\nSo you're telling me that there's more to making a website than 13 `npm install` commands and 4 lines of code to call one of those libraries?\n\nyou forgot to mention how big your node_modules folder is after that\n\nbut it's understandable, you probably ran out of memory\n\nI mean. Come on dude.\n\nPrefetching and cached SSR is doing 99% of the heavy lifting here, and both are utterly trivial to set up.¬†\n\nNothing here takes significant developer time (it probably takes less dev time than crazy SPA techniques). Nothing is absurd or overwhelming. Nothing is stuff that web developers should not know about. The ONLY difference between your comment and the developers of this site is that they care.¬†\n\nThe original comment was pretty sarcastic.\n\nEither the person replying has Autism or is a joker themselves?\n\nWith a traditional web framework, there wouldn't even be anything to set up at all. There is no SSR to configure, because that is how things work anyway. You render the template and you serve it. Maaaybe the cache, but that is maybe also configured on the reverse proxy, not the actual website.\n\nThe website shown in this example is also extremely minimal. \n\nMost modern bussiness need to balance feature and profit, along side performance. \n\nUsually there is a threshold of ‚Äúfast enough‚Äù, generally anything under 2s (for some cases under 1.5s). Where investing additional effort on performance offers heavily diminished returns\n\nMaybe I'm a moron but I didn't know you could do  DNS prefetch.\n\nJust server-side templates and no dynamics where they aren't needed will get you 90% there.\n\nExactly this. Simply, what he said in the first few seconds of the video, and ignore the rest (except for interest or knowledge).\n\nBy creating application specific controls on the server then just pushing out the resultant HTML you will have a stupid fast rendering. One reason i use ASP.Net (.net framework) and C#, but it is not the only solution to do this.\n\nThis is also one of the reasons Laravel maintains such a hold over the web development ecosystem.\n\nIt does offer first class support for Vue these days, but it shines as a Framework for delivering server-side templates as fully rendered HTML.\n\nI‚Äôm not familiar with Laravel, but isn‚Äôt it the same for similar web frameworks like Rails or Django?\n\nYes, I believe it was heavily inspired by Rails, in fact.\n\nI do client side heavy websites for a living. React, Vue etc. Even properly optimised they are all garbage and the DX of supporting them long term is insane. This whole way of building websites needs to go the way of the Dodo. And I say that as someone who makes a living doing it.\n\nI feel you! I'm currently working on a PWA that would have been done months ago *and* been faster and more responsive if it wasn't front-end heavy.\n\nBut users are apparently allergic to page loads or something.\n\nIt‚Äôs all just naive assumptions at this point I suspect. We don‚Äôt need all of this.\n\nThe problem is that there are multiple generations of web developers who are unable to do anything without these types of tools.\n\nAnd how do you hire competent frontend devs for a website that actually well put together without all this JS nonsense? The tech stack would almost be indistinguishable from one built in 2010.\n\nI assume you meant client-side application, not progressive web app? I personally hope PWAs catch on, as that would undermine the Google/Apple app store monopoly.\n\nThose are not mutually exclusive terms.\n\nHTMX gets you really far, and use JS for that last 10%\n\nWhen I had a few people test out my website, I actually had a few complaints that it was \"too fast\". It turns out that if your website loads instantly, some people will see it as a red flag. It's kind of funny how people actually expect websites to take a while to load.\n\nEdit: Demo site in question (don't worry, the data won't be saved so you can write anything):\n\nhttps://clear.dental/newPatientDemo/\n\nI‚Äôve had to add fake spinners more than once to make customers more satisfied. It‚Äôs a thing.\n\nThat‚Äôs the stupidest thing I‚Äôve heard all week\n\nHumans are not rational beings, it‚Äôs how it goes ü§∑‚Äç‚ôÇÔ∏è\n\nPhones ringing when you make a call with a smart phone was artificially added. Same thing with electric cars are very silent. Some add artificial sound back in.\n\nPeople respond differently when you‚Äôre asking for feedback, and for some reason this sounds like one of those. And, no one who uses McMaster is going to see it as sketchy. It‚Äôs like ultimate brand authority in its market.\n\nAlso to add to that, in the context of my website, it as taking in user input and responding back instantly. So a lot of people thought that their information was being lost.\n\nThis is a pretty common thing too. Tax websites do this all the time, once you‚Äôve put all your info in the computer could give you a result in under a second easy. They have you stare at a loading screen for 30+ seconds though because users don‚Äôt trust the results if it‚Äôs too fast. \n\nIn general any sort of calculation that is perceived as difficult or complicated by an end user can actually benefit from artificial delays so consumers will trust it. Just make sure you program a flag for it so you can turn it off for your account and have a speedy experience lol\n\nFreetaxusa doesn‚Äôt do this nonsense.\n\nI've experienced the same thing. I custom built the entire system that ran that company, and as a result, everything was very tightly integrated, and we had it hosted on a pretty beefy VPS, considering its typical load. Round-trip times were often barely over 100ms, and when it came to security-related issues, it was so fast that users weren't convinced it was actually working. I ended up just putting an artificial delay in so it \"felt\" like the system was actually doing something... oh the irony.\n\nThat is a design problem on your part.   People should get confirmation that a transaction actually completed correctly.\n\nI've actually have come across this on some sites and you are left wondering if things happened as you expected.\n\nI get this.  Extremely snappy websites feel like they must be lacking in something.  I know this isn't the case but the feeling is there.  It's kind of like how an EV feels like it shouldn't be that fast because we're so used to loud engines being associated with power.\n\nInteresting point.   There is actually a segment of the ICE vehicle using community that makes their cars loud on purpose as that supposedly indicates performance.   Then there is the rest of use that think these guys are ignorant and couldn't drive a high performance car if their life depended upon it.\n\nStory time, I spent 5 years in big tech building back end services. I moved to a start up with a friend and he gave me a tar file with all the code for the project. I opened and build it in 20 seconds. First thing I did was walk over to his desk to ask what I was screwing up for the build dependancies. Turns out it was nothing and it just built that fast. When you don't try to be everything for everyone you can actually do good work.\n\nThat was me when I first tried Linux, was playing around with a VM for fun.\n\n\n\nI couldn't get over how snappy everything was.¬†\n\n\nOn Windows everything takes times when you open and click on things.¬†\n\n\nIt felt like it was taking action before I expected it to start doing anything and it just felt weird.\n\nWindows has just gotten worse over time.   My company tried MS Surface laptops for a bit and the behavior of Windows on those machines was terrible.  This especially when I had an M1 AIR to compare against with the M1 effectively running a cell phone processor.   Windows is somewhat better on newer hardware but you still end up wondering if anything is happening after clicking on an icon.\n\n[deleted]\n\nHave you tried file explorer in Windows 11? It‚Äôs noticeably, painfully slow. I got worried at first and ran diagnostics on my storage and RAM because I thought my hardware was failing‚Ä¶\n\nAnother major reason for it being fast: no ads/analytics. Not having that crap alone makes it so much more faster.\n\nthe big disappointment when you deliver a site with good speed and the marketing department comes in :(\n\nIt‚Äôs why good speed is so important in the first place.  So people who have no idea what they‚Äôre doing can ctrl v ad tags into google tag manager.\n\nThere's calls to trk.aspx on every sort of actions, browser resize events,  product views, searches. It has quite a bit of analytics!\n\nWhile frontend performance is important, and inlining your CSS is great and all, I believe the real secret to this site is in their backend. Which of course, a youtube video isn't going to be able to observe.\n\nYeah I‚Äôm an asp developer and their front end may look like it‚Äôs made in 2001 but I guarantee their backend is exceptional and I‚Äôd actually pay money to look over their code.\n\nTheir middleware must be insane, as like he says, there is some sort of service dedicated to serving JS files and aggressive caching. I‚Äôd love to see how they deal with frequent price updates of products as they cache almost everything by the looks of it. The sprite trick is brilliant and I‚Äôm stealing that for assets that don‚Äôt change often.\n\nliterally a conversation i had last week.\n\nPMs: why is QA getting better lighthouse scores?\n\nme, after looking at the network panel for 5s: because you are loading 6 different trackers on Prod.\n\nOnly 6? Where can I apply. Marketing has us put duplicate services in. \n\nNo one can explain to me why we need Microsoft clarity AND hotjar. Like pick a fucking product.\n\nWhat's crazy is some of these analytics services let you share data with other analytics dashboards. So you don't have to load several of them! Most of them integrate so well because that's exactly what they're there for, free data.\n\nThe problem with analytics isn‚Äôt so much e.g GTM or whatever script you‚Äôre loading. It‚Äôs the mistake of handing off the reigns to non-technical people in marketing who have no clue about websites or website performance. And they will randomly add whatever shit they want, dragging the website down. That single script turns into a chain of 15 scripts and soon no body even knows why half of them are there, and there isn‚Äôt any source control to figure it out either.\n\nI‚Äôve seen this in countless companies at this point.\n\nI highly doubt an e commerce website would have no analytics\n\ntry it? I don't see anything showing up on my browser console, and nor is my adblock detecting anything out of the ordinary.\n\nSome analytics can be done server-side.\n\nI bet that is what is going on here.  Client-side analytics is useful if you anticipate the server developers are not particularly skilled.\n\nOnce again it looks like in-house analytics. The developers of this site are very old school mentality.\n\nLove it.  Ten bucks says it's one dude and he's been in the job for 18 years.\n\nWell, you can check for yourself by looking for analytics scripts in the Network tab.\n\nCheck all the calls to trk.aspx. It's on everything and has no impact on performance. Why would it?\n\nMy pro tip is using an analytics package that is much less creepy than Google Analytics.\n\nMy pro tip is to use something less shitty and render-blocking than Adobe\n\nVery true\n\nThey have no tracking/ads because the type of people that use the McMaster Carr website on the daily are not the type of people to make impulse purchasing decisions. \n\nPeople are forgetting that it‚Äôs a business decision. It‚Äôs not because they ‚Äúcare about performance‚Äù but it‚Äôs because they don‚Äôt have a need to upsell the people who actually use the site on a daily basis. \n\nThe type of people that use the site are specifically going on there to order a specific thing. They‚Äôre not buying for the sake of buying and quite often they‚Äôll be purchasing for their job or work. \n\nAs a result they use a company card or similar that they‚Äôll be scrutinised for when the company does an audit or similar. So you can‚Äôt ‚Äúupsell‚Äù them because they‚Äôre not going to try buying anything else other than what they need.\n\nIt‚Äôs a very specific website with a very specific purpose. This extends to most other distributors for stuff like this, [farnell](https://uk.farnell.com/) for example is quite fast (after initial load) as well compared to 99% of commerce sites, and they have tracking/analytics. Another example is [metals4U](https://www.metals4u.co.uk/) in the UK who distribute metal stock. \n\nThese companies have just realised that their target demographic quite literally doesn‚Äôt or can‚Äôt buy anything else because they‚Äôre on the job and buying through a company or such.\n\nAs a result, the majority of tracking information is (almost) useless and the best analytics to use are going to be the actual orders placed.\n\nIt‚Äôs the same mindset as when you‚Äôre developing an internal tool or dashboard for your company, you‚Äôre only focused on the specifics because the goal is to just be reliable and consistent. As a result it tends to be fast and consistent.\n\nThis should be much higher.\nIt‚Äòs actually not *that* hard to make a website fast. Society has gotten used to slow websites (due to a number of reasons) that a perfectly normal one can stand out as fast üòÖ\n(I don‚Äòt want to downplay the efforts that went into making mcmaster, it‚Äòs super nice and pleasant to use)\n\nI hate analytics as much as the next guy, but you can totally have a fast webpage filled with them. The other fast example site I see a lot is USAtoday (also very quick) and they have plenty of analytics scripts from what I recall.\n\nNow if only adblock and blocking cookies would get us the speed back.\n\nIt's blazingly fast when compared to any badly optimised websites, otherwise it feels like a just a regular website that is optimised well, specially if you are browsing it from another side of the world.\n\nAlso, they only need to load a 93 kilobyte image as a sprite sheet of their inventory on a page. The pictures are tiny and gray scale meaning they don't take up much space at all. Any website that wants to display one full color photograph that looks good will easily take up literally millions of bytes as even compressed high quality photos are at least 1mb. Example: a website that sells watches or laptops or whatever gadget is probably gunna need at minimum 5 photos or the website or listing will look sketch as hell. With McMaster, you just need one symbolic simple grayscale image and then the specifications like length, head type, thickness, and thread spacing is what matters and you know what you are buying.\n\nYou don't need 4MB or even 1MB images to look good on a website.  You only need the 4MB images available if someone clicks on one of the smaller images.\n\nHere is the type of image you see on Amazon when browsing a random listing:\n\nhttps://m.media-amazon.com/images/I/61t6XIxGQFL.__AC_SX300_SY300_QL70_ML2_.jpg\n\n8 kilobytes.\n\nAnd here is the \"high resolution zoom\" version when you click or hover on the image:\n\nhttps://m.media-amazon.com/images/I/61t6XIxGQFL._AC_SL1500_.jpg\n\n77 kilobytes.\n\n[removed]\n\nI bought it 2 weeks ago, it‚Äôs very good imo.\n\n&gt;Example: a website that sells watches or laptops or whatever gadget is probably gunna need at minimum 5 photos or the website or listing will look sketch as hell.\n\nWatches, Black \n\nhttps://www.mcmaster.com/5262N11\n\n$449.98\n\nThough this one does have 6 images on it. The images are all black and white, Unlike their [popsicles](https://www.mcmaster.com/3542N12).\n\nFunny, both of those links load an empty webpage with a header. Put a loading circle in the middle and after it resolves, stay empty.\n\nWebsite might not be that great after all. I am a standard Windows10 and Firefox, no plugins.\n\nHave to log in to see certain products.  I see a lot of e-commerce sites do that, I think it's a thing to stop bots from seeing certain things.\n\n&gt; photograph that looks good will easily take up literally millions of bytes\n\nDude, do you even jpeg? 100kb is all you need for a full product photo, maybe 200kb if you really want to see the finest details.\n\nYou are so seriously underrating this. It shows why server rendering should be the way to do things, scalability be damned, companies just kept pushing the CPU on to the browser and our online experience is shit because of it.\n\nAbsolutely agree with that\n\nThe funny thing is this is ASP.NET, so C#, .NET etc. The second funny thing is this is actually pre-open source and cross platform .NET, meaning this is running on Windows and IIS, so around .NET 4.5 - .NET 4.8.\n\nSo, what this means is that should they upgrade to a more modern .NET version made in the ~ten years since 4.5-4.8 was released, their site will become significantly faster still. .NET has had huge performance improvements, like reduced allocations or even no allocations, it's great.\n\nFinally, the last funny thing is that the usual crowds would be drooling and shitting their pants about \"hurr durhhh .NET bad, not open source, C# is only windows\". But yet, something running on Windows is beating the average website experience by 10x, and there is yet even greater performance available should they upgrade to a newer .NET running on Linux.\n\nThe lack of privacy invading adverts is another helping factor.\n\nMeanwhile some hype wave chaser would suggest \"they should just use Next and get SSR reee\" or \"but node is webscale because event loops i read about on some blog post\" or \"we should put all our ads scripts inside partytown that will solve all problems\". Well, it is literally already using SSR. Oh and StackOverflow is also ASP.NET.\n\nEdit: Also one final thing, upgrading an ASP.NET 4.8 app to an ASP.NET Core app, while sometimes tricky, especially if you have an older dependency, can often be done in a few hours or days assuming nothing needs refactoring. Now try do that for any Node application that's ten years old with the usual miserable experience of thousands of interdependent npm packages, good luck as it would be easier to rewrite it.\n\nI think a few hours or days might be underselling it - I was in charge  of upgrading much of TFS/Azure DevOps to .NET Core and it was a pretty significant effort.\n\nThis is how I feel writing websites in coldfusion. The older technologies just work but they aren't \"cool\".\n\nThe website in question, it is impressively snappy! [https://mcmaster.com/](https://mcmaster.com/)\n\nTweet referenced in the video: [https://twitter.com/mattwensing/status/1847279680828645491](https://twitter.com/mattwensing/status/1847279680828645491)\n\nFor those interested in their range of products, they are great to deal with and have great delivery lead times on the East coast if the US.  Great for SS nuts and bolts..\n\nI don't know it feels normal to me. It doesn't feel \"impressively\" snappy\n\nThe website prefetches data with a 2s timeout, if your internet is slow it won't prefetch and it'll just work like any other website, open the network tab and see if the prefetches are working for you.\n\nWhen it does, it acts as if you've already prefetched all products they have, making all navigations quick\n\n[deleted]\n\nSend request to prefetch data, timeout if it takes longer than 2s, this can be done frontend in js or server side.\n\nIt's not complex, the timeout is not why it's fast, it's why it's not fast for some people.\n\nThe website just: \"oh you're on the categories page? Ill prefetch the first page of each category\" and to not keep those requests hanging times out pretty quickly\n\nSame here. Just feels like a regular website without too much JS.\n\nThis tells you about the garbage people are used to consider normal nowadays\n\nI don't even say hello to the world without 800 MB of react.dumpersterfire.js\n\nYou really notice the difference between this and something built with client side javascript frameworks when you regularly use 10 year old hardware\n\nSome pages have dogshit speeds. This one sits for about 6 seconds on a throbber for me\n\n\nhttps://www.mcmaster.com/products/o-rings/\n\nhttps://www.mcmaster.com/products/bearings/\n\nYeah search seems to be their Achilles.\n\nAlso overall UI seems laggy sometimes? Tapped around on mobile site and sometimes I don't know if it registered my tap. Things refresh literally 2 seconds or so later.\n\nInstant for me. Clicking through several products was instant. I saw the loader image appear but it was brief. My email takes longer to open on a fresh chain.¬†\n\nThinking that might be a cache miss.  Since a bunch of traffic is being sent to it now I'm guessing Akamai fetched it because when I clicked on it it was instant.\n\ndon't know really.. looks like nothing out of the ordinary, I get some white pages for like 5-6 seconds.. no skeleton, no loading state.. UI wise looks pretty poor,\n\nAh, they're masters of reddit advertising\n\nI see constants loading screens when navigating pages and products\n\nmcmaster has generally been pretty committed to a high quality consumer experience. they had an excellent catalog before websites were the de facto source. that‚Äôs the reason behind the reason.\n\nAnd you can return literally anything. Simply send it back and you get a credit.\n\nFantastic service.\n\nThey still have the amazing print catalog, and plenty of people still use it!\n\nI worked on a B2B commerce site back in 2001-2003 which targeted auto repair shops ordering parts from their local parts store. First time the owner went out to a test customer he reported back that the site was too slow. Turns out the shop computer was only getting about 5-10k down on their 56k modem due to the ruralness and splices in their lines at the shop. We ended up having to do a lot of cool things like XML data islands and XSLT transforms in IE before AJAX was even a thing. I also had the backend guy pre-render some specific chunks of data so that I could download it directly and then cache it. I had a blazing fast Year-Make-Mileage-Engine selector back in the day. Good times!\n\nThe amount of time I‚Äôve spent in my life refining a YMME selector‚Ä¶\n\nWe had to modify the internals of the Qt combo box because we needed keyboard handling to work like an old green screen app. A normal combo box filters dynamically based on character matching. Type ‚Äúch‚Äù and it‚Äôll narrow to Chevrolet, Chrysler, etc. \n\nWe wanted to maintain numeric codes for makes that existed in the old application. Like 1 for Chevrolet, 2 for Ford, etc. \n\nSo we hacked in a lookup table so that you could either type ‚ÄúF‚Äù and have it filter like usual or you could type 2, and it would select Ford and move focus to the model control. \n\nProbably still the worst code I‚Äôve ever written.\n\nOh yes, I love how thick clients allow you to type several characters to narrow down the selection. I hate how web browsers don‚Äôt.\n\nWow.  Its amazing that they are using the Yahoo yui library and Jquery.  Old tech can still get the job done!\n\nI miss jQuery\n\nIt‚Äôs still available, you know. Nothing stopping you from using it except other people‚Äôs animosity.\n\nWe have htmx now, because... well, I don't know why.\n\nhtmx pushes you towards doing almost everything that the McMaster-Carr website is doing. Server rendering, history push, loading indicator‚Äìthey even have a prefetch extension. This website is almost like a showcase for htmx.\n\n[deleted]\n\nWhy? I see this sentiment repeated pretty often but no one seems to go into details about it\n\nMost of what jQuery can do, can now be done with native JS. Also, it doesn't provide enough to do what modern app frameworks can do. So for me it is either too much or too little. There might be performance or interoperability issues, but I never saw them.\n\nEven so, part of me wishes we lived a steampunk-like alternate reality where jQuery and KnockoutJS became the predominant libraries for building apps.\n\nUsing pure JS giving better performance becuase jQuery is a bloated translation layer.\n\nNowadays we also have a lots of bundler/compiler that could optimize for the best performance with the smallest size.\n\nI'd say Jquery had two value propositions:\n\n1. Crossplatform code, which is kinda not necessary now that Safari is the only badly behaving browser you'd wanna support. And even then, it's mostly edge cases\n\n2. Genuinely useful apis. Like the jQuery function itself (sometimes called by the dollar sign) was great when document.querySelectorAll didn't exist or wasn't reliable.\n\n\nI think Jquery had plenty of good ideas, as evidenced by their adoption by vanilla JS.\n\nMcMaster-Carr is an amazing company!    As a little kid, in the 1960's, I can remember my father bring home the \"old\" copy of their catalog from work.  For a kid it was absolutely fascinating to browse through that big yellow catalog.\n\nToday their web site should be considered as a bench mark for many E-commerce sites.  For the type of person that already knows what they need, it is one of the most responsive sites going and more importantly fast.   It simply doesn't get in your way when you are trying to get your work done.   By the way in my mind there is a difference between responsive and fast.\n\nIt is great that an old school company can transition to the modern world in such an impressive way.   Many other have failed or have been eaten up by Amazon or one of the others.\n\nImagine if the website people for MC had worked on Sears when it was still relevant‚Ä¶\n\nActually that is a good point.    I wonder if MC site is all done by internal development teams.   I could see people (web site contractors) trying to sell Sears the latest and greatest updates to make their web site fashionable.  Meanwhile over at MC there is likely a management team and software team working together to make the site a customer delight.\n\nWatched this yesterday. It was a really in-depth and fascinating case study.\n\nthe fact that McMaster is used almost ubiquitously in the US and has been for decades, yet everyone still likes and depends on them, tells you they've got some smart people on the payroll including good management to not pull it into some dumb direction.\n\nHoly hell that was extremely informative.¬†\n\n\nSo much new info for a newb like me!\n\nA video is a horrible way to present this info. Is there a written summary somewhere?\n\nCan someone summarize the video?\n\n- Preloading of pages when you hover a link\n\n- All images the same dimensions so the page doesn't shift when the images pop in\n\n- JS lazy loaded\n\n- Using \"pushstate\" to change pages instead of reloading\n\n- Caching\n\n- Everything's server rendered.\n\nParaphrasing the tweet the creator of the video made on his twitter account @wesbos\n\nEssentially when you hover over an item, it fetches the whole pre rendered content for that page, then when you click it it swaps out the content of the page dynamically instead of loading the page fully.\n\n&gt; Caching\n\nTo add to this, (not sure if it's mentioned in the video because I can't watch right now, wish people would provide readable content alongside a video) they are able to cache so aggressively because their content is read from often but only written to occasionally.  As opposed to a website like reddit where the content is changing all the time.\n\nNext.JS provides the preload link functionality out of the box, right?\n\nThat doesn't sound like something unique. Many Ruby on Rails sites used (and still use) all listed things. If I recall correctly, tech called turbolink\n\nIn a nutshell\n\n* Its server-side rendered HTML\n* They are pre-loading fonts and DNS fetches\n* When you hover over a clickable element, it pre-downloads the HTML just in case you click the link.\n* They make heavy use of caching and service worker\n* The CSS is all loaded before you get to the body. No CSS link tags\n* All the images are in sprite sheets and each image on the site has a fixed width/height\n* They are using YUI (Yahoo Library) &amp; Jquery for UI\n* They are figuring out what JavaScript they need for every page and only loading the minimum required.\n\nBasically they really care and have put a lot of thought into performance. Apparently the guy said, they have 700,000 products in the catalog to browse from!!\n\nThanks. One question, is CSS not loaded before the body when you have it in a `&lt;link&gt;` tag in the `&lt;head&gt;`?\n\nWhat they mean is the CSS is loaded on the same request to the server as the HTML file rather than burning 50-100ms to make a second request.  Normally this would be a disadvantage for loading subsequent pages but because they use javascript with pushstate rather than a full page load when you click a link there would be no advantage to your browser being able to cache the stylesheet separately.\n\nand that's just the stuff we can see! probably some interesting layers behind the scenes too, layers of varnish or something, and surprisingly i would actually guess no cdn.\n\nClose! I think it‚Äôs mentioned on the video they are using [squid](https://www.squid-cache.org).\n\n&gt; i would actually guess no cdn\n\nThey're using Akamai and possibly some of their proprietary and expensive magic. Things like Akamai ESI can really speed up certain sites.\n\ndey make it rain wid dat cache\n\nIt's not \"wicked fast\", tho\n\nCan you name another e-commerce site with a largest contentful paint under 174 milliseconds at the 75th percentile?\n\nCraigslist maybe?\n\nAnother great example. I love Craigslist.\n\nPeople claiming it isn‚Äôt impressive might be navigating a different web than me\n\nrockauto.com\n\nYeah it's a good ok+ but it's nice to see a large sales platform with a simple and performant structure\n\nwithout watching i would say jQuery and no non sense JS frameworks ...\n\nFYI vanilla JS is way faster than jQuery.\n\nyou were half right.\n\nWebsite designed to be used on 3G networks standing inside your work van. So of course it‚Äôs fast af on gigabit.\n\nCool presentation, informative.\n\nNo typescript or web assembly? Not cool enough /s\n\nWes Bos is fantastic. One of the few people who make excellent paid courses.\n\nSmall images, little data over the wire, no extraneous features. It‚Äôs not like this is magic, it‚Äôs just a simple catalog made into a website.\n\nYoutube could learn from this. Almost unusable on older computers.\n\nIf you really want to see impressively snappy, https://lite.cnn.com.  That's how fast things _could_ be if we stop overloading it with javascript, hundreds of calls to microservices, etc. etc.\n\nThats only text on a white background.\n\nI think that‚Äôs the point\n\nthe speed defo makes a difference\n\nwhen traversing through websites where am trying to find parts, am usually trying to fix a problem, by ordering parts\n\ni dont give a shit about fancy css or the rest of it. i just want my god damn product.\n\nwhich is why i appreciate the above.\n\nWent to the website. When browsing the products it was not snappy for sure. Some caching would help here.\n\nThe Factorio website is also silly quick\n\nWhen a site I used to use daily shows up, haha!\n\nSource: ex CNC machinist\n\nwhen I saw this come up on my youtube recommended I thought it was going to be about their shipping, because I swear their stuff arrives so fast they had to have shipped it before you ordered\n\nI was expecting some no-JS minimalistic website but it is actually a .NET ecommerce with about 10 JS files (2.7 MB the heaviest one, but it takes 500 kB compressed). The browsing feels fast once loaded though. Images are &lt; 100 kB each.\n\nI wonder if it could be made still faster by switching to fully static pages and enhancing the caching. But it is already fine as it is.\n\nEverything about McMaster carr is amazing. No surprise to me their website is killing it too.\n\nScrew them and their overpriced shipping though. Sometimes shipping is as mush or more than the stuff you buy. Although their customers are primarily businesses who don't normally care about shipping costs. They don't cater to retail buyers. But they can be a good source of otherwise hard to source stuff, like G10 (garolite) which I use as a print surface for my 3d printer.\n\nBookmark\n\nI've used McMaster my whole career. The website is PERFECT, nothing else even comes close.\n\nCool\n\n\"174ms to render is so fast!\"\n\n*Cries in gamedev*\n\nI always marveled at the Mcmaster Carr catalog. Somehow this doesn‚Äôt surprise me.  With inventory like they carry you have to be on top of your game.\n\nI don't go here but it showed up in my feed, and...what the fuck happened in this comment section?\n\nMade me think of [ofc.nu](http://ofc.nu) (swedish fishing store). It's blazingly fast. Made in C running on slackware."
  },
  {
    "title": "Winamp finally open sources their code, under license preventing forking and source/binary distribution",
    "body": "people have been discussing that this breaks GitHub TOS and is no more open source than a leak. I think it's cool that we have an up to date piece of winamp source. ",
    "score": 1251,
    "url": "",
    "created_utc": 1727260089.0,
    "author": "bruisedandbroke",
    "permalink": "/r/programming/comments/1fp15q0/winamp_finally_open_sources_their_code_under/",
    "all_comment_text": "The ‚Äúwrite code for us but only we can benefit‚Äù license. Wonder how this will pan out for them.\n\nit's been about 12 hours (afaik) and about 500 forks... so as of now badly lol\n\n&gt;winamp-how-bout-i-fork-anyway\n\nTop fork, lmao.\n\nYou could make a religion out of this.\n\nIt really whips the lama's ass\n\nThis is a fork. Here, it whips the alpaca's ass.\n\nNo. don't.\n\nToo late I have my own bible on my github\n\nCan I fork it?\n\nEdit: let me nail these 95 theses on your door\n\nwinamp-bible-how-bout-i-am-now-mormon\n\nLeoX has rejected your PR with reason \"wontfix\"\n\nBut it‚Äôs a sweet, dank repo!\n\nWith your help, we can finally take a bite out of those damn false gods, like the flying spaghetti monster. Those impastas stand no chance against our mighty forks!\n\nWhat exactly are the doctrines of Contrarianism, and how would I be punished for not following them?\n\nToo much risk of heresy. Someone will always fork the religion anyway\n\nwinamp go fork yourself\n\n[deleted]\n\nI also saw winamp-spoon\n\nLmao.¬†\n\n\ni'd probably Name it¬†\nSomething Like¬†\n\n\nwinamp-we-cant-forking-wot-m8\n\n\nEdit: checked the repo. They updated the license and Struck the 'no forks' rule from Section 5\n\nFork-me-outside-how-bout-dat\n\n[Important updates to the README](https://github.com/WinampDesktop/winamp/commit/67c68e6dc24f36b266427034d016fb86ef4d486c).\n\nLmao i love it\n\n600 forks now. Let's go reddit\n\nedit: they [removed the restriction](https://github.com/WinampDesktop/winamp/commit/64a51755c6f5d85039463c8bf7c2a9e98e862586)\n\n&gt; - No Distribution of Modified Versions: You may not distribute modified versions of the software, whether in source or binary form.\n\nTechnically having a fork with modifications would breach this condition no? \n\nSo silly\n\nTrue. But now it takes much more work to be petty than to just press fork button\n\n[deleted]\n\nI would guess it's borderline impossible to enforce\n\nAlso [\"Contributor's waiver of rights is probably not legal under Belgian law #24\"](https://github.com/WinampDesktop/winamp/issues/24) lol\n\n\"not clear\" as if it was the readers mistake\n\nJust a simple Fork of the repo isn't probably what is meant by the \"No-Forking\" restriction.  \nHow else would one \"gift\" them code as a PR?\n\nIt's rather to prohibit creation of derived projects, I believe.\n\n---\n\nBut what a terrible terrible wording in that absolutely laughable license\n\nPresumably the same way you do for projects on sourcehut: send the patch to the maintainer through `git send-email`.\n\nIIRC, by making it public on Github they've granted forking rights anyway. There's a bit in the TOS that says \"users can fork if you upload here, and you can grant *more* rights with a license in your repo\".\n\n&gt; with certain restrictions on the distribution of modifications to maintain the integrity and collaboration of the project.\n\n90% AI.\n\nOver 700, now!  My personal favourite is:\n\n&gt; winampussy\n\nIt's a bit weird to write a license that forbids forking, then deliberately choose to upload the code to a site that explicitly allows forking and indeed *requires* public repos to be forkable.   IANAL, but that sounds like might about to some sort of estoppel.\n\nTheir license is invalid since it directly violates GitHub's own terms of service.\n\nBeing against the GitHub TOS in no way invalidates the license.  They‚Äôre two separate issues that are unrelated.\n\nGitHub can certainly enforce their TOS and remove their project, but users who fork it are still violating the license and doing so will just make those users an easy target for lawyers.\n\nStatus of Llama's ass: Whooped.\n\nWhat are forks?\n\nA fork is when you take the source code from a storage location they own and move a copy of it to a storage that you own.  Presumably so you can make your own changes to it\n\nTo be fair, I think the winamp source code is only really interesting from a historical context.  There's tons of equivalent open source pieces of software nowadays if you really want to use some media player source\n\nAgreed. What made winamp neat was the default look. That look can be simulated - and has been simulated - by many clones.\n\n&gt;What made winamp neat was the default look. \n\nGiven how popular Winamp skins were I'm having trouble believing that. I think the fact that it was the second program capable of playing MP3s in real-time on a home computer, and a major improvement over the first (WinPlay3) had more to do with it's initial popularity, and the skinning support helped maintain it.\n\nWhat I desperately want is someone to plug in an api from something like iBroadcast so we could use our hosted library in a cool retro looking player. \n\nTurn it into a streaming player using APIs is my hope versus it just being another local player.\n\nSounds like Subsonic? There are hosted and self-hosted Subsonic servers available, then you can have your pick of the Subsonic clients.\n\nIt‚Äôs more like the old google play music where they hosted your music like a locker.\n\nHah - I know what iBroadcast is. :-)  I meant what you were trying to describe you wanted...\n\nWe graduated from MilkDrop to Plane9 in VR! Doesn't make the MilkDrop memories any worse.\n\nLook at the issues tho. Most of them are at peak idiocy levels. Probably 17 y/o wanting to be cool, or just low-IQ individuals.\n\nIssues have been outlined, time to stop posting stupid memes.\n\nIt reminded me of that time when a shitload of indians started creating pull requests in several repositories with random changes to the README because there was a contest to win stuff somewhere that involved having commits on open source projects.\n\nWas this an India-specific contest or something?  Hacktoberfest caused that issue a while back too.\n\nYeah I think they‚Äôre describing the Digital Ocean hacktoberfest t-shirt fiasco\n\nThis sounds like a line from Silicon Valley. üòÇ\n\nThe best part of that was that AFAIK it applied to ANY repos, including your own. I think all I had to do was create a couple of proper PRs to my own learning projects that I was going to make anyways, and boom, got a free shirt lol\n\nI wonder why they don't do that anymore...\n\nI really wish github would permaban accounts that are only used to submit smoothbrained posts as issues.\n\nYeah, Darklang has a similar license - https://github.com/darklang/dark/blob/main/LICENSE.md\n\n\nI think you can still benefit by seeing how they implemented features, but it's definitely a downer if you want any rights to changes you might want to add\n\nThat's the thing: you can't! Back in the very early days of the PC there were a bunch of issues relating to the code for the IBM PC BIOS precisely because IBM freely published the source code for anyone to read.\n\nThe legal hazard here is that the company publishing the source code can then go after anyone who has read their code and implemented a similar feature in another project. That's because they own the copyright and can then claim that you, the person who read their publicly released code, is guilty of violating said license and, as such, have committed copyright infringement or IP theft. And IBM did exactly that!\n\n[https://books.google.pt/books?id=gy4EAAAAMBAJ&amp;lpg=PA15&amp;pg=PA15&amp;redir\\_esc=y#v=onepage&amp;q&amp;f=false](https://books.google.pt/books?id=gy4EAAAAMBAJ&amp;lpg=PA15&amp;pg=PA15&amp;redir_esc=y#v=onepage&amp;q&amp;f=false)\n\nAlthough in this case there‚Äôs approximately nothing special or unique in WinAmp‚Äôs source, so it‚Äôd be a hard slog proving you didn‚Äôt osmose ideas from (e.g.) XMMS or one of the many other clones from its era.\n\nNote that in the case(s) mentioned in the article they settled out of court (and without any monetary payments either). It's possible that, in court, cloners may have argued that the BIOS _had_ to be near-identical to preserve compatibility; something that was also argued in the similar Apple vs. Franklin case over the Apple II ROM code. Ultimately that case also resulted in a settlement with that question unresolved.\n\nStill, \"clean-room\" PC BIOS implementations were already available by early 1983, before both Apple vs. Franklin and the 1984 article you linked. Chances are, Corona and Handwell just licenced Phoenix's or AMI's BIOS implementation after agreeing not to ship anything more with code copied from IBM.\n\nConsidering that the whole point of my argument is that there's a legal hazard I think it still stands. The issue is not that you are in fact doing something wrong, it's that a company can use the threat of legal action in the future. The fact that the cases were settled out of court only helps my argument (because there's no precedent set either way).\n\nWhile not ideal most of the time this is enough since there are rarely active forks of bigger projects, so most modifications are just pull requests that then get merged at the mercy of the maintainers anyways.\n\nDont worry they have a crypto wallet integration with the player so this will decentralize profits /s\n\nTake a look at the closed issues. People seem to be having fun.\n\nWinamp provides access to their source code. In order to open source their code the license must at least conform to [The Open Source Definition](https://opensource.org/osd) maintained by OSI.\n\nYeah, this seems like an excellent example of a \"source available\" license, which is a different concept to open source. Similarly paying customers can get access to the source (even distribute modified copies) of Unreal Engine, but that doesn't make it open source.\n\n&gt;paying customers¬†\n\nJust to correct something, Unreal Engine source is open to absolutely everyone who signs the agreement, not paying customers. It takes a few minutes and is automated [https://www.unrealengine.com/en-US/ue-on-github](https://www.unrealengine.com/en-US/ue-on-github)\n\nWith the Unreal Licence you are allowed to fork and maintain a modified version of it. You are however not allowed to re-licence it.\n\nYou're correct that it's Source Available, not Open Source - primarily because it doesn't fall into one of the OSI open source licences.\n\nWhy is this such a deeply misunderstood term these days?\nIs the name \"Open Source\" just a bad name that makes people think the wrong thing? I once got into a long discussion with an employee at a faang company who was fervently trying to argue that shared source was a subset of open source.\n\nBecause there's an incentive to muddy the waters.  The exact same thing happened with \"Free Software\", and the name \"Open Source\" was chosen to try to make it clearer.  If large companies can get the benefits of open source development without providing the user freedom of open source, they will.\n\nThat's not quite accurate history. While some in the Open Source movement pointed out the ambiguity of Free Software (that the alternative Libre Software phrasing avoids), the movement was founded as a \"business friendly\" reaction to the Free Software movement's goal of eradicating all proprietary software and bringing equality to user and programmer. By eliminating the political-social messaging of Free Software and softening the goals (Open Source is perfectly fine coexisting with proprietary software) once it became the dominant current the state we're in today was made inevitable.\n\nSince Open Source is the dominant current and Free Software adherents are painted as rigid ideologues and kind of nutty, many people who actually support the goals of Free Software falsely ascribe them to Open Source (not really their fault, we all operate on the information available to us).\n\nA major part of what led us here is the Open Source preference for non-copyleft licenses because copyleft \"restricts freedom\" -- when in reality copyleft merely prevents one party from depriving others of the freedoms they received. The attitude that freedom is the power to deprive others of freedom really leads into this return to \"source available\" nonsense and since Open Source is devoid of ideology the term is very easily muddied. Ironically use of strong copyleft licenses rooted in the Free Software tradition like the AGPL rather than Apache/BSD style licenses would prevent SaaSS companies like Amazon and Google from exploiting the output of \"Open Source companies\" and putting them out of business (Elasticsearch seems to have finally figured that out which is nice).\n\n&gt; the movement was founded as a \"business friendly\" reaction\n\nIf by \"business friendly\", you mean \"doesn't live in lala land\", I suppose. The FSF is 39 years old and still doesn't have a good answer to \"how do software developers get paid?\"; \"they have an office somewhere at MIT\" isn't a practical answer for most of them.\n\nThis is really interesting history. Do you know of anyone who has compiled the early stuff into a book/blog/video. I would love to track down some of the sources for this to keep as a reference for future discussions.\n\nI am not sure if there is a more modern or concise summary than the book [Open Sources: Voices From the Open Source Revolutioon](https://www.oreilly.com/openbook/opensources/book/) which was thankfully published under a free license and still available online. There's also a [bit of history on the schism](https://www.gnu.org/philosophy/open-source-misses-the-point.en.html) written around 2007 (and I think updated in 2016) from the GNU project. This part is pretty relevant:\n\n&gt; However, the obvious meaning for the expression ‚Äúopen source software‚Äù is ‚ÄúYou can look at the source code.‚Äù Indeed, most people seem to misunderstand ‚Äúopen source software‚Äù that way. (The clear term for that meaning is ‚Äúsource available.‚Äù) That criterion is much weaker than the free software definition, much weaker also than the official definition of open source. It includes many programs that are neither free nor open source.\n\nI think ESR's (as unpalatable as he is) *Cathedral and the Bazaar* gets more into things from the Open Source side, but it's been 20 years since I read that and it's not something I've revisited. I actually wrote a paper on this in 2004 and still have my notes but it's in a backup that I'm having trouble unpacking (maybe I should convert that to restic while I still can...).\n\n&gt; However, the obvious meaning for the expression ‚Äúopen source software‚Äù is ‚ÄúYou can look at the source code.‚Äù Indeed, most people seem to misunderstand ‚Äúopen source software‚Äù that way. (The clear term for that meaning is ‚Äúsource available.‚Äù) That criterion is much weaker than the free software definition, much weaker also than the official definition of open source. It includes many programs that are neither free nor open source.\n\nI find it interesting I heard Stallman's voice as I was reading this. I clicked the link to confirm, and yes, it was Stallman. \n\n&gt; Free Software adherents are painted as rigid ideologues and kind of nutty\n\nI guess it's a question of pragmatism versus idealism. Linus vs Stallman. I will always have a deep admiration for people like Stallman who hold a strong set of egalitarian beliefs and religiously follow them. (I just try not to think about specific statements of his)\n\nI respect and understand the pragmatism, but I admire the idealism. \n\nIt makes me wonder if we will reach a world where truly free software is the standard. I'm guessing our economic system would have to change. Our entire IP legal framework\n\nESR has written some thing about it, especially the top two essays. Keep in mind these are all old and don't really touch on things like the wide adoption of MIT license instead of the various GPL-based licenses.\n\nhttp://www.catb.org/esr/writings/\n\nIt is ironic that the other user here is trying to muddy the waters just like you describe.\n\nYes, \"open source\" is a bad name for it.  It's too ambiguous for people who don't understand the licensing models.  The source is open for anyone to see and inspect...\n\n/r/StallmanWasRight/\n\n&gt; No Forking: You may not create, maintain, or distribute a forked version of the software.\n\nGood luck with that. I created one just to spite them.\n\nI don't think they meant repository forking. After all, there's this in the LICENSE\n\n&gt;Contribution to Project: You are encouraged to contribute improvements, enhancements, and bug fixes back to the project. Contributions must be submitted to the official repository and will be reviewed and incorporated at the discretion of the maintainers.\n\nThe only proper way to contribute something to a GitHub repository as an external contributor is by forking. I mean, what other methods are there? Email a patch?\n\nReally, it's just a poorly written license, that's it.\n\nThis reads like the license was written by project managers. No lawyer or software engineer involved at all. Then they gave each other a pat on the back for their great work.\n\nLawyers and PMs ruin everything.\n\nWinamp it forks the llama‚Äôs ass\n\n[They removed that line about 3 hours after your comment](https://github.com/WinampDesktop/winamp/commit/64a51755c6f5d85039463c8bf7c2a9e98e862586)\n\nStill not free.\n\nLegally speaking it‚Äôs not removed. As in the license ‚Äúthe license‚Äù refers explicitly to only v1.0 of said license, not the updated license with the forking line removed.\n\nIt is so confusing to me that their goals with the license are the same as the GPL, yet they decided to create their own license.\n\nThe license reads like it's AI generated.\n\n&gt;This custom License aims to maintain the collaborative nature of the project while restricting the distribution of modified versions.\n\nthat‚Äôs like the explanation an LLM gives you *after* it generates what you wanted. like someone did a lazy copy/paste without actually reading it.\n\nthey probably meant forking as in \"here's Derpnamp, an improved Winamp with more llama\"\n\n&gt;The Winamp Collaborative License is a **free, copyleft** license for software and other kinds of works.\n\nWhy are they trying to offend everyone on purpose? Is this some kind of a stunt to gain notoriety?\n\nI know the term \"open source\" is often misunderstood. But this is too much.\n\nYeah I feel like the wording is so bad and so obviously inflammatory that I feel like it must have been on purpose. People aren't that clueless.\n\nProbably written by non-technical people and then stamped by lawyers.\n\nDoubt any lawyer was involved.\n\nYou'd think lawyers would know better than to claim something is copyleft when it isn't. There are lots of IP lawyer who know better.\n\nI'm sure their lawyers understand very well that describing it as copyleft in no way alters or invalidates the actual license. There's no penalty to their claims.\n\nA lot of (even IP laywers) don't know software copyright. Software is in this weird space where it is governed by both IP &amp; Copyright law, which can make it a real nightmare unless you're specialized in both.\n\n&gt; non-technical people\n\nyeah, chatgpt\n\n&gt; copyleft license\n\n_technically_ copyleft is a legally protected term under the international Berne Convention and French Law. I sure hope there isn't a [petty organization](https://www.gnu.org/home.en.html) with a long successful track record willing to test that in court.\n\nIt will now be preserved forever, thanks old friend\n\n~2.96 million lines of code. That is a surprisingly high number.\n\nDamn Justin. You really did whip the llamas ass.\n\nWhat's wild is that it'll be 30 years old in a few years. I've been using it since windows 98 (maybe even on 95? Can't remember).\n\nAnything good in there?  I'm cloning now to take a peek.\n\n[There's some copyrighted stuff](https://github.com/WinampDesktop/winamp/issues/11). Not sure if [the code](https://github.com/WinampDesktop/winamp/commit/0003d3d743e5d0d4e4049e59ab92c86d142722a8#diff-1debcfa8cc0ae704309f9e553953af6e29080ee4f2f587f38c94e6505d6fd6f7L5-L7) is actually interesting beyond the copyright notice. :\\^)\n\n[Source-available](https://en.wikipedia.org/wiki/Source-available_software) isn't [open source](https://opensource.org/osd)\n\nThey just removed that clause from the license. \n\nhttps://github.com/WinampDesktop/winamp/commit/64a51755c6f5d85039463c8bf7c2a9e98e862586\n\nYeah except they left the part where you can't distribute any version of it. Meaningless.\n\nAnd they called their license Winamp Collaborative License. Collaborative! What a joke.\n\nYou can collaborate with them on their product.\n\nIs there really much value to not-really-open-sourcing Winamp (whose code is probably about what you'd expect for a Windows program first released in 1997) when there are more modern, more portable, actually open-source media players (even ones that support Winamp skins; e.g. Audacious) around?\n\nIt will be once the owner goes bankrupt.\n\nEveryone is bitching but yes nice! I can inspect the code and modify it to fit specials needs if I want.\n\nSure, for me Winamp is useless (now) but this would be great for drivers, Os and many tools.\n\nYou don't need to forfeit your right to expose your source.\n\nI'm fine with that. It's not open source. It's not useful to me. Still a good transparency move.\n\nWinamp sharing their source is great. The problem is that they are trying to get a lot more credit then they deserve by claiming they open sourced it with a free copyleft license, which they did not.\n\nCredit for what, by who, to what end?\n\nIt's useless software that's only relevant in maybe intro to programming courses and digital preservation.\n\nThey can say whatever they want because it doesn't matter.\n\nCredit for open sourcing their code. By the general public. To ends we can only hypothesize about, but are at best: nothing.\n\nThanks for the precision, I understand the issue then.\n\nI would like a world where you HAVE to share your source. Security wise, everything that is closed sources around us scare me. Embedded software in cars, Bluetooth speaker, phone and so on is a big security issue.\n\nThat would be a nice world. The GPL is probably the closest to that we have right now. It's doing a good job.\n\nThey could have gone with the gpl\n\nFinally? Was someone waiting for it? I want to know more!¬†\n\nI think this restriction comes from their corporate overlords. But yeah, posting it on Github kinda screws that up. There are some reasonably good alternatives so this is more for melancholic enthusiasts\n\nThat is not open source. That‚Äôs source available.\n\n[deleted]\n\nAnd yet the license is still self-contradicting and written by ChatGPT.\n\n[They opensourced the entirety of shoutcast too](https://github.com/WinampDesktop/winamp/commit/1be04037cdba95396eef7728134043ba3ee6fbf4).\n\nwinamp: voyeur edition\n\nWinamp?\n\nNow that's a name I haven't heard in a long time.\n\nA long time...\n\n20 years of so...\n\nPeople still use winamp? What on earth for?\n\nit had a ton of very useable plugins. \n\ne.g. like gapless play between songs.\n\nYeah, but there are other players that are just as lightweight with more features and more useful plugins, like foobar2000. It's just not as easily skinnable because most of its users don't care about that.\n\nBecause it really whips the Llama‚Äôs ass.\n\nAfter what, 27 years?   Winamp must have a hell of a lot of stamina to still be whipping the llama's ass.  Never mind the longevity of said llama! üòÇ\n\nI'm still using v2.8.1 from the space year 2002, because as something that just runs on my PC itself, no network connectivity I didn't ask for, and plays .mp3s right off my local disk... it really whips the llama's ass. Simple, unobtrusive, uncluttered, skinnable to a ludicrous degree so I can make it super tiny and hide in the corner of my monitor. Love it.\n\nNow, granted, I hardly ever actually *use* it, because SoundCloud's meandering recommendation algo is so good I can just set it playing one thing I like and it'll keep playing new stuff hour after hour, *buuuuuuuuuut* when I do feel like diving back into something I know, v2.8.1 is right there.\n\n[deleted]\n\nWinamp shipped with a soundbite that played by default, and the recording is a radio voice promo \"Winamp ‚Äì It really whips the llama's ass!\". Llama being the pun for slang word \"lamer\".\n\nFound the youngin‚Äô. üòÇ\n\n[deleted]\n\nhttps://m.youtube.com/watch?v=oQid2jSU7Ww&amp;pp=ygUMV2luYW1wIHNvdW5k\n\nThis is what it was, lol.\n\nno idea, foobar2000 is so much better\n\nunfortunately, foobar2000 is also non open source, and doesn't have proper linux alternatives, which discourages me from switch to linux\n\nThere are many other players out there besides that.  This is NOT a real barrier to Linux adoption.\n\nWhen I was switching to Linux more than 20 years ago, there were already better alternatives to WinAmp, lol.\n\n\nLiterally for any taste. From mpd to amarok and such. I don't even know what exists now because it's easier to open a tab with Spotify but certainly there's more and better than 10-20 years ago.\n\n&gt; foobar2000 is also non open source, and doesn't have proper linux alternatives\n\n[wine foobar2000.exe](https://appdb.winehq.org/objectManager.php?sClass=application&amp;iId=1749)\n\n&gt; and doesn't have proper linux alternatives\n\nhttps://www.fooyin.org/\n\nNot proper enough for you?\n\ncan you select and copy them in another tab?\n\ncan you batch rename? batch move files?\n\nCopy/Paste across playlist tabs? Yep.\n\nCopying/Moving/Renaming files was added as part of the File Operations plugin.\n\nIt's faster to search for and enqueue music (if you already have your favorite music downloaded; it's not a music discovery platform...  but Spotify constantly re-uses songs on my Discover Weekly playlist, so maybe they're not much better?), it never needs to update, it never says \"Oops, something went wrong\", it never needs you to log out and log back in. It just works (tm).\n\nI think people are asking because there are now other players that do all of those things, are just as fast, small and stable and offer more features if you want them.  \n  \nBut I do understand that once you find an application that's good enough for your needs, you don't see a reason to change even if it's 20 years old.\n\nNothing I have found is quite as fast and small as Winamp. Using 2.95, with 10,000+ songs loaded in the media library + enqueued, shuffle turned on, actively playing, it uses less than 10 MB RAM. \n\nfoobar2000 is very close -- with a single album loaded and actively playing, it uses ~25-30 MB RAM. Which is still outrageously good!\n\nWacup, a modern fan remake (ish) of Winamp, also with my full library loaded including all FLACs (not that this matters, it's just more metadata loaded is all), uses somewhere in the realm of ~15-30 MB RAM depending on how many plugins are enabled and on-screen at once. The Big Clock window alone uses a few MB. EDIT: Wacup seems to consume more memory as it plays back, I've noticed, up to ~90 MB. But the other two above remain relatively static. Once they've got what they need they don't ask for more.\n\nAll three, when idle, fall down to like ~5 MB RAM. Spotify or Deezer, idle, use at minimum 300 MB RAM. \n\nThese are still great numbers, and all these programs are great in their own way. It's nice to use software that is so snappy and just works. They do the thing you signed up for them to do and nothing else. And once they're installed, your cheese is never going to move.\n\nI mean, I wouldn't have guessed that Winamp is even more compact than foobar2000, which is mostly what I had in mind in my comment. Pretty cool, and makes me wonder what they were thinking when releasing Winamp 3, lol.  \n  \nI too have a deep dislike towards software as a service that ideally uses humongous slow Electron apps.\n\nThe 2.9x media library doesn't collect as much metadata as newer versions did plus the OS can swap things out so its always a bit tricky imho to know what's really allocated or what's pulled in from things that aren't even part of the coded program (i.e. dlls injected into the running process).  \n  \nFor wacup it's collecting a lot more metadata if the files provide it which'll sit in memory &amp; is an aspect I know needs to be improved especially when some of my test local library db instances with around 750k items can easily get up to 1.5GB of allocated process memory.  \n  \nThere's also what plug-ins, the skin including it's size (higher res images will use more memory), how large the local library &amp; playback history dbs are, if you've got albumart being shown, what media library view amongst other things which the OS can end up keeping loaded instead of the reported numbers dropping unlike other players &amp; is again something I've got on my todo list to try to improve where I can as after a point imho RAM not being used is a waste though I also don't intentionally go around wasting it as that irks me too.\n\nI'm not sure about the big clock comment since it's basically a known sized in-memory bitmap that's being updated &amp; I'm not aware of that having a resource / memory leak. As all of the skin elements have to be in-memory to be able to displayed which is why the size / scaling can have a memory impact which the likes of fb2k don't have to contend with since they're not providing a skinned ui.\n\n-dro\n\nv2.91 does everything I need it to, and nothing I don't. One of my first installs on any new machine.\n\nI'm going to boot up my windows 95 PC and let all my friends on AOL instant messenger know about this right away! I hope GitHub supports Netscape Navigator.\n\nI can understand why the WinAmp team would be so protective of their codebase though, it's the only way to play music files that I know of until someone invents music streaming!\n\n&gt; I'm going to boot up my windows 95 PC and let all my friends on AOL instant messenger know about this right away!\n\nFunnily enough there's [someone](https://forums.nesdev.org/viewtopic.php?t=25441) developing an MP3 player right now (in x86 ASM) that seems to run on Windows 95.\n\nMy favorite mp3 player for Windows 3.11 and Windows 95 is [Winplay 3](http://www.gaby.de/win3x/esoft.htm).\n\nI forked it\n\nlink please\n\nSo not so much \"Open Source\" as it is [\"Source Available\"](https://en.wikipedia.org/wiki/Source-available_software), or at least something very close to it.\n\nWinamp is still a thing?\n\n[Better?](https://github.com/WinampDesktop/winamp/commit/64a51755c6f5d85039463c8bf7c2a9e98e862586)\n\n&gt; - No Distribution of Modified Versions: You may not distribute modified versions of the software, whether in source or binary form.\n  \nThis still prevents you from doing anything. You can't do a PR without pushing your changes to your fork, and doing so breaks this clause as you are in fact distributing modified source code.  \n  \nThey need to use a proper license, not this joke.\n\nwinamp still exists !?!\n\nIs Winamp still a thing? Or has it been regularly refactored over the years to not be written in 1995-style C++?\n\nThey could have at least credited the people that work on that and got them there, but nooooo.. Jef has the skills of a dude that discovered git 5min before the publishing\n\nWell that certainly doesn't \"whip the llamas ass\".\n\nI call it \"Shared Source\".\n\n&gt; [...] open sources [...] under license preventing forking and source/binary distribution\n\nNo\n\nIt isn't open source tbh\n\n&gt; 5. Restrictions.\n&gt;\n&gt; * No Distribution of Modified Versions: You may not distribute modified versions of the software, whether in source or binary form.\n&gt; * No Forking: You may not create, maintain, or distribute a forked version of the software.\n&gt; * Official Distribution: Only the maintainers of the official repository are allowed to distribute the software and its modifications.\n\nI suppose the devil is in the precise definitions of each of the words in these terms, but this could even be considered to prevent collaboration. Doesn't `git clone` create a kind of fork of the repository? And aren't the changes I may make to the code in it a kind of maintenance? And the eventual pull request I may submit back to them a kind of distribution?\n\nThe forking stuff was nixed it looks like \nhttps://github.com/WinampDesktop/winamp/commit/64a51755c6f5d85039463c8bf7c2a9e98e862586\n\nDo we care anymore though?  Even if they become legitimate FOSS, I can't help but think we have much better alternatives now that are already there.\n\nIn a world of great OSS like VLC exists why should anyone care about winamp open sourcing their code (with a terrible license no less) outside of some historic curiosity?\n\nReading their algorithms?\n\nUse Audacious. It can look like winamp and use winamp skins\n\nWinamp still does playlists better than vlc. I don't know why it's so hard to just have vlc play a collection of folders but they made it complex and opaque for a casual user\n\nWhy not just use https://github.com/captbaritone/webamp instead? I mean it is very similar to how winamp used to be - and nobody has to bother with (unreasonable) restrictions on the source code (it is MIT licence).\n\nCan I fork for private use?\n\nWhats the point of open code that cant be forked?\n\nWait, Winamp is still around?‚Ä¶ I‚Äôm not here to hate on them, but you would think after decades they would port things to other platforms. Guess all I can say is, that‚Äôs interesting, but I don‚Äôt get the purpose.\n\nTo me AIMP is already the modern day WINAMP.  \nToo bad not many people know about it.\n\nThe title is incorrect: the code wasn't open sourced, it was merely published.\n\nI don't understand, I thought they released their source code back in 2020. Hell I think I might still have it somewhere.\n\nIs it legal to fork it and change the readme file?\n\nThis repository is now owned by russian bots. I almost got cancer looking at the issue page.\n\nThis is not open source. The word is being abused by companies to get free labor. Same with llama, the people in media that claim llama is open source should be sued. \n\nOnce llama is stable we all know that Facebook will charge exorbitant amounts for its use and people who build lives around it will get screwed.\n\ntoo late, Winalpaca coming right up!"
  },
  {
    "title": "How YouTube Was Able to Support 2.49 Billion Users With MySQL",
    "body": "",
    "score": 1240,
    "url": "",
    "created_utc": 1717157252.0,
    "author": "sdxyz42",
    "permalink": "/r/programming/comments/1d4u12d/how_youtube_was_able_to_support_249_billion_users/",
    "all_comment_text": "TLDR: they sharded their database and put their own thing in front of it to manage sharding\n\nI need nosql because it's web scale and can handle my 20 users\n\nWoah woah, I think you put one too many zeroes there, cowboy\n\n(It's just me and my mom)\n\nIt is what it is, once your website grows to 10s of people you can replace your entire stack with NextJS, serverless for edging,¬†pay hundreds for cloud managed mongo, break apart the backend into microservices and spin them up on AWS lambos, make sure you have a DB for each microservice, otherwise it's an anti pattern. slap on an API gateway to take requests from your new shiny NextJS app and pass them on to your microservices. Add service discovery and load balancers, and thousands of dollars per month later you can rest easy knowing that you're ready to scale up to 10s, dare I say 100s of users\n\n&gt; serverless for edging\n\noh god it can do that?\n\n[deleted]\n\nEven from a cold start, this service sure runs hot!\n\ni love this thread\n\nPersonally I prefer to use a wand for my edging.\n\nBy which point you've laid off your entire devops and dev team and hire a consultant to examine a business requirement change, he would like you to write v2 of your application which his company can do for you for $2.4 million, just as soon as you've got your second round of investor funding in.\n\nBut don't worry, that's capex not opex so investors know it's a healthy looking company.\n\nThe nice thing is that at the 1000 user threshold, you can go back to hosting the website on a raspberry pi. Until you hit the 10000 threshold, of course.\n\n1000 users? Okay there big shot.\n\n\nBut seriously, why would you pay $100+ for a Pi (hard to find cheap ones these days) when you can lock yourself to a vendor using their free tier? Sure, you'll pay out the wazoo the moment you need to do anything beyond the free tier, and the vendor now has you by the jewels but that's what VC money is for.\n\nIf you don't have an rpi, you can always just use your smart fridge. Of course, first, you need to do some reverse engineering, but in the end, you get a VPS with a serious cooling array. I think that's what they mean when they say on-prem?\n\nNo, that's edge computing.\n\nThat would be using your neighbours Ring doorbell\n\nIncludes free bandwidth\n\nOr you just slap [this bad boy](https://www.raspberrypi.com/products/active-cooler/) onto your raspberry Pi and go all the way to 50k.\n\n\"But it saves us money because we don't need to know how to run ops!\"\n\nAWS lambos?\n\nVroom vroom!\n\nresponse times in the thousands of milliseconds. blazing.\n\nso i can buy my Lamborghini from AWS ?\n\nJeff Bezos can buy his Lambo with your money\n\nThis is the way!\n\nYou seem salty lmao\n\nmake sure to put cloudflare in front of it, as the caching should help reduce your bandwidth use from 9Mb a week to 4Mb a week.\n\n\\#powerusers\n\nI think it'll be only days before you'll be reached out to by their sales team for an enterprise plan.\n\nOr else.\n\nThanks for reminding me of this [classic](https://www.youtube.com/watch?v=b2F-DItXtZs).\n\nFirst time I saw that I was at work 10+ years ago and bursting out laughing. I think about parts of that so often when I encounter cargo-culting.\n\nIt's so amazing how applicable that still is today. I self-taught myself a lot of command line tooling and sysadmin  along with setting up various tech stacks,  which was definitely not part of my computer science degree and sometimes I feel like so many people don't have a clue about the fundamentals of things but they can sure put a bunch of things together that I can't do. But I'm glad I spent time on the fundamentals because if you know the fundamentals you can understand why particular technology exists to begin with and what problems it can solve.\n\nUnderstanding what problem you‚Äôre trying to solve is such a hugely important step that so many people blow right past, thinking they‚Äôve already identified the solution. \nI‚Äôm a big fan of the Five Whys. Keep asking why until you‚Äôve got the big picture. \nIf you don‚Äôt have this big picture, you‚Äôre probably implementing the wrong solution and wasting time. \n\nA somewhat recent example is someone coming to me and saying we need to start using Elasticsearch. Oh do we? Uh, why? Once they explained what they were actually after, no, that‚Äôs the completely wrong solution in every way and the right solution is a reporting system and also some simple SQL queries‚Ä¶\n\nI need nosql because I can‚Äôt understand object modeling and I want to store everything in my single Persistence pojo. We are not the same.\n\nBut it sounded soo cool when that person from &lt;big company&gt; described it.\n\n\\* fails FAANG interview *\n\ncries in *leetcode*\n\nObligatory: https://www.youtube.com/watch?v=b2F-DItXtZs\n\nI mean üò≠‚Ä¶ I would have been impressed if it was only one DB instance running on a Raspberry Pi.\n\nI had Timescale (postgres time series plugin) ingesting a thousand row a second (in 24 row batches) on an industrial equivalent of Pi 3, and it didn't even break a sweat. Iirc it was something like half a core for the whole thing.\n\nDisk speed would have been a bottleneck, no?  I would assume CPU wouldn't need much for ingesting simple inserts.\n\nGiven that it‚Äôs inserts plus at least some amount of index updates, there‚Äôs still *some* CPU work.\n\nIirc, it was 15 ms per batch using eMMC, and that dropped to 5 ms per batch when we added an USB SSD.\n\nAnd well, timestamp and sensor ID as  composite PK, a multi column FK, and some constraints.\n\nTimestamps as a PK? \n\nLog entries? I'm trying to think where you'd do that. How much precision do you need there to make sure they're unique?\n\nIt's a pretty specialized system so I need to be thin on some details. I misremembered. It was timestamp + sensor ID. Each sensor only sends once per cycle, there's no more than thirty sensors, and we're guaranteed a cycle takes at least 20 ms. The ingress process batches the data for each cycle since it simplifies downstream processing. For the same reason the whole batch had the same timestamp iirc.\n\nOne of the things Timescale does is partitioning by timestamp, and it's done in a way that is invisible to your queries.\n\nOh man, I‚Äôm spoiled with PI Historian. It is a tag based system where the tag is the PK. Timestamp as PK is hard to wrap my head around since we have hundreds of thousands of tags and trending and analytics at similar time ranges is how we find data patterns.\n\nConsumer time series database like these are free to use¬†-\nGraphite\nInfluxDB\nPrometheus\n\nTimescale has one of those almost FOSS source available licenses. TLDR: it's FOSS, but you can't use it for a competing offering. As we're doing it locally (working without internet access is a hard requirement for the system), and provide analytics and other stuff on top, it's perfectly fine for us.\n\nThe big thing for us was that it's a PostgreSQL plugin. We're a small team, and using a single database for everything is a major boon. Plus, well, data integrity - you can't insert a data point without referencing an existing sensor. And we have stuff like sensor calibration data in that DB.\n\nIt's a low volume high margin application which doesn't fit into a typical pricing model because we'd need hundreds of small licenses for every product we deploy.\n\nAnother thing is that, well, it's relational. Every type of data point goes into a separate table. Sensor ID? Yup, a column. I don't think there is a need for tags. But I'm responsible for data ingress and system integration, not for analytics, so I might be wrong.\n\nWe use timescale as well, roughly 85 billion rows in our primary time series hyper table. I think we ingest around 300 rows a second based on the size of the partitions I see. Partitioned on timestamp, uses timestamp + 2 text columns as PK, and has a data and metadata jsonb column in addition to those. We're ingesting arbitrary iot sensor data, hence the jsonb columns.\n\n[deleted]\n\n&gt; I‚Äôm spoiled with PI Historian\n\nYou gotta be the first person ive seen whose happy with that\n\nWith PI? Been working on that system for over 13 years. Utilities and O&amp;G for me.¬†\n\nAre people not happy with PI? Not like there are a ton of options with interfaces, visualization, historian, analytical tools,‚Ä¶ for those industries.\n\nIf they're doing timescale then it's probably time series data and is probably inherently unique\n\nNah, I misremembered. It was a composite key. See [other comment](https://www.reddit.com/r/programming/s/vd9OqmDydE) for details.\n\nRight, that makes a lot more sense, thanks\n\nAgree. that is also how you can \"resurrect old laptop by simply replacing the hdd with an ssd.\n\n1000 rows of 64kB (which would be pretty fucking phat) is only 65MB/s. That's like half the transfer rate for average spinning rust, let alone anything SSD.\n\nProbably but time-series typically implies append-only, so you should be theoretically operating at the maximum write efficiency.\n\nI have ClickHouse running on a local ubuntu server with AMD 2400g, 8gb ram and 512GB HDD and it can insert upwards of 20M rows per second (5 columns per row) with a batch size of 2M. For indexing, it's by device id and timestamp.\n\nHaha\n\nI've worked at some of the biggest tech companies. One used a lot of NoSQL, one used SQL. In both cases, the way they scaled was sharding.\n\nIt's genuinely funny how sharding solves like 60% of the scaling problems, while introducing an issue about how to manage shard routing.\n\n\"man this load is too much for this one database\"\n\n\"Well... What if we just had like... *A bunch* of them\"\n\n\"God dammit Jenkins, you're a genius!!\"\n\n‚ÄúIn honor of your great idea, I‚Äôm naming our CI tool after you.‚Äù\n\nGreat timing too, Jenkins. Hudson got fired and our CI tool was left nameless.\n\nJust sidecar cache.\n\nWhat do you mean 'data sanitization'?\n\nCache expiration?\n\nOrder sensitive packet delivery across sharded databases?\n\nWhose Idea was this...\n\nDamn it almost like time and space complexity ceases to be a problem if you put an upper bound on space\n\nI sharded once. Nobody wrote an article explaining how or why I did it. Mostly people just said it was gross.\n\nThe software I specialize in did this back in 1993.  ;)\n\nThis is how every technical architecture explanation should be done. To the fucking point lol.\n\nSometimes while working on databases I drink too much coffee and shard.\n\nI sharded my pants\n\nThanks.\n\nThis article was.\n\nDifficult to read.\n\nSite is spammy as hell. I haven‚Äôt visited a site as annoying as that one in a while\n\nThanks for the tldr.     \nThese link posts are annoying.\n\nYeah but written with 200 buzzwords\n\nTLDR: they sharded\n\nImpossible.\n\n\nI've been told by VERY SERIOIS PEOPLE that SQL can't scale past a dozen users!\n\ntypically the same people that go \"what?\" when you ask when they last checked their execution plans.\n\nNow see, I know vaguely what an execution plan is.\n\nYou kill the process when it's taking too long and spin up a new process and it'll go faster cos it doesn't want to be executed.\n\nYou have to strike fear into the processes so that they run faster.\n\nYou gather all the processes to one place and randomly kill one, while making the rest watch.\n\nThey'll be so scared that they'll even bring their own resources and let your CPU and RAM rest.\n\nExecution by decimation\n\nDon't make me negative nice you!\n\nWe got tired of manually executing the programs, so we set up an auto-executioner that only lets tasks run for 300 seconds. If it tries to go longer, it kills it and automatically restarts it. That keeps the processes plenty busy like little worker bees. We expect the 2023 Q4 reports to be finished any day now.\n\nI see you are also an expert at resolving memory leaks.\n\nAges ago I had a customer that administered some custom software we wrote for her company.  I was talking to her once and she casually mentioned that she had to come in late on Thursday because it was time for the monthly reboot.  I was like, ‚Äúsay that again?‚Äù and she repeated it.  I asked her if I could login to her system and we had a process that was leaking memory with every request.  About 20 minutes of code inspection plus build, transfer and install time, she no longer had to do prophylactic reboots.  Amusingly, she‚Äôd just been sucking it up for almost two years and her employer (a big insurance company) paid about $10k/month for support.\n\nThat's why I have a batch file that opens a process and kills it a hundred times before the 101th iteration actually keeps running.\n\nYou jest. But I was roped in as a consultant on a performance optimisation project where the application was taking several minutes to fetch records IN DEV. Production was literally unusable and the business was basically just idling. Meanwhile, their chief architect was pitching to rewrite everything in MongoDB(?) or something similar because they obviously had a web scale problem with their zero customers.\n\nI discovered the bottleneck not twenty minutes into running the dev environment - no indexes on any tables in their database. Not even primary keys. Apparently, they were taking too much space. So their db madman deleted them.\n\nThe problem with SQL is that if you aren‚Äôt very careful with the architecture of your system you can end up with huge problems unless you have people specialising in SQL optimisation who understand execution plans. It‚Äôs not a skill a lot of engineers are interested in working with so you get a ton of startups that have sql on the backend and end up in a real mess when they start to scale up the amount of data flowing through the system. Having gotten very, very familiar with MSSQL earlier in my career I‚Äôm all too aware of the cost of doing SQL correctly both in terms of the sorts of roles you need and the way that it can hamper teams that rely on those roles to help them do it correctly to ensure you don‚Äôt end up with huge problems in production.\n\nmaybe true, but it is not that hard and MSSQL environment is probably easier. \n\nLook into worst offender , fix them, repeat until everything looks better.\n\nReally depends on your database. Ours was created before my time at the company (the one I really cut my teeth on) and had tables that were used by multiple services for reads _and_ writes including reporting and was processing a non trivial number of calls a second. As a result there were a large number of poorly written indexes (it was also quite a while ago so the indexes were not as fully featured as they can be now), oh and it required transactions for the writes.\n\nA ton of contention, indexes being scanned, hardly any normalisation, and a ton of jobs to keep it chugging along meant it took a _lot_ of work to ensure it didn‚Äôt fall down and so much more to build a better working system (which ended up being a mix of NoSQL and MSSQL with the MSSQL being used purely for reporting and dashboards). Now I‚Äôm aware that this isn‚Äôt what all databases are going to look like but I think it‚Äôs a very easy trap to fall into as a startup where you‚Äôre just throwing things together without a care - I think more engineers have a mid-level understanding of NoSQL issues whereas a lot of the engineers who come onto SQL projects just know indexes are a thing and you use them to make queries faster without any consideration of the messes you can get into or how to resolve them (it would be about 7 years ago since I was last involved in hiring for engineers with SQL experience so I expect it‚Äôs only gotten worse).\n\nmaybe i should have put that : it is not hard to get started. I have experience on same kind of MSSQL databases which were build over year in startup. \n\nDB stuff is somewhat easy on MSSQL environment as there is SSMS which has several reports in build etc. Of course basic understanding of indexes , stats, query planner etc is good to have. But after that small improvements are quite easy to achieve as so called monkey style can be used for various queries. ( rewrite query , look if it is better, repeat) \n\nBut i do agree that for somereason companies are willing to spends 10k-100k for sql server but SQL specialised dev/dba is too expensive and \"full stacks devs\" develop ORM's\n\nAnd god forbid they have to scale their servers when the DB starts hitting its limits! Yeah I agree with the above, and I got _very_ familiar with SSMS. It‚Äôs weird because I wrote a ton of T-SQL and learned a load of stuff about the inner workings of MSSQL but I manage now and the solutions we work on don‚Äôt go anywhere near traditional SQL (Athena is probably the closest we get). Oh well!\n\nIt's not that simple to start with, and gets slightly harder with scale. Whereas nosql is stupid easy to start, and grows exponentially. It's really really easy to shoot yourself a leg off with MongoDB.\n\nOh sure, agree! I‚Äôve worked with three fairly different NoSQL solutions over the years and they all had their tradeoffs, and particular foibles. I would say that DynamoDB generally has been the least painful to work with but you do still have to be careful. Data storage is never easy!\n\nJokes on you, execution is illegal where I live!\n\nI mean even if you don't shard and don't but some fancy layers in between, vertical scaling nowadays can go very far. a 64-core server with TBs of RAM and a boatload of ssd storage can be had for less than 50k. You need some serious workloads to limit such a setup.\n\nIt's actually cheaper and more reliable to buy a high end IBM P9 than to license Oracle RAC. Bonus points when IBM doesn't try to sue you every couple of years.\n\nThe only price I could find was \"Get a quote\"\n\nYes. When potentially spending hundreds of thousands of dollars, you get the pleasure of talking to a salesman. If it's an Oracle salesman, and you don't buy anything you get a free audit for your trouble.\n\nHow many lawyers get involved? I have to assume one lawyer per $1,000 you didn't spend?\n\nJust for reference, the whole of stackoverflow was running on a single beefy machine for a really long time. They do have a couple machines now for their more diverse services, but the point.. you likely ain‚Äôt serving anywhere close to enough to saturate a single mid-end server machine.\n\nA single instance database is eventually going to run into issues at enterprise scale. Our company upgraded to the largest size oracle could offer and it wasn‚Äôt enough and we aren‚Äôt the size of YouTube (although still  large).\n\nYour fault for choosing oracle. They sell selling you database solutions, not database solutions. Try Postgres, MariaDB, or even SQLite on the biggest server you can buy.\n\nI didn't choose this wtf? You think I'm the CTO of a fortune 100 company or something? Also all of those solutions are going to run into issues eventually at the scale we operate. You're crazy if you think a single instance server can handle our load with 99.9% availability with no downtime during our peaks.\n\nThen just blame your CTO for choosing oracle.\n\nDefine enterprise scale? We support a multi billion row system with a single AG cluster.\n\nYeah complexity of the data model matters as well. If you are using oracle for this i have to assume you are in the financial industry. Or who else would be insane enough to still use oracle and have the money for it? ;)\n\nI would argue if you put caching layer in front it could work again but then you could argue what is more complex or if it's very write heavy that also doesn't help.\n\nDon't tell me ... internet's SENIOR DEVELOPERS? I heard they're upgrading next Paint to run on microservices in cloud cluster (mongoDB obviously, duh)\n\nThey stopped using MySQL in 2018. And it was vitess, which is a lot more than just manually sharding MySQL.\n\nYour comment should be at the top. I‚Äôll give the benefit of the doubt though as it‚Äôs a tl;dr\n\nIt does not [webscale](https://www.youtube.com/watch?v=b2F-DItXtZs)!\n\nits not even webscale\n\nOK man but they built their own separate service on top of it to manage the load, it's not exactly like they edited a couple config files and MySQL was suitable for their needs.  And all that complexity has its own costs, some of which you could avoid paying by giving up some of the guarantees a SQL database gives you and switching to something simpler like a key-value store.\n\nThere are also RDBMS that support easy horizontal scaling. Like CockroachDB, YugaByte, etc.\n\nAnd even document dbs don't scale horizontally without proper design. MongoDB still needs you to set up sharding keys for example. If you didn't do this right when designing your data model, you are still fucked.\n\nBut at the same time.. they are fkin youtube.\n\nYeah, there's no easy solution if you are YouTube, but I find it a little disingenuous how it's being presented.\n\nWithout reading any comments or the article, and having never worked at youtube or google... Let me tell you the answer: Sharding. How do I know? That's the only possible answer. Other things they might pile on top of sharding:\n\n1. Custom kernel extensions to really fine-tune IO.\n2. Custom table implementations\n3. Caching layers\n\nBut ultimately... the only way you scale MySQL to that many users... Sharding.\n\nDude, you shard!\n\nIt's still worth reading... well, *some* writeup, maybe not this one. I kind of hate the guy's one-sentence-per-paragraph writing style...\n\nThe step you missed is [the sharding middleware](https://vitess.io/) -- it routes, rewrites, and filters queries. It's not a necessary component of a system like this, but it's pretty convenient.\n\nI considered mentioning such middleware, but decided against it since any sharding requires ‚Äúmiddleware‚Äù even if it‚Äôs just a simple query router based on sharding key. \n\nBut, yes‚Ä¶ you need *something*\n\nSure, and it doesn't even need to be middleware, could be baked into the app. But I'd love to read an actually-good article about Vitess. Here are some things it does that I found interesting:\n\n* Supports resharding by replicating the entire cluster into a new one with more shards.\n* Supports some pretty efficient connection-pooling at the per-replica level. So your query is routed through some conceptually connectionless layers until it finally lands on a \"tablet\" that then finally pools all incoming requests through some number of local connections to mysqld.\n* Does a ton of [query rewriting](https://vitess.io/docs/19.0/concepts/query-rewriting/), from all the tricky sharding parts (routing or scatter/gathering), to really basic stuff like automatically [adding a `LIMIT` to every query](https://vitess.io/docs/19.0/user-guides/sql/vtexplain/) to avoid someone's unbounded `SELECT *` from tying up a replica by dumping an entire table at once.\n* Can [buffer writes](https://vitess.io/docs/archive/16.0/reference/features/vtgate-buffering/) during a failover -- since a Vitess shard is a ton of small mysql replicas plus one primary, any of those replicas can take over fairly quickly. If you can arrange for that to happen in under ten seconds, *your application might not even notice* -- it'll see queries take a little longer instead of failing outright.\n\nI'm not saying everyone should use it -- I bet the project is getting a ton less development effort now that Google has abandoned it (since YT runs on Spanner now). But there's enough interesting details here beyond just \"they sharded.\"\n\nLow quality article. It's easy to say just shard the data and use some kind of shard index or consistent hash.¬†\n\n\nThe design glosses over how you could scale up or down servers.¬† I would be more interested how they handle adding and removing nodes.¬†\n\n\nWhen adding or removing a node:¬†\n\n\n- Is there a background process that replicates the data and updates the shard inddex server as it goes?¬† How is progress tracked?¬†\n- What happens if a node fails mid scaling? Can it rollback or be canceled?¬†¬†\n- How is the transaction of migrating records between the servers and updating the index server managed while writes are constantly occurring to them?\n\nWhat do you mean by \"node\" here? If you're thinking of a single physical machine, you may be underestimating the scale here. For one, each shard can have an enormous number of read replicas.\n\nYou're right, the article is pretty low-quality. [Here's the middleware Google wrote for this.](https://vitess.io/) You might be interested in the [resharding](https://vitess.io/docs/19.0/user-guides/configuration-advanced/resharding/) process. I didn't find docs on rolling that back, but it seems pretty straightforward -- for example, before switching the application writes over to the new shards, the old shards are still very much active.\n\nBut again, there's no need to worry about an individual *machine* failing, because shards are already replicated, and already do failover within each shard.\n\nWow, I am writing a \"sharding\" memory storage right now, and that's the exact questions I am grappling with! Difficult ones to answer. Do you happen to know some answers ;)?\n\nI use java.util.Random for inconsistent hashing.\n\nThey should switch to NoSQL, as it is made for web scale.\n\nDon't worry, I picked up on the sarcasm\n\nPretty sure you are being downvoted because people are missing the original reference right?\n\nhttps://youtu.be/b2F-DItXtZs?si=NhghRHUhWfHAWLCw\n\nWow, is that 13 years old now? Still funny, still relevant.\n\nIconic\n\nYes, mongodb does not use joins so it is very performant\n\nI hear that they pipe all the data to /dev/null so that they can get those sweet benchmark results.\n\nIt has great benchmarks!\n\nAs a recovering Mongo user, I am finding solace in relationships these days\n\nRandom related story.\n\nMany years ago I attended a conference (ScaleConf), Etsy did a great presentation on how they had tackled sharding to deal with their data scaling issues. Very informative with example code and explanations of their decisions. It was actually the most ‚Äúcomplete‚Äù presentation I‚Äôd seen on the subject, you could take what she had presented and put it into practice yourself.\n\nNow, this presentation was done during the MEGA hype period of MongoDB as ‚Äúthe silver bullet‚Äù to this problem. One of the most disappointing things I‚Äôve seen in my career was the, not just lukewarm reception to this presentation, but audible disapproval by many of the attendees, ‚Äúshould have just used Mongo‚Äù.\n\n&gt; This means application logic should find what shards to query.\n&gt; And that increases the chance of downtime.\n\nEr. Why?\n\nIf your logic says to query a specific server then if that server is down you're going to get errors even if other servers are up.\n\nThe solution is to understand the full state of your DB pool, but doing that in your application itself is a bad idea so they built these additional pieces.\n\nFWIW, this is outdated. They are fully on Spanner now\n\nIt's not outdated, the article doesn't say they're using this today. Its clearly talking in past tense. Nothing is outdated by the statement \"YouTube **Was** Able to Support 2.49 Billion Users With MySQL\"\n\n[deleted]\n\nThey switched off vitess +¬†MySQL in 2019, not 2006. Vitess came out of Google. In 2019¬†they had 2 billion users. Today they have 2.7 billion. I don't think anyone reading this article has this scale problem, vitess will work just fine for them\n\nNot necessarily. Different applications have different performance requirements. Vitess' emphasis on [many small shards, each with many read replicas](https://vitess.io/docs/19.0/overview/scalability-philosophy/) may be too expensive for a startup, and then, by the time that startup grows to where it needs to shard, it may have gotten to used to just making the machine bigger.\n\nA startup won't even have the scale requirements to require Vitess. MySQL on its own can handle a high volume of transactions per second on moderate hardware, but they can rest easy knowing if they need to scale by sharding, Vitess is a great solution.¬† Also Google simply switched from MySQL + Vitess to their own custom RDBMS in Spanner\n\n[deleted]\n\n[deleted]\n\n[deleted]\n\n[deleted]\n\n[deleted]\n\nbruh are we in fucking kindergarten lmao\n\nno, youtube has 2.49 daily active monkeys\n\nIt‚Äôs a shame the public product names Spammer available in GCP is absolutely nothing like the internal product with the same name. I would love to use an SQL database that scales like a NoSQL database.\n\nOut of curiosity, what do you think is the difference between Cloud Spanner and the internal one?\n\nReal spanner can replicate different rows to different sets of regions. All data in fake spanner is replicated everywhere. Real spanner can choose write masters on different continents, fake spanner always uses a single region as the write master for all writes. \n\nFake spanner can scale to large data sizes but is close to useless for scaling across locations. Real spanner does both.\n\nThat and a bunch of other smaller features that end up being really nice, things like Spanner Queues (think transactionally write down data AND enqueue a pub sub message), protobuf columns, and GCP spanner is just insanely expensive.\n\nThanks for the insights. I'm not an ex-Googler, I just have some co-workers who are, so I've never used real Spanner myself. But yeah, Cloud Spanner is basically useless for me, because (as you said) it is too expensive, and the P99 latency is unacceptably high. My employer uses Bigtable for hundreds of services where an actually good Spanner would be a better choice, and we're implementing the parts of Spanner we need the most ourselves on top of Bigtable. I was really looking forward to using Spanner when we moved to the cloud, but the Real Cloud Spanner was such a letdown.\n\nMySQL has a distributed engine that has been in it forever and scales lile crazy, I'd you give it hardware. MySQL NDB Cluster. I got a chance to work with it for 2 years... people have no idea how badass that thing is.\n\nI saw the title and assumed almost immediately that Google would build their own thing.\n\nNot because MySQL is bad (I don't know anything about databases other then some really basic SQL), but because Google is a company that is constantly building it's own tooling to meet it's own needs.\n\nAnd it's the best way to try and fully prevent known backdoors in your software when you're a company that's on that level.\n\nI'm talking things like government-known exploits.\n\nWhich is basically PostgreSQL with global-regional partitioning and indexes.\n\nSpanner is not based on postgres, I would even say it's closer to MySQL.\n\nAh no!   Here this might help.\n\nhttps://cloud.google.com/spanner/docs/whitepapers\n\nChop Suey but YouTube is a table\n\nDoesn't seem too weird.  Good database architecture can go a long way, normalized relational data or adopting a columnar approach, sharding across clusters of servers (maybe in a region specific way for latency) and tying them together with a caching front end for quick reads.  Reporting done on replicas to avoid load on the live servers.\n\n&gt; This case study shows that MySQL can easily handle internet-scale traffic.\n\nuhm no? it shows the exact opposite.\n\nNo database could handle 2.49 billion users without some degree of extra work.\n\nYou can both be correct.\n\nSQLite could manage it, you just have every client have its own little instance embedded within the program/webpage\n\nIt can't. Because you forget that user data is far far more than just login, passow9rd and some settings.\n\nActive platform users have hunderds of megabytes of data associated with them. Times the billi9ns of users, then indexes and other stuff and you get out of capabilities of single server. Or 20.... the data you might be able to fit I to one extremely big storage server, but queries per second... good luck\n\nMySQL once again proving it can scale orders of magnitude more than commonly thought.¬†\n\nThis isn't MySQL anymore.\n\nIt now has a custom query engine a custom caching engine a custom replication engine and a custom storage allocation engine.\n\nIt's not MySQL anymore in any meaningful sense.\n\nWhat this actually proves is that application logic scales better than the DB. Which is largely the point of No SQL in the first place. There comes a scale when your DB is going to basically be a storage bucket and all the bells and whistles just get in the way.\n\nNow in fairness, much better database engines than MySQL would have failed at this task too.\n\n[deleted]\n\nThe whole point of this thing is that YouTube had a problem that MySQL couldn't solve, but they were using MySQL and instead of taking a step back and realising that they had a problem MySQL couldn't solve, they spent millions of dollars replacing every bit of MySQL with something else. It's what led to NoSQL in the first place, systems where relational databases just couldn't work and holding onto all that unused junk just made things slower.\n\nOf course then the rapid MVP people got hold of it and used it as an opportunity to skip schema design and we ended up with thousands of applications that actually did need all that stuff and didn't write a replacement for it, but with MongoDB or Couch or whatever they could get something that looked functional three hours earlier and could get to market slightly faster and then go bankrupt paying off the three hours of debt with thrre thousand hours of trying to make no SQL work properly.\n\n[deleted]\n\nAgain.\n\nIt's not.\n\nIt has a custom query engine, a custom replication engine, a custom index, custom data sharding, custom connection pooling, custom transactions, custom everything.\n\nThis isn't just making DB scaling an ops problem it's rewriting the entire DB.\n\nSort of?\n\nThey are using vitess to shard and scale\nhttps://youtu.be/57al_MMGr-Q\n\nIt's crazy that the population of the entire world was not 2.49 billion a 100 years ago and even computers and internet did not exist. \n\n  \nWe made a new technology and provided accessibility and training for more people than had existed from a 100 years ago. \n\n  \nI wonder what the equivalent of this would be a hundred years from now. A new kind of technology we cannot presently imagine that supports over 8 billion people !\n\nPopulation trends seem to indicate the population in 100 years will be about 11 billion, and the increase rate by then will be nearly 0 or even negative.\n\nhttps://en.wikipedia.org/wiki/Population_growth\n\nBut you're right, in 100 years, technology will certainly be beyond anything we can imagine just like absolutely no one would've predicted most tech we have now.\n\nYeah but apparently 11 billion will be peak population, after that we‚Äôll be declining again: https://ourworldindata.org/population-growth\n\nYes that's what I said :).\n\nOh yes true üòä\n\nSo they stored the videos in MySQL? ü§î\n\nWhy aren't anybody curious about how they were able to install new storage capacity to keep up with the uploads - was it  a week worth of videos every minute or so?\n\ncombination of caching... like redis, im not sure if they are using redis.. and google is rich, they can get a very strong and performance server.\n\n&gt; So they scaled out by adding a cache and preloaded all the events from the MySQL binary log. That means the replication becomes memory-bound and faster.\n\nWhat does this even mean? Preloaded what events where? From the log of which database?\n\n&gt;While YouTube was able to serve 2.49 billion users with the Vitess MySQL combination.\n\n&gt;This case study shows that MySQL can easily handle internet-scale traffic.\n\nYes, but.. but no SQL, is... is better.\n\nAm I the only one thinking this article is mostly AI-generated?"
  },
  {
    "title": "Uber Migrates 1 Trillion Records from DynamoDB to LedgerStore to Save $6 Million Annually",
    "body": "",
    "score": 1235,
    "url": "",
    "created_utc": 1716228206.0,
    "author": "rgancarz",
    "permalink": "/r/programming/comments/1cwm04c/uber_migrates_1_trillion_records_from_dynamodb_to/",
    "all_comment_text": "Based on the quote from the TL I think this was more about it being a verifiably immutable source of truth than cost savings.\n\nExactly, Uber wanted a Ledger, so they would have built LedgerStore regardless. The real choice was between using DynamoDB or their in-house DocStore for index storage: they save $6M yearly by using DocStore.\n\nPlus, they have already used DocStore for other purposes, so part of its cost has been paid off\n\nAlso I tend to think 6 million $ is basically peanuts for Uber.\n\nWhere do you draw the line what's peanuts and what's not?\n\nConsidering uber has 30k employees, lets suppose each costing them $50k yearly, $6M would be less than 0.5% of their payroll annually\n\nMy company has close to 50k employees and 6 million is definitely not peanuts.\n\nMy company has 30k and they waste that each month for cloud overspend resulting from incompetence, let alone their regular bill.\n\n same here\n\non the total IT budget\n\nDoes it say it's verifiably immutable? It says it is verifiably complete and it is immutable. Do these interact in a way I don't understand?\n\nIt's append-only. And it is verifiably complete. But that doesn't mean you can prove it is immutable because if you wanted to rewrite history you could do so. Or does it for some reason I don't understand?\n\nEither way, for a company that plans on keeping their business records in it sounds like a good solution.\n\nGood call, that's an important distinction. I suppose I should amend my statement to say more generally \"It appears to offer immutability and completeness features beyond DDB\".\n\nI worked in compliant storage migrations once upon a time (prior to blockchain) and was always confused/nervous to discover that at some point it's just \"Trust me, bro\" for the in-flight data.\n\nI thought, one would prefer  strongly consistent relational DB to store a financial ledger (or event log) instead of using DynamoDB which is following BASE (Basically Available,Soft state,  Eventually Consistent).\n\nWhy?\n\nEvery medium sized company and above in the real world uses a relational database for their finance systems. Switching to the latest fad is considered to be way too risky for the mediocre benefits they offer.\n\n6m doesn't seem like that much for an organization that size, all things considered\n\nDeath by a thousand papercuts I suppose\n\nThe 6 million could also just be to start with. Over time, it could continue to save them more and more ‚Äì if it really solves their problem and is solid.\n\nThat would be my guess, it's 6 million now, but what would it be in another 3 or 5 years\n\n18 or 30 million\n\nmath checks out\n\nwhat's that like 1 or 2 senior engineers salaries\n\nSenior Engineer Salaries are 3-6 million dollars a year where you live?\n\nInside a van in thr Uber parking lot. Have you seen the price of rent in SF? 3-6 million barely cover a shared bedroom. \n\n/s\n\nMore like 10, over 30k employees of any kind\n\nWhoosh¬†\n\nor cost more and more as they learn the platform and use more of the services\n\nThey could have worked the savings out wrong or ignored a costing so it ends up costing more and saving them nothing, they also might not know the real cost of their current setup.\n\nI have seen projects where they kept the old setup because they missed other functionality it provided so the new solution ended up costing double, 5 years later they still stuck on both. \n\nGetting your costings wrong is very common for IT departments.\n\nI imagine Uber has people in their finance team(s) that verify this stuff.\n\nWell, it depends on much engineering time they spent on it.\n\nIn general, $6 million is considered a substantial optimization in big tech. In mature organizations like Uber, realize that a lot of the low hanging fruit has already been taken.\n\nSo the calculus changes to ‚Äúhow many devs does it cost versus how much will it save us, and what‚Äôs the opportunity cost in terms of feature work‚Äù\n\nAlso, a lot of times it‚Äôs hard to predict savings at scale until you actually do it. I would do some preliminary estimates, but those always have some amount of artificial assumptions baked in.\n\nSome optimizations work really well, and others fall flat, but it‚Äôs difficult to predict in advance so you just kind of have to average them out over a longer period of time.\n\nHonestly, I feel like it was normal for a lot of optimizations to be hardly break even, some I even rolled back. But every now and then I would hit a jackpot that justified my team‚Äôs headcount for another few years.\n\nIn my case, I wasn‚Äôt optimizing naive code. I was optimizing code that was written by really smart people and has been optimized by hundreds of engineers over decades.\n\nIts not that they shouldn't make the move, but that it isn't really news worthy.\n\n#Uber saves $6m of their $40BN budget \n\nIsn't really all that thrilling.\n\nI work for a company larger than Uber, and our tech budget is closer to $4B. Saving $6m would definitely be considered a win though.  We have likely close to 1000 contracts over $1mm, and every bit counts as it's not like the entire company spends X evenly.  Freeing up that budget could let an organization hire an entire team to work on something new.\n\nThe news is probably more about the underlying tech stack being swapped over as opposed to the money saved, which may be of interest to other people considering something similar. Or maybe considering using dynamodb because it's good enough for Uber.\n\nI‚Äôd consider it a notable savings. It‚Äôs probably around the cost of 2 teams of software developers. So you could take that savings and use it to build a major new feature.\n\nEdit: math is probably closer to 2 teams than 1\n\nSometimes its about sending a message to the provider that you are willing to move a shit ton of records over 6 million dollars.\n\nNa usually that goes straight into upper management bonuses.\n\nLedgerStore seems to be something that Uber developed internally, and hosting/maintaining/developing software costs a fair amount of money. So this savings could be an \"all-in\" difference. Considering how risky such a project is and that $6m likely isn't much in the total allocated for this data, it's a pretty good ad for DynamoDB (its pricing isn't that out of whack.)\n\n&gt;  it's a pretty good ad for DynamoDB (its pricing isn't that out of whack.)\n\nI'm not so sure, they save 6M each year by moving 12 weeks of financial transactions into their own DB. It's not some general built database to store all their data, only financial transactions. They only stored 12 weeks worth of data in DynamoDB before moving it to object storage. But to be honest Uber operates on such big scale that it's pretty hard to make any quick conclusions without bringing out a calculator.\n\nThey already built a general purpose \"database\" to store all their data.  So yes it is that, but this group didn't build that for this project, some other group built it for many projects.\n\nThey migrated their financial data onto its backend away from DynamoDB as the backend for that particular service.\n\nThey're saving 0.0006 cents per record.\n\nAt Uber's scale that adds up to serious money, but for most customers where you might have a million rows that's $600 dollars in savings. At a billion rows, which would be a huge dynamodb you'd save six hundred grand, which is probably two to three FTE devs at most.\n\nIf you're not Uber it's likely that building an in house alternative is going to be prohibitively expensive and your savings are going to be substantially lower.\n\nTo me that says that if you need DynamoDB in the first place dynamodb is pretty good value.\n\nOff by two decimal places.  $6 for a million rows, $6000 for a billion rows.\n\nBut that's in DynamoDB's favour, rather than against it.\n\nYou are correct, I translated my cost per record to cents, but forgot to translate my total cost back to dollars.\n\nIt's 600 cents for a million or as you say $6.\n\nWhich makes it even more ridiculous.\n\nA trillion rows is a lot of data. Just an immense amount of data and it's data generated in 12 weeks and then purged so it's not just sitting there it's highly volatile and had a high transaction account.\n\nI've never worked with anything close to that kind of volume.\n\n6m per year is a lot\n\nA million here, 6 million there, sooner or later it starts to add up to real money\n\nTo put it in perspective 20 devs for a year costs 10m. Uber has 2000 engineers apparently...\n\n[removed]\n\nIs it? 500k total comp, including insurance costs, equipment, etc. that's not that much for a major, publically traded, company like Uber. \n\nWho do you think is building a custom data store? The interns? Most likely senior and higher engineers. They probably cost more than I estimated \n\nWhen you are paying someone even 160k a year, you also have to pay for benefits and other expenses. Employees costs more than their immediate salary...\n\nHere's some data to back things up https://www.levels.fyi/companies/uber/salaries/software-engineer\n\nPut another way, they saved 6m, but Ubers reported revenue is 32.7B. So they saved 0.01875%.\n\n[removed]\n\nLooooool\n\nThat's only if its their US team, it could also be their team in the netherlands, where a senior is on about 150k a year for example.\n\nThe thing is it‚Äôs 6 million annually, right now. You would expect your volume to continue to grow and the service to potentially raise prices. Let‚Äôs say by the time your fancy new starts to show its age it‚Äôs been 5 years and your annual savings are now 10M/yr.  That team of X number of devs created ~50M in value for your company by the time the useful lifecycle of their new product was up.  That is a good chunk of change regardless of the size of your company. Adding value greater than your compensation is the whole point of the company paying you lol.\n\nSpread out over 80 billion financial transactions it's less than a hundredth of a cent per transaction.¬†\n\nok but can still fund some more salaries in addition to overhead profit\n\nHey, gives people BS work in politically charged situations. 10 \"consultants\" would bill that much amount in half a year lol.\n\nSome one needs a raise, by cutting cost\n\nI‚Äôve heard theres a fortune 500 spending 1 billion annually on their cloud bill\n\nThe two source articles from uber:\n\n- https://www.uber.com/blog/migrating-from-dynamodb-to-ledgerstore/\n- https://www.uber.com/blog/how-ledgerstore-supports-trillions-of-indexes/\n\nEveryone speculating as to why and all the answers are in these blogs\n\nA lot of the \"speculation\" is really just baselessly casting doubt\n\nBut costed a team of 20 engineers paid 500k a year üòÇ\n\nStatus quo does not give your team promotions\n\nWhich is stupid\n\ndon't worry we'll migrate it back in a year or two\n\nSo a migration that took a full calendar year of those 20 developers cost the company about $20 million?  A 4 year ROI isn't exactly a long time in enterprise calculations.\n\nLess than 2 years ROI\n\n$10 million in salary ~= $20 million in company expense, $6 mil a year saved means 3.33 years is the breakeven, so year 4 is profitable (for 8 months).  You only get less than two years if you ignore the fact that an employee's compensation is only roughly half what a company pays for them, once you factor benefits, facilities, taxes, support staff, perks, etc.\n\n&gt; $10 million in salary ~= $20 million in company expense\n\nEven in the Netherlands where we have high taxes, good benefits etc, an often seen factor from gross pay to company cost is 1.6. This is atleast used by payrolling companies and the like. With a 1.6 factor, you're talking about 16 million, thus 2 years and 4 months before break even.\n\nDoubling it for an american company seems quite generous.\n\nTypical rule of thumb for software is 25% overhead for taxes, benefits, office, etc.\n\nDoes it include the 3-6months when someone joins and basically adds zero value?\n\n&gt; $10 million in salary ~= $20 million in company expense\n\nNot even close. Especially for a small number of highly compensated employees.\n\nProbably more like $13M - highly doubt it will hit $15M.\n\nThis is why tech companies pay in stock, that doesn't vest for a few years.  Allows shifting the expense past where it's returning ROI\n\nYou're assuming the system will maintain itself, which of course it doesn't.¬†\n\n\nThat'll take a team of engineers who understand its¬†internals. Not cheap. Good for job security though.¬†\n\nThe original system would require maintenance as well, so that's not really a cost specific to the transition\n\nThe original system didn't include a home-grown DBMS. That cost is specific to this new system, which in the old system was included in the $6 million.¬†\n\nThey already had this home-grown \"database\" at the same time as the original system.\n\n&gt; The original system would require maintenance as well\n\nIt wouldn't, at least not by their team. Thats the comments point. Dynamodb is a AWS hosted service. Maintenance and continual development costs are baked into it.\n\nThats why these types of 'cost savings' articles are just tongue-in-cheek. They rarely, if ever, actually factor in the real scope of the costs.\n\nThere's no way they're paying 20 engineers $500k/year each.\n\nProbably not far off. \n\nlevels.fyi says that Uber pays:\n\n$165k for a SWE-1\n\n$274k for a SWE-2\n\n$480k for a Senior SWE\n\n$636k for a Staff SWE\n\n$814k for a Senior Staff SWE\n\nSince that's just comp and doesn't factor in additional costs to the company of managing and supporting those employees, depending on the ratio of SWE-1 and SWE-2s to Seniors and above- it very well could average a cost of $500k/anum per employee that organised this migration.\n\nAnd in 4 years some other technology will come in and they will migrate to that to save 6 more millions\n\nIf they keep doing that each year they‚Äôre basically printing money\n\nThey now control the future of their data instead of being under the mercy of Amazon. It's a huge win.\n\nUnder-rated comment. The operational cost isn't the full picture in infrastructure selection\n\nUnfortunately people always forget that when it comes to cloud solutions.\n\nsure, even if the team were all paid 500k a year (which they weren't), that's 10 million in costs.\n\nWhich means that in just two years, you've already paid back the investment.\n\nBuuuuut you can fire them next time you need a boost in stock price!\n\nIt's a 2-3 devops max, in addition to their regular responsibilities\n\nDoesn't seem like they were \"all-in\" on DynamoDB already though, only retaining 12 weeks of data (and all the processes used to move that data for archival).\n\nSo moving it all in-house means less worrying about that at the cost of perhaps some reliability but at their size that should be a non-issue and they have in-house key systems already which would warrant a dedicated operations team... this would just be an extra head count to that existing team to sustain this.\n\nPlus, it's year over year savings; so it's a net positive in the following year.\n\n[https://www.uber.com/blog/how-ledgerstore-supports-trillions-of-indexes/](https://www.uber.com/blog/how-ledgerstore-supports-trillions-of-indexes/) goes into the technical bits of it all though.\n\nThe bigger question is why not QLDB from AWS?\n\n&gt; purpose-built data store named LedgerStore\n\nAnd now they need a team to maintain that system.\n\n&gt; LedgerStore implements eventually consistent indexes by leveraging materialized views from its home-grown Docstore database, a distributed database built on top of MySQL.\n\nOh, gotcha. Couple years ago they migrated from Postgres to Mysql. Then developed something on top of that, it seems. And now another system on top of the other system.\n\n&gt; backfill job running in Apache Spark\n\nYet another system\n\n&gt; The backfill process alone posed significant problems\n\nHow many databases are there now? And how many of them are home-grown, and need dedicated teams to maintain and develop the systems.\n\nSounds like a nightmare.\n\nSounds bad but I can't imagine there is a simple solution to handle trillions of records and Uber's scale\n\nExactly this. Most of the commenters here have no clue what it‚Äôs like when you have Uber scale\n\nExactly! I know cases where there was no more instances available in AWS to scale. Those big techs have problems in a different scale\n\nYet I doubt rolling your own DBMS makes it any easier.¬†So many ways to mess that up. I wouldn't want to be on the team responsible for maintaining it.¬†\n\nAnother group already did that for them.  And they went further than that and they built their own object storage instead of using S3.\n\nSo all this group did is swap back-ends for their service, from DynamoDB, to the internal \"database\" that already existed for them to use.\n\nMaybe, maybe not. One good example of rolling your own DBMS (well sort off) is Vitess. And I‚Äôam happy that at some point some devs at youtube did that. It makes my life easier\n\nAs to ‚Äúwouldn‚Äôt want to be on the team responsible‚Äù sometimes devs forget what they get paid for - that is solving hard problems\n\njudging from a lot of comments here it feels like often times people _think_ their apps are uber scale, maybe their employer organizationally are as big as uber, but their APIs in that little corner of their corporation that handle orders/purchases/patients/kittens probably just store and return a fraction of what uber does, for a fraction of the rate/concurrent users that uber has\n\nThere are out of the box solutions without having to write a custom DB. In Australia smart electricity meters sends out a energy consumption reading every 5 minutes. That is 288 readings a a day, 105k readings a year for a single customer. An energy retailer with 1m customers will have 105b records for 1 year. This is raw KWH, then the retailer processes it for each customer based on the tariff plan the value in cents and displays it on their app aggregated at 30mins interval. All using conventional technology.\n\nAEMO distributes this for all smart meters across Australia and by 2030 all meters will be smart meters. That will be trillion data records per year.\n\nThat's not their use case though.\n\nThe challenge here was massive indexing operations not storage and aggregation.  They need the massive indexing operations to comb through trillions of records with some reasonable read performance.\n\nBecause of the requirement for such extreme indexing of every record, it meant that writes were really slow.  So they took a short-cut and didn't do the full indexing at write time, and were back-filling the indexes with a background job.\n\nThis was conflicting with actual production load spikes, so they were spending tons of time building dynamic scaling into their background jobs which themselves we're already a band-aid to the limitations of the previous technology.\n\nAll while the total data they were storing on the previous solution had to be constantly pared down to keep it running.  Not to mention it was costing them a lot.  \n\nThere aren't off the shelf solutions that support streaming manifest files with unlimited indexing and no write lag.\n\nAdditionally, because these include payment records, they had very strict auditing and logging requirements that you generally wouldn't care about from an IoT stream.\n\nSurely a commercial database like Oracle would also be able to easily cope with maintaining indexes for a lot of data writes.\n\nNo because it was almost certainly semi-structured data they were indexing, not integer primary keys.\n\n&gt; An energy retailer with 1m customers will have 105b records for 1 year.\n\nThat's really not as much data as you think it is. I would be like 420GB without any kind of compression or aggregation. You don't really need any specialized tech for that, you probably could put that much data into SQLite database. Uber is supposedly dealing with at least 4 order of magnitudes of more data compared to that. So your your data is less than 0.01% of what Uber is dealing with, which is peanuts. And the above is only talking about their financial transactions. Supposedly they have over 100PB of analytical data (in 2018) and probably lots of other challenging stuff as well. https://www.uber.com/en-FI/blog/uber-big-data-platform/\n\nAnyway, doing stuff with \"conventional technology\" isn't some kind of achievement. You might not realize it but huge amount of tech is made by these big companies who try to solve their problems at huge scale. If Uber ends up saving money with their own db compared to \"conventional tech\", it's the right choice.\n\n&gt;¬†doing stuff with \"conventional technology\" isn't some kind of achievement.\n\nIt is. These tech companies will justify it because if their unique culture. Super highly paid engineers in USA got to do something. Others will try PostgreSQL.\n\nI worked in the said Energy retailer. Do you know how they processed 100b records, in SAP. The DB was SAP HANA.\n\nThat's only a few columns, and probably easily partitioned into a time series database. The records are most likely written once and can be frozen. These record types are easy to store, and may databases (eg duckdb etc). Exist\n\nThe issues arise when you have 100 to 500B+ records with wide tables, where mutations can occur often and lots of records need to be kept warm.\n\nTime series DB makes sense, but utilities do get amended data feed for up to x days in past, or have missing data points.10 years back in a traditional enterprise it wasn't an available solution. Anyway the backend is SAP and data has to be stored there for billing.\n\n[deleted]\n\nFucking lol\n\nYou have no idea what you're talking about. Find me one example of a single server setup that can meet the requirements of a company as large as Uber.\n\nWhile I sometimes like running things on Postgres, you have no idea how much effort it is to scale the database to such sizes.\n\nRunning in a raspberry pi?\n\nhave you ever worked for an organization of ubers scale?\n\nYes, and a custom database sounds like a maintenance nightmare\n\nNobody comes up with that idea unless something easier isn't working.\n\nglorious nutty rotten encourage hobbies roof insurance gullible oatmeal history\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*\n\nYeah and they should get one if what they built does the things that blog said it does.\n\nJust to be clear what happened here:\n\nUber built not only their own custom \"database\" they also built their own custom object storage solution for it to sit on instead of even using S3.\n\nAnother group, in charge of some payment and financial services, were using a commercial \"database\" that was expensive and limiting.  \n\nSo they switched that commercial backend for in-house backend that was already built.  Certainly, in the planning of building said custom \"database\" they thought through many use cases they had internally for it, with the idea many services would migrate to it eventually. \n\nWhy wasn't a commercial solution sufficient?  Because apparently they had such extreme indexing requirements, that the indexing itself was limiting the write performance.  But without it, the read performance would be destroyed.  So they needed a database that could not only write the data, but write probably many, many, many times that amount of data, in indexing, for every single record.\n\nI think thats a daft conclusion? Someone knew it could be done that way, that doesn't mean it was the best or right way to do it.\n\nHave you ever maintained your own piece of software?\n\nCan do, but it's a lot of work. You want participation from other people, and development driven not only by your own needs. Writing and maintaining a database is really hard work.\n\nSo, no\n\nIn my day job we scale different database products to small and large, both on-premise and in the cloud. Some of our customers scale their databases to large TBs. None of this is easy, every database product has it's quirks and problems. Sometimes analyzing a single problem takes a team member a couple of days, and that's for an existing product. Verifying transactional integrity and scaling up and out is a challenge for every existing vendor out there, no matter if open or closed source.\n\nIf Uber builds their own database they need to spend all the engineering resources for development on top of maintenance and operations. That is a sizable chunk of money.\n\nThe product that handles scanning for brand safety at my job has a single table that is close to 5tb in size for 2 weeks of data. Then there's other tables too each with hundreds of millions of records albeit smaller in size. That's just for one project. We run it on top of percona and still struggle handling the data.\n\nSingle table, around 20 TB here, this customer is also struggling. They are currently redesigning this, because this table holds all the data from the beginning of time.\n\nCan't even partition it.\n\nYeah you basically can't do shit with tables that big I can understand Uber making their own thing if they have the engineering resources to support it.\n\nWhat does scale have to do with anything? Dynamo also scales except you don‚Äôt need to maintain its features.\n\nOrg scale is different than ‚Äúscaling for number of users‚Äù. \n\nSometimes writing your own is the best choice when you have the resources to support it\n\nIt all comes down to operational cost vs. TCO. Sometimes operations wins, sometimes it doesn't. I've seen first hand the trouble building a house of cards on open source stacks can bring. I'd rather take the dependency on a managed service in many cases, but it's never black and white. I'm sure the people who make these decisions at Uber know more about the scenario than you or I do.\n\n&gt; I'm sure the people who make these decisions at Uber know more about the scenario than you or I do.\n\nYes... which is why my original post was a question saying \"has OP every worked at an orginization of ubers scale\". These decisions are not taken lightly, and there is usually a good reason to make them.\n\nHypocritical thought process. So building their backend using Dynamo was taken lightly, but switching off dynamo was not? Orgs change their mind all the time and invest in things that don't always work out. Just because they thought about it for a bit doesn't mean they're omnipotent and can foresee all of the headwind and intangibles that will come with this.\n\nThis is irrelevant. What matters is cost to operate vs cost of the service. Just cause you have money doesn‚Äôt mean you have to burn it. How does that ever make sense?\n\nAll i mean is that orgs of a certain scale have the luxury of weighing these tradeoffs and making a choice. That is why you see places like google, meta, amazon, uber, etc building their own solutions. They have people whos entire job is to analyze these financial decisions \n\nSmaller scale startups don't have this luxury. Even if building your own is cheaper, the 20 person shop is not going to build their own DB\n\nUber is not google or amazon or meta. They have 1/20th of the market cap and a lot less personnel. I work at a tech company larger than uber, but we don't build out home grown infra unless we find that providers aren't capable of providing a reasonable cost effective solution. I'm hesitant to believe a database fits into that criteria given their complexity and that this is *only* saving them $6 million.\n\n6 million annually.\n\nAlso I get it‚Äôs not as big as Amazon or Google or meta. But it‚Äôs still an org of 5k engineers.\n\nEverybody gets a promotion and moves on. Next guy in charge looks at the actual costs instead of projected costs, then: ‚ÄúUber migrates to DynamoDB and lays off Ledgerstore team, saves 10 million dollars‚Äù, gets promoted, then repeat.\n\n&gt; Couple years ago they migrated from Postgres to Mysql.\n\nthey what now?\n\nhttps://www.uber.com/en-DE/blog/postgres-to-mysql-migration/\n\nSpark is just a distributed execution engine and would be used throughout Uber anyway.\n\nCost saving measures rarely save money, they just redistribute who is getting it.\n\nJust complete conjecture lol, yeah every system is definitely already set up optimally.\n\nIt's more that the act of implementing change is usually quite a bit more expensive than people realize, enough so that maintaining the status quo is far more likely to be the cheapest option than people seem to think (even though it might not be the best option for a variety of reasons).\n\n6m a year buys you plenty of developers.\n\nDevelopers, project managers, team leads, internal support staff.\n\nAnd you want the savings, not spend the money in a different way.\n\nThis is a classic problem of when you have team of highly paid engineers every solution looks like a nail. It also justifies the very existence of the huge engineering team.\n\nThat's interesting. I would have simply negotiated a better price for DynamoDB with AWS and split the difference without all the headache. What's the TCO for LedgerStore?\n\nPossibly a case of having tried that, AWS called their bluff.¬†\n\nIt's not just DynamoDB, no? Ledgerstore is replacing both dynamo db and the s3-backed custom db. That means they don't have to have any replication process from dynamo -&gt; s3, nor do they have to pull from two different data stores once the migration is complete.\n\n100% they already maxed out their AWS private pricing deals.\n\nAWS does not care about $6MM, Uber would have zero power in that negotiation.\n\nI wrote about this a few years ago: https://blog.drgriffin.com.au/posts/2020-06-21-the-three-fs-of-cloud-pricing.html\n\nInteresting question about the TCO of LedgerStore. Using a conservative $250k annual cost per engineer, $6MM is equivalent to a team size of 24.\n\nI wonder how much the time spent doing the migration actually cost\n\nWe can save millions if we create an in-house datastore. We can call it Project Kludge. We can also save millions by outsourcing design and development. We can call that Project ~~Mayhem~~ Incompetence. It'll all work beautifully.\n\nUntil it doesn't.\n\nOutsourcing the development of a custom-built datastore... what a brilliant idea!\n\nAre they making profit now?\n\nthe people says $6m is not a lot to a company like uber. think about how many people they could hire and teams they could build with that for developing new features. the reward of additional revenue from that action would amplify the savings. people think too small üôÑ\n\nWish it was open source!\n\nSo, promo project for a bunch of people.\n\nMaybe I do not have all the details but also others have a huge volume of data, why does everyone have his own custom solution?\n\nWell, different data storage strategies have different performance characteristics that may be more or less appropriate for any given workflow.\n\nNot everyone does. Build versus buy leans to build when your company is big enough. Uber is big enough.\n\nAmazon, Google, MS, etc. offer solutions for databasing and long-term databasing (ledgering) for those for whom build versus buy comes down on buy.\n\nThere are lots of performance tradeoffs when it comes to databases.  A general-purpose database will make tradeoffs which apply to most applications. \n\nIf you have an application with trillions of records, you might need to make different tradeoffs, and at that scale, creating your own custom database can be worth the engineering cost.\n\nPlus, they'll probably open source it and/or spin off a company to provide hosting and support for others who want to use it.  Like various other companies have done.\n\nBecause they're the first companies who have the scale that requires these problems to be solved.  So when they went out and looked for commercial solutions for them, either they didn't exist, or they were much too expensive.\n\nHaving gone through this before, I learned my lesson ‚Äî every row in DynamoDB should have a TTL or the storage costs eventually kill you. I LOVE DynamoDB and use it for just about everything I can, but it can get pricey if you aren‚Äôt thinking about your complete data lifecycle.\n\nI work at Amazon and this is a win for Uber for sure.¬†\n\nSeems like they just re-implemented DynamoDB with blockchain for the transactional ordering . . . or did I miss something?\n\nI mean, depending on your data needs, DynamoDB is just a flat file database with indexes. \n\nIt only gets tricky with replication and redundancy -- which is why DynamoDB exists, and is not just berkeleydb or dbase 3, lol. So, unless I'm misunderstanding what they did? They seem to have created their own version of a scalable, performant, replicated flat-file database, just like Amazon did with DynamoDB.\n\nI'm pretty sure any custom database/indexing solution to a custom problem will beat a generic solution in both cost and performance. \n\nIt's literally one of those steps in the lifetime of an application as it goes from proof of concept, to well oiled machine.\n\nOr, am I missing something novel that Uber or LedgerStore did? I am assuming they're leveraging the block chain for transactional consistency, but, I am VERY ignorant of blockchain, so this is likely where I'm not noticing the genius of their move. (or of LedgerStore in general)\n\nI help by not creating any records for them to store. I should start charging for this service.\n\n[deleted]\n\nWhat's i'm absolutely ignorant of, because I've yet to be in a position to make these positions, is what is that sweet spot where AWS or Azure is your best bet? Because if you're too small you might be footing a bill for something you don't need, and if you're too big, you might just need to do what Uber is doing\n\nUnless of course you're acquired by Microsoft and your infrastructure will surely be thrown to ADO\n\nNow THAT'S /r/programming.\n\nThanks for bringing this here."
  },
  {
    "title": "How Discord Reduced Websocket Traffic by 40%",
    "body": "",
    "score": 1237,
    "url": "",
    "created_utc": 1726982826.0,
    "author": "ketralnis",
    "permalink": "/r/programming/comments/1fmlyvg/how_discord_reduced_websocket_traffic_by_40/",
    "all_comment_text": "Good read, also includes the experiments which did not yield the expected improvements. It‚Äòs not always a straight route to the final result\n\nYeah in my experience optimization always has the \"Well I was absolu-fucking-tely certain that this would make it better based on CS theory, but it didn't, it even got a lot worse\" part. You have to benchmarks even the most obvious of things...\n\nI find that with database indexes. Seems obvious. You try it in staging. Shows great results.\n\nPut in production massive performance issues.\n\nIndexes aren't always magical. The DBMS has to maintain them, so INSERT/UPDATE/DELETE queries are more expensive. If queries use them, then the DBMS has to put index pages in memory which increases pressure in the buffer pool.\n\nDo you have some examples? I usually find indexes quite predictable, if the table gets a lot more reads than writes it will have a positive or neutral impact, while if it is mostly writes it will have a neutral to negative impact.\n\nAnd you can usually get a good idea of how much positive impact it will give you from looking at the EXPLAIN results.\n\nI think the problem is a lot of people don't know (well) how indices work.\n\nI've seen too often DBs with (almost) no indices, or indices on (almost) everything. If you than ask what's going on there, and what's the rationale, you hear either \"Indices? What?\", or \"We've heard indices make the DB faster, so we add them everywhere.\" Sad but true.\n\nMy first job: Indices are expensive, use sparingly!\n\nMy current job: We index EVERYTHING.\n\nGood article, shows the complexity in implementing realtime optimisations on a massive live service like Discord.\n\nAlso shows how optimizations that may only save a few CPU cycles here and there can lead to major savings when working at scale!\n\nWhat are you talking about here? The article was about saving network traffic, mostly though compression. The cpu savings were from dealing with massively over allocating memory.\n\nOP is smoking something, or an AI?\n\nI hope either is the case, but I would guess it's more someone just wanting to post and repeating cliches instead of coming up with something relevant.\n\nwell, I suppose  sometimes a smaller memory footprint =&gt; less CPU usage\n\nIs what they did *really* that complex? I mean they basically just swapped to a different compression library and optimized some data payloads in a logical way.\n\nSure the whole dark launch stuff is really important to make sure it goes smoothly but the optimizations themselves were pretty straightforward things I feel like\n\nIf anything it shows how small changes to a system can make a massive improvement in overall performance, and the hard part is actually knowing *what* to do rather than the actual implementation\n\nThere were several places where they didn‚Äôt see expected improvements - e.g. zstandard not having streaming compression. And detecting the root cause takes time and effort. Your observation is right in that if this optimisation were applied to a small hobby project it would probably take a couple of hours max. The fact it took weeks at Discord underscores the complexity of deploying changes on a large scale live system.\n\nIt says that Discord is using Rust for the desktop, which is weird since its an electron app? Maybe they are calling to some Rust code from nodejs?\n\nYes, it's very common practice to use lower level languages to run performance critical stuff within your Electron app.\n\nMakes me wonder what they do in traditional browsers, though. WebAssembly perhaps?\n\nno probably javascript, there‚Äôs no way to compile a complex web app into webassembly AFAIK\n\nBut parts of it can be WebAssembly. It could be they are using rust to build native npm modules also.\n\nUmm blazor?\n\nIt could be rust compiled to wasm.\n\nDoesn't appear to be the case.\n\n&gt; Since zstandard ships as a C library, it was simply a matter of finding bindings in the target language ‚ÄîJava for Android, Objective C for iOS, and Rust for Desktop ‚Äî and hooking them into each client\n\nI can't see any wasm used on the web or Windows desktop versions (didn't try to check the others). Curious how the performance would've compared.\n\nSome info on that in [this blog post](https://discord.com/blog/why-discord-is-switching-from-go-to-rust).\n\nThey were using Go to track the messages read. After a few years they realized Go has a garbage collector so they switched to Rust.\n\nThat article is about the server service fwiw. But yea in the opening it explains that they use it on both server and client.\n\n&gt; After a few years they realized Go has a garbage collector\n\nlmao\n\nA shitty one at that\n\n1password did the same.\n\nElectron is pretty awesome to share front end between platforms; the problem becomes when apps try to use shitty javascript for something crazy complex.\n\nOh wow, literally 2 days ago I listened to a podcast with the author of zstandard - how it started, developed and became an innovation. Now I see it being used at Discord, amazing. If anyone is interested the podcast is Corecursive, episode is ‚ÄúFrom Project Management to Data Compression Innovator‚Äù\n\nCan you link this zstandard episode of the podcast?\n\n&gt; Corecursive, episode is ‚ÄúFrom Project Management to Data Compression Innovator‚Äù\n\nthanks for reading through, here is the link though :D\n\nhttps://corecursive.com/data-compression-yann-collet/\n\nI would be more interested by an article explaining why discord increased memory usage by 400%.\n\nA few years ago me and my friends were amazed by how optimized the client was, especially compared to Slack that was the leader at the time. Now it's full of bloat feature and competes with my browser memory.\n\nMy guess would be offloading more processing and caching to the client, as well as adding more libraries that relate to this. Cheaper to run stuff on the users computer than your own.\n\nDoesn't help they have \"marketplace\" capabilities to customize the client. That's potentially a lot of plumbing to support the features, that's bloat even if you don't use it. It's still doing checks for each place a plugin _could_ hook into. \n\nStarts to add up when every single message bubble has to be checked for more and more \"add-ons\", and the client is ready to perform GPU-accelerated animations at any time, for any number of events.\n\nAlso, with many modern apps in the modern internet, more image/video messages being sent at higher resolutions\n\nThat and Javascript. To do the simplest thing you‚Äôre importing kilobytes of external libraries best case and megabytes worst case. Then the engine optimizations do their magic and eat all your ram to make it run kind of fast.\n\nLooks like you've angered the JS community, friend. \n\nTo put their mental space into video representation, this video is only *partially* joking.\n\n[https://www.youtube.com/watch?v=aWfYxg-Ypm4](https://www.youtube.com/watch?v=aWfYxg-Ypm4)\n\nI guess resource scarcity is in the eye of the beholder.  After all, this blog post outlines the fact that they spend over 600 bytes on their message for ‚Äúthe user is typing‚Äù and are happy to compress it down to less than 200 bytes.  Even if that message contained a UUID for the user, a millisecond timestamp for when they started typing and 4 bytes for a message type identifier they should only need 24 bytes uncompressed. Where did the other half kilobyte of gobbledygook come from?\n\nAlso might need a channel and instance identifier, but your point stands.\n\n&gt; Where did the other half kilobyte of gobbledygook come from?\n\nDiscord sends a Member object with the typing event, which is why it can be a bit big https://discord.com/developers/docs/topics/gateway-events#typing-start\n\nDependencies /s\n\nAs they mention in the article, using zstandard requires more memory, and that could be contributing.\n\nIt's important to note that cloud providers often charge relatively high fees for data egress, so being able to reduce traffic by 40% is crazy good. I'd make a very rough estimate that their egress costs could be as high as $25k a **day**, just to give you a sense of the possible scale of savings here.\n\nUser memory is free (for Discord), so any chance they can push a compression optimizations onto your memory is just free money they would otherwise be leaving on the table.\n\nEgress fees are controversial because they are generally not related to the actual cost of egress that cloud providers pay their ISP; it's an open industry secret that they are effectively pure profit for the cloud provider, a hidden fee that is billed in arrears and takes advantage of the fact that the potentially high costs are missed by clients who focus on the cost of compute instead.\n\nYou can save 95% on your bandwidth costs by not using those companies.\n\n&gt; It's important to note that cloud providers often charge relatively high fees for data egress, so being able to reduce traffic by 40% is crazy good. I'd make a very rough estimate that their egress costs could be as high as $25k a day, just to give you a sense of the possible scale of savings here.\n\nWasn't discord on their own infrastructure? Why would shared infrastructure providers matter?\n\nThey mostly use GCP from my understanding\n\nCloud providers are still normally cheaper than self-hosting at extreme scale. For a service like Discord with such global reach the moment they decide to self host they are now an infrastructure company with a chat product. Its easier just to negotiate a good contract with GCP or Azure.\n\nI honestly doubt that.\n\nI don't.\n\nData Centers ain't cheap and economies of scale are a thing.\n\n\nCan you stick a server in a closer and do it cheaper than cloud? Yeah. But unless you're big enough to run multiple datacenters with hundreds of thousands of servers cloud is pretty competitive.\n\nLotta folks who came into the industry post cloud don't understand what a shit show many \"data centers\" were. Musty basement closets with mold, an old office with a window permanently cracked because they were worried about fumes from the deep cycle marine batteries that acted as a UPS. DR? Whats that? Redundancy? LOL. Backups, I don't know did Bob check them out this week? I mean we can't really check because we only have one X servers so we can't even try a restore.\n\nCloud doesn't prevent people from not setting up redundancies, and backups either. Wow, congratulations, now you don't manage physical infrastructure, and get to blame google or microsoft or amazon if they push an update that kills their RAID cluster, or the virtual vmware deployment gets silently deleted after a year.\n\nNot to mention once you get locked into the provider specific features they get to hike the prices all they want, while giants like discord, slack, reddit, or others would consider it to be just opex to stay in that cloud instead of considering moving as they're just too big or too settled in that provider.\n\nYou are correct cloud does not make it impossible to fuck up.\n\n\n\nIt \"just\" makes it much easier to do it right.\n\n\nYou don't need to build a DR data center and then make sure it all stays running. You push button.\n\n\nSame with backups, redundancy, etc.\n\n\nThere is a huge different between \"let's push the button and get geo redundant backups\" and \"does Joe still take yesterday's tapes to his house?\"\n\nLet alone between \"Lets push button\" and \"Lets go ask the business for a multi-year multi-million dollar project to setup all the infrastructure it takes to do it right\".\n\nTo be fair, joe should still take tape backups on site, even with geo redundant backups.\n\n&gt; I would be more interested by an article explaining why discord increased memory usage by 400%.\n\nSure, but it would be a very short article titled \"Electron\" with a single paragraph \"See title.\"\n\nThe issue with Electron apps have less to do with technicality than mentality. A few years back, Discord was light and fast. There are other apps built with Electron that are relatively light and fast like [Ueli](https://github.com/oliverschwendener/ueli).\n\nIs there an overhead when using Electron compared to a native framework in C++/Rust? Yes. But, is this overhead relevant when talking about the performances downgrade of Discord? I don't believe so. I think there were some looseness from them.\n\nA few years back every update log was filled with performances optimisations and how they were doing that very smart thing to improve performances. Now every update is full of useless talk about a feature built for an Amazon deal or something like that. There was a shift of priorities.\n\nI don't remember a time when discord was lightweight and fast\n\nThen it would be a poor article. Electron is an A-list star in this problem but it doesn't solely explain the rising use of resources over time.\n\nIt tends to do if you actually map it to features/changes in the application. It's not like the same version of the Discord has started using more and more resources, the usage grows as the application grows in size and complexity. \n\nBut the question should be why electron behaves like that rather than discord, since the issue is prevalent in other electron clients like Slack and VS Code (although a lot of extra work has been put in VS Code in the last few years to optimize it).\n\nThe answer is pretty simple. It's *really* easy to make JavaScript absolutely hog memory.\n\nvscode has entered the chat\n\nI think it‚Äôs a mix of the electron problem everyone‚Äôs mentioning here, and that it simply doesn‚Äôt pay for them to optimize the client. Backend optimizations = reduced infrastructure costs. Frontend optimizations = lower user churn. I think it‚Äôs safe to assume that discord is strongly engrained into enough communities that user churn isn‚Äôt an immediate concern.\n\nTypical bloat from electron apps.\n\nIt was an Electron app five years ago as well, what's your point?\n\nWhat about all the features it got in those five years? Even if you don't actively use (or even know of) most of these they are still there and consume resources.\n\nRAM is cheap, I don't mind that much, it still uses &lt;2GB for me at the end of a long day, especially because it's mostly caches. What I DO mind is that switching a channel takes anywhere between 0.1s to 0.5s (measured from mouseup) which cannot be considered interactive.\n\nI can barely use Discord on my Android phone anymore, the performance is so obnoxiously poor. It is slow and unresponsive to the extreme.\n\nThe really infuriating part is that it used to be fine. It would be no problem if I could just downgrade to an earlier version, like I have still on an older phone that runs just fine, before the app suddenly became disgustingly slow maybe a year or two ago.\n\nThat's because it is a browser. It uses [electron](https://en.wikipedia.org/wiki/Electron_(software_framework)) on desktop\n\nIt already used Electron a few years ago. I don't think Electron became worse during that time.\n\nWhat did you use it for? What feature set did your app actually use? How many users/how much activity? It's not about electron becoming worse, electron has _always_ been like this.\n\nAnd it's true for all web component based applications, not just limited to Discord or even electron based apps. \n\nIf you didn't encounter memory or performance issues odds are what you built wasn't very demanding or needed to a lot of concurrency, live updates, caching, media management/playback, plugin system with third party integrations, etc.\n\nYou should spend more time reading the comments you are answering to.\n\nHe has a point, though.\n\nAll you need to do to get it where is was before is remove all the junk channels you've joined, and delete all the old DM chats you don't care about anymore.\n\nWhy would a start typing packet be 636 bytes?\n\nThat also was surprising to me, so I looked into it a bit. I found this in the code of an open-source client: https://github.com/serenity-rs/serenity/blob/current/src/model/event.rs#L730.\n\nBy the way, I don't understand why they use JSON, which is likely one of the main culprits of big payload sizes. I know that browser applications often benefit from JSON compared to other, more space-efficient formats because `JSON.parse()` in JS uses native optimizations under the hood... but Discord is app-first. There must be a good reason, but I can't imagine what it is.\n\nEDIT: Now that I think of it, streaming compression would probably make the space savings of other serialization formats negligible anyway.\n\n&gt; Discord is app-first.\n\nThe desktop application is just an electron shell over the web application. You get the same thing when you open it in a browser instead.\n\nSure, but Electron applications can move as much code as they want out of the Electron runtime and spawn native processes. VS Code does this, for example, for anything performance-sensitive, which is a big part of why it feels so snappy. Perhaps they've decided the complexity is not worth it.\n\n&gt; By the way, I don't understand why they use JSON\n\nJust guessing, but I expect easy cross-version / third-party compatibility and ease of use. It does seem like an expensive choice though.\n\nWhy can‚Äôt I find the field definitions in their code? I spent far too long hunting for the def of ChannelId. Found lots of constructor calls but not the field definitions. \n\nShouldn‚Äôt they be at the top of the definition? Maybe that‚Äôs why their packets are so big. Takes too much energy to track down the size of the structures.\n\nJust double-click on `ChannelId` and GitHub will tell you it's in `src/models/id.rs`.\n\nStill as ignorant as I was before. \n\nhttps://github.com/serenity-rs/serenity/blob/d3665b7f25019b0fbf163c38014fe2cd31935416/src/model/id.rs#L142\n\nAre they all just 64 bit numbers?\n\nThese are, yes. `Member` is not\n\nDiscord ID's are called \"snowflakes\", which are borrowed from Twitter I believe. Largely treated as a u64, but include a timestamp. They're used for server IDs, message ID, user IDs, etc, etc.\n\nTheir internal structure is documented here: https://discord.com/developers/docs/reference#snowflakes\n\nI modelled their typing notification in Protobuf (including a realistic member object) and you can serialise that information to about 80 bytes uncompressed, which is less than a half of the 187 bytes they report for compression with dictionary.\n\nWithout doing an exact like-for-like comparison and/or an experiment you can‚Äôt say for sure, but I would be surprised if more efficient serialisation turned out to be negligible.\n\nGood read. A window into problems I don't see in my day to day working on an internal only app\n\ntl;dr; swapped out zlib for zstandard and then extended zstandard to use a \"compressor cache\" like zlib and then optimized it further with dictionaries for small messages\n\nnow that they have introduced the other great complexity of compsci at least they have a great name for it - message compression\n\nPretty sure that tldr is inaccurate. They didn‚Äôt use dictionaries in the end, and also didn‚Äôt extend zstandard other than extending the bindings to support streaming compression.\n\n&gt; didn‚Äôt extend zstandard other than extending the bindings\n\nk\n\nthe distinction escapes me but whatevs \n\n&gt; They didn‚Äôt use dictionaries in the end \n\nthis is I missed\n\nthey sure talked about it a lot only to say 'we did not use this'... i mean - okay. then why bring it up? im pretty sure you also didn't use blockchains so why not ramble on about those for a few paragraphs and then end it with 'nevermind we didn't use this'\n\nSince they were explaining their process, they shared the insight that using dictionaries didn‚Äôt work for them. If they had tried blockchain, they would have mentioned it.\n\nAs to the first point, the main distinction is that they just updated the Erlang bindings. A language binding for a library is just a wrapper for the library that allows it to be used in various different programming languages. For reference, the specific binding they updated (ezstd), is around 1000 lines in total. The main library (zstandard) is almost 200k lines.\n\n&gt; the compression time per byte of data is significantly lower for zstandard streaming than zlib, with zlib taking around 100 microseconds per byte and zstandard taking 45 microseconds.\n\nAm I reading this wrong? They went from 10kb/s to 22kb/s?\n\nZstd lists compression speed of 500mb/s on the website, surely there must be a multiple orders of magnitude mistake there\n\ntheir payload is tiny, I suppose \"launch\" of message compressing eating most time here\n\nAfter testing the actual library, it takes 1.91 microseconds for 1024 bytes, it only crosses a millisecond threshold when payload is more than 6 megabytes. There is no ‚Äúlaunch time‚Äù. They are doing something seriously wrong or measuring something else or using incorrect units.\n\nThis is still not ‚Äúrealtime‚Äù, a 660 byte payload taking 30ms in compression is not good in any situation and their messages are much bigger.\n\nthey posted MICRO seconds, so 1000 times faster\n\n45 microseconds * 660 does equal 30 (well, 29.7) milliseconds.\n\nIf only the people who worked on this optimization worked on the Android app.  Seriously, on my Pixel 8 Pro lags... Discord is a chat client.\n\n&gt;my Pixel 8 Pro lags... Discord is a chat client.\n\nSeriously, the WHOLE reason I chose a pixel 8 pro is because it had 12 gigs of RAM when everything else had the commonly-standard-but-nowhere-near-enough 8 gigs.\n\nThis sloppy agile methodology, zero optimization, everything-is-javascript app development stance has to change.\n\nUnlike on the PC, we can only throw as much hardware at the bloat problem as the phone manufacturers make available.\n\nI don't even bother with discord on my phone anymore. If I want to chat, I'll fire up almost anything else (telegram, veilidchat, hell, termux + irssi for IRC) but I sure as hell will not launch discord because it's not even installed anymore. :(\n\nI had no idea compression was that slow. 45 - 100us per byte is crazy slow compared to encryption.\n\nHave they maybe tried not to send all fucking servers with channels and subscribing to all servers on start?\n\nData ingest is free (literally in AWS) but compute isn‚Äôt. Why trade an expensive resource for a free one? No player wants discord using more CPU, either.\n\ndelivering the worst possible shit Blazingly Fast\n\ngood to see zstd getting more love\n\nBut why are they not regularly refreshing tokens so that token theft has less damage? Or better yet, why aren‚Äôt they preventing it entirely by making the token a httpOnly cookie? It‚Äôs only used on the discord domain, so it should be fine.\n\nWhy and how is it after all this time, they allow their user base to be susceptible to token theft without a minimised attack window? Crazy that a platform as big as Discord has shit ass security for its users.\n\nWhy the hell do they still not have a way to distinguish a bot token from a user token and just prevent a user token from working  with bot APIs and vice versa.\n\nI don't like Discord. Now the reason may be a bit strange, but from how I observed things, Discord was (is) very successful - and is also heavily responsible for the decline of phpBB webforums (if there is a plural for that word). I am not saying Discord is the primary reason for that; the primary reason is probably people changing their web-related habits, the rise of smartphones changing communication and what not. But still, at the end of the day, I noticed how people kind of expect things such as Discord, and for that Discord is partially to be blamed for the decline of alternatives. (Of course phpbb also had more competition, e. g. Discourse web-software. But I am noticing a decline of communication in general here, for both those who replaced phpbb with Discourse, but also older projects that kept on using phpBB without Discorse, where suddenly people only communicate on Discord and no longer on phpbb. ANother reason I dislike Discord is that the communication goes on in private, Discord own channels, whereas older phpbb forum communication was largely open, at the least more open than Discord, so now communication in a game, for instance, is suddenly private, when before it was public - that also annoyed me. So I am not too overly happy with Discord, even though I of course understand that it is very popular among folks.)\n\nWhat does this have to do with the blog post?\n\nwtf are you talking about. you're posting this on reddit. An actual website which made forums pointless\n\nAt least on reddit stuff is indexable. Same for forums. Not discord."
  },
  {
    "title": "Most micromanagers don't know their engineers consider them to be such.",
    "body": "",
    "score": 1203,
    "url": "",
    "created_utc": 1713424477.0,
    "author": "zaidesanton",
    "permalink": "/r/programming/comments/1c6x7eg/most_micromanagers_dont_know_their_engineers/",
    "all_comment_text": "&gt;A simple way to ease your mind is to request short (1-2 sentences) written updates at the end of the day. This is very easy for people to do, and can help you get a piece of mind.\n\nYeah. It's just that we're putting new coversheets on all the TPS reports before they go out now. So if you could go ahead and try to remember to do that from now on, that'd be great.\n\n&gt; A simple way to ease your mind is to request short (1-2 sentences) written updates at the end of the day.\n\nMy manager requested this but still wanted 15 minute+ morning meetings to discuss the 1-2 sentences of each staff member while you sit there bored out of your mind\n\nSometimes he wouldn't even read the 1-2 sentences and I'd have to say out loud the exact thing I wrote in the email to him, and he wondered why morale was on the floor\n\n15 minutes daily meeting isn't really too bad. A bit long, but not the worst.\n\nDepends. 15 minutes total, or 15 minutes for each staff member while requiring everyone to stay for everyone? Or, one short meeting or a Cartesian join of meetings?\n\n5-15 minutes total I think is totally reasonable and something like that, I would even say is moderately important just to get everyone to see each others faces, exchange some words, and be present so to speak. I think if you habitually don't see each other all day, especially if there are remote workers, it's really easy to get out of sync and disconnected. A quick regular meeting I think is a good thing.\n\n15 minutes each is a fucking nightmare.\n\nAgreed. Sadly, I have more experience with the second format. It gets particularly heinous when people get the impression that they need to one-up each other. First guy talks about what he did for 5 minutes, and then each next person talks increasingly longer and you start wondering how strong the window is and how pleasantly cool the breeze on the way down might feel.\n\nPull a Tversky and walk out.  Don't give an excuse before you head for the door because as you're walking out it will come to you.\n\n&gt;[Amos Tversky's] advice for anyone looking to get out of doing anything they didn‚Äôt want to do is simple: It could be ‚Äúa board meeting or a TV show,‚Äù Lewis explains. ‚ÄúHe said, ‚ÄòDon‚Äôt worry about making up an excuse for not being there. Just get up and start walking, and it‚Äôs amazing how quickly your mind will formulate the words as to why you have to leave.‚Äô‚Äù\n\nOf course he was also an eminent psychologist with cache and swagger.\n\nI just remembered, I left my apartment on fire.\n\ncachet when it‚Äôs specialness, cache when it stores\n\nWhat if it stores and it's specialness?\n\nExcuse me, but there's something I've been wanting to say for a while.\n\nWhat is it?\n\n\"Bye\"\n\nAgreed. People naturally feel a need to justify their existence. You have to have good facilitation to keep the meeting useful.\n\nSomething that my team did as an experiment and then completely switched to: instead of going person-to-person, go item-by-item. Anything that hasn't been started can be mostly glossed over.\n\nThat prevents people from feeling like they need to say \"spent a lot of time yesterday doing reviews, then had a few meetings, had to dip out in the afternoon to run an errand\".\n\nNot when there is no real update. \n\nI was plugging away on something for a couple weeks, porting a legacy system. It was a pain in the ass and hard to see when it would be done. Daily updates with the same content were breaking me completely. \n\nBetween that and the flu I finally snapped a bit. Thankfully my manager just backed off a bit and I finished things up but it really sucked.\n\n\"Still going smooth\" is a real update. If you run a command in your command line, and it takes 10 minutes, it's good UX to have some feedback that something is happening, even if it's going smooth or even if it's stuck on something.\n\nImagine if it went multiple weeks. I agree that micro managing isn't great, but if 5-15 minutes a day communicating to the people who pay your salary what you're doing, unless they're totally grilling you or something, if that's breaking you completely, I feel like there is a question of professionalism that needs addressing.\n\n\"hey I'm still here, I'm still working on this problem\" and either \"I progressed this much and we're this much out of this now\" - if it's a progressing task, or \"I tried this thing yesterday, but that was a dead end, today I'll look at this\" - it's not really a lot to ask, especially if the manager's response is expected to be \"Okay, thanks for the update\".\n\nWHEN'S IT DONE? WHEN'S IT DONE? WHEN'S IT DONE? WHEN'S IT DONE? WHEN'S IT DONE? WHEN'S IT DONE?\n\nI wanted to quit every goddamn day.\n\nYeah I agree that's bad. But that's not the same as asking for a regular update. That's asking for a regular moment to harass you, which is a different thing.\n\n\"So, what's your plan today?\" is a totally reasonable question to communicate to the business that pays you.\n\n&gt; \"I tried this thing yesterday, but that was a dead end, today I'll look at this\"\n\nWHY DON'T YOU KNOW WHAT YOUR DOING? \n\n&gt; \"hey I'm still here, I'm still working on this problem\"\n\nARE YOU STUCK? DO YOU NEED TO PULL IN BILL?\n\nYeah, I agree there‚Äôs a problem there. But I don‚Äôt think the problem is inherently the regular short meetings.\n\nI mean it's called a standup because you're supposed to stand up, so it stays short because everyone gets tired and wants to sit down.\n\nOh man, we've been doing sprints all wrong then. I'm going to need a smaller monitor.\n\nYou guys are lucky. Since WFH, I have multiple 30min-1hr meetings a day :(¬† Even when filtering out all the BS ones I skip, I still find there are too many where the meeting benefits from having me there. If I try to skip, I usually get multiple pings asking me to join. It has been impacting my time to actually do things lately (develop and debug) as some days are almost completely filled 9-4. Add in random requests from people/teams located in other countries I am sometimes attempting to field meetings at all hours of the day.\n\nit's the jumping through hopes while management continues to explain how important something meaningless is. when a manager actively tries to manage, they are just trying to dissuade their managers from realizing how useless they are.\n\nThis is a lack of trust. This lack of trust is what is the problem. If they want that level of granularity then the problem is either the company culture, or the manager.\n\nTo some degree, yes, but I think there is a feedback aspect too.\n\nIf you're working on something complicated that might have an effect on other teams, or be affected by other teams, or if you're working with evolving requirements - then it's pretty important that the person who coordinates all those parties gets regular updates.\n\nThat may or may not be someone who the developers report to on in an org structure capacity, but *someone* needs to have high visibility of what's going on.\n\nI think 5-15 minutes isn't a particularly unreasonable amount of time to devote to that.\n\nWanting communication isn‚Äôt the same as a lack of trust. In my experience a large part of developers never communicate anything unless ‚Äúforced‚Äù by meetings or being asked directly. I get that everyone hates managers but there‚Äôs a good reason why managers will need to know what‚Äôs going on. \n\nYou might be doing a good job but there‚Äôs always some people who have no clue, slack off, over complicate things or just don‚Äôt make progress. In those cases you want to find out quickly enough to correct.\n\n&gt; Wanting communication isn‚Äôt the same as a lack of trust.\n\n\nAgreed. It's the strict requirement of a regular, frequent, written update that signifies a lack of trust, instead of trusting that the developer is getting on with the work and will communicate problems and progress when appropriate.\n\nAnd what if the dev goes days or weeks without any communication?\n\nReally depends. It can just kill the flow you are currently in. I joined another team and they asked me why I am always 2-3 minutes late. It's because I'm completely in flow and just forget to look at the time. So is this really a good practise if your engineer will be late because he is too focussed on his work regularly at this time?\n\nYeah I prefer to have any kind of standup at the beginning of the day, then I will start working after it. At one job we had standup every day at noon, and I absolutely hated it. It's \"lunch time\" isn't that convenient?\n\nBut I don't usually take a lunch break and prefer to work 8 hours and leave earlier, so at noon I'm typically in the zone...\n\nIts just a complete waste of time, just come speak to us each separately so I can get on with some work instead of getting bored and losing my motivation in the first 15 minutes\n\nI think it's useful for social reasons and organisational reasons.\n\nPeople aren't robots, and just being present and showing your face - even just for 5-15 minutes I think is useful\n\nI'm sure you can have useful meetings but my manager asking us what sentence we wrote in an email last night so he can think what to tell us to do today instead of him reading the emails beforehand is a complete waste of time for everyone\n\nThe 15 minute pow wow isn't the problem in your equation. You are wrongfully assigning the blame. Your manager is micromanaging. If it wasn't in the stand up, it'd be another way.\n\nI have regular 15 minute meetings, and i don‚Äôt see ANYBODY‚Äôs face. We don‚Äôt do scrum to see each other‚Äôs faces. We do it so management can rest assured that the grown-ass adults they hired are working. As for developers not stepping all over each other and being coordinate, that‚Äôs what version control is for. So sick of stupid half-assed agile shit and kanban boards with 20 lanes for the entire fucking company.\n\n\nAnd yes, I know management is doing everything the wrong way, but this is what happens with cargo cult management. People need to stop writing books about development so developers can develop.\n\nI actually do think there is a case to be made to have some sort of brief check in to make sure the grown-ass adults are working. \n\nSince remote working has started, I'm pretty sure that at least 3 of the people who have been hired on our team have literally not worked for days or even weeks at a time. I'm not the manager, but sometimes they'd be working on the project with me, and they'd be way behind on things that I would have thought would be easy. Or they don't answer questions promptly on chat, or whatever. \n\nOne guy I'm convinced gets hired to 4 jobs at a time and just does enough chat to make it seem like he's present and coasts for a few weeks taking multiple incomes (he literally submitted no work by the end of the 4 weeks before we let him go).\n\nI think having just a daily face-to-face connect, and set the expectations that you need to be present helps with this sort of thing. Forces people to actually lie to your face if they're going to lie, makes them actually have to come up with an explanation of what they were doing, even if it's brief.\n\nObviously there's a myriad of ways to half-ass cargo cult agile, but independent of any stand-up rules or whatever, I really do think it's not unreasonable that if you have a team of people you're paying a salary to, to at least have a regular moment where you can see their face.\n\nYou'd never tolerate this with any other salaried project. If you hired builders and were paying them hourly, and they just didn't show up to your house at all for multiple days in a row, I think you'd be well within your rights to at the very least have a moment where they can tell you what they were doing for those days.\n\nYou responding to me makes more sense why you were pushing back so much when I was being forced to do 15 minute standups with no opportunities for remote work so we're all in office anyway and he'll interrupt you at least once every 20 minutes to check up on you to see what you're doing\n\nYeah it's tricky - because on one hand, even very good developers sometimes have periods of time where they're working on something and they don't necessarily have something tangible to show. Sometimes 'figurin out stuff' takes a lot of work. \n\nBut at the same time, you don't really wanna be taken for a ride by someone for weeks on end by someone unscrupulous, who actually was doing fuck-all. \n\nOr another, perhaps even more common thing, is when a well-intentioned developer get's really tunnel-visioned on something that isn't super important, but the importance has been miscommunicated or something.\n\ne.g. the business says \"Can we get [thing X], ideally quickly\", but they think that [Thing X] should be a half-day job. But actually there's a bunch of blockers to [thing X] or it's harder than you'd think, so a developer takes it on and is pursuing it for like a week.  Even worse if it's a problem that the developer finds really interesting, and wants to really learn about and explore. Then 2 weeks later it's like \"Hey did you get all the work we asked for done?\" and it's like \"Well, no, I'm still working on [Thing X], because it's harder than you'd think\" - and the business is like \"What!? really? Fuck, if it's that hard, it would have been way more useful for you to finish things A, B, C, D, E, F etc.\"\n\nHaving a culture and process where the product owners who represent the business regularly get updated on what everyone is doing, what problems are slowing them down, whether or not it looks like they're on track to whatever estimates they gave sort of addresses both problems. \n\nI think having someone who's coordinating the project, who can answer at any point what any worker is broadly working on and what is likely to be done and when, and how far along it is, is quite a useful and reasonable thing. Updating every 20 minutes is overkill, but just a quick little \"Hello\" once a day is not too extreme.\n\n&gt; Fuck, if it's that hard, it would have been way more useful for you to finish things A, B, C, D, E, F etc.\"\n\nWow, business still doesn't learn it's ESTIMATION, not THIS WILL TAKE X TIME, GUARANTEED\n\n&gt; If you hired builders and were paying them hourly, and they just didn't show up to your house at all for multiple days in a row\n\nAren't contractors infamous for doing *exactly* that?\n\nyeah, bad ones.\n\n&gt; As for developers not stepping all over each other and being coordinate, that‚Äôs what version control is for.\n\nVersion control isn't going to save anyone time if you have multiple people duplicating work, or writing something that's going to be immediately broken by someone else's work. That's why you talk about things out before hand.\n\nEverywhere I worked has things called cases/tickets/tasks wherein no developer has the same task. You get a conflict to resolve if there are conflicting changes. But breaking shit in DEV is an average Monday. It should be fixed before it goes to QA. What are y‚Äôall just releasing shit directly from DEV to PRD?\n\n&gt; That's why you talk about things out before hand.\n\nYes, on refinements when creating technical tasks and on planning. \n\nYou really need 3rd time everyday?\n\nI know what everyone's doing after the planning. Maybe if you'd all pay a bit more attention we wouldn't need multiple redundant meetings.\n\nI was only pointing out that version control isn't how you coordinate work.\n\nYes, and higher ups shouldnt take time in daily just to say \"meetings, and stuff\" but they do.\n\nIt's not. That's your desires being foisted onto everyone else.\n\nIt's not my desire. Hell my desire is to work on a project with well defined, non-changing requirements and no blockers, with the authority to make my own calls about what the business wants.\n\nBut that's not realistic, priorities can change, requirements can change, and it's important that everyone involved knows what's going on even if what's going on is \"Still going to plan\"\n\nWhy every day and why not once per week? Do you have studies or you just vibes based?\n\nNo studies, and I'm not adamant that every single day is necessary either. \n\nBut whatever period you have, that's the amount of time you could waste doing something useless due to a miscommunication or a change in the situation or requirements. \n\ne.g. If you spend a week doing something and then at your weekly catchup you say \"This week everything went smoothly building [X]\" and whoever it is says \"What? you built [X]? I thought that was phase 2 because it's going to need to accommodate for [Y] which we don't have yet\" - then that's a week of lost work that you'll have to re-do. \n\nSure you could say \"Well get all the requirements perfectly clear up front\" - but that's not anymore realistic than saying \"why do we need testing, just get the code right the first time\".\n\nWhether it's daily, weekly or monthly, depends on how likely that event could be, how much the requirements shift, how well defined everything is, etc.\n\nAnd secondly, it's also the amount of warning time that the business gets to pivot their decisions (and you need to factor in any extra delay between the communication between the PO and the business).\n\ne.g. Let's say you estimate \"This will be done in a week\". With a weekly meeting, the PO finds out that you're half a week behind. Then he schedules a meeting with the relevant stakeholder, which maybe happens a few days later (depending on how often *they* meet), and then they make a decision over a few more days (missing your next weekly meeting with your PO - where you've now finished the feature), and then they update the PO, who then updates you in the *next* weekly meeting to tell you \"Actually it's too late, we miss our window, we don't need this feature anymore, might as well pull it out because we don't need to support it\".\n\nIf it's more regular and if there's someone with their finger on the pulse of the project (the PO presumably), they can be a lot more proactive in commuincating with the business, and could possibly save a hell of a lot of time, just by not duplicating work, and/or removing things that you don't really need, so not doing the work in the first place. \n\nAgain the time period depends on the project and the risks etc.\n\nEverywhere I've worked though, I find that a week would be a bit too long. Having a regular scheduled communication just to prevent big time wastes has saved a lot of effort.\n\nI could see every 2 days, maybe even every 3, but you'd need a really well defined project where you can sick a dev on it to dissapear for a week I think.\n\nHow long have you worked? I've worked for about 20 years and once a week tag up is all that's necessary.  Following up throughout the week adhoc is good if it's needed. Otherwise this is really retarded\n\nJust under 20 years. I imagine it depends on the field. When I was in agencies working on external projects there was contracts preventing scope creep and changes (though obviously it did still happen). \n\nNow I work on internal projects for a large company, and generally my edict is \"make things to help people\" - and most people don't know exactly what they need, largely with straightforward technical requirements, but vague and complicated business requirements. So being in tight communication helps immensely.\n\nYou are very passionate about being there for your management üòòüòòüòò‚ô•Ô∏è‚ô•Ô∏è‚ô•Ô∏è\n\nThe idea that one week delay could make a feature miss the window where it was useful is utterly alien to me. Do you work exclusively on small internal tools that'll be used exactly once and if you fail to have it ready in time people will just do the work manually?\n\nI disagree. Its **crushing**. Due to timezones, our standups are at 9:45AM. Due to context switching, no one wants to Alt+Tab out of Visual Studio and break train of thought, so really development stops at 9:30. But since most people arrive at 9:00, 30 minutes isn't really enough time to 'zone in'. After the meeting, everyone wants to bio break, then we have friendly chat, then development starts. At 10:30. This 15 minute meeting cost over 90 minutes of dev time. Every day. \n\nAnd somehow, despite giving the same status update for 4 weeks (20 fucking meetings) our manager was confused as to how a feature assigned to a team member wasn't complete. This dev seriously gave the exact same status update for 20 fucking meetings before management caught on, meaning mangement doesn't actually pay attention. 20 * 90 * 5 (team members) / 60 = ONE HUNDRED AND FIFTY **HOURS** of dev time down the drain for a **15** minute meeting that no one even pays attention to.\n\nPlease kill this shit with fire.\n\nLook agree context switching is bad, but it‚Äôs a 15 minute meeting that is completely predictable and scheduled. \n\nIt‚Äôs a bit nuts and unprofessional to not be able to plan your day around that to the point where you need to lose 90 minutes of work. It‚Äôs always easier to work without having to talk to people in a total silo without being accountable to anyone, but part of the job is communication, and not all of that can be done with jira boards.\n\nYou‚Äôd never tolerate that from some other professional. If you paid a plumber or builder, and they got there at 9:00 am, started setting up their tools and what not, and then at 9:45 you said, ‚Äúhey I just wanted to fill you, I‚Äôm going to be out today, and could you keep me posted on how the project is going‚Äù. If they said ‚Äúwell you‚Äôve interrupted me now for 15 minutes, so that‚Äôs 90 minutes that I‚Äôm not going to work, but still bill you for‚Äù, I don‚Äôt think you be like ‚Äúof sorry, totally my fault.\n\nI agree that constant unplanned interruptions is bad and so are endless meetings, and I‚Äôll even give you that 15 minutes is a bit long. But this idea that we‚Äôre totally unaccountable and shouldn‚Äôt have to tell anyone what we‚Äôre doing or whether it‚Äôs going well or badly or keep any updates on the project is just completely unreasonable.\n\nEspecially if you want any equivalent understanding from the business when things aren‚Äôt on track. E.g, if you say ‚Äúit‚Äôll be done in 3 weeks‚Äù and you refuse to keep them updated, then in 3 weeks if you say ‚Äúactually we ran into some unexpected problems we‚Äôre not even half done‚Äù, I think the business has every right to be mad. ‚ÄúWhy didn‚Äôt you tell me this as soon as it looked like you were off track‚Äù is a completely reasonable answer then.\n\nSo for me verbal communication really helps me understand, I really struggle with written communication.\n\nMy manager doesn't micromanage but if I have a tough project they will make sure I have some people to brainstorm with.\n\nDaily standup?\n\n[deleted]\n\nThat's the easiest decision a manager has ever made: both, obviously.\n\nI'd choose neither\n\nI host 2 meetings, one Monday one Tuesday and for each meeting I need an agenda. Fine, fair. \n\nExcept the agenda has to be out by Wednesday COB for the next week. \n\nThen the Thursday emails start, reminding to send in the weekly report by Friday at 3 pm. \n\nEventually, a reminder to submit a summary of my monthly accomplishments, which is literally just a copy of my weekly reports‚Ä¶\n\nSo am I not suppose to work on new stuff Wednesday - Friday because it will disrupt the agenda for Monday and Tuesday? And what update should I have for Wednesday when I haven‚Äôt had a chance to work on other stuff yet? \n\nI know my PM doesn‚Äôt look at these things.\n\nMost managers who ask for daily email updates don‚Äôt actually read them no matter how short. They just check to see if you sent it and ask for it when you forget or when you‚Äôre late just to give the impression that they read it.\n\nI've been on projects where I'm *trying* to get them to read and comprehend a status e-mail because it involves something actually important and and they still don't read shit. And then I bring up the issue in a meeting later and everybody's like \"what?\". I feel like I could just send an email with a few words at the top and then the \"lorem ipsum dolor\" text for the rest of it and nobody would notice.\n\nA word of advice. \n\nAdd a tldr or an ‚Äúexecutive summary‚Äù at the very top of your summaries. Just a one sentence description, even if it‚Äôs ‚Äúall is well, no blockers‚Äù or ‚Äú&lt;one sentence problem description&gt;, there‚Äôs a plan to resolve‚Äù\n\nJust something I learned to do that got me attention from higher ups and execs. Even has resulted in me getting a couple of promotions.\n\nNow I wonder if you can have AI monitor your pc for the whole day and automatically compile a summary to send everyday.¬†\n\nThis is purely from my experience as somebody who's been in the industry for 20 years, but this wouldn't help at all. Managers don't care about the content of the updates at all, so even a summary of updates wouldn't help. Nor would I want a manager who cares about the specifics of my progress enough to warrant a daily update. That's not the role of a manager.\n\nif an AI was watching my screen I would be too anxious to touch my computer\n\nI never liked putting the onus on my team.\n\nI did need to know what was going on, mostly because my manager expected me to answer questions about it every day. But instead of \"what did you do today\", I would drop by and ask \"Is there anything you need from me, or anything I can help you with? Do you feel like you're on track?\". Most important, also, was to actually trust what the person said. If they said, \"I'm fine, I don't need anything.\", I would just tell them \"thank you, that's all, have a good evening\". I already know their tickets, I don't need them to rehash them. I just need to know they're not stuck and spinning their wheels, and that's enough for me to answer my boss's hour of questions in the morning.\n\nThe best teams I work with are asynchronous remote teams that literally dump out where shit is at at the end of their day on a common teams message.  They don't do it because it's required, they do it because it keeps a fast moving team organized when there's lots of stuff moving.\n\nI hope people are upvoting because of the office space quote.\n\nüëçüëçüëç\n\nWe have stand-ups for the short updates. Don't bug me unless you have a blocker\n\n&gt; If that junior is creating their 5th microservice, do they still need you?\n\nThey need you to tell them to stop.\n\nThey can‚Äôt keep getting away with it!!\n\nMicroserice1: ltrim\nMicroservice2: rtrim\nMicroservice3: trim(there was an issue where strings still had new lines and invisible characters at the end)\nMicroservice4: isempty\n\nOr, they simply don't give a shit. They're not meant to be leaders but they take the job anyway. By meant to of course, I mean they don't spend time learning the aspects of what a leader should be. Mentorship, guidance, being there for your team and not on some isolated plane far away from all their issues. I'm afraid most managers are just climbers who are onto their next shiny title and salary.\n\nManagers and leaders are different roles. Sometimes the same person can fill both well, but this is rare.¬†\n\nI will have to agree with you there. Wouldn't hurt for more managers to also possess some leadership skills as well -- and here I'm not even blaming the employees themselves, after all they are doing what they are told in the best way they can. But company culture, available trainings, mentoring for managers themselves would definitely help.\n\nI do think it's entirely possible to be an excellent manager who doesn't micromanage, who adds value and who still isn't a leader. Good management is a skill onto itself and when done well I think people appreciate it.\n\nNot sure I'd agree to this one, at least not entirely. Not micromanaging requires trust first, which is a trait of leadership. So I think, while a manager doesn't have to be a fully fledged leader, surely they have to at least share some traits with one in order to be effective in dealing with their team(s).\n\nTrust is established by good leaders, sure. But it's not exclusive to leaders. I trust my friends and my partner and none of them are acting as leaders in our relationships. I trust my peers at work as well.\n\nIndeed, that‚Äôs a good point of view.\n\nI explicitly told my VP that promoting me to manager would be a mistake\n\nThere are certain aspects of leadership that‚Äôs impossible to have when you‚Äôre manager. There‚Äôs a different dynamic when the person has the power to promote and fire you than a leader who‚Äôs in the same codebase as you dealing with the same issues and code.\n\nA managers job is to understand the companies needs and make sure it gets done.\n\nOf course things need to get done. Not sure where I mentioned otherwise. Napoleon's armies got things done, the Red Army got things done. Napoleon raised his soldier's salaries, gave them new uniforms, gave them inspiring talks and mentorship to his direct subordinates. Stalin ordered the NKVD to shoot any soldier who didn't follow his exact orders. See the difference?\n\n&gt; Stalin ordered the NKVD to shoot any soldier who didn't follow his exact orders.\n\nDidn't, but the myth probably helped. \n\nHe did systematically purge their leadership and drastically reduced their effectiveness as a result.\n\nlol yeah the red army was way more effective in terms of the scale of their conquests. Not advocating for a red army-esque approach obviously, but if you think corporations don‚Äôt prioritize results over feelings then you are deluding yourself.\n\n&gt; lol yeah the red army was way more effective in terms of the scale of their conquests.\n\nI'm sorry? Are you aware of Grande Armee's victories? The Red Army had one single enemy and had massive mechanized support from both the US and the UK and lost millions of soldiers, they basically threw as many people as they could at the problem as canon fodder. Plenty of times, Napoleon seized entire countries and lands while losing less than 100 men.\n\nAnyway, not sure why things keep being assigned to what I think or might have thought without me explicitly saying so. Of course corporations don't give a shit about people. That's why micromanagers with zero leadership skills are usually the most successful there.\n\nNapoleon's victories are almost unbelievable. Winning decisively when outnumbered 2- or 3-to-1 became an expectation. He lost like 4 battles out of 100 over a 20+ year career. He was not infallible, but it's telling that [avoiding him](https://en.wikipedia.org/wiki/Trachenberg_Plan) was the coalition's eventual strategy for defeating France.\n\nGreat analogy btw.\n\n[deleted]\n\nIt's true that France mostly did not instigate any of the Napoleonic wars, the coalitions did. But of course Napoleon being bent on keeping territorial gains and installing continental trade blockades would provoke war.\n\nBut I would argue that the French abolition of the monarchy and the church did much more to provoke other European leaders than did treating their peasants marginally better - although those two reforms are clearly correlated. You can tell it was about the monarchy because once France was finally defeated, the coalition's #1 priority was reseating the Bourbon monarchy, undoing other revolutionary reforms was far less important to the coalition.\n\n[deleted]\n\nI'll forgive your cheekiness if you'll excuse my pedantry! I like nerding out about the period, it's one of the most complex in history - it cannot be reduced into a simple predetermined narrative, like most historiology of the French revolution is determined to do. P.S. amazing username, /u/teslas_love_pigeon\n\nNapoleon was ahead of his time. \n\nThe Red Army got a lot better strategically as time went on but they were always pretty willing to bleed men tactically.\n\nThe best tactics for getting things done depend on the situation.\n\nContrary to what most managers think or do, getting things done is mostly dependent on team morale and hiring decisions. If you hire reasonable people with reasonable skills sets and then help the team feel enthusiastic, engaged, and supported they will get things done. Everything else is just managers trying to feel important.\n\nIn the real world you deal with the people you actually have, not the people you'd like to have. Some of them will be lazy, some of them will be stupid, and the smart ones will think they know best, and the suits are to stupid to understand.\n\nFrom my experience they generally care and want to get stuff done, but they mostly don't have anything useful to contribute so they figure they can be useful by watching over everyone's shoulders\n\nGive people a career path that doesn't feel like a dead end in 5 years and maybe career climbers won't head for management. \n\nI don't think I'll ever get the chance to move past senior, I don't even know if I can get another job at the same level with how things are going at my current place. I'd hop to management because no matter how much they try to gaslight us, it's absolutely a promotion.\n\nAt my last job I had 3 bosses in 12 months, the last boss - finance background but \"had an interest in my area\".\n\nTotal nightmare, would not listen to anyone technical and f\\*cked up so many things - I left shortly after and nothing has improved.\n\nWould call me in the car, on leave, sick, in the bathroom, request status updates 6 times a day, wanted to sit and watch me do everything and requested 2 x 30 minute meetings a day.\n\nmicromanagement aside, why do people just think they can waltz into tech and be on the same track? There's a culture and away of thinking in any field. \n\nIf you don't understand the very fundamentals of a system, why do you think you can advance upon it?\n\nI worked for someone like this, and he is definitely on the dark triad spectrum.\n\nSpreadsheets is basically programming at some point, right?\n\nEveryone else, from lawyers to construction workers, deals with it too.\n\nI'm not in those fields, but I want to say I could only imagine construction being vastly different. If you're a lawyer, then you're probably familiar with how the machine works. Problem is we get business people managing us, which we resolved with a new managing style. But people do not get it so...\n\nHow would construction be different?  It's also got business people telling them to do things that compromise the structure. Lawyers have to deal with clients who think they know more about the law or winning a court case than the lawyer does.\n\nyou right\n\nThat describes the ceo at the startup I recently left...finance background, knows enough python to be dangerous, thinks he should dictate technical/web development stuff and then throws a tantrum when things don't turn out as he wants them. Complained about how long things took even though they took so long because he didn't know wtf he wanted. Just an unpleasant prick overall.\n\nTo say I was fed up with him is the understatement of a lifetime. I quit after I had stressed out over a project, had an eye twitch and other stuff, and then as soon as I was done the mfer decided he was going to redesign everything. (and this guy would not know good UX if it punched him in the face)\n\nEvery day I am so thankful to not have to deal with him anymore.\n\nI think the lack of awareness generally extends further than their employees‚Äô opinions about them.\n\nWhen I was an engineering manager, my own manager tried to push what we lovingly called the \"micromanagement spreadsheet\".\n\nI had to project, for the next three months, which feature each of my 9 direct reports would be working on each day, mixing in the rotating servicing duty (bug fixes scheduled for regular updates).\n\nLet's just say that it didn't last...\n\nJesus. I've got to forecast what percentage of the team will be dedicated to our 3-4 major initiatives over the next 6 months or so, and that's enough of a pain in the ass as is.\n\nHoly shit how do people who understand so little about software development get jobs managing it???\n\nrizz\n\nThis week I figured out our new principal engineer writes scripts to track developer productivity on gh.\n\nI worked at a small company that was receiving grants from the government, but had to submit time tracking sheets for each feature. \n\nRather than get the developers to try to track their time, they wrote scripts to take the project start time from the ticket and the merge time of the associated feature branch. Everyone was happy with that, as far as I know.\n\nThis was me and my old boss üòÇ. Good times... as far as anyone knows.\n\n    SELECT COUNT(*) FROM gh_commits WHERE username = 'AZXCIV' AND MONTH(commit_date) = 'April'\n\nTime for your performance review!\n\nI had one job where just as a result of what I was working on I was way ahead of the whole field in total commits. \n\nI would have loved that sort of review.\n\nWhen a measure becomes a target, it ceases to be a good measure.\n\n-Goodhart's law\n\nI know, and like I said it was just a result of the particular work I was doing and not a measure of how productive I was.\n\nI‚Äôve done this. It doesn‚Äôt take a ton of effort and it‚Äôs a useful tool for identifying issues or confirming feelings about performance. A poor manager might rely on those metrics but a good one might use those to identify trends, dig deeper, and resolve issues that aren‚Äôt being brought up\n\nAny company I have seen doing this ends up with people being wildly verbose in their code, never deleting or refactoring anything, and making excessive commits (which makes using commit histories all but useless).\n\nI‚Äôve began doing that\n\nThere are companies that make money on this. My last company used way dev and then source level.\n\n&gt; A simple way to ease your mind is to request short (1-2 sentences) written updates at the end of the day. This is very easy for people to do, and can help you get a piece of mind.\n\nHad a micromanager who did this and then wanted me to write status to each of my tickets every day, and then would slack me three times a week and then.  It's all \"15 minutes\".... but adds up to hours of up keep, and usually I want to just leave at the end of the day, especially if it's after a long meeting, so yeah that gets forgotten because.... \"1-2 sentence\" takes more than \"10 seconds\" that managers expect.\n\nAt the same time I was doing scrum with my other team.  If he literally opened up the Scrum document my status was right there in perfect English including the ticket link and any blockers (there never was any).   He never looked at that file even though I linked it to him.\n\nMicromanagers don't know how to set limits and expectations, that's why they're micromanagers. \n\nAnd btw I'm a senior developer, I proved myself with other projects with large and small teams, and I updated the guy twice a week in a meeting we had IN ADDITION to all this. \n\nBut the end result of all this experience was make it so I told my scrum master to never volunteer me for a project with that manager.... apparently he recommended me because the other two seniors had already said that. \n\nStill, I love how the title is \n\n&gt; Most micromanagers are blind to being seen as one\n\nBut all the suggestions are recommendation to Micromanagers... but let's check the title, oh the people who this is most applicable too won't realize it applies to them.\n\nHere's my policy whether I'm a scrum master or a member of a team.  If you have a daily scrum, get your updates there.  It's what that meeting is for.  I have had to ask for updates about something that wasn't covered in scrum once in a while, but that's a \"Emergency\" not how updates should be done.\n\nEven if it's not your scrum, if you can open that file and see my update, that's your update.  As a manager your goal is to try to make sure employees are able to be productive, not add additional tracking to them, if the decision is a small inconvenience to you, or a change in the process so you can be updated on your favorite method... make the inconvenience on yourself if you can.\n\nBut how do they appear busy then?\n\nWatching YouTube?\n\nMy god, I hope your work updates aren‚Äôt as long as this Reddit comment.\n\nThey‚Äôre telling an anecdote, not writing a status update on their ticket. Don‚Äôt be a micromanager, use some common sense\n\ntik tok brain kids when they see something that takes more than 3 seconds to read.\n\nHilarous comment. I don't think people got that it was a joke.\n\n‚Äúa piece of mind‚Äù\n\nSeriously??\n\nMany of them actually imagine they are contributing to the project in some way.\n\nThe moment I see AI-generated pictures in your blog post, I'm going to (correctly) assume you shouldn't be listened to, and close the tab.\n\nEdit: To whomever reported this to Reddit Care - sure hope you did it from a sockpuppet account that's in no way connected to your real account, because I just reported it, and abusing Reddit Care is a permanent ban.\n\nEdit2: Reddit banned them, RIP bozo.\n\nPrompt Engineers are the new Managers\n\n[deleted]\n\nSounds like a reasonable filter to me.\n\nThis is just some dumbasses blog, they are not an expert in management they probably aren't even an expert in programming, they certainly aren't an expert of the English language.\n\nBlog posts are not a valid learning source they are just random peoples brain farts.\n\n\"Development team leader @taranis\" - I was unable to find a Twitter or Substack account for \"@taranis\" and the authors got some truly terrible other articles that illustrate him as a worse manager than Michael Scott.\n\nI am sad this is so heavily upvoted.\n\nThe real problem with most 'managers' in tech, micro or otherwise, is that they don't know much of anything at all.\n\nIllusion of control.\n\nThere are different levels of micromanagers. If you need to pass every single thing pass your manager look for another job. Managers like that are very bad at their job or are doing things they shouldn't be doing.\n\nConsider just using the article's title next time.\n\nWhat do my engineers think of me.\n\nThey tolerate you.\n\nSplendid.\n\n&gt; 13:15\nAnton: \"Great, thanks. I've checked it too, seems like the problem is in repo Y, file X, line 235, let me know if you need any help fixing it.\"\n\nThis is the frustrating one because it's completely meant to be helpful and save you time and it's still just so annoying.\n\nAnd they always use Jira.\n\nPolitely telling them to fuck off usually gets the mesage across though.\n\nWill something like this work? \"Christian, can you politely fuck off? Thanks\"\n\nYes. Best served with two seconds of eye contact.\n\nBullshit. It's not even about adding value, especially when you know less than your specialists, it's only about retaining control and throwing shade. And I say that as a manager.\n\nWhat I do is I make sure everyone is comfortable asking for help when they need it and outside of agreed touch points I do NOT interrupt their work to leave my fingerprints on their achievements.\n\nSo true. The absolute worst micromanager I've worked with was the ceo of a small startup. Everything he did was a power move.\n\nI had one of those. \n\nEntirely convinced he was gods gift to software engineering.\n\nOne time I got a new manager. He was trying to control how I wrote my emails. Telling me not to send certain emails, even though the email was required for me to do my job and he had no other solution. I sent an email he told me not to send. He didn't like it. He said why are you being insubordinate?  I told him I felt he was a micro manager. I think he was taken back by this. We came to a understanding after that meeting and things were much better.\n\nYeah. I once had a manager who was 4'8\", but he wore these giant clown shoes.\n\nOn the flip side of that I left one of my software engineers to it, trusting him, and he simply forgot he had to write and deliver an emulator as well as the software.\n\nIf you don‚Äôt want to be managed - be competent.\n\nThere's a middle ground between \"justify your existence for the last 15 minutes so I can write this hours reports\" and \"here's a project, see you again in 5 months when you've finished it\"\n\n100% yes, but in defense of the \"see you in 5 months\" method, it *can* work if the developer is both trusted and reasonably visible with their output--\"Just finished milestone A, starting work on milestone C\"...this provides the manager with the opportunity to be hands-off or hands-on as needed.\n\nOr... maybe... have a process in place better than \"let's talk about a bunch of stuff and hope you remember 8 months from now LOL\"\n\nAnd software engineers will find a way to call anything micromanagement.. daily stand ups - micromanagement, weekly reports - micromanagement, year late and a million overspent? Don‚Äôt micromanage me or I‚Äôll cry.\n\nSo much this. \n\nThe number of genuinely competent people is very small. The number of genuinely competent people who will stick around long enough in a role to solve problem X or deliver Y is even smaller.\n\nExactly, but everyone will moan about being ‚Äòmicromanaged‚Äô while they bumble along and screw up, that would be avoided if they were managed.\n\nthat's the secret, being managed doesn't fix those things. having a smooth brained individual poke you with a stick incessantly doesn't help\n\nIt presents an interesting dichotomy on the spectrum from being a supportive and helpful leader to becoming a micromanager üôà - I can relate to this challenge!\n\nI‚Äôve had the unfortunate experience of starting out with high hopes of being a leader and successfully leading the top engineers but having to micromanage a few. It‚Äôs terrible babysitting people. Especially when you throw them a bone and they won‚Äôt take it.¬†\n\nThat [AI art](https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcbd58065-13a2-4ea1-ac9c-befc75f2c8ef_3152x2618.png) gives way to some scary implications if you look at it at full resolution. He sees himself as a hero standing among literally faceless employees.\n\nI hate the way literally every article about software engineering (be it about new tech, work culture, or the market) seems to use AI generated images like this. It's still way too easy to notice details like those faceless people, and when the article is about programming, the image more than likely has a monitor with meaningless text-like shapes on it. Not to mention the creepily smooth human faces.\n\n\nIt's distracting and actually makes me value the text less - because either the author didn't make an effort to find a relevant \"normal\" image, or didn't even try to narrow their prompt and minimize issues like this. And if that's their attitude to the thing that draws people to their article, well...\n\n\n\nAlso, this is probably not-well-founded, but seeing an AI image makes me watch out to see if the text is also AI-generated (which is the case more and more often). Sidenote: Why does the disgruntled office worker on the right look exactly like David Harbour?\n\nit was the only way for them to feel useful. then, the miracle of scrum meetings was bestowed upon them\n\n&gt; doing the work for the people\n\nOh, that's considered micromanaging now?\n\nTelling someone else _how_ to do their work feels like micromanaging.\n\nBeating someone to root cause analysis during a pager event is... considered micromanaging?\n\nThey think they are helpful by contributing the knowledge and do not have anything useful to do.  I get it.\n\nThis is disingenuous, your boss is just a cog in the micromanaging machine designed to extract the most labor from your time\n\nThey want you in their bullshit (micromanaged) or dead (fired, quit, gone)\n\nThis sounds a lot like situational leadership but with one less level.\n\n... tight asses?\n\nlol  I'm the one\n\nJohn believed he was helping his team by closely monitoring their work and stepping in frequently. However, what he saw as support, his team perceived as overcontrol. This is a common issue in management. Good intentions do not shield from the negative effects of micromanagement.\n\nA Day of Overcontrol: Recognizing the Signs\n\nMorning Check-in:¬†¬† At noon, John messaged his team member, Steve, on Slack, asking, \"How is the project going? Do you need any assistance?\" Steve, feeling on track, replied, \"No, thanks, I'm good.\"\n\nAfternoon Follow-up:¬†¬† By 3:30 PM, unable to curb his impulse, John checked in again, \"How are things, Steve? Any updates? I'm here if you need support.\" Steve reiterated his earlier response, signaling that he was handling his responsibilities well.\n\nEvening Overreach:¬†¬† A production issue arose at 4:00 PM, and Steve quickly took charge, posting, \"Handling it now.\" Nevertheless, at 4:15 PM, John intervened, providing a detailed analysis of the issue and even started working on the fix himself. He added, \"Great, thanks. I checked it too, it looks like the issue is in repository Z, file A, line 235. I'll start fixing it.\" Steve‚Äôs curt reply, \"John, we need to talk‚Ä¶\", highlighted his frustration and perceived lack of trust from John.\n\nThis sequence of interactions typifies micromanagement and reveals how excessive control can undermine team confidence, even among effective managers.\n\nOvercoming Micromanagement\n\nEstablish Clear Expectations:¬†¬† Clarify how and when you prefer updates, particularly with experienced team members. Reduce check-ins to essential communications only, respecting their autonomy.\n\nSolicit Feedback:¬†¬† Encourage your team to provide honest feedback about your management style. Be open to criticism and ready to make adjustments based on their suggestions.\n\nDelegate Successfully:¬†¬† Assign responsibilities clearly and trust your team to execute tasks without constant oversight. Demonstrating trust can diminish the urge to micromanage.\n\nFoster Trust and Autonomy:¬†¬† Promote a culture of independence by allowing team members to approach tasks in their preferred manner and make decisions without frequent interference.\n\nEvaluate Adjustments:¬†¬† Regularly review changes in your management approach to ensure they are effective. Be honest about what works and what does not, and continue refining your style to better support your team.\n\nAdapt to Your Team Members:¬†¬† Understand and respect individual preferences and requirements for communication and support. Engage with each team member to gauge their unique needs.\n\nTailor to the Task:¬†¬† Consider the complexity of the task and the expertise of the employee involved. Adjust your level of involvement accordingly, balancing between supervision and autonomy.\n\nLesson Learned: Good intentions can be perceived as overbearing and micromanagement.\n\nThis reeks of ChatGPT\n\nChadGPT\n\n[deleted]\n\nMicromanagers don't, in fact, know that they are seen as being Micromanagers... by their employees.\n\nVersteh ich nicht ganz, finde die Dinger die Mitten aufm Fahrradweg geparkt sind richtig gut /s\n\nN\n\nThere are bad managers and bad engineers - but all else being equal, the level of micromanagement you get from your manager is inversely proportional to your maturity as an engineer.\n\nThis is true for engineering and for most other corporate jobs.\n\nYou're talking like a micro-manager here.\n\nYour engineers being \"bad\" didn't mean you have to micromanage. It means you have to teach them, whatever aspect there are 'bad\" at.\n\nAnd well, a micromanager is going to micromanage both bad and good engineers anyway\n\nMicromanagement has to do with the micromanager‚Äôs maturity more than it has to do with that of their targets\n\nSpot the micromanager ^^^\n\nThis fails to take into account that some managers are more micro-managey than others\n\n&gt; but all else being equal, the level of micromanagement you get from your manager is inversely proportional to your maturity as an engineer\n\nStrong disagree\n\nThe more someone micromanages me the more I let them take over\n\nMy first job they just left me alone and I did shit loads of work and loved it and then the second job he micromanaged me to hell and I just gave up trying to do extra work\n\nit's the same for me with time reporting. if you let me work on my own time I'm willing to put the work in even if it means that I work off-hours / overtime sometimes. the moment an employer asks for time sheets you can bet I will work exactly the times I've been given whether I'm productive during those times or not\n\nBeing hourly helps devs who aren't afraid of the clock because it forces management to consider the cost of asking for a crunch or extra work. Giving away your time sometimes because you don't want to account for it is just reducing your pay.\n\nEh? That‚Äôs like saying the quality of the engineers in your team is related to your maturity as a manager. \n\nSometimes there are just bad engineers, just like there are bad managers. And in line with Dunning-Kruger, both are typically unaware of their incompetence.\n\nIn my opinion, the level of micromanagent is mainly dependent on the orientation of the manager, maybe with small adjustments based on your own maturity.   \n  \nAnd as I mentioned in the article - juniors can suffer from it too. If you do a task in the 5th time, being micromanged sucks, no matter your years of experience. \n\nI struggled A LOT in stopping micromanaging the seniors in my team, as it's my natural tendency to be over controlling.\n\nFound the bad manager\n\nFound the micromanager.\n\nSad to say but you're right. I'm on the lower end of mid-level so I'm not surprised I get micromanaged sometimes. Fact is, a junior engineer needs some micromanagement because they might be lost and too shy to ask for help, even when you encourage them to.\n\nI just wish my manager wouldn't ask for updates on issues in the form of meetings that take 20 minutes every couple hours."
  },
  {
    "title": "I spent 18 months rebuilding my algorithmic trading in Rust. I‚Äôm filled with regret.",
    "body": "",
    "score": 1191,
    "url": "",
    "created_utc": 1719545430.0,
    "author": "Starks-Technology",
    "permalink": "/r/programming/comments/1dqa2dm/i_spent_18_months_rebuilding_my_algorithmic/",
    "all_comment_text": "&gt;Hot take: the Rust community isn‚Äôt as nice and cool as they pretend to be. They‚Äôre a bunch of narcissistic assholes that hate being told that their favorite language has flaws.\n\nüçø\n\nHe's right tho\n\nGood luck finding a community of decent size with self selected participants anywhere which doesn‚Äôt have some portion of users that aren‚Äôt assholes or never have a bad day. \n\n‚ÄúMe having to defend myself against angry Rust fanatics on Reddit‚Äù &lt;- this is where he went wrong, don‚Äôt defend yourself, just ignore interactions you don‚Äôt want to have.\n\nYou're half-right. It's true that I shouldn't feel the need to defend myself or cry about imaginary internet points.\n\nWith that being said, the comment I replied to was **extremely** highly upvoted. Not only that, but the more upvotes he got, the more downvotes came in (not just on that post, but other posts in my profile). Eventually, a mod stepped in to remove his comment. In his words, \"we don't do public lynchings\". But it was extremely bizarre, the guy wrote a 8 paragraph essay proving I used ChatGPT to write my article (I didn't).\n\nIt is bizarre indeed. This Reddit seems to have a lot of immature people upvoting low effort, accusatory comments even when they're blatantly wrong, or completely baseless at least... the easiest kind of comment to get upvotes without any effort is to accuse blog post authors of having used ChatGPT. It's almost like people think only ChatGPT is able to write well structured posts using correct language (look, there's no typos, obviously AI!!). Another is to pick on some sensitive topic even if just tangentially mentioned in a post, and completely deviate the discussion from the main topic. Works every time.\n\n[deleted]\n\nEh, Reddit was better back then, we just had users like the guy who faked cancer and the other guy who ran all the nsfw subs, and dumb memes like pancakes dont you mean waffles hahaha\n\nIt's eternal September. Don't forget you are probably arguing with some 18 year old with no real world experience.\n\n[deleted]\n\nI feel you. I had people downvoting all my posts on a thread of mine, just because I summarised the opinion of a renowned professor in the field on what went wrong with the Horizon IT-system and people disliked his conclusions. These hiveminds suck and can sink many hours of work because of an unpopular fact. Having said that, I also had some successes in my articles being upvoted, one spent considerable time on both the top of hacker-news and r/programming and the comments in those cases were just as bad as with the unpopular ones. In other words, the angries in the comments aren't representative of the general readership of the articles, in fact they represent a small minority of them. Once I've learned this, it helped me to put a perspective on these events. Hope this thought helps you as much as it helped me.\n\nHonestly, though, this article is also poking the community with a sharp stick. This will get you to interact with \"angry fanatics\" pretty much everywhere.\n\nWasn‚Äôt there a dude on here or on YouTube that said that some word meant that a paper was from ChatGPT because the word started trending around ChatGPT launch. Like he lived in a world where certain words don‚Äôt get more popular at certain times\n\nPeople say all kinds of shit to \"\"prove\"\" you used ChatGPT to write your articles. The same commenter said because I started writing roughly the same time ChatGPT was released, and that I wrote quite frequently, that I must use ChatGPT to write the articles.\n\nYou can't make this shit up.\n\nAfter working in this industry for almost 15 years, I can confidently say that it boils down to ‚Äúprogrammers are grumpy narcissistic assholes‚Äù.\n\nThe only languages where you won‚Äôt find this mindset is probably typescript where everyone knows and recognizes the language etc sucks balls but they‚Äôre just trying to make the best of a bad situation.\n\nWith Rust/Go/et al they‚Äôre trying hard to build something better and you‚Äôve come along to complain about their work.\n\nDon‚Äôt get me wrong though I totally get you on some of your points‚Ä¶ I fucking hate Rust‚Äôs syntax sometimes. Like why do I need to do all the `if let Ok(blah) = blah.await else {}` when I could just have something like a nice clean do-notation or pipe‚Ä¶ in the end they‚Äôre doing many of the same things a language like Haskell does but doing cartwheels to avoid a saner syntax.\n\n&gt; The only languages where you won‚Äôt find this mindset is probably typescript where everyone knows and recognizes the language etc sucks balls but they‚Äôre just trying to make the best of a bad situation.\n\nIn my 30 years experience (not trying to argument ad authority or age, but to show that at least I've had some exposure), I've found C, C++, lisp[1]/scheme, and ruby communities to be pleasant. \n\n\n[1] I'm old enough to have had discussions with Erik Naggum in comp.lang.lisp, and even he, in his abrasiveness, wasn't without kindness. The fucker *knew* what he was talking about as well.\n\n&gt; C++\n\nExcept the subreddit which is full of people with extremely prescriptive views about how one should be allowed to program in C++.\n\nNaturally, quite a few of them are contradictory.\n\nIn my experience, as long as you do not ever write \"C/C++\" in a message, you can generally have a sane conversation with the C++ community :)\n\nBut then, my experience is generally positive with most PL communities. Starting with Rust.\n\nJust to be clear: I do not count Reddit as being representative of any PL community.\n\nIME, I'd add C++ people to the exceptions. I don't spend much time in those communities, but people are willing to admit the warts. They'll still argue for why C++ is better despite the warts, or at least better for their use case, but it's very hard to try ignoring the issues.\n\nI am not a fan of the infix syntax too, and it could be better (I think there is an RFC to add a postfix alternative), but for me, the stronger the type system the better.\n\nAs for Haskell... I don't remember if it was Haskell specifically, or some other functional language, but I bounced where all the tutorials I found started with an intro to lambda calculus.\n\nThe C++ community has humbled a lot over the years. Back in the 90s and early aughts when Boost and the STL were introducing generic programming to the broader world and C++ was dealing with the explosion in error message size and compile times, the community was insufferable. Either you knew every esoteric aspect of the language and pretended you could follow the error messages or you weren't worthy of using C++. (I'll admit I was partly guilty of this back then)\n\nAt the same time, they were getting pushed out of corporate dev by Java and C# and Java was replacing everything in undergrad curriculums (\"that's what industry wants!\"). Python + Numeric/NumPy were starting to edge in on their (small, but hard won) turf in scientific computing, so they did have legitimate reasons to be on the defensive. \n\nNow that C++ has found its niches and is ensured a stable place in the pantheon of languages, the community has chilled out.\n\nMaybe the same will eventually happen to Rust?\n\nDespite being a computer user since late 90s, I only ever started participating in online communities the past five, maybe seven, years. So I skipped all the C++ flame wars.\n\n&gt; users that aren‚Äôt assholes\n\nMaybe I got lucky, but I found the Julia community to be polite and helpful. I thought maybe it's because these people are numerical analysts.\n\nThis is why I also used the qualifier `decent size` which isn't very clear. Maybe Julia still is small enough to not drag in a lot of the problematic people that come with general popularity?\n\nIn my experiece languages with smaller number of users often consist of people who has a general interest in programming languages and/or computer science. Most of the time the early community don't have a need to prove that a particular languge is \"better\" than another one or whatever the controversial topic of the day is. \n\nThere is of course always a risk of some problematic individuals joning early as well but it's much easier to deal with than an endless stream of new anonoymous posters on reddit.\n\nSay what you will about Java, but the community is very nice - helpful bunch, very few snobs and all programming styles are welcome.\n\nMany people judge Java for the language quirks or for JVM performance, while in reality the thing that matters most in 99% of real world projects is community and ecosystem - and both are superb in javaland.\n\n/r/csharp would like a word.\n\nNah we know our language sucks but enjoy the masochism\n\nThe csharp community mostly consists of people doing business related stuff with it. So helping a another lost soul is appreciated.\n\nC sharp doesn‚Äôt simply suck. It steals all the good parts from new languages and bolts them onto itself in a desperate attempt to look good. It‚Äôs a monster and it‚Äôs my favorite\n\nYou said it, it takes the good parts from other languages. That's not a bad way to go about creating a language that works well.\n\nI attended a talk by Mads Torgersen and he mentioned that the language team wants to start deprecating old C# features in the future. This should certainly help make the language less of a monster as you describe it.\n\nIt‚Äôs that or end up like C++. As the old saying goes ‚Äúmost people use only 10% of C++, and that‚Äôs fine. The problem is that everyone uses a different 10%‚Äù.\n\nI think we can take this whole thread replacing C# by Java and it will be totally correct.\n\nI‚Äôm unconvinced the JVM isn‚Äôt one of the seven circles\n\nthats silly. c# is probably one of the best architected languages/frameworks around. I can't hardly think of a footgun anywhere in the language, except maybe around the latest features like primary constructors.\n\nHow does it suck? I love it\n\nI did C, cpp,  some js and c# for money\n\nAnd c# definitely does not suck\n\nExcept the language itself doesn't suck. There's things about the ecosystem which isn't great, but the language itself is a total joy to use. It fits its use case magnificently, a higher level managed runtime based language focused on building large applications. If you want to write drivers or low latency trading platforms then avoid, but if you just want a Web server it's a solid choice.\n\nI write garbage. I should feel like garbage.\n\nwait until the garbage collector picks you up\n\nTake me home,\ncountry road,\nto the place,\nwhere I belong!...\n\n90% of developers are just working professionals who clock in and out of their job, then go home and live their life. All the business oriented languages don't have the same tribalism vitriol,¬† because they haven't made it a core component of their identity.\n\nI hear the Ruby community is nice.\n\nRight. So the author wants to vent. I can appreciate that. I personally want to vent quite regularly on another programming language. We've all been there.\n\nFor context, I've looked up OP's screen-captured conversation, which revealed a few things.\n\nFirst, OP is a junior developer coming straight from TypeScript and Python and into Rust. Rust can indeed be quite a culture shock. Some people realize that they hate Rust, which makes entire sense, because Rust is neither for every task not for everyone ‚Äì I'm saying this as someone whose current favorite languages are Rust and TypeScript. In particular, OP went straight for a fairly advanced topic (writing generic async callbacks), using way too advanced techniques (`Pin`), which is a surefire way to burn oneself out. I'm sorry you had to live through that, OP.\n\nOP, if you're reading this, have you tried something [along these lines](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2021&amp;gist=dfb54f60e2ebc35193d76f292625673e)? I don't think it's harder to understand than the full Go version (your Go screencap seems to be missing a type definition, so I can't judge for sure), but YMMV.\n\nSecond, the screen-captured conversation is sadly typical of Reddit. OP comes in a bit strong (the very topic contains the word \"shitty\"), the conversation attracts some people who want to crap on MongoDB (and who afaict are not regular members of /r/rust) along with some people who genuinely want to help but can't (because OP requests help but won't provide any technical detail), nobody is happy with the result. Definitely something that could have played better, for everybody involved.\n\nOP, if you're reading this, and if you ever feel like giving it another try, perhaps https://users.rust-lang.org/ would be a better place?\n\nFinally, yes, OCaml is simpler than Rust :)\n\nThe OP admits that they're using LLMs to write Rust code, so I have no doubt the intentionally obtuse code from the article is at least partially autogenerated. They took their Typescript/Python mindset straight to ChatGPT, compiled some crap, then wrote a medium article about it. GIGO.\n\nI don't think that the code from the article is particularly obtuse, either in Go or in Rust. It may or may not have involved LLMs, but then, who are we to judge whether a developer should use LLMs?\n\nRegardless, it feels like someone who dove in the deep end (attempting to implement a `Box&lt;Pin&lt;Future&lt;...&gt;&gt;&gt;`, which is something I've done about twice in ~14 years of Rust) without the prerequisites and got frustrated. It can happen to anyone of us.\n\nDespite saying a quite few things I regret on Reddit, the only sub I've been banned from is r/rust. My crime, suggesting M$ may come up with rust#.\n\nEDIT https://ibb.co/wpHF9wG\n\nAnd now there's a person writing a .Net codegen backend for Rust as a personal project. Doing great work too.\n\nDo you have a link? I'd be interested to see it.\n\nhttps://www.reddit.com/r/rust/comments/1doh929/media_the_rust_to_net_compiler_backend_can_now/ is the latest. Seems it was a GSoC project.\n\nyou know, first we need rust++ then we can talk about #\n\nWas that for `M$`?  That was new in 1992.  New kids, amiright?\n\nYeah since 1996 we've been calling them Micros~1\n\nHm, are you sure that was the reason?\n\nSmells of [missing missing reasons](https://www.issendai.com/psychology/estrangement/missing-missing-reasons.html).\n\nWhat a great read, thanks for sharing!!\n\nSeriously, I haven't found such a interesting article on a topic I know not-enough-of in years.\n\nCheers!\n\nHot damn that article basically textbook describes the way people with borderline personality disorder live life: with their emotions as the single source of truth, not reality.\n\nThis user is not, in fact, banned from r/rust.\n\nIf you used another user which was banned, I'd be more than happy to examine the reason, and possibly rescind the ban. Please send a modmail to us from your banned account to get the process started.\n\nI had a look and apparently it was a pointless comment. [https://ibb.co/wpHF9wG](https://ibb.co/wpHF9wG) . Still felt harsh to be permanently banned.\n\nThat's very strange, I can't find your username in the list of banned users.\n\nWe did have a wave of trolls around the announcement that Microsoft was working on Verona, in which conditions we (and specifically I) may have handed bans a bit more liberally to stem the flow, with the idea that genuinely interested users who just made a mistake would just appeal the ban and we would sort it out, so it's definitely possible that it occurred... but then I should be able to find your user in the banlist.\n\nCan you access r/rust these days?\n\nYou did not get banned for that, stop making up bullshit.\n\nAre you saying that someone would just lie on the Internet? Just like that?\n\nHaving written multiple trading strategies, OMS,EMS, realtime analytics, pricing libraries and way too many exchange connectors since 2004 using Q, C, C++, Java, C#, Python, Go and Rust, here is my take on the OP‚Äôs article:\n\nChoosing your language should come after choosing your tail latency requirements.¬†\n\n- latency &lt;5ms -&gt;, no GC: c, cpp, Rust¬†\n\n- latency &lt;50ms -&gt; fast GC : Java/.Net/OCaml / Q\n\n- latency &gt;50ms -&gt; interpreted or how go-level: Scala, Haskell, Python, Lua‚Ä¶\n\nHigher-level languages give you ‚Äúnicer‚Äù code at the price of runtime complexity, obviously, but the main issue is not how nice your code looks but how it behaves.¬†\n\nHaving written a realtime execution platform in both Go and Rust, my Go project failed for two reasons:\n1- tail latency due to GC were crazy (wrong tool for the job)\n2- I am not an expert and disliked the language (pre generics, and I dislike duck typing)\n\nI have picked my ‚Äústack‚Äù based on these constraints, and either build my systems in Q, Rust, .Net, or Python. ¬†I have invested the time to master (or be more than dangerously proficient with) each ecosystem and would have to achieve the same level of skill if I were to swap a tech for another.¬†\n\nTL;DR: don‚Äôt write trading systems in a language you do not master. Try smaller projects like market data connector or order book simulator first to get the hang of it.¬†\n\n&gt; TL;DR: don‚Äôt write trading systems in a language you do not master. Try smaller projects like market data connector or order book simulator first to get the hang of it. \n\nTo expand here, as someone with a much shorter experience time with Rust than the blog writer, there are several tells in their code example and their responses here of a lack of proficiency, like\n\n* Using `println` for error messages, instead of something like [`tracing::error`](https://docs.rs/tracing/latest/tracing/index.html#using-the-macros) for a proper logging system, or even `eprintln` to print to stderr. That sort of thing should elicit a \"wait, hang on\" response for professional code in _any_ language.\n* Apparently no exposure to [`anyhow`](https://docs.rs/anyhow/latest/anyhow/) and [`color-eyre`](https://docs.rs/color-eyre/latest/color_eyre/), which come up very frequently in Rust discussions and code as examples of how to handle errors in a simple yet powerful way. In addition they seem to have just ignored the bit where Rust panics tell you about the `RUST_BACKTRACE` variable.\n*  Mixing up syntax errors and semantic errors. E.g. \n  * When Rust needs hand-holding with the type restrictions for a generic function, that's not a syntactic problem, it's a semantic problem. Other languages may either not even offer generics (like early Go), or gloss over it, by passing just `interface` or `Object` or `void *`. or other equivalents of the [Any](https://doc.rust-lang.org/std/any/) type. \n  * When it complains about mutable references and ownership in concurrent code, those aren't syntactic problems, they're semantic problems.\n\n  It's part of the sales pitch for Rust, that those kinds of problems are actually caught by the compiler, rather than become runtime errors or inscrutable race conditions.\n* Repeating themselves in the Go code: By having an `if attempts == maxRetries-1 { return ... }` inside the for loop they'll never reach the `return nil, errors.New...` beyond it.\n\nI'd kind of consider being exposed to stuff like tracing and anyhow to be part of the stuff you do in the first few weeks with the language as you're familiarizing yourself. Going 18 months and writing an angry blog post instead sounds harsh.\n\nMight be kind of a warning tale for what can happen if someone tries to learn a language through ChatGPT rather than more traditional ways?\n\nIMO, it's also a good example of an expectation that \"all languages are essentially the same apart from runtime characteristics.\" OP seems to have found out the hard way this isn't true: TypeScript and Rust really don't have much in common beyond the _very_ loose observation that both support a kind of uneasy mix of imperative and functional constructs. I'd probably be OK with the post in general, were it not for OP's claim Rust exhibits \"bad language design.\" But his example code makes clear, as others have pointed out, that he didn't actually learn the language or its ecosystem beyond what many do in their first month. So at least _that_ aspect of his claim seems to be undercut by those other responses.\n\nSo I hope OP takes this thread as an opportunity to maybe revisit his project, expand his exposure to Rust and the ecosystem, maybe study a broader and deeper range of examples, and if he discovers Rust isn't as bad as he thought, great; if he decides it's still not for him/this project, also great. But at the very least, I think there's more to learn and try than his conclusion here indicates.\n\n&gt; Might be kind of a warning tale for what can happen if someone tries to learn a language through ChatGPT rather than more traditional ways?\n\nI feel like it's about equivalent to learning language based on random tutorials rather than reading a proper book and understanding it deeper. Like, he complained about Rust but the Go code also isn't anything to write home about, just big blob of code that should really be split on \"function that does the thing\" and \"function that retries it\".\n\nI don't think its fair to put Scala and Haskell in the same category as Python.\n\nHaving used both professional I would have expected Java-level performance out of both but sadly that wasn‚Äôt the case. \r\n\r\nTo be fair this might be due to the aging code bases and army of contractors that built software by accretion rather than the languages themselves.\n\nFor latency &lt; 50ms Go should be acceptable. Isn't it? At least after Go 1.14, when preemptive scheduler were introduced.\n\nYo are absolutely correct, my subconscious removed go from the list after a traumatic experience :) \r\n\r\n\r\nGo/java/.net are pretty much in the same perf ballpark in terms of perf, unless you‚Äôre looking at async IO and scalable concurrent tasks where Go shines.\n\nOn JVM world, there is a Genrational ZGC since jdk 21 which can have 1ms latency and lower\n\nHow tail are your tails?\n\nI've seen Java trading applications in the 5us band most of the time, and they were not particularly optimized -- they GCed _a lot_ -- but still fast enough to be below 5us 99.9% of the time -- ie, anytime the GC didn't kick in.\n\nIf we're talking about the episodes where the GC does kick in, then post JVM 14, the GC pauses were under 5ms so no problem.\n\n&gt; Just give me a garbage collector, and let me do what I want to do!\n\n&gt; I‚Äôd rather my application take a few dozen milliseconds longer to run if it means my development time is cut in half.\n\nI've barely written any Rust, but from my perspective it's obvious that Rust just isn't the language for your use cases; sometimes the round peg doesn't actually go in the square hole.\n\nThere are absolutely workloads where garbage collection is way too slow and/or unpredictable; every microsecond matters. When you need very explicit memory management, it's easy to get wrong, and languages like Rust try to make it safer without sacrificing speed or flexibility.\n\nI do agree with your point that Rust is praised as the second coming of sliced bread, it's wild to see it suggested in places where you'd never think about suggesting C or C++. Sure you *could* write a web server or desktop app or ML/AI stuff in Rust, but honestly why would you? There are much better tools and ecosystems for those jobs.\n\nEverything goes in the [square hole](https://youtu.be/6pDH66X3ClA).\n\nOnly if that square hole is C ABI compatible\n\nThat's okay, it's probably compatible to [at least _one_ \"C ABI\"](https://faultlore.com/blah/c-isnt-a-language/#c-doesnt-actually-have-an-abi).\n\nI will never not watch this\n\nI will never not be frustrated watching this.\n\nRust or C++ are absolutely the best languages for OP's usecase if they had an entire SDE department working for them. But for what OP is doing on their own, it's a pretty bad fit.\n\nwrite a web APP in rust? stupid.\nwrite a web SERVER that hosts apps? maybe not so stupid.\n\n\nSee also; Every other purpose build web server written in c/c++\n\n&gt; purpose build\n\nNot to be an ass, but \\*purpose *built*\n\nI‚Äôm testing that thesis with Leptos + Tailwind. It‚Äôs surprisingly great in many ways, but the dev cycle time is slightly slower than hot reloading a JS web app.\n\nIt‚Äôs more of pet project than anything I‚Äôd recommend for a business to use (unless everyone on the team already has rust exp)\n\n&gt;I've barely written any Rust, but from my perspective it's obvious that Rust just isn't the language for your use cases; sometimes the round peg doesn't actually go in the square hole.\n\nBut the joke is that the only jobs are for writing cryptocurrency trading engines. So trading engines in Rust are supposedly the perfect project.\n\nunironically algo trading is where you don't want to be hit with gc\n\n&gt; I've barely written any Rust, but from my perspective it's obvious that Rust just isn't the language for your use cases\n\nHe literally rewrote an existing application in Rust because his use case, performance dependent code with high reliability requirements, is pretty much the exact use case Rust is targetted at.\n\nThat line is him saying that even though his use case is exactly right for Rust it still wasn't worth the downsides. Even though the languages strengths directly map to his needs it still wasn't worth the hassle.\n\nIf I understand correctly, the previous version was made in Typescript. \n\nIf that's the case, we now have two wrong language choices for the same user case.\n\nLet me give him a hint for next try: php.\n\nI'm just gonna re-write it in Python and call it a day   \n(/s)\n\nIf you want a GC, I think Go is the obvious choice here. OTOH you'd probably be approaching mental illness if you rewrote this thing again.\n\nI work on a very large performance sensitive Go application and never once have I said \"I wish this were in Rust\", and your article just drove that home further.\n\nTypescript is a fine choice to start with for this because there exist free exchange integrations in the language. We use it for our admin web app. It‚Äôs going to be hard competing true HFT right from the start so you probably want to get somewhere and trade slower to build something. \n\nWe use Java with JNI (for network stack) for trading and it‚Äôs fast enough. It was sufficient stuff to make it to top/top three volume on many of the major exchanges. A lot of the magic is in figuring out networking and hardware and the cloud (because many exchange MEs are in the cloud).\n\nWe do have Rust in live trading for some stuff (feed handling from the CME) and extensively in simulation (filesystem stuff up). Overall, when I look at practitioners of Rust like burntsushi they are very good at writing code in the language. The problem is that the language ramp is high.  less so than C++ imho but C++ has more experienced practitioners.\n\nIn any case, this was a useful article. I find that LLM assistance plus frequent compilation is the best way through Rust. Java‚Äôs IDE story is way better. Even RustRover isn‚Äôt close.\n\nIf he rewrote in Rust, but is now complaining about GC, either he didn't have the use case for Russ or didn't understand his use case. If you find yourself yearning for GC then Rust was the wrong choice. \n\nI hear a lot of trading systems are still written in Java.\n\nNo, he is saying he would gladly trade the downsides of a GC for the upside of not having to deal with Rust anymore. He praises Rust for delivering on what it said it would he's just saying his dislike for the language is such that he'd rather take the performance hit of a GC in future.\n\n&gt; He literally rewrote an existing application in Rust because his use case\n\nAccording to his own blog, that is not the reason.\n\nThis is their stated reason:\n\n&gt; Every guide on Medium, every post on Reddit, every answer on Stack Overflow ‚Äî everything is glowing.\n\n&gt; Given this, I decided to re-write my entire open-source algorithmic trading system in Rust.\n\nFrom the first article in this two article series talking about why he chose Rust:\n\n&gt; NextTrade was built using TypeScript in order to focus on maintainability, readability, and reusability, however, when the core trading logic started experiencing significant performance issues, a full rewrite was necessary in order to build a paper-trading and backtesting platform that could scale to tens of thousands of users. Thus, Rust emerged as a top contender, and after a lot of research, eventually won as the language to use for the overhaul.\n\nHe didn't just randomly choose a language, he looked at the specific needs of his app and saw that they were all the things Rust is supposed to provide.\n\none can make research and come to the wrong conclusion.  \n\n&gt; Just give me a garbage collector  \n  \nthis would already exclude all the top \"performance\" languages, C, C++, Zig, Rust.  \n  \nHonestly only go, java or c# would remain on the table  \n  \nProbably at the time he did not realized how much simplicity was giving up in exchange for a performance hit, and that give him the wrong stick to compare.\n\n&gt; Probably at the time he did not realized how much simplicity was giving up in exchange for a performance hit, and that give him the wrong stick to compare.\n\nExactly this. I didn't realize how much these high-level languages helped with holding my hand.\n\nI didn't want to re-state the same information in a previous article. I also didn't want the article to be overly long. But, maybe I could've done a brief recap of what I've talked about before.\n\nu/nnomae is correct. I put a lot of thought into what language I wanted to use. Rust was supposed to be ideal for my use-case. I didn't just pick it because randos said its a cool language.\n\n&gt; Just give me a garbage collector, and let me do what I want to do!\n\nIf you‚Äôre ok with saying this, then Rust (and C and C++)  is the wrong language for the job. Literally THE selling feature of rust is to have memory safety, without garbage collection. For high performance/ time critical systems garbage collection is death. \n\nDo I need to read any further?\n\nThat was my understanding.  I'm a C dev by day and the only GC language I've done any professional work in is C#\n\nAnd my god I had to fight against the GC as I was live processing and displaying image data and the software would repeatedly hitch.  I had to repeatedly \"request\" that the GC run at a time which would keep the framerate stable, but even that was just a suggestion as the GC execution time was non-deterministic\n\nDoes that mean that GC is always bad?  No, it means that GC is not the right tool for the job I was doing.\n\nI used to work on a team that did performance work on both JVM and C# managed runtimes. We made massive progress on the JVM but our meetings with Microsoft didn't go so well. We identified tons of threading issues, bad code causing mispredictions, poor code causing cache misses. All kinds of issues that had reasonable fixes suggested.\n\nAt our meeting to hand off our research, they told us a story.\n\nFirst of all, they were well aware of every single thing we had identified. Second, the engineers that wrote the lowest layers of the of the windows kernel and support libraries long since moved up the ladder or called in rich. Teams that came in after them were not familiar enough with the low level code to add the features they needed so built abstractions on top.\n\nThose teams also eventually moved on and so the cycle kept going of adding abstractions to abstractions. Built into those layers of abstractions were workarounds for bugs that nobody even remembers which makes fixing things at a low level almost impossibly complex.\n\nThey said the only way out was a ground up rewrite which was probably never going to happen.\n\nI always wonder if their friendliness to linux is because that might be their ultimate goal to solve that issue.\n\nWas this before or after .Net Core? Because that was (to some degree) that rewrite that gave them much more freedom to change things (including not being tied to Windows).\n\n[deleted]\n\nFiguring this out and correcting it is \"fighting the GC\".\n\nYes. The author also claims Rust doesn't have stacktraces even though crashes tell the user that the can get a stack trace by enabling an env var.\n\nNot entirely true, you only get backtraces for free if you panic. But he is printing error messages and just doesn't know about `backtrace::Backtrace` to print it himself\n\nThe \"complex\" transaction function example is pretty poorly written as well. As earnestly as I can say it, I think the author just doesn't really know rust that well.\n\nIf they took some time to learn a few of the common libraries and patterns that people use for error handling, they would probably have a better time. It also does get easier to understand how to specify the right generic type signature the more you do it.\n\nI write rust full time for my job, and the code they wrote wasn't hard to comprehend, it just seemed like something I would see in a junior engineer's code review.\n\nEDIT: I truly don't intend this comment to be mean-spirited. I empathize with the author's frustration. Online communities can be very unwelcoming, and Rust has a steep learning curve. I do think the author's struggles can be overcome with more learning.\n\n&gt; The \"complex\" transaction function example is pretty poorly written as well.\n\nI gave up on the article when I saw the Go equivalent the author showed. The rust function definition was complex (including multiple traits and at least one lifetime), but then they compare it to the Go function that returns `interface{}, error`, which is the equivalent of returning `void*`.\n\nI could maybe understand that after trying Rust to get away from GC OP got burned and decided GC is worth it after all (lifetimes are hard after all), but to abandon type safety as well? At that point the article might as well be generated by an LLM, as OPs understanding of how to pick a language seems to be about as deep as a hallucinating LLM.\n\nHe also mentions using an LLM, and they are terrible for rust.\n\nThe complains from the author about the issues suggest it's a skill issue. If you are fighting with \\`where\\`s, you probably don't know what you need.\n\nIs not the point then there is a steep learning curve and after 18 months he's still not understanding certain concepts also demonstrate the difficulty in learning the language?\n\nAs someone coming from a dynamic programming background, I also found rust very difficult without a mentor to help me understand it better.\n\nIf at 18 months your takeaway is ‚ÄúGive me a gc and let me go my merry way‚Äù then you‚Äôve learned nothing.\n\nFor me, once rust clicked, which was in a couple of weeks, the way I thought of memory ownership and management in C and C++ changed fundamentally for the better and I genuinely became a much more mature programmer.\n\nI think its really the journey from different places leading to different outcomes. Rust was written as a better C++, its going to be most appreciated/enlightening for people who come from a managed memory background. I get the feeling that OP had only really worked with TypeScript before Rust. And he was trying to port a TypeScript project to Rust. With that approach, I can understand how it never clicked. He never really understood the problem that Rust solves. I think he was just hoping to rewrite the same algos in Rust and have it magically be faster without really having to learn how to think about the problem differently.\n\nI think you are on point; if your background is gc‚Äôd languages, rust will feel like a downgrade because it is. The benefits are not obvious and if anything feel limiting.\n\n\nIf on the other hand you have struggled with cpp, c and had to learn to be very careful, rust‚Äôs approach feels genuinely like freedom and a breath of fresh air.\n\nMy background is GC languages. I know next to nothing about C. Rust isn't \"18 months of learning curve\".\n\nAs someone who recently forced themselves to go through the struggle of attempting to learn Rust, any pointers?\n\nLearning to use Rust in general was awesome, and mapped nicely to my C/C++ understanding. Life was awesome until I decided to try to implement data structures. My brain melted a little while working my way through [Learn Rust With Entirely Too Many Linked Lists](https://rust-unofficial.github.io/too-many-lists/).\n\nI didn‚Äôt.\n\nOP clearly isn‚Äôt the audience for Rust. I doubt many would pick Rust as their favorite syntax given any language, and that‚Äôs not what it‚Äôs selling.\n\nWhen you are coming from say, an embedded environment, it provides a leap in _functionality_. I‚Äôm sure many would gladly pay in syntax for the difference.\n\nIt does have some nice syntax features though, and I prefer it over C. That said, unvirtualized languages simply don‚Äôt have the room to dream ‚Äî  rubber must meet the road down to every last type, until it can be fully described at the machine level. By their very nature these languages enforce this by front loading that effort into syntax.\n\nThere's a compiler, no?¬† It's not like we're writing assembly here.\n\n&gt; That said, unvirtualized languages simply don‚Äôt have the room to dream ‚Äî rubber must meet the road down to every last type, until it can be fully described at the machine level. By their very nature these languages enforce this by front loading that effort into syntax.\n\nOr, hear me out, use dynamic dispatch. `Box` in Rust, virtual functions in C++, or function pointers in C. And if anyone tells you it's slow, they don't know the [three rules of optimization](&lt;https://course.khoury.northeastern.edu/cs5010f17/Slides/08-Efficiency-Lessons/theRulesOfOptimization.html?&gt;).\n\nGiven that this is a medium article, I think OP basically wrote an inflammatory post for money.\n\nThere are far, far better criticisms of Rust, which I enjoyed reading and which will eventually make the language better. They pointed out real issues that need to be fixed (or avoided by people choosing a language), and they did it without hyperbole or charged language.¬†¬† ¬†\n\nSeriously, read one of these to understand how mature people write sane critiques that are well received. After the video game critique was published it led to a lot of reflection in the Rust video game community about how they could be doing better.¬†¬† ¬†\n\n- [Why Not Rust](https://matklad.github.io/2020/09/20/why-not-rust.html) written by the developer who started the rust-analyzer project.¬†¬†¬†\n- [Frustrated? It‚Äôs Not You, It‚Äôs Rust](https://fasterthanli.me/articles/frustrated-its-not-you-its-rust) by fasterthanlime, one of the most prolific writers and content creators on YouTube. This article is a _31 minute read_, so he gets deep into Rust‚Äôs flaws.¬†¬†\n- [Lessons learned after 3 years of fulltime Rust game development, and why we're leaving Rust behind](https://loglog.games/blog/leaving-rust-gamedev/)¬† ¬†\n\nSeriously, look at how well that video game article was written. It got 2.1k upvotes on *the Rust subreddit*, along with a ‚Äúmeaty‚Äù tag that many aspire to but few get. Look at the comments on the [reddit thread](https://www.reddit.com/r/rust/comments/1cdqdsi/lessons_learned_after_3_years_of_fulltime_rust/) - the top comment with 1.1k upvotes is effusive in praise of the article for giving such constructive and useful feedback!¬†\n\nYou said¬†\n\n&gt;¬†the Rust community isn‚Äôt as nice and cool as they pretend to be. They‚Äôre a bunch of narcissistic assholes that hate being told that their favorite language has flaws.¬†\n\nYou call people narcissistic assholes and then act like a surprised Pikachu when they don‚Äôt praise you, reinforcing your opinion that they‚Äôre assholes because only assholes would fail to see your genius right?¬†\n\nIf there was even a shred of truth to this allegation, that video game thread wouldn‚Äôt be the **7th most popular post on the Rust subreddit of all time**. The Rust community loves this sort of criticism!¬†¬†\n\nYour article isn‚Äôt even as constructive, enlightening or useful. My opinion, of course. But please don‚Äôt be upset that people aren‚Äôt praising your article or agreeing with you. They aren‚Äôt because your post just isn‚Äôt that good. Your critique is superficial, while also being rude and alienating.¬†\n\nIn a comment around here I claimed it‚Äôs a skill issue on OP‚Äôs side, and given the criticisms they presented, i stand by that comment. \n\nBut, that isn‚Äôt to say rust doesn‚Äôt have issues, and tbh the rust community is the first one to point those out. Async is perhaps the biggest one, the unwieldyness of pointers is another one ‚Äî zig does great here btw. Programs of certain structure are very difficult to represent with current borrowck, and on and on. \n\nRust is far from a perfect language, but if you are going to be a critic, at least be a good one.\n\nFair criticism. I'll take a look at the articles you linked, thanks!\n\nIt‚Äôs not just what you say, it‚Äôs the way you say it.¬†\n\nMy first draft of this comment was much harsher, picked specific examples that I found lacking.¬†\n\nBut I deleted all of that stuff before posting, because there was no point alienating you before you got to the meat of my comment, which is that there has been a lot of quality criticism already written and it has been welcomed by the community.¬†\n\nJust imagine if my comment had started with ‚ÄúOP is a fucking moron and here‚Äôs why ‚Ä¶‚Äù. You would have stopped reading right there.¬†\n\nI‚Äôd suggest you adopt that while writing too. Get the first draft out with all your feelings and then edit it so that people will actually read and respond to it. Use the compliment sandwich technique if necessary. People will appreciate it far more, and it‚Äôll end up being constructive. And bonus for you, you‚Äôll end up looking mature and technically sound.¬†\n\n&gt; I‚Äôm just an idiot and can‚Äôt figure out how to enable stack traces\n\nI thought I got stack traces on Rust out of the box on Linux. Am I misremembering or is he on a different platform?\n\nWorks on windows just fine too, just had to set env variable RUST_BACKTRACE=1. I'm not sure what author is confused about...\n\nThe default panic message literally mentions setting `RUST_BACKTRACE=1` as well...\n\nPanics and some error types support backtraces. This is enabled via the RUST_BACTRACE environmental variable. It should work on any platform.\n\nAre your referring to panics? Or handling results?\n\nYou can capture and print a backtrace at any time. You can also store them in your error structs/enums and print them down the line, or just use a library like anyhow (which is [doing that internally](https://docs.rs/anyhow/1.0.86/src/anyhow/error.rs.html#872)).\n\n    use std::backtrace::Backtrace;\n    \n    println!(\"{}\", Backtrace::capture());\n    println!(\"{}\", Backtrace::force_capture()); // Works without `RUST_BACKTRACE`\n\nNot sure about the std lib errors, but with the `anyhow` crate you can get a backtrace for errors:\n\n    \n    use anyhow::{anyhow, Result};\n\n    fn inner_most() -&gt; Result&lt;()&gt; {\n        Err(anyhow!(\"inner-most\"))\n    }\n\n    fn inner() -&gt; Result&lt;()&gt; {\n        inner_most()\n    }\n\n    fn outer() -&gt; Result&lt;()&gt; {\n        inner()\n    }\n\n    fn main() {\n        if let Err(e) = outer() {\n            eprintln!(\"e = {:#?}\", e.backtrace());\n        }\n    }\n\n\n...\n\n\n    $ RUST_BACKTRACE=1 cargo run\n    Compiling foobar v0.1.0 (...)\n        Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.16s\n        Running `target/debug/foobar`\n    e = Backtrace [\n        { fn: \"anyhow::error::&lt;impl anyhow::Error&gt;::msg\", file: \"...\", line: 27 },\n        { fn: \"anyhow::__private::format_err\", file: \"...\", line: 689 },\n        { fn: \"foobar::inner_most\", file: \"./src/main.rs\", line: 4 },\n        { fn: \"foobar::inner\", file: \"./src/main.rs\", line: 8 },\n        { fn: \"foobar::outer\", file: \"./src/main.rs\", line: 12 },\n        { fn: \"foobar::main\", file: \"./src/main.rs\", line: 16 },\n        { fn: \"core::ops::function::FnOnce::call_once\", file: \"...\", line: 250 },\n        { fn: \"std::sys_common::backtrace::__rust_begin_short_backtrace\", file: \"...\", line: 155 },\n        { fn: \"std::rt::lang_start::{{closure}}\", file: \"...\", line: 159 },\n        { fn: \"core::ops::function::impls::&lt;impl core::ops::function::FnOnce&lt;A&gt; for &amp;F&gt;::call_once\", file: \"...\", line: 284 },\n        { fn: \"std::panicking::try::do_call\", file: \"...\", line: 559 },\n        { fn: \"std::panicking::try\", file: \"...\", line: 523 },\n        { fn: \"std::panic::catch_unwind\", file: \"...\", line: 149 },\n        { fn: \"std::rt::lang_start_internal::{{closure}}\", file: \"...\", line: 141 },\n        { fn: \"std::panicking::try::do_call\", file: \"...\", line: 559 },\n        { fn: \"std::panicking::try\", file: \"...\", line: 523 },\n        { fn: \"std::panic::catch_unwind\", file: \"...\", line: 149 },\n        { fn: \"std::rt::lang_start_internal\", file: \"...\", line: 141 },\n        { fn: \"std::rt::lang_start\", file: \"...\", line: 158 },\n        { fn: \"main\" },\n        { fn: \"__libc_start_call_main\" },\n        { fn: \"__libc_start_main@@GLIBC_2.34\" },\n        { fn: \"_start\" },\n    ]\n\nif you propagate it to your `fn main() -&gt; anyhow::Result&lt;()&gt; {...}` it‚Äôll be formatted nicely, too.\n\nPanics and some error types support backtraces. This is enabled via the RUST_BACTRACE environmental variable. It should work on any platform.\n\nWhile I don't agree with the style of the article, I get it.\n\nThe first point for me is not \"syntax is bad\" but \"figuring out rust types is too often near impossible\". And for help I usually go to r/learnrust which I found more helpful. And yes, error handling is a bit whacky. I find it super odd that I need to add a crate or two just to handle errors in a sane way.\n\nAfter doing two projects with it I had the same conclusion - unless I really have to, I'd prefer something else.\n\nThe article piles up unrelated criticisms. Which makes it hard to discuss. Some are warranted, but, indeed, the point about types isn't.\n\n\nWell, it's hard. And the strong types as found in Rust, require some design up front (always bad). It's difficult to impossible to just yolo your way through a proof of concept and the discover the types you'll need.¬†\n\n\nDiscovering the types, shapes and architecture through writing the code, is a very normal process. Decades of experience give some intuition to speed up that discovery (I often know what's certainly not going to work). But with rust, that'll land you in these horrendously tightly coupled, complex, nested types.¬†\n\n\nSome tips that work for me:\n* Think about the shape up front.\n* TDD to discover what works and what doesn't.\n* Keep refactoring. Again. And again. And then some more. Functions and their fingerprint, like author posted are unacceptable to me.¬†\n* Better to define too much structs and aliases than too little.\n* As soon as I've discovered the rough shape, introduce value objects. (A creditcardnumber isn't a string. A db connection pool is a DBConnPool, not an Arc&lt;Box&lt;Some&lt;Result&lt;PGconnection, PGconnectionError&gt;&gt;&gt;&gt; )\n* Write quick POCs in Ruby or python to discover the domain and shape when it's entirely new for me. Allowing to focus on mastering the domain first.\n\nThe Go example you posted looks just as awful as the Rust one.\n\nGo feels like its 90% `if err != nil { return err; }`\n\nHonestly, that can just be solved by having an error propagation operator. Like Rust or Kotlin or pretty much any functional programming language.\n\nI wish Kotlin had Rust like error propagation operator. Kotlin has `?` for `null` checking if that is what you were thinking of.\n\nOutside of that kotlin has the normal java-esk try/catch/throw.\n\nNot a particularly insightful rant. And I do love a good rant. His three complaints are:\n\n1. Bad syntax\n2. Bad error handling\n3. Bad community\n\nHis complaint about no call stacks on error codes is interesting. I think maybe anyhow supports adding backtraces? I just learned that and am not sure how usable that is in practice.\n\nIt‚Äôs god damn criminal that std::fs operations have errors that don‚Äôt report the god damn file path that failed to open. But I digress.\n\n&gt; His complaint about no call stacks on error codes is interesting.\n\nIn the first big code screenshot, his error handling consists of\n\n* Converting proper errors to Strings\n* 'Logging' using println (to stdout, without a proper logging system so no line numbers etc)\n\nI don't know why he expects an error's human-readable display format to come with a stack trace. The `Display` impl for errors is typically things like `The filename, directory name, or volume label syntax is incorrect. (os error 123)`\n\nYeah, his error handling in Go is better with the `return nil, errors.New(\"blah\")`; the actual equivalent of the Rust code would be `return nil, \"blah\"`.\n\nI suspect he may have been tricked by how Rust calls the constructors of `Result&lt;a,b&gt;` for `Ok(a)` and `Err(b)`. It's not actually an error type, it's just a wrapper!\n\nHaskell's `Either b a` and `Left b` and `Right a` might be the better nomenclature for this; it really is just a variant of stuff you can express through a tuple in Go or Python as `(a, nil)` and `(nil, b)` (except without the `(a, b)` and `(nil, nil)` states).\n\nBut in all these languages and cases, proper error handling requires proper error types, not just returning a string in the failing situation.\n\n&gt; It‚Äôs god damn criminal that std::fs operations have errors that don‚Äôt report the god damn file path that failed to open. But I digress.\n\nIt‚Äôs likely because Path is an abstraction over OsStr, which doesn‚Äôt implement `Display`, because paths don‚Äôt necessarily have to be UTF-8. A compromise fallback would be to call `to_string_lossy()` I guess, since it‚Äôs likely to be fine most of the time.\n\nI would venture it's a performance issue, instead.\n\nThe problem of embedding the path in the `io::Error` is that you'd need:\n\n - A beefier error -- it's very slim, very cheap to copy right now -- for _all_ cases, even those without a filename.\n - To allocate in order to get an owned PathBuf.\n\nAnd _this_ probably send another segment of the Rust community arguing it's too costly and if others want the path they can just add it at their option at the call site -- which is a fair criticism, indeed.\n\nbad error handling? that's interesting, rust definitely is different in terms of error since it's a value, and I'd rather deal with rust option return than dealing with try catch nightmare, is it really bad or is it not familiar, because bad syntax can also be caused by not being familiar too\n\nHonestly I quite like Rust‚Äôs error handling. I utterly despise try/catch and think Python‚Äôs errors are infuriating.\n\nBut I think the lack of a callstack in Rust Results is a totally valid and interesting complaint. It‚Äôs something that Rust could do more betterer, imho.\n\nIn any ‚Äúhow to get started with rust‚Äù you get recommendations for two of the four popular error handling crates that support call stacks: anyhow/color\\_eyre for applications and thiserror/snafu for libraries.\n\nYes, one has to invest 5 minutes into choosing one of the two contenders for each use case if one knows of both, but both will get the job done if picked.\n\nThe stack trace is available, the problem is that OP just took the Error and converted it to a String via the Display trait, which then gets displayed via println (i.e. print to terminal). The display trait is specifically \"give me some readable error message, not too much details\". \n\nThe solution is to use real error handling and logging (e.g. https://docs.rs/thiserror/latest/thiserror/ and https://docs.rs/log4rs/latest/log4rs/, just two I use, other options are available), which can handle all of this for you. Or if you don't want to to use google for 5 seconds and find: stackoverflow.com/questions/56558321/is-it-possible-to-print-a-backtrace-in-rust-without-panicking\n\nAs someone that got used to the almost perfect stack traces of Java, playing with Go and Rust where errors are values was really jarring.\n\nBoth languages have modules/crates to add stack traces to errors, but it feels like this is a major hurdle for Developer Experience. It would be almost entirely positive to have stack traces added by default in development.\n\nI agree but I would guess the reason is to avoid allocation. You can add that information to a custom error.\n\nYour blog post confused me. It feels like you think you have legitimate, technical, issues with Rust. In reality, everything you complained about is a matter of taste/opinion/preference.\n\nI‚Äôm not trying to diminish anything you said. I‚Äôm just calling out something that feels like a discrepancy to me.\n\nAdditionally, it doesn‚Äôt sound like you looked into Rust‚Äôs targeted use cases before diving in. Rust is not designed to be fast. It‚Äôs designed to be *safe* (meaning deterministic behavior and unambiguous syntax) and *efficient* (meaning compiling to as few ASM instructions as possible, and making the best use of available memory). Speed is a happy side effect of these goals.\n\nRust works hard to be ergonomic *within the constraints of its design requirements/goals*. Comparing Rust to Go, Python, and/or TypeScript betrays a pretty fundamental lack of understanding of Rust‚Äôs intended use cases; a garbage collector simply is not tenable on most embedded systems or performance critical applications (Rust‚Äôs primary intended use cases).\n\nI think it‚Äôs more accurate to say that you‚Äôre not judging Rust on its terms more than that you don‚Äôt like it.\n\nEdit: removed garbage added by autocorrect and reworded a couple things for clarity\n\nTL;DR Rust is a fish you‚Äôre trashing because you think it sucks at climbing trees\n\n&gt; Rust works hard to be ergonomic within the constraints of its design requirements/goals. Comparing Rust to Go, Python, and/or TypeScript betrays a pretty fundamental lack of understanding of Rust‚Äôs intended use cases\n\nTo be fair, there's no improvement without trying to get better, and looking at the ergonomics of other languages is a very fine way to demonstrate a gap and start wondering how it could be narrowed down or closed.\n\n&gt; if you don‚Äôt have access to an extremely powerful Large Language Model, then writing the function becomes literally impossible\n\nI'm not sure if I'm that smart, or if everyone else isn't, but I never, ever had need for LLMs for anything Rust related. And I'm fairly fluent in it, despite being a Java coder by day.\n\nThere should be a second subreddit for all these AI/blockchain/fintech/linkedin people cosplaying as programmers.\n\nI would be filled with regret, too, if I was spending 18 months doing something as useless to society as programmatic trading\n\n&gt; AI/blockchain/fintech/linkedin people cosplaying as programmers.\n\nlmao. that's a good line\n\n&gt; There are two types of languages. The ones people complain about and the ones no one uses.\n\n\nRust has finally made it! This is a watershed post!\n\n\nAs for the issues raised, I think there is definitely room for more training material on how to write rust without getting into the fiddly issues of types and lifetime management.¬†\n\n\nI know I struggle at the beginning of projects trying to find my feet and its super painful. I saw a lot of my thoughts from those times reflected in this post. But once I do find the right abstractions, I do enjoy writing rust very much.\n\nSo I read the article and looked at your code, and I'm still unsure what about Rust you don't like.\n\nI don't code in Rust and I have no opinion about it, but I don't feel your article told me anything about the Rust language.\n\nYour rust code is not great considering you've been doing it for a year and a half. It feels like you just haven't taken the time to actually learn what best practises are. For example:\n\n* Using `String` (!!) as your error type, rather that using [anyhow](https://docs.rs/anyhow/latest/anyhow/). It solves your stack trace issue and means you don't need your `.map_err`.\n* Not using an actual logger, but `println!` everywhere... `anyhow` would also help here.\n* `Pin&lt;Box&lt;dyn ...&gt;&gt;` what? why? Just use a generic Future!\n\nLook how much cleaner this signature is\n\n    use std::future::Future;\n    use std::fmt::Debug;\n    use anyhow::{Result, bail};\n\n    pub async fn run&lt;T, R, Fut, F&gt;(t: &amp;mut T, f: F) -&gt; Result&lt;R&gt;\n    where\n        Fut: Future&lt;Output = Result&lt;R&gt;&gt; + Send,\n        F: Fn(&amp;mut T) -&gt; Fut,\n        R: Debug + Send + 'static,\n    {\n        let r = f(t).await?;\n        if todo!(\"something with r\") {\n            bail!(\"r not as expected: {r:?}\") // returns an anyhow::Error\n        }\n        Ok(r)\n    }\n\nHoo boy as an engineer with 15 years of experience in multiple languages (including low level stuff like C and assembly) but who has never really looked at Rust code before, this looks...bonkers\n\n80% of the scary things in there are due to the use of `async`, and specifically due to taking an `async` lambda as a parameter. Since `async` involves data being potentially moved across the threads of the threadpool on the whims of the scheduler, it gets complicated when you try to write generic code with it.\n\nThis code actually looks very nice, but it would be so much easier to understand with longer generic type names. As it is,   it is very high on the cognitive load scale, especially with no comments.\n\nObviously this is just an example for the author, but it doesn't really demonstrate the elegance of Rust to the uninitiated : at minimum you would need to understand generics, where clauses with traits, async functions, and the macro environment\n\nThank you, this is what I was thinking. Rust sucks for OP because he's not using the features of the language, or not using them correctly. This isn't surprising for someone who prefers Go and Mongo.\n\nMy basic position on these types of posts are, how would anyone expect to rewrite a non-trivial piece of software in a fairly radically different (in multiple ways) language that they have little experience in and expect it to come out optimally? It's just not likely to happen.\n\nThe same would have applied to C++. It would have ended up being badly sub-optimal because it just takes some number of years to spin up on a systems type language and to write non-trivial code in it that's well done, maintainable, and idiomatic.\n\nI'm a seriously experienced C++ dev and I'm now getting close to 3 years into Rust working on my own (which is still a lot of hours in my case), and I'm just now getting to the point where I'm starting to feel confident in how to structure a large system, how to write good, idiomatic APIs and code, etc... \n\nAnd that's completely to be expected. We aren't working the drive-through window here.\n\n&gt; don't inform yourself about pro/cons of languages and what would be a good pick for your use case\n\n&gt;waste 18 month\n\n&gt;rant on the internet about it\n\nWell, OP just learned the hard way about the golden rule of engineering: always choose the right tool for the job.\n\nMaybe it was \"resume driven development\"? You pick the tool you want to learn, to put in the CV later.\n\nI think their goal was to use this as a learning project¬†\n\nWhile i disagree with quite a bit of this I do enjoy reading other peoples opinions. One thing i will say is that a lot of programming communities in general are like the rust one.\n\nI honestly have had only good experiences with the rust community, but i haven‚Äôt dipped my toes in too deep.\n\n[deleted]\n\n&gt; ‚ÄúIf you want to find an article about what‚Äôs right with Rust, look literally anywhere on the internet. You‚Äôll be hard-pressed to find anything less than neutral about the language‚Äù  \n  \n90% of the articles I see linked here about RUST are negative and similar to this one.  \n  \n&gt; ‚ÄùThey ignore all of the giant glaring flaws with the language, like its crazy learning curve‚Äù  \n  \nWhat? It‚Äôs the most agreed upon thing about the language!  \n  \nI‚Äôve wanted to learn rust for a while and have only dipped my toes in but the things you are complaining were the first things I found when learning it and researching it. This is a pretty lazy article if I‚Äôm being honest and kinda sounds whiny from someone who just struggled with new concepts. This is coming from someone who doesn‚Äôt even write RUST code\n\nSome simple fixes for many of the technical things your doing:\n\n- Rust doesn't build things into the language, that's what crates are for.\n- Use a crate to implement async retries instead of implementing this yourself (e.g. tokio-retry comes up in a quick search - I'm not sure if there's something better more recent)\n- Use a crate to implement nice error handling (e.g. thiserror / color-eyre) instead of converting all your errors to strings and throwing away all the good parts of error handling\n- Use tracing crate for logging instead of println\n\nIn summary, crates are great.\n\nYou also noted that the syntax for that function param was pretty crap - agreed. You've found a part of the language that is still being worked on (async closures as function parameters get de-sugared into nasty things that Pin Futures with Send and Sync and Generics and ...). These are understandable if you give them some time, but they're not newb friendly in the slightest.\n\nBTW, images of text are literally the worst way to share code (aside from punch cards). They make any code more difficult to read. Doesn't medium have some sort of syntax highlighting for code blocks built-in?\n\nRegarding your thoughts on \"the community\". I think it's fair to say that there are shitty people everywhere on the internet. The posts of yours that I've read in r/rust however in general come across as ascerbic, and I've noticed that you you don't seem to have an easy going communication style that makes good friendly people want to gravitate to your problems. I don't think it's surprising that you attract and interact more with jerks / trolls given that observation. (To be clear, I'm not victim blaming here, just pointing out that trolling is a part of internet culture that is impossible to fix, and if you take a step back from things it's easy to see things which tend to provoke them).\n\nIn fixing this, I'd say probably your best bet is to slow things down a bit. Take less hottake dumps on a language, culture, community, etc. Find ways to explain your problem well in the right places (users.rust-lang.org is a much better place than r/rust for actually solving problems). Try to avoid the XYProblem (I've seen you try to solve problems at a too low level of abstraction a few times). Seek advice and spend less time criticising. And stop interacting with trolls.\n\nBest of luck bud.\n\nNo comment on the syntax.\n\nSmall programming communities tend to be insular. It sucks.\n\nIt does strike me as odd though that you are mixing people's attitude toward mongo (seriously try postgres, its a better mongo than mongo all while being a good database) with rust the language.\n\nThe go example looks worse in terms of readability. So many nil checks. How can you say Rust is so verbose, then¬†show Go in contrast¬†with if err == nil checks all over the place\n\nMy man you're comparing apples to oranges. You're coming at it from a web dev perspective and that may skew the conclusions. Rust isn't meant to be compared to typescript or even Go. Its meant to compete with C and C++. Rust is a systems and embedded programming language where determinism, resource use, and every single millisecond matters. If you would attempt to write your app in C, you would come to the same conclusion that its too complicated.\n\nOk, so complaining that you don't have GC in Rust is just hilarious. That's the main selling point: \"IF you don't want GC, here, try Rust\". So you do want a GC, why then you're writing in Rust?! Same with the type system - some people do not like the weak and dynamic type systems present in Python and other such languages and they *want* a language with a strong and static type system: \"IF you do, here, try Rust\" and you seem to actually not prefer to have it yet you pick Rust. ?!?\n\nWhat kind of criticism is this? It's as if you'd be looking for a vehicle to transport lots of heavy stuff and you'd select a Ferrari and then complain that it's not best at transporting plywood.\n\nSkill issue. I'm kidding (no really). \n\nI picked up Rust and used it too. Got swept up in all the same raving reviews as you. Ran into lots of unintuitive things along the way, learned a lot too. There's no doubt that Rust carves a unique niche for itself as a fast and safe tool. For me, the \"fearless refactoring\" experience was unlike anything I ever found before. Certainly a great language for what it is, and if what you want to build fits, great. \n\nI think you are failing to realize that Rust was never your problem. You just made it your problem. \"I spent 18 months rebuilding my algorithmic trading\" is the root cause of suffering. If your close friends were in academia and you got shilled Haskell instead of Rust, you'd still be miserable, back where you started with your application, and writing a post about how unintuitive monads can be.\n\nWhen Rust, or Haskell, or any flavour of the month/year/decade language doesn't fit your intended use case, the only option to make it work is to go deep and prepare to learn some of that black programming magic usually reserved for the wizards. Which can be fun, except when you are trying to be productive. Hence your pain.\n\nSo, how do you know if the tool fits your use case? Well, you have to learn to use it first. Do you see the catch-22?\n\nNever rebuild adequately functioning software, and never learn a tool on the job. New tool doesn't fit? It's still in your toolset for when it does, and when to use it will become obvious.\n\nHorses for courses surely?\n\nFor example if you can afford the unpredictable latency of garbage collection then using a language with garbage collection can be a good idea. But garbage collection has its own pitfalls. I've spent time fighting admittedly badly written code for J2ME where you can run out of e.g. sockets while waiting for them to be garbage collected.\n\nOdd that the author criticises Rust for being too verbose. I'm fairly new to Rust and my nitpick is that it's too terse. It can be hard to read. Maybe that comes with practice. The language designers seem to have followed K&amp;R's thinking that less typing == good. I don't agree with that at all. More time is spent reading code than writing it so language design should be optimised for ease of reading.\n\nYou get stack traces via [std::backtrace](https://doc.rust-lang.org/std/backtrace/index.html). Async stack traces are best done via the tracing crate since there is no way to do them in a zero-cost way, so they‚Äôre not part of the base language. \n\nYou are fine with a GC and slower execution, but claim to want the highest possible performance. \n\nThe database take is the most boring technical disagreement ever. \n\nIt feels like you were leaning too heavily on LLMs and didn‚Äôt actually learn the language. You would have run into std::backtrace before if you had done the tiniest amount of googling, or would have gotten to any of the numerous blog posts explaining why Rust doesn‚Äôt have async stack traces built in.\n\n    RUST_BACKTRACE=1\n\n&gt;Every guide on Medium, every post on Reddit,\n\nYeah no, Reddit and Medium are casual mediums (lol) for mental masturbation. If you take your engineering design cues from them you're gonna have a hard time.\n\nedit: also, MongoDB bad\n\n&gt; Horrendous Error Handling\n&gt;\n&gt; As long as you avoid unsafe unwraps , you can be damn sure that the code will run and keep running.\n\nI don't understand this criticism. There is nothing unsafe about an unwrap. An unwrap in Rust is equivalent to not wrapping a function with `try`/`except` in another language, except you can't `grep` for missing `try`-blocks like you can for explicit `unwrap` calls.\n\nThis has to be a joke\n\nI honestly don't think the author has the self awareness to recognize that they're as bad as the people they're calling out. At least those other people just wrote Reddit comments; this person put their toxicity into a blog post. Who knew there were assholes on the internet!\n\nfor syntax arguments, it's always the same argument with new language, and most of the time it comes down to unfamiliarity, sure there's an objectively correct argument why some syntax from a language is bad, but most of the time it's just being unfamiliar, and that's the first feeling I got when learning VB6-&gt;VB.Net-&gt;C#-&gt;Java-&gt;C/C++-&gt;Ruby-&gt;Python-&gt;JS/TS-&gt;Go-&gt;Rust\n\nIt always feels weird and even thinks it's bad and/or unintuitive, I was unfamiliar with it, but the more I learn and use the language it starts to sink in and I start liking it, becoming familiar\n\nStopped half-way through, but this person just sounds confused.\n\nsigned, one of the narcisistic rust fanatics\n\n&gt; There are certain things where, if you don‚Äôt have access to an extremely powerful Large Language Model, then writing the function becomes literally impossible. I don‚Äôt want to spend 90 minutes figuring out the where clause in my run_transaction function. I just want to write my damn function.\n\nThere's no nice way to say this but maybe if this is your level of skill you shouldn't be the primary or solo person behind a product that deals with money.\n\nHonestly, skill issue\n\nIf you can solve your problem in go then maybe rust isn't a good fit for your problem? They are designed for very different use cases.\n\nI love it! I'm not even in an area of software engineering that would use Rust, but I love your article üòÅ\n\nYou seem to have fallen into the \"Any program can be implemented in any programming language\" trap. \n\nRust is meant to be *really* good at the things that C/C++ struggles with, runtime memory safety, type safety, and usability. \n\nIt is not a drop in replacement for any language, not even C/C++.\n\nYour complaints are basically this:\n\n\"I tried to build a house with TNT without understanding how to use TNT, and now I wonder why there's a smoking crater.\"\n\nTry to build your trading system in C++, and you will run into very similar issues with one difference:\n\n***C++ compilers assume you know what you are doing and, therefore, will allow any and all syntactically correct code. Rust does not follow this assumption for code outside of unsafe blocks.***\n\nThis is a good thing, because Rust is meant to fill a similar niche in systems and embedded development as C/C++ does, where the issues caused by those problems are hard to detect and catch, potentially harder to handle even if you have enough memory to detect and catch them.\n\n[deleted]\n\nGarbage article.\n\nThis is not criticism, this is your childish whining about  you chosen a wrong language for a wrong task while simultaneously lacking experience with it.\n\nYou would have gotten the same reception asking about mongodb in a C# forum too, just saying.\n\nThe criticism of it that you saw are all as old as time, and Reddit is somewhat in notorious for not answering the question you asked and instead telling you to do something different entirely. \n\nBut that's not really a forum question, sometimes you're facing an X-Y problem some technical folks sometimes over-do it in trying to suss them out.\n\nI also don't particularly love Rust, but this article is just weird to put it mildly. The 3 main criticisms are:\n\n1. Syntax. I disagree that Rust syntax is bad (I wouldn't say it's good necessarily tho). Actually bad syntax is C and C++, where the syntax leads directly to logical mistakes. There are good reasons to use \\`{\\`, \\`}\\`, \\`;\\`, \\`,\\`, \\`let\\`, \\`mut\\`, etc, so many mistakes are prevented this way. It is verbose and a lot of the bad syntax is an attempt to lure C and C++ people but it's not the end of the world, you learn it. I also think some of the sugar is quite nice, like \\`?\\` and \\`if let\\`.\n\n2. Error messages and error handling. It's literally the same as in Go, except better. Semantically Go and Rust do things very differently, but in practice it feels very similar. One thing I don't like is unwrap, in hindsight there's no reason not to use expect. If you need a lot of control, making your custom Error type is not a bad idea. As for python and other such languages, they are so much worse then Rust, it's just that they hide mistakes from you so you think the app is fine when it's not. I think the debug tools can use a lot of improving, which is a genuine critique.\n\n3. The community. Generally, most communities online that are big enough start to become toxic. You see it all the time but I think generally you get the answer you're looking for. In C++ world, not only are people toxic, they also give you advice on the exact thing you should absolutely not do. When people say that MongoDB is bad and just use postgres, there's a good reason for that. It's absolutely the superior tool and every way shape and form but especially for Rust.\n\nFor me, the biggest downside is that you need the code to be perfect from the start, which is difficult when starting to design an application. Perhaps this is unsolvable, but I think some things might help. One of which is better debuggers. The other is printing error messages in the order they appear in the code, not the order they happen. Finally, perhaps a better language server could help.\n\n‚ÄûIf we compare it to C++, it‚Äôs obviously the better language. But when compared with other languages (like Go), its ‚Äúsafety‚Äù to me is more of a detriment. I‚Äôd rather my application take a few dozen milliseconds longer to run if it means my development time is cut in half.‚Äú\n\nI‚Äòm definitly no language warrior by any means, but isn‚Äòt this exactly the trade you take as engineer when choosing Rust? Safety and application speed for development time? Honestly, I quite don‚Äòt get the rant besides the shitty community comments though\n\nYeah it's weird. Elsewhere he says every millisecond matters yet he's happy to throw 12 away here.\n\nFor the record, I don't think they do, because his homegrown algorithmic platform won't have a direct connection to an exchange so he's at the mercy of however well the exchange partner (sellside) routes his orders.\n\nThanks for the perspective. I think people unduly dismiss MongoDB which is perfectly suitable for a lot of use-cases. \n\n\"If we compare it to C++, it's obviously the better language\"\n\nSorry you lost me right at the end lol.\n\nOCaml is great FYI. It‚Äôs unironically my favorite ‚Äúnot totally academic‚Äù language, though Rust and Python are my go to languages for most projects.\n\nSeems like horizontal scaling might be a better way to go, as performance will eventually become a problem regardless of language.\n\nI‚Äôd probably have written this app in C# if I wanted GC. Dotnet is an underrated platform."
  },
  {
    "title": "AI engineers report burnout, rushed rollouts as ‚Äòrat race‚Äô to stay competitive hits tech industry",
    "body": "",
    "score": 1183,
    "url": "",
    "created_utc": 1714738680.0,
    "author": "Franco1875",
    "permalink": "/r/programming/comments/1cj78vc/ai_engineers_report_burnout_rushed_rollouts_as/",
    "all_comment_text": "[deleted]\n\nSeconding, AI is a clusterfuck of insane deadlines for a year and a half now. I've never felt this tired in over 20 years of development.\n\nNever before has the phrase \"*The reward for hard work done is more work.*\" been more true\n\nDon't forget the goal of no work for everyone\n\nFor which of course the reward is to be fired and left at the whims of a society and economic system that refuse to update with the times to account for less work being necessary.\n\nThe goal of AI: People around the world will be freed from work! (Because we will attempt to lay off 90% of the population)\n\nDon‚Äôt worry. It should only take a few months or years of 90% unemployment before the rate falls drastically and permanently!\n\nI heard somewhere that for every 1% increase in unemployment 40,000 people die.\n\nI mean, on the surface, isn't that wonderful?\n\nThen you realise the problem with the techbro techtopia promise: *no consideration to how the workers make a living.*\n\nWhat do you mean? AI will bring sustainable gains in quality of life for our society's hardest workers: venture capitalists.\n\nWill need to transition away from the current Capitalist system for it to be sustainable in any way\n\nlols in end stage capitalism.\n\nBro all this shit insanely wasteful. It's fundamentally incompatible with sustainability.\n\n\n\n-planned obsolescence\n\n-devaluation of wages through inflation/shrinkflation while companies post record profits\n\n-keeping houses empty because of speculation while people are homeless\n\n-optimising for the cheapest product cost at the highest price rather than quality (Bonus points for when a company sells a deadly product knowingly)\n\n-Monopolies that naturally form through acquisitions which naturally leads to Oligarchy without strong regulations (meaning Capitalism requires heavy handed restraint for it to function)\n\n&gt; meaning Capitalism requires heavy handed restraint for it to function\n\nwhich is a fundamental contradiction cause capitalism ultimately funds the hands tasked with restraining it.\n\nYep. It‚Äôs like. How about you work so hard that your fruits of your labor that will take your existing job?\n\nBut where's your motivation? You should feel proud to be part of this opportunity to make more money for the CEO and shareholders!\n\nThere's gratitude for you. pfft.\n\nYou're right, you've given me a free lunch, a t-shirt and emotional damage out of all this. I am forever grateful for these gifts.\n\nObviously these people lack true \"passion.\"\n\nAs various folks have said, I'm pining for the good old days of crypto-spam.\n\nAt least with crypto you didn't actually have to do anything - just put the word in the name and you're good, it's not like the business guys or investors know what it means.\n\nWith AI they actually have like, expectations and junk.\n\nYep. Working on unstructured data. Also a shit show. Kill me.\n\nJust use regexes for every edge case\n\nYou joke, but we're using this to get the last few hallucinations that slip through... It feels like CRC error checking tbh\n\nResult of Hammer Engineering. Executives, venture capitalists and product managers look at every business opportunity now, and decide \"We should fix that with an LLM!\"\n\nThis guy gets it.  You can fix anything with a good regex. You can also break the fuck out of shit irreparably with one that's just a little more clever...\n\nI feel ya man. \n\nInstructed data destroyed my appeal of tech. Been so fucking hard coming back from it. Been a year.\n\nHello, working in IT too, but have escaped the AI craze so far. Do you feel there is something in it besides cheap content generation that will soon hit a wall (in part due to lack of non ia generated content to feed the models) ? From the outside it looks like everyone is trying to get investment funds but no one has a clear idea of what it be used for besides scenes from scifi movies from the eighties.\n\n&gt; Do you feel there is something in it besides cheap content generation\n\nNot the person you asked but: at my $JOB (government owned pension company) AI is used to pre-classify incoming email/ snail-mail (that may come in in various languages) and automatically route them to the correct department. This was previously done manually and the AI seems to work quite well. If the AI gets it wrong (which apparently doesn't happen too often) nothing bad happens, the (wrong) receiver corrects the classification and/ or re-routes the document.\n\nThere are applications beside the hype :-)\n\nThank you. Not sure the billions poured into it will be worth that, but it's nice to see another real use.\n\n&gt; From the outside it looks like everyone is trying to get investment funds but no one has a clear idea of what it be used for besides scenes from scifi movies from the eighties.\n\nIt's basically this. It's bitcoin all over again. Or the dotcom bubble.\n\nEveryone remembers the Dotcom bubble.\n\nNobody remembers the telecom bubble and how it burst right after the Dotcom bubble. It was much bigger than the Dotcom bubble.\n\nCause the telecoms were bailed out by Steve Jobs introducing the iPhone.\n\nBut the interim period 2004-2006 was particularly bad for them.\n\n&gt; It was much bigger than the Dotcom bubble.\n\nNortel alone appeared, then disappeared billions of dollars. That being said, the telecom bubble did leave higher and higher capacity networking gear. \n\nBobbyBroccoli on Youtube has good treatments of Nortel.\n\nIt is, and it isn't.\n\nChatGPT and generative techs like image/media, are certainly overhyped. But they're also incredible. the problem is they're being shoehorned into every business problem, whether they're suitable or not, and idiot venture capitalists all want to be in on the next 'internet' early.\n\nIt's definitely transformational technology, and there's a *lot* more to it than ChatGPT, and many interesting problem it can help us solve that were difficult before.\n\nBut it's all getting overlooked and buried under the hype and ruthless VCs who are more concerned with turning a quick buck and cost cutting than looking for genuinely innovate ways it can help people solve problems they couldn't before.\n\nChatGPT is even better.\n\nCrypto didn‚Äôt have people crying about their jobs and the dot com bubble didn‚Äôt kill the internet either¬†\n\n[https://globalnews.ca/news/10463535/ontario-family-doctor-artificial-intelligence-notes/](https://globalnews.ca/news/10463535/ontario-family-doctor-artificial-intelligence-notes/)\n\nWhat are the major roles? Like I'm mostly a web-app guy with a focus on backend, architecture, infrastructure, developer experience stuff.\n\nDoes an AI team have roles in that space or is it all super smart dudes who can actually calculate gradient descent on the back of a napkin?\n\nThese are the same \"super smart dudes\" who picked python as the language de jure of their domain.\n\nSure, they need someone to write glue code to plug together the black boxes that do the AI parts\n\nNot to mention, if you‚Äôre working with open source AI, there‚Äôs literally 1000 different libraries to do a task, with a new one released every day, and most of them aren‚Äôt great.\n\n\"Hi I  today's YouTube tutorial I'm going to teach you a library that was just released yesterday, and that I learned how to use as I was asking an AI to write the script for this video!\"\n\nShit is gonna get real bad real fast when the investors realize this shit ain't magic.\n\nThe fact that I am seeing job posting for ML managers that require 4-6+ years of work in ML/AI already despite this not being a real market segment that long ago or expecting every ML manager to have a PhD in math or compsci is giving me flashbacks to the early 2010s.\n\n[deleted]\n\nYikes, hope you‚Äôre not too overwhelmed and taking time for yourself dude. \n\nMy employer has been very much in an ‚Äòexploratory‚Äô stage for a couple months now, but nothing crazy as of yet. Waiting for that one use-case to throw us into disarray.\n\nI'm stuck in email knowledge extraction with PII and data governance. So fun\n\nStart. Stop. Start again. Stop again. Sit in a dark room. Scream. Start again.\n\nUs too.  The AI stupidity is sucking every bit of energy and investment out of the room.  There are too many people who think it's _the tool_ not _a tool_.  I also don't get the people who want to make everything conversational when a simple modal dialog would be easier, faster and less error-prone for the user.  While I get that you can do it, it's hostile to be re-prompted three times for additional categorical data.\n\nThe other thing that's unfortunate.  Because of the hype, projects are attracting people with stars in their eyes or the most self-serving, self-promoting, can't do anything but manage upward types.  While the first type is manageable, the second is toxic as fuck.\n\nWe could have such amazing technology but its thwarted by these fucking mega-rich investor idiots wanting to put the population out of a job. We know how that works out, so we're losing out on creating generally innovative products because these morons want to destroy this country before they die off.\n\n&gt;Late last year, an artificial intelligence engineer at Amazon\n&gt;\n&gt;was wrapping up the work week and getting ready to spend time with some friends visiting from out of town. Then, a Slack message popped up. He suddenly had a deadline to deliver a project by 6 a.m. on Monday.\n&gt;\n&gt;There went the weekend. The AI engineer bailed on his friends, who had traveled from the East Coast to the Seattle area. Instead, he worked day and night to finish the job.\n&gt;\n&gt;But it was all for nothing. The project was ultimately ‚Äúdeprioritized,‚Äù the engineer told CNBC. He said it was a familiar result. AI specialists, he said, commonly sprint to build new features that are often suddenly shelved in favor of a hectic pivot to another AI project.\n\nThis should be a simple 'NO'.\n\nEdit: Fixing the quotations.\n\nThat sucks, but like... what did they expect? Does anyone take a job at Amazon without knowing what the work culture is like? Why do they think they get paid so much?\n\nAt Amazon, they really expect anything other than a big \"NO\" in this kind of scenario? WTF I would be embarrassed to ask someone to skip the weekend for some bullshit idea like that.\n\nThere are other places that pay just as much without that work culture.\n\nSuch as?\n\nsweaty devs like that are the ones that do all my work and allow me to take my vacation stress free. theyre great\n\nThey're not great. They ruin the work culture, and get you laid off\n\nTbf he chose to work at amazon, this BS is literally their culture.\n\nAmazon is chock full of people on H1B visas who constantly feel like if they don't do stuff like that, they'll end up back in their home country. It's a lot like legalized slavery.\n\nSo everything‚Äôs working as designed¬†\n\nAll tech companies are full of H1Bs, Amazon is the only one sleazy enough to do L visas where they can only ever work for Amazon\n\nYou can remove the words \"a lot like\" and your comment is still correct.\n\nWhat no unions does to a mf\n\nI've had several experiences like that. My first job out of college was a giant slog followed by the company completely dropping the project.\n\nI think it's actually good experience to have your project shit canned early in your career, as long as you're not laid off. I've met some people who weren't used to that and got really upset about their project being canceled. One even left the company because they couldn't deal with it. But it happens pretty frequently, especially at some of the top companies.\n\nOnce I was in a position to, I've absolutely said 'NO' several times. The last time I said 'NO', they begged me and bribed me to work, I messed up and gave in. After I delivered on time, they didn't treat me like the fucking second coming, so I gave them my two weeks notice the next day. Truth be told, I probably ruined the job for myself the moment I gave in. It's nice to be later in your career and to be able to do things like that, though.\n\nGotta get that VC money before the hype bubble pops and the next one starts growing.\n\nAI will follow the trajectory of internet companies.\n\nThere'll be a rash of startups, including a lot of incredibly stupid ones. In a couple of years there'll be a bunch of big bankruptcies and failures of companies trying to do things that, by that point, are obviously bad ideas. Many smug people will talk about how AI was a fraud all along.\n\nBut amongst all the \"user the internet to sell dogfood\" companies, there will be some Googles. In another 10-15 years the biggest companies in the world will be the AI versions of Google and Facebook, who have built products that have an enormous impact on people's lives.\n\nI know it'll follow this trajectory because this is the trajectory of every new industry built around a major technological improvement.\n\nThats just the norm of tech- throwing everything at the wall and seeing what sticks.\n\nSure, but it's not new. The railroad boom of the 19th century followed the same pattern, as did a number of other major technology booms between then and .com.\n\nThe great Tulip crash of 1630 comes to mind. People go all in on that new new.\n\nTulips are not tech. Speculation on Tulips is more akin to speculation on luxury goods, Supreme merch, comics, or real estate. The closest tech parallel is crypto currency. Thats not to say that tech isnt impervious to bubbles, but tech bubbles at least leave a permanent lasting and usually positive impact behind.\n\nI have dozens of tulips in my yard. They are great flowers that are so of the first buds of spring.\n\nWell look at mr moneybags over here.\n\n&gt; Thats just the norm of tech- throwing everything at the wall and seeing what sticks.\n\nThat's just the norm in the US, because they throw someone else's money at the wall.\n\nThats the norm for all research and development. Experimentation is costly. The amount of money the US throws at innovation is unparalleled, but practically any other country that tries something new will pay a cost.\n\nAfter throwing a mess of somebody-else‚Äôs lives at the wall, no less\n\nThere‚Äôs no guarantee that this will happen. AI as it is now is nowhere near as disruptive as the internet. It‚Äôs more likely that the current big guys will dip into AI and acquire startups that have actually useful products, however few that may be.\n\n[deleted]\n\nLmao. There‚Äôs absolutely no way a tech startup can become big on ai. They‚Äôll basically have to rent their compute from one of the monopolies and the hope is to sell out to them anyways.\n\nBig agree that the only way we‚Äôre seeing shakeups is if big tech starts getting hit with monopoly and antitrust laws.\n\nEven just the advantages the big ones have in terms of training data are pretty much insurmountable\n\nThe internet is free to access for anyone. For now at least¬†\n\nThe website you‚Äôre using runs on AWS\n\nThat would require the government to do something¬†\n\n&gt;  AI as it is now is nowhere near as disruptive\n\nOh, you've gotta listen to more Ezra Klein podcasts where he interviews AI CEOs, and they all swear if you give them enough money they'll change the world. Also they super want to be regulated but probably not. Anyhow, give them money alright?\n\nYeah you get it\n\n&gt; AI as it is now is nowhere near as disruptive as the internet.\n\nIt took nearly 25 years before the internet was part of everybody's daily life.  I think AI will be _vastly_ more disruptive and that disruption will happen _much_ faster than the internet did.\n\nThe internet was more expensive and not immediately accessible unlike ChatGPT that only requires a log in¬†\n\nThe Internet was invented in the 1960s, used industrially since the 1970s and mass commercialized in around 1994.\n\nYou're saying after 2 years of commercial generative AI that it is \"nowhere near\" as disruptive based on what you've seen so far?\n\nOpenAI already makes revenue of more than $1B per year. What company was comparable in the first years of the Internet? It took Amazon 5 years to make its first billion.\n\nI suggest open-mindedness and curiosity instead of quick rushes to judgement.\n\nIt‚Äôs pretty clear that I‚Äôm not talking about ARPANET in my comment, but the mass adoption of the internet in the 90s, which spawned the dotcom boom. Generative AI is already being mass commercialized, so you really should not be comparing it the internet in the 70s. The methods used by OpenAI have also been around since the 60s and 70s, deep learning is not a new thing. Not to mention that AI capabilities are bounded by our industrial capacity to produce the needed compute resources to train and run these models, which we have already virtually exhausted, and there are diminishing returns at that.\n\nAI as we know it has a place going forward, but the valuations of these companies new and old that are pushing AI is driven by hype.\n\n&gt; OpenAI already makes revenue of more than $1B per year. What company was comparable in the first years of the Internet? It took Amazon 5 years to make its first billion.\n\nWhat is inflation?\n\n&gt;but the valuations of these companies new and old that are pushing AI is driven by hype.\n\ndefinitely agree with this. Most of them will collapse, and many are just smoke and mirrors, or trying to force LLMs in to solving every problem they have, whether they're good for it or not. Or looking at AI as a cost cutter, rather than a productivity enhancer.\n\nThat is, they're trying to solve problems like 'how can you cut staff', rather than 'how can you produce at higher quality and increase revenue'. The prior is counter productive in the long run, as you end up with a society where everyone is unemployed. The latter creates new jobs and industries and real wealth for everyone.\n\nThey said AI ‚Äúas it is now‚Äù is nowhere near as disruptive as the internet which is obviously true. \n\nThe market conditions that prevailed at the dawn of the e-commerce era are ‚Ä¶ uh, materially different ‚Ä¶. than those we have today, which would explain the difference between OpenAI‚Äôs revenue today and Amazon-of-25-to-30-years-ago‚Äôs revenue.\n\nMaybe. Cory Doctorow makes a [reasonable case](https://locusmag.com/2023/12/commentary-cory-doctorow-what-kind-of-bubble-is-ai/) that some bubbles burst and leave residue that can stimulate innovation, and others burst and leave little.\n\nBut the issue is that those companies almost certainly won't be using current tech. We got this surge because a bunch of big companies realized that, if they were willing to spend stupid money and burn immense amounts of energy, they could scale up existing LLM ideas to a new plateau. But how far can that scale? \n\nThere's such a thing as getting in too early. I imagine more likely that the Googles and Facebooks and Microsofts of AI will be Google, Facebook and Microsoft, because they can afford to keep going in on each new iteration until it finally gets to a point where it's practical and scalable, while folks going all in on the current state of the art can't follow through because the real solutions are still too far out and they blew their cognitive load betting on the current thing.\n\nThough, none of these companies probably want it to reach a point where it doesn't require massive resources, because that's what insures that they retain control over it because it remains cloud based and you have to come to them to use it.\n\nThe real breakthough is when we can have that kind of power locally. But, how can you do that because it requires constant massive training and massive data sets to support that. We won't get to that point probably until we really reach generalized intelligence. That's way out, and of course once it happens, humans are probably doomed shortly after so you you better cash in with the VCs quick once that happens.\n\nThere might be a difference this time though.\n\nWe're set up so that the next 'google' or 'microsofot' might just be google and microsoft. Look at OpenAI and microsofts close relationship, for example.\n\nI'm a little cynical, but I don't think there will be new companies coming out of this. Just bigger, and more powerful old ones.\n\nThe AI versions of google and facebook will just be the existing big N internet companies lol they will just buy up/merge with any upcoming challengers.\n\n&gt; ~~AI~~ Blockchain will follow the trajectory of internet companies.\n\nIf it hasn't already, it won't.\n\nThe only popular use of blockchain in day to day is speculation on bitcoin and crypto.\n\nIt hasn't transformed anything else. Well, apart from enabling new types of grift and money laundering.\n\nI read this the other way around: There's a risk that AI will follow the trajectory of blockchain. It's much more likely to produce *something* useful (arguably already has), but the ratio of hype to actual utility is way too high.\n\n&gt; AI Blockchain will follow the trajectory of internet companies.\n\n- Guy that can't explain why anyone should use a blockchain instead of a database in 99.9% of cases\n\nYou think AI, a technology with immeasurably vast applications, is comparable to blockchain, a technology with none?\n\nYou are going to be very surprised in your life.\n\nAI in this context refers to LLMs. LLMs have applications just as the image recognition AI boom (mid 2010s) has applications.\n\nImage AI can recognize a face with superhuman accuracy. AI can tell you if something is a bicycle or a car with human accuracy. AI will recognize that plant on your desk as a [Swiss Cheese Plant when it's actually an Arabica Coffee](https://youtu.be/ddTV12hErTc?t=177).\n\nLLMs similarly have things they are good at like summarizing documents and sounding like a human. But apply them to the things they are bad at, and they will mercilessly gaslight and misdirect.\n\nThere will be more and better AI technologies in the future, and of course they will have useful capabilities. But this current marketing trend of AI = LLMs is not going to revolutionize everything as we know it.\n\nGoogle and Facebook will be the AI version of Google and Facebook. This market is massively favorable to incumbents that can afford to incinerate billions of dollars trying to get this right.\n\nYour characterization is exactly correct.\n\nThis quote from 1999 could be rewritten today:\n\n&gt;I know I sound like those demented digerati who have spent too much time in the insular world of Silicon Valley, but I firmly believe that the Internet is underhyped. I almost cringe when I write this because some of what is going on here has been underwhelming and derivative of the old world. For all the attention given to electronic commerce of late, and the incredibly high valuation being given to companies that lose scads of money, some of the business on the Web is little more than a glorified version of selling crap on the Internet. Not very exciting to be sure, and a little unnerving to me since fewer companies I see these days are as concerned with building a real business as they are in popping out an IPO, taking the money, and hoping to the heavens to figure out what to do next. This makes me very nervous and it should make a lot of others nervous, too.\n\n  \nBut...but...but...Bitcoin.\n\nAI was rolled out to roughly a billion people on Facebook properties last week. Companies are putting AI in your doctor's office. More than a million developers already use AI in their IDEs.\n\nThis is not pure hype like Bitcoin. This is products that millions or billions of people are already using. Probably the fastest roll out of a new product category in the history of history.\n\n&gt; AI was rolled out to roughly a billion people on Facebook properties last week.\n\nAnd people seem to absolutely hate it. You should also look at some of the actual usage stats on chatgpt. People said it was going to replace search within a year but it barely made a dent and user retention seems like a huge problem for OpenAI.\n\nexcept for crypto, which has still failed to have an appreciable positive impact on anyone\n\nWhat's funny is that a lot of these \"internet does x/y/z\" things became a lot more financially feasible on Mobile where everything is a website or app and it's more accessible then going to the store.\n\nPets.com probably failed because it came too early, not because it was a silly idea. Chewy is basically the same idea.\n\nAmazon operated at a loss for years as an online retailer before they started selling AWS to people and became a tv and shopping power house.\n\nedit: If anything the \"AI does x/y/z\" stuff probably will be really terrible at first, but then we'll see the technology or formfactor change in a way that consumers just expect it, or at least make it part of their workflow.\n\nlmfao, sure. I bet that'll happen right after the facebook of blockchain and the google of NFTs rise to the power of nations\n\nThis is such a lazy analogy.\n\nOpenAI -- alone -- makes more than a billion dollars in revenue PER YEAR.\n\nThere was never anything even remotely comparable in Blockchain.\n\nThere wasn't any company in the early days of the Internet producing revenue like that.\n\nCounter: No other company in the early days of the internet has had quite so much money invested in it either.\n\nOpenAI, currently, is a machine that has taken **13 billion dollars** of investment, and *looses* *money.*\n\nSo yeah, it's easier to have a revenue that high when you have been given even more money, and are burning it as fast as you can.\n\nThe tech scene of today is very different from the 90's internet scene.\n\nIt's irrelevant to the questions we are discussing whether OpenAI loses money. So did Amazon for decades.\n\nOpenAI has proven there is demand for these products. The cost of providing GPT-4 is going to drop to near zero and we know that there is large demand for GPT-4. So we know that these products are going to be part of the future. Not like NFTs.\n\nIf OpenAI goes bankrupt, Groq or Amazon could serve Llama at a profit forever.\n\nMy point is there is demand for a lot of products - especially when you sell it for less than cost, and have more money than pretty much any other startup, ever, to market and build it with.\n\nIf you're going to compare it to the 90's internet boom, you need to do so in a unbiased fashion (there's an AI pun for you! :D )\n\nThey don't sell access to GPT-4 for less than cost.\n\nThey invest enormous amounts in future models. That's a capital cost like building a factory. Every new company is \"losing money\" if that's how you measure it. It's totally irrelevant to discussing the future of the market.\n\nIf they go bankrupt, others will sell access to Llama 3 at a large profit forever. So generative AI is not going away.\n\nA quick look would indicate that they made that last year, and a small fraction of that the year before. And how much of that is going to the huge expenditures to get this far plus ongoing costs? And also, how much of it was investment money, not earned money?\n\nThat big a jump in one year is almost the definition of hype, it would seem to me.\n\nThe only remaining trace of AI bubble will be a [dedicated keyboard key](https://www.reddit.com/r/linuxquestions/comments/18zqfuu/soooo_what_are_we_going_to_do_with_a_copilot_key/) triggering LeftWindows + LeftShift + F23 key event.\n\n&gt;AI workers at other Big Tech companies, including Google and Microsoft, told CNBC about the pressure they are similarly under to roll out tools at breakneck speeds due to the internal fear of falling behind the competition in a technology that, according to Nvidia CEO Jensen Huang, is having its ‚ÄúiPhone moment.‚Äù\n\n  \nHardly surprising given the razor sharp focus these firms have at the moment. A race to the top and its human workers being thrown into the meatgrinder to achieve it. \n\n&gt;They spoke of accelerated timelines, chasing rivals‚Äô AI announcements and an overall lack of concern from their superiors about real-world effects, themes that appear common across a broad spectrum of the biggest tech companies ‚Äî from Apple to Amazon to Google.\n\nThe 'chasing rivals' AI announcements' aspect of this is something that has struck me across the last 18 months - Microsoft can't breathe without Google jumping down its throat, and likewise with AWS and vice versa. A complete slog and battle of attrition at this stage.\n\nThere‚Äôs something extremely dystopian about human workers breaking their backs in a rush to be the first to create the thing that will put them out of a job.¬†\n\nEDIT: I was being a bit dramatic. I should not have said it will put them out of a job, as it probably won‚Äôt (unless it‚Äôs a bust and the whole team gets laid off). It will, however, provide employers with tools that they will use either so that they can hire fewer people (pessimistically) or so that they can do more work with the people they have (optimistically). I imagine the reality will be a bit of both.\n\nFriendly reminder:\n\nThe technology in it's current form and shape is in no way even clode to being taking over developer jobs (or no other jobs really)\n\nMaybe in 10 years we can come back to that discussion but please keep it realistic.\n\nThat the technology doesn't work has never stopped shitty management from firing a bunch of people and implementing it anyway.\n\nExactly this. *it's happening right now.*\n\nAI companies are even advertising 'cost cutting' in their marketing materials.\n\nI guess it's gonna be a goldrush for consultants to come in and put out fires and fix the steaming piles of garbage generated by these tools ü§∑‚Äç‚ôÇÔ∏èüí∏\n\nExactly, now we have:\n\n  * powerful but extremely narrow tools (eg. whisper AI ...)\n  * general purpose somewhat unreliable tools (e.g copilot ecosystem)\n\nNow everyone and their mama in media hints that this means general artificial intelligence will somehow magically arise from this and we are this close.\n\nIf you believe that, I have a bridge to sell you.\n\nWe will more eventually likely see products like personal on premise secretary for everyone, just for 49 USD/monthly on your android 18 phone or Iphone M6.\n\nNow that I am looking forward to.\n\nI don't think it's dystopian to think of a world where you don't *have* to work. The problem is our society right now doesn't really have a way to deal with a potential future where human work isn't actually required.\n\n&gt;\tI don‚Äôt think it‚Äôs dystopian to think of a world where you don‚Äôt have to work.\n\nYeah, but that is very much *not* what people like Altman and Huang are building towards.\n\nI can see two futures:\n\n- We achieve full automation, robots can do anything we need humans for now. We ban the technology, to allow the current \"work to survive\" model to keep working. Robots are limited to jobs that nobody can or will do, like extremely dangerous or intensive jobs only.\n- We achieve full automation, and it puts everyone out of a job. Anyone who currently relies on a job to survive is rendered unnecessary and income-less, doomed to homeless poverty. This goes on for a while until riots happen and some kind of UBI is implemented, or we just ban automation like in future 1.\n\nUbi at that point will never be enough for any good standard of living, everyone will be stuck in low income housing with very little cash flow while few jobs that are left will be there to service the wealthy.\n\nBut it won't happen because at that point climate change will get us first or population crash will.\n\nFully Automated Luxury Space Communism :)\n\nOr WALL-E.\n\n100% agreed. We‚Äôre headed towards (already in?) a world where we should be able to have fewer people working, but we (from my Western perspective) are so committed to the Puritanical idea that if you don‚Äôt work, you‚Äôre not valuable that we cannot allow that model.¬†\n\nIt's not possible to prosper (in a capitalistic world) without work.\nI feel like some level of socialism is needed\n\nI think its more of a realization that we have no good way to handle massive amounts of people not having any job prospects at all. If we had a good UBI system in place, then it'd be different.\n\nI think we‚Äôve been at that realization for a while. UBI has been on the table for a long time. You have to ask yourself why it hasn‚Äôt been implemented.\n\nThe people breaking their backs here aren't going to get put out of a job by AI. OTOH they might get put out of a job by their CEO's jealously of Elon Musk.\n\nAgreed - for some it must be a case of hoping at least their company is the one to take a major lead and be immune from it all. Think we all know that won‚Äôt be the case though.\n\nThey don't have to all of these people can find employment elsewhere easily enough...they are actually choosing to do this probably because they are getting paid a shit ton.\n\nI think the problem is that their focus *isn't* razor-sharp, it's clear as mud.  They know they want to use AI, but they don't yet know what to use it for.  They're throwing as much shit at the wall as they can, and a lot of it is bound not to stick.\n\nI agree. It is almost an \"I am better than you\" d*k  üëã contest, rather than a struggle towards something meaningful.\n\nWith allthe gung ho around language models and so on, and the amount of money and compute thrown at it, meaningful usecases are yet to be discovered. Long terms benefits to humanity are only spoken of, no reality. Maybe in healthcare. Who knows.\n\ncurious but are the companies you guys work for building anything useful with AI?\n\nI interviewed with one that makes an actually useful product to drastically improve the speed of legal research, which aligns with my anecdotal observation that one thing LLMs consistently do well is speed up and summarize research. You just need to have a competent enough professional to understand the data enough not to blindly trust the machine.\n\nYes, it's like the same learning curve when you finally find out \"what to google\" after you learn the right term.\n\nI wanted to know different kinds of photography that were specifically created using the \"wrong settings\" on the camera, and Google knew jack shit, because I didn't know what to Google. I could have researched for an hour or two to find it.\n\nHowever, ChatGPT listed 10 of them immidiately!\n\n    Certainly, here's a short list of unusual photography concepts without the definitions:\n\n        Intentional Camera Movement (ICM)\n        High ISO Noise Photography\n        Overexposure and Blowout\n        Lens Whacking\n        Bulb Mode with Flashlight Painting\n        Tilt-Shift Photography\n        Cross-Processing\n        Pinhole Photography\n        Infrared Photography\n        Double Exposure (In-Camera)\n        Lens Flare and Haze\n\nThis is a GREAT point - GPT is very good at having broad domain knowledge and can often unstick you just knowing things you aren't aware of in a domain.\n\nI am sorry to tell you that half of these have nothing to do with \"wrong settings\". So yeah, don't trust ai if you cannot interpret the results.\n\nOf course? I Googled each term. Lmao.\n\nI'm not saying to trust AI. It is a tool.\n\n[deleted]\n\n&gt;it gave you a couple things to google\n\n\nI'll take that over dead forum links and ads out the ass.\n\nIt's an EXTREMELY confident junior &lt;whatever&gt; with absolutely no bullshit detector. It's some of the dumbest shit in an industry that thought selling people links for hundreds of thousands of dollars was some kind of business plan.\n\nuhm. I prefer tools I can trust :P\nthat said, using GPTs for exploration and idea generation *is* one of their strong sides.\n\n&gt; You just need to have a competent enough professional to understand the data enough not to blindly trust the machine\n\nPlease read all of the comments in the chain not just the parts you disagree with. Also the context is getting nothing back from google but instead getting 5.5 (your number) things to look into...and somehow you think thats a bad result? Reddit is dumb.\n\nThis just in: AI is smarter with millions of words of context than reddit users are with about 90.\n\nI can't see how something that routinely makes shit up could be the least bit useful for research.\n\nBasically, it could give you a summary of the current state of the research and, ideally, even give you resources to look at. It's probably pretty good for a first quick exploration.\n\n\"You're working on a legal case of a specific type. Here's the general information that I can give you:... Also, here are legal cases to support my claims:...\"\n\nYou can then verify that these cases exist and actually read them to verify the information and get more details than the LLM would be able to give you. LLM won't replace a human, but it can help them.\n\n&gt; Basically, it could give you a summary of the current state of the research and, ideally, even give you resources to look at. It's probably pretty good for a first quick exploration.\n\nThat's great, until it starts making stuff up, which these LLMs are wont to do. \n\n&gt;\"You're working on a legal case of a specific type. Here's the general information that I can give you:... Also, here are legal cases to support my claims:...\"\n\nAnd when (not if, but when) it makes cases up, you've now lost every bit of trust in the tool.\n\nIt's fairly reliable if you provide good context. Summarization is better than humans would do 99% of the time.\n\nVery true - I also interviewed with an AI startup that was working on automating a task that humans do but frequently do poorly. In that context, it's also better because an automated solution that's occasionally wrong is better than a labor-intensive solution that is frequently wrong.\n\nI've seen some companies using AI in signal processing tasks very effectively. You can extract signals at a much lower SNR than with traditional signal processing algorithms.\n\nWas working in a Recruitment SaaS startup \n\nWe tried AI to do job matching between jobs and candidates. It didnt worked all that well for a few reasons \n\n\nWe also did had integration with ChatGPT because boss wanted the AI to write job descriptions to save recruiters time, which didnt made sense because we would also have an \"AI\" read the description to find the best candidates\n\n\nAnother one was to read a resume and find all the revelant info, parse and then we save it, instead of the candidate having to type out the same stuff again. \nThat one was actually really good. It helped both candidates and recruiters. \n\n\nBut as many others, we were being \"forced\" to use AI. Even when it didnt made all that sense. \nSometimes it did helped us to save time, but it was a case of boss saying such feature and immediately saying to use AI\n\nYes. But one of my great challenges is explaining the bosses why my team of 3 can't do the things deepmind/openai does. \"this problem is easy compared to.. folding, alphago.. etc\"  \n\nEvery morning, I have my coffee and read about a new ML breakthrough, and regrettably, so do the powers that be. Which means every late morning I get to explain why we did not invent xyz in house or are using it.\n\nThe most useful is (as the other poster stated) summarization tasks. As someone who takes my own automation skills for granted, I‚Äôm amazed at some of the crummy non-standardized manual processes that workers do around clock. Like I would go insane having to do these things! And they can all be easily streamlined so long as we have documents and genAI.  \n\nAnother big thing is just educating people about AI. I have a ton of clients who are excited about the word but don‚Äôt even use current offerings in their daily lives. Most non-tech old people have never used chatGPT and so don‚Äôt even know how realistic their requests are.\n\nYea this seems like the weirdest part. Its very accessible, anyone can try it, yet people who haven't tried it out are glomming their hopes and dreams to a new technology. I don't even think LLMs are that difficult to understand for the layman if they just take a minute to think about it.\n\nFor 6 years now..  Computer vision for industrial applications. Things like quality control in factories. It works. At it's base it's pretty old tech, for some customers, we're still using AI model architectures from 2015 or so. Resnets and U-nets etc.\n\nActual data science is just a fraction of our work now. It's a lot of front-end work and UX to enable factory workers to label images and train new models etc.\n\nI'm in the product part which has been (somewhat..) decoupled from customer deadlines so pretty low stress. It's Europe, man. Half my colleagues work 4 days, nobody expects answers after 17:30, and there's always a few guys off on holiday. Doesn't mean we can't build stuff that works.\n\nA ton of really useful stuff is happening in gamedev rn,  just needs a bit longer to get integrated into the ecosystem and for the tools to mature.\n\nAlthough that's less llm specific.\n\n The companies that decided to mass market ‚ÄúAI‚Äù as a labor replacement tool instead of an enhancement tool are treating their workers like expendable dogshit?!\n\nNo way\n\nThe ad money must be drying up\n\nI had to install ad-blocker on my kids Chrome books because google ads were feeding them \"Your Computer has been infected by a virus click here\" ads.\n\nI can't believe how badly they have screwed their own business model.\n\nChrome books should be banned as much as TikTok.  Super google garbage that are unregulated just as bad.\n\nNever been a better time for a union than now.\n\nCompanies are really burning people out to build shitty AI integration that no consumer would pay a dime extra for\n\nHere's the thing about dramatic increases to developer productivity: the more productive a developer could be when working, the more pressure will exist for that developer to be working, because every minute spent NOT working is a greater and greater opportunity cost.\n\nSo, if you could shit out a new app in a week vs a year, then any week you spend not doing that is very costly - equivalent to now spending a year doing nothing.  \n\nAs a developer, I do not look forward to this world where all my moments become potentially that valuable.  The pressure will be immense.\n\nAlso they they don't seem to want to listen to the things that would actually increase productivity...things like scheduling meetings in a way that gives us blocks of uninterrupted time and having it be a priority. \n\nThere is so much time wasted in a given week - I don't even hate meetings, but I do hate the expectation that meetings are just sprinkled all over the place, which destroys focus, and then there is still pressure, so some people work long hours/weekends/etc. \n\nIf engineers had more control over their schedule, and focus time was respected, productivity would absolutely increase.\n\nMy take on the meeting thing is that it's just a result of managers believing their own time is more valuable than their reports, and thus making schedules that suit themselves.\n\nPlease stay strong in your AI jobs, because I don't want those jobs and I don't need more competition for the non-AI engineer jobs.  It's hard enough.\n\nChoo choo motherfucker! I'm a (hype) train!\n\nIt's not just AI engineers. Our VP is pressuring us to shoehorn AI into our product. None of us were hired for AI and it doesn't make sense for our product, but that doesn't matter. AI is good for the VP's career, so now we have to figure it out instead of solving the problems our customers actually care about.\n\nDoes anyone notice how every god damn article has this fake feel to it? Like it was shit out by some kind of AI or something?\n\nMust. Bait. Clicks.\n\nCan't wait for the bubble to burst! üòÖ\n\nWhat's the interesting space for your generic API devs like myself? I'm building out a prototype for a project right now and there's a spot where I think I can integrate some LLM summarizing through GPT, but I'd basically just be hooking up OpenAI and doing some \"prompt engineering\". Is that what many are doing? Or is there some other lucrative space for run-of-the-mill devs right now?\n\nYeah a lot of api wrapper stuff. You could also look into how to make custom rag pipelines, which really isn‚Äôt that hard either.\n\nAI is new crypto üôÑ\n\nOn one hand, it's been great for anyone in R&amp;D roles who really like to tinker and experiment. My company has been shoveling money at my team to create integrations for GPT and other foundation models. We've created a lot of cool things in the last year and have learned a lot.¬†\n\n\nOn the other, it's pretty damn stressful because management really does treat it as a race and we need to show constant progress and innovation, even as we're running up against the limitations of these models\n\n&gt; On the other, it's pretty damn stressful because management really does treat it as a race and we need to show constant progress and innovation, even as we're running up against the limitations of these models\n\nSee that's the thing - if you need to tinker and experiment, can you even really do that in the type of environment you describe? \n\nRush,rush,rush - progress, progress, progress.\n\nReally stifles creativity imo.\n\nI've dialed-back my voluntary participation in AI side projects at work.  It's fun and management gets excited, but it's takes a lot of time away from my day job and often the efforts are rendered obsolete within a few short months when inevitably some new AI technique comes out that is way better and easier.\n\nI don't know how much longer I can tolerate Agile and the idiocracy of upper management.\n\nThe key is not caring. Fuck em. I will do what I‚Äôm paid for but I won‚Äôt give two shits past that. It‚Äôs very freeing.\n\nWe all oughta become mercenary contractor hired guns. F being 365√ó24√ó7 cannon fodder\n\nWhat does Agile have to do with this?\n\nI don't see what agile has to do with any of this. Shitty management is shitty management, no matter what system you use.\n\nI swap places with them in a heartbeat. Change jobs every year between competitors for huge sums of money or shares. Work for 5-10 years and never have to work again.\n\nIf you mentally survive. I‚Äôve seen some of the best PhD‚Äôd individuals who survived gruelling grad school programs slowly crack in these environments.\n\nYou underestimate the money for ‚Äúnever needing to work again‚Äù. The stock for most of these isn‚Äôt growing to turn into a fortune and you have to be in an expensive place. You‚Äôll make good money, but often under awful conditions, and in the end the marginal difference between whatever else you could be doing in a cheaper place and this ugliness won‚Äôt be so huge.\n\nWow! Fucking knew this would happen.  \n\nFrom my experience. When standards and quality control get thrown out the window to prioritize on $$ and rushed deadlines. ALWAYS leads to very bad decisions!\n\nPeople ask me if I want to move into the LLM and AI space, I'm like hellllllll no\n\nThat was quick LOL\n\nAll the ai developers need to strike before AI gets out of hand and the AI can start writing itself putting all developers out of work\n\nAn AI that can write itself won't be trained on code I wrote\n\nthey should just use AI\n\n&gt;Engineers and those with other roles in the field said an increasingly large part of their job was focused on satisfying investors and not falling behind the competition rather than solving actual problems for users. Some said they were switched over to AI teams to help support fast-paced rollouts without having adequate time to train or learn about AI, even if they are new to the technology.\n\nFocus on investor satisfaction and perceived market edge over customer satisfaction, for user-facing software, seems shortsighted and destined for failure.\n\nAre they crying into their half million dollar paychecks?\n\n-sincerely, gaming industry\n\nPlease stay strong in your AI jobs, because I don't want those jobs and I don't need more competition for the non-AI engineer jobs.  It's hard enough."
  },
  {
    "title": "One Of The Rust Linux Kernel Maintainers Steps Down - Cites \"Nontechnical Nonsense\"",
    "body": "",
    "score": 1173,
    "url": "",
    "created_utc": 1724943541.0,
    "author": "steveklabnik1",
    "permalink": "/r/programming/comments/1f44kp0/one_of_the_rust_linux_kernel_maintainers_steps/",
    "all_comment_text": "Everyone should watch the video clip that the maintainer in question posted for context: https://youtu.be/WiPp9YEBV0Q?t=1529\n\nThat was very hostile for no reason.\n\nOpen source always seems to attract more than its fair share of assholes and petty tyrants on an ego trip.\n\nIt's a great example of [Sayre's law](https://en.wikipedia.org/wiki/Sayre's_law). Disputes about less important things produce more intense reactions. Or: \"~~academic~~ open-source politics are so vicious precisely because the stakes are so low\".\n\nVolunteer organisations always do.\n\nWhen the only people working there are people who have some personal or hobby interest in the cause, you‚Äôre bound to have some very emotional responses to things.\n\nThere is well established corporate governance theory around the phenomenon.\n\nBut the vast majority of Linux development is done by paid full time professionals. Most subsystem maintainers are employed to at least work part time on Linux.\n\nI would think that most people who get into programming at the level of kernel dev are very passionate about what they do. There‚Äôs plenty of easier programming jobs that pay very well. Not saying the hostility is okay. Only agreeing with u/Xyzzyzzyzzy &amp; u/comparmentaliser\n\nAs someone who worked full-time as an open source developer for *years*, and who still contributes to FOSS projects: That isn't it at all.\n\nYou find these exact sort of people in the corporate and proprietary software worlds as well, even in easier / better paying jobs, and it is not rare to hear about people quiting their jobs because of dealing with toxic team members.\n\nWhat is different is that we don't see them.\n\nOn the one hand, the corporate environment is designed to quash open discussions and impose non-social controls over these interactions, so they happen less often and usually less visibly.\n\nBut they do happen .. we just don't get recordings of them on youtube or big reddit posts about them (save on the subreddits dedicated to work gore).\n\nJust this past year, I had something not disimilar occur at work and it shook some of my teammembers. We worked through it, but it had the same energy as this.\n\nWe can blame FOSS all we want and invent all sorts of theories about the people who work on open source, but it's just that simple: these people exist in similar amounts across the industry, open or proprietary, hobbyist or professional. \n\nSome organizations do a better job than others of handling these situations as well as generally disuading them (often by working to create non-toxic environments in the first place), others ... do not. The Linux kernel has never been good at this, in no small part because their \"upper management\" has some serious personality issues (which they are aware of and have been working on). I've worked with companies producing proprietary tech that are no different. \n\nThere are also open source communities which are an absolute joy, including ones that tackle very difficult and 'unrewarding' types of tasks. I have worked with companies producing proprietary tech that are no different.\n\nIME (well over 30 years now), the occurance rate is about the same, and has generally been improving over time. Hopefully others in this thread such as u/Xyzzyzzyzzy will read this so they can rethink their simplistic stories about what is a pretty universal phenomenon.\n\nExactly people are passionate about this. The concern that was being pressed was non trivial. Breaking the Linux Filesystem and chaining down C from making any changes (because it might break Rust) matters to these people.\n\nI can understand the heat, my empathy goes to the maintainers of both Rust and Linux.\n\nIt sounds like the speaker was trying to say he doesn‚Äôt want potential breaks in the rust code to prevent people from making changes in the C code. Did I misunderstand? I don‚Äôt really know much about what they‚Äôre talking about\n\nThis unfortunately is true.\n\nAs a \"generalist\" who has volunteered in a few different organizations, dealing with the true believers quickly gets tiring. They tend to think that their cause exempts them from having to observe normal social niceties.\n\nI‚Äôve heard this called ‚Äúpainting the shed‚Äù. No one wants to build the shed or challenge difficult things, but when it comes to the trivial act of painting the shed. The critics come out of the woodwork.\n\nEasy to gripe about things that are well understood. :)\n\nI've seen it called bikeshedding\n\nhttps://en.wikipedia.org/wiki/Law_of_triviality?wprov=sfla1\n\nIt doesn't hurt that probably the 2 most prominent proginators of the open source movement, RMS and Linus Torvalds, are both notoriously huge assholes.\n\nYup, a lot of programmers are imitating Linus's older days because being abrasive and rude to them seemed like 'succeeding' like Linus did. They kind of forgot that Linus realized how much of a jackass he was being and has improved, can't say that for RMS though.\n\nLinus might have improved but he's still pretty darn rude IMO.\n\n\nI think another problem is that being abrasive DOES work on a whole lot of people. If more people called out their bad behavior and refused to work with him, they might actually change even more.\n\n&gt; Linus might have improved but he's still pretty darn rude IMO.\n\nDo you have an example? Most of the time people mistake being direct for rudeness.\n\nhttps://lkml.iu.edu/hypermail/linux/kernel/2401.3/04208.html\n\n\nalso the linusrants sub\n\nThose linusrants subs are mega-biased. They WANT to depict Linus rude.\n\nI noticed this years ago, when people pick out one email out of 1000. This is not an objective analysis about a person if you select only the one \"controversial\".\n\nYou are missing the earlier message where Linus politely tells the guy he got some key things wrong, and that he should approach the problem from a different perspective (which he shows), to ensure the patch works correctly. The guy then decided to double down on his original approach, prompting this response.\n\nThat‚Äôs usually how most of his flame messages are. They are replies to people who ignore his explicit instructions on how to do certain things.\n\nHa ha, touche.\n\nAt least these days it feels like he insults the thing you brought to him. In the past the rants would be targeted at *you*.\n\nI don't consider it \"abrasive\" - I consider it quality control. You need to ensure standards.\n\nNow, I am not saying that the Linus way is the best way; perhaps the japanese way is better (there is a reason why kaizen originated mostly from japanese, if we exclude prior quality control steps done in the world). But either way you need quality control and quality management. Being nice does not guarantee results. \"Look, that code that you used to invoke rm -rf could perhaps be ... uhm ... written differently, but I really really like your effort and the documentation about it.\" Is that better?\n\nYeah, I had no idea. There‚Äôs entire subs dedicated to rants of Linus. At first I thought it was kind of comical and funny, but it quickly lost its flavor. Appreciate that he‚Äôs fighting the good fight, but I don‚Äôt appreciate the fighting style.\n\n&gt; Sayre's law\n\nObjection: this is called bikeshedding!\n\n&gt;Open source always seems to attract more than its fair share of assholes and petty tyrants on an ego trip. \n\nYou know those people on r/cscareerquestions who make posts like \"I have a first from Cambridge and I've memorized every single leetcode task yet I keep getting rejected at the culture fit stage, I don't understand what I'm doing wrong!\"\n\nThose are the people who end up working on OSS projects.\n\nHostile bike-shedding.\n\nThat was very hostile, but for very good reasons that you didn't understand.\n It's a dispute between philosophies and practices. f you watch the video in its entirety:\n\n1) the C team insists that the Rust API must mirror the C API (or be a wrapper), because else, it makes their verification far more difficult.\n\n2) The Rust team thinks they shouldn't model the C API because it's unsafe, while the Rust API could be much better and safer.\n\nThe issue here is, in the end there is only one FS maintainer, who is responsible for everything that goes out and every bug in the system. He now has to verify TWO completely different code bases that are supposed to behave exactly the same. He refuses to have double the maintenance work, especially when one code base he has to validate is written in a paradigm he doesn't master.\n\nWhat is in the line is his responsibility. It's the file system API after all. Logical bugs there can result in data loss for millions of users, and entire systems going down. Blaming him for being too lazy to bother learning Rust is completely besides the point. There is no more reason to expect him to understand the Rust codebase than to expect the Rust developers to understand the C codebase by themselves.\n\nAlso, while not knowing Rust, Ted Ts'o understands this: https://www.reddit.com/r/programming/comments/1f44kp0/one_of_the_rust_linux_kernel_maintainers_steps/lkmt0rx/\n\nWhat you describe is *‚Äôpositive criticism.‚Äô* Legitimate issues put across in a straight forward or positive manner. Everything you raised is legit, and there is a tiny bit of that in the video.\n\nWhat‚Äôs also in the video is *‚Äônegative criticism.‚Äô* That includes nonsense claims like they are pushing a religion, ignoring what the Rust maintainer has said in reply, misunderstanding things and refusing to try to understand the other persons argument, nitpicking irrelevant issues as though they are major negatives, and so on.\n\nPositive criticism gets you to better software with everyone happy. Negative criticism is an asshole being bullish with his closed minded opinions.\n\nThank you. I wish other redditors were able to express themselves without resorting to belittling and bad faith behavior.\n\n&gt; 1) the C team insists that the Rust API must mirror the C API (or be a wrapper), because else, it makes their verification far more difficult.\n&gt; \n&gt; 2) The Rust team thinks they shouldn't model the C API because it's unsafe, while the Rust API could be much better and safer.\n\nBut even with a wrapper, you still need to know the semantics of the thing being wrapped, and Ted Ts'o and gang are refusing to provide such documentation.\n\n[deleted]\n\n&gt; insists that the Rust API must mirror the C API \n\nThe rust API is just making explicit what the C driver has implicit.  \nAnd they also been clear they have no problem if the C guys change the API, they will update their code.  \n  \n&gt; He now has to verify TWO completely different code bases. \n  \nNo he does not, rust guys said very clearly they are willing to do it, the issue is communication.  \n  \n&gt;Logical bugs there can result in data loss for millions of users\n\nWhich is why we need good documentation, and making those implicit assumption explicit in code.  \n  \nSimilar issue happen recently with ashaii: she wrote a graphic driver in rust, the maintainer said it was wrong because she did use the C API wrong, her answer was pretty much \"there is no docs so I just did what the other driver in C do, so if I am wrong all of them are wrong too\".  \n  \n &gt; Blaming him for being too lazy to bother learning Rust  \n  \nWho blame him for that? Tod claim so, but both the presenter are very clear this is not the case and that responsibility would fall on them.  \nYeah maybe a Rando on the internet told him so, but I'm sure a Rando told him he should rewrite it in brainfuck.   \n  \nSorry but Tod is inventing/manipulating issue just so he can be enrage by it.\n\n&gt; but for very good reasons\n\nIME, there's really no good reason for *hostility*. Anything that needs to be communicated can be done without hostility, and usually ends up being communicated more effectively and with better results.\n\nI agree with the points you made about the nature of the disagreement, but there is no \"and therefore hostility\" argument that follows from that.\n\nIt's a learned skill, sure, and everyone fails at this at some point or another, but it doesn't mean we ought to accept or condone it, even if there is a valid underlying issue.\n\nIn this case, I suspect their case would have been made much more effectively, and listened to much more carefully and with more openness, had he made an effective and clear argument.\n\nAs a side note: if you can't make that sort of argument, you don't understand your proposal well enough yet. Or, you're just wrong.\n\nWhat the hell did I just watch... A poor guy on stage is trying to do a presentation on \"here's how encoding semantics into the type system can help detect bugs earlier\", barely gets *2 slides* in his presentation before it all gets derailed with \"Yeah, but you changed the name, I like the old name\", \"actually, you didn't perfectly capture all the pedantic details in your example that I refused to help with\", and \"you won't force me to learn Rust!\" bullshit.\n\nThe patience on this man to stay diplomatic and not just tell \"Shut up, it's just an illustration, not a code review. I have 20 more slides I'd like to go through\"\n\n&gt; \"Shut up, it's just an illustration, not a code review.\"\n\nIt's a bit of a code review too though. They were introducing new concepts into the API. They proposed changes that have significant consequences for the 50 filesystems in the Linux tree.\n\nThose changes make sense for Rust, and it makes life easier for them, but makes life harder for the C filesystems, and makes life much harder for the guys in charge of the API.\n\nRust's major pain point as a language is the need to refactor a lot of code when some semantic is changed. The Rust guy was proposing to push some of that pain to the API maintainers, and the maintainers were like \"hell no, we have enough problems already\".\n\nThe guy on stage repeatedly reminded the guy who was losing his shit that they weren't pushing anything more than documentation onto their responsibilities and that the Rust guy was willing to do most of the heavy lifting there.¬†\n\n[deleted]\n\nWho hurt that dude ? This type of devs (whether they are smart or not) are the worst\n\nI remember back when I was that type of person.\n\nI was 14.\n\n\"Look, this doesn't affect me one way or another, but I think this is going to be a train wreck.  I'm just going to stand back and watch, but when this train wreck happens just remember I tried to warn you,\" says man with a rope looped around the railroad switch that he keeps tugging on.\n\nThis is insane, he's not pushing anything on anyone, he's just showing how Rust's verbosity can aid it's static analysis and catch bugs early.\n\nHe isn't pushing anything on them, but in the end, they will be the ones responsible. That's why they are pushing back.\nhttps://www.reddit.com/r/programming/comments/1f44kp0/one_of_the_rust_linux_kernel_maintainers_steps/lkn0wxs/\n\nwhy is the c/c++ community so toxic?!\nAnd why do they keep repeating the same Java jokes for 20+ years, its getting weird at this point\n\nC developers especially are always elitists.\n\n~~C~~ developers ~~especially~~ are ~~always~~ elitists.\n\nDecades ago i was in a townhall at IBM where they said:\n\n&gt; Java Developers are a dime a dozen and cheap. C developers are expensive.  We want to use the C developers to build a framework for java developers to work in\n\nI'm not saying C developers deserve a chip on their shoulder, but i will say they may have acquired it through external means.\n\nLots of C developers hate C++ developers.  Lots of C &amp; C++ developers hate Java developers.  Lots of non-rust developers hate Rust developers.\n\nEveryone is afraid that technology Y is going to be the hot new thing and their skills will become unmarketable, despite the fact that the most valuable language you can possibly know right now being COBOL.\n\nThat's a myth really. You have to know COBOL, which isn't hard, and really understand the buisness logic of the types of systems your working on so you understand why things are done the way they are. Which isn't as easy.\n\nYou have to understand the business logic of the internals of any company you work for, regardless of tech stack.\n\nI don‚Äôt hate them, I am getting sick of C programmers shitting on every other language for vapid reasons.\n\nIt‚Äôs been a recurring theme around here lately.\n\nProfessional C++ dev. The big big majority of us couldn't care less. The ones you see on stages like these do, sometimes unhealthily so.\n\nIt's also just not that hard to learn a new language. It's kind of silly this guy is acting like it's everyone else's problem the community is using a new language he doesn't feel like learning.\n\nThe rust devs bring this to themselves tbh\n\nThe C++ community is generally fine (more so than Rust, IMO). C, however, not so much. Too many bitter boomer neckbeards and elitist twats with inflated egos.\n\nIt's probably a similar reason to why hospitals insist new doctors work stupid hours and put patients at risk: because they had to go through it.  C and C++ are super complicated languages with more foot guns than features.  These are people standing on the pile of bodies of those who couldn't or wouldn't suffer through it.  The difference between this and doctors is: the creation of more advanced languages has put their voodoo nonsense at risk.  Maybe it doesn't have to be so hard that few people are earth are able or willing to get involved.  Maybe large portions of the work they are doing could just be done by the system.  If that happens then we don't need to work with such people anymore because so many new people would be able to help.  That's what scares them and that's why they're so toxic about it.\n\nThe best bit was the religious fanatic calling them religious fanatics.  A real engineer uses the best techniques available to them.  Imagine these guys at the unveiling of the first automobile: they'd be raging and ranting about how we've got to stay with horses, etc.\n\nlavish wipe jobless depend squalid gold imminent scandalous coordinated cow\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*\n\nHe is talking about the concern with Rust encoding a bunch of semantics into the API and that making it easier to break things and then his major problem with that seemed to be that by convention the person who breaks APIs goes and fixes it for everybody else to remedy the breaking change. So if things are now written in Rust, then that creates an expectation that he learn Rust well enough to do that, meaning now he has to work in C and Rust.\n\nSo for a simple example, that Linus Torvalds will probably come out of the woodwork and roast me for, a pointer in C is just a pointer. Like, they might be using `void*` or some aliased type of that. So it doesn't matter what it points to. But now if Rust is expecting stuff to return `Either` a `This` or a `That` then if the do the wrong thing with that `void*` it will break the Rust and then they would (normally) be expected to go fix it.\n\nIt‚Äôs a way for him to pretend that this whole idea is some incredibly new thing and it‚Äôs just so questionable and high risk.\n\nAs opposed to modern languages having modern type systems for decades now.\n\nJust typical bullshit from C people. It‚Äôs like how first the Go guys insisted that generics weren‚Äôt needed then they insisted they hadn‚Äôt seen an implementation they liked.\n\nIt‚Äôs just like how they frame the lack of features and shitty type system from C as ‚Äúsimple‚Äù and insist that any flawed code is just a skill issue.\n\nlunchroom vast fuzzy sense wild wine station seed snow husky\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*\n\ngo still doesn't have packed structs.\n\nWant to read a binary file? Good luck!\n\nThis has nothing to do with modern vs legacy programming languages\n\nIt's religious talk.  He's basically saying \"we'll see if having the compiler exclude whole classes of errors from our code would be good or not!\".... of course it would be good.  This is like a script kiddy trying to claim you can use e.g. PHP to write big production systems.... you can but why would you?  It's too expensive to work this way because the developers have to do a bunch of work that the system of a more appropriate language can literally prove is safe or not.\n\nThe best part was him calling *them* religious.  His position is not an engineering position, it's the position of a religious fanatic and Linux will eventually die if they don't get dinosaurs like this out of key positions.  You can be sure that Apple and Microsoft are working with more advanced languages to make creating and maintaining operating systems cheaper.  It's just a matter of time before they are both superior to linux in every dimension because of it.\n\nCan somebody explain what is going on in the context that was included?\n\nLooks like a conference presentation about a filesystem written in rust and an audience member is talking down on them? What's going on there?\n\n&gt; Can somebody explain what is going on in the context that was included?\n\nhttps://lwn.net/Articles/978738/\n\nAmazing summary, it makes though sound like the discussion was more rational than it seemed if you watch the video linked above.\n\nHonestly even the video linked above makes sense if you are willing to accept people can have diverging opinions.  \nYes adding a new language is going to add extra burden, and this needs to be addressed. The way people communicate is not the best, but the worst that could happen is being ignored, then the project would truly die. Here you know what you need to work on.\n\nIt makes sense, the problem is the style, timing, and not be willing to listen to what the other person is saying.\n\nExcept he attacked them as being religious zealots then claimed they were making demands they have never made and finished off by crying about much he doesn‚Äôt want to learn rust.\n\nThis wasn‚Äôt a diverging opinion, it was just asshole having a public tantrum.\n\nI've been working as a C programmer for the last 15 years or so, and I don't know a single thing about Rust.\n\nWatching this video has substantially increased my interest in Rust. The C guy is sounds like a dick and says dickety things in a dickety tone.\n\nThe problem is that it's not a \"small burden\", like \"oh, just get on the shiny new Rust train and get with the program and deal with it\".\n\nYou have 10000 programmers who have been working with C in the kernel for 35 years.  There are hundreds and hundreds of different subsystems (filesystems, drivers, memory management, schedulers, you name it), that have groups of maintainers that all have to work together.\n\nYou can't just waltz in there with your shiny new language and say \"this is the future, you must now start coding with an entirely new paradigm that fits in with our shiny new toy, and if you break something in my code when you fix something, that's your fault\".\n\nIt's really easy for the Reddit peanut gallery to come in and say \"Oh, that Ted, what an asshole\".  He has some valid points; even Linus' acceptance of Rust is conditioned on the interface being kept clean and simple, and not acting as a boat anchor on future development of the kernel.\n\nRust is a massively new paradigm, and while it may seem now that it's \"obviously the greatest thing since sliced bread, and C is such a shitty stupid language that's only for stupid people, and they should just bow to our superior language now\", that's just not going to happen.\n\nAnd that's just the truth.\n\nEdit:  If the Rust community (which includes the Peanut Gallery above) can produce even 100 competent kernel developers who are willing to work with Rust in the kernel, that would be a HUGE thing.  It's easy to throw stones from the gallery - get in there and do the goddamned work yourself, and your opinions may well change.\n\nThe guys presenting didn‚Äôt say any of that. Why would you make such claims?\n\nPeople are calling Ted a toxic asshole because he‚Äôs doing things a toxic asshole does. You‚Äôre furthering the problem by repeating the same nonsense.\n\nWhy the fuck would anyone want to deal with being bullied for trying to do their job? The asshole won, he bullied another kernel dev into quitting. He won‚Äôt have to give up shitty C.\n\nAnd if you aren‚Äôt willing to admit the problems of c at this point you‚Äôre hopeless buds absolutely hopeless.\n\nJust another arrogant C dev convinced they are experts on everything even as they refuse to learn anything outside their comfort zone. Arrogant fools.\n\nMate. You can't fight toxicity with more toxicity. You need to chill.\n\nThis comment seems to give some context: https://www.reddit.com/r/linux/comments/1f3q0l8/comment/lkg1vk9/?utm_source=share&amp;utm_medium=web3x&amp;utm_name=web3xcss&amp;utm_term=1&amp;utm_content=share_button\n\nEverytime I see something like this now I think back to XZ with the official tarballs getting compromised and how they harassed the original maintainer until he burned out and handed the project over to them.\n\nIt seems especially relevent here...\n\nYea it sucks, Linux and open source devs are notorious for extreme toxicity. It‚Äôs all they have and never developed personal, social, emotional, or professional skills in how to treat people.\n\nI used to contribute but got burnt out and now just build stuff for myself, sometime releasing some stuff publicly if I feel like it. I stay away from big projects though since it‚Äôs dumbass divas over the stupidest shit.\n\nThis dude has been working at major companies for decades, he currently works at google.\n\nHe‚Äôs never learned to act like professional? Doubt that. He chooses not to because no one will call him out on it\n\nHe very clearly did not act like a professional here.\n\n&gt; I stay away from big projects though since it‚Äôs dumbass divas over the stupidest shit.\n\nWell if the good dev are all leaving then sure, only the assholes will stays. (Speaking as a big lib maintainers who had to leave an organization controlled by a single asshole with 5 \"can't bother standing up to the asshole\" normal friendly devs)\n\nI highly doubt that [Ted T'so](https://www.reddit.com/r/linux/comments/1f3q0l8/comment/lkg1vk9/?utm_source=share&amp;utm_medium=web3x&amp;utm_name=web3xcss&amp;utm_term=1&amp;utm_content=share_button) is a black hat trying to compromise Linux by driving out Rust developers.\n\nI never said he was, I was referring to how they created a toxic environment to burn them out. If this isn't a toxic environment I don't know what it is.\n\nZersetzung is very effective.\n\nThank you for introducing me to this [term.](https://www.maxhertzberg.co.uk/background/politics/stasi-tactics/)\n\nThe more who know about it the better, it hasn't gone anywhere.\n\n[Putin's Stasi spy ID pass found in Germany](https://www.bbc.com/news/world-europe-46525543)\n\nTed T'so has certainly stubbornly maintained many incorrect positions despite many people disagreeing with him (/dev/random).\n\nYou can ALWAYS find people agreeing or disagreeing with just about anything. That in itself does not mean much at all.\n\nFrancis Ford Coppola in his prime had numerous film critics conclude that movies such as Apocalypse Now or the first two Godfathers were crap. And that turned out to have been wrong by these film critics. (Note I write prime; I think age caught up to him as well in the end.)\n\nSome people probably didn't like those movies, but I think what you are referring too was actually fake.\nhttps://www.bbc.com/news/articles/cwywdppv9n3o\n\nPeople disagreeing with you has never been a reason to change your position\n\nNo he‚Äôs just doing it because he‚Äôs an ass.\n\nHe absolutely does want to drive out Rust developers.  Not for black hat reasons, but because if you have a more sophisticated programming language that can detect more issues suddenly we don't need to deal with jerks like him, there are suddenly way more people able to contribute because the code isn't nearly impossible to maintain as a human.  He has built a castle and now he's trying to protect it apparently the only way he knows how.\n\n- Ted: I don‚Äôt like Rust, the experiment will wind up a failure\n- Ted: Flames Rust developers to make it clear he doesn‚Äôt want them, refuses any attempt to be accommodating, does everything possible to  block progress\n- Rust maintainers: get burnt out from uphill battles, contributions slow down \n- Ted, in another year: ‚ÄúSee? Told you it would be a failure‚Äù\n\nSounds like this is an attempt to bully rust out and then confirmation-bias that it was doomed to fail, by doing everything possible to try to make it fail.\n\nLuckily the kernel is full of many many people that are more open minded people than Ted, the naysayers are always just the loudest.\n\n&gt; \n&gt; \n&gt; Ted: Flames Rust developers to make it clear he doesn‚Äôt want them, refuses any attempt to be accommodating, does everything possible to block progress\n\nIn any other world, this kind of open hostility would be taken seriously by program leadership and he would change course or be excised.\n\n&gt; In any other world, this kind of open hostility would be taken seriously by program leadership and he would change course or be excised\n\nNo. You can't do that when such a large part of your most competent developers are against a change.\n\nYou can be against a change without being a caustic shithead. You can kick out someone you agree with on technicals if you think their behavior is inexcusable.\n\nWith Linus backing rust?\n\nLinus's leadership is at the level of \"strong moral suasion\" interspersed with curses. He can't, however, straight out fire people.\n\nLess and less curses and toxicity recently.\n\nHe is getting old. Sadly it'll be the young ones who change the world ... I mean, old Linus wouldn't write a linux kernel from scratch. That required a young Linus. (And yes, he had help from tons of people; I am not saying the Linux kernel is solely the work of Linus.)\n\nWell cases like this are what make a leader. And if Linus wants he certainly has enough social capital to do that.\n\nI sincerely hope he spends a little of that capital and says \"this isn't ok.\"\n\nthe developer of the GPU Driver for MacBook (or M CPU/SoC in general I guess) so you can run Linux on it also experience the same thing, since she uses Rust for the driver the upstream progress is so slow and her suggestions or discussion just not being considered, they're actively slowing down Rust adoption just because they don't want new language, not because the language is bad or anything\n\nFuck you, fuck you, fuck you‚Ä¶\n\n&gt; To the Rust for Linux team: thank you, you are great. \n\n‚Ä¶ you‚Äôre cool, and fuck you, I‚Äôm out!\n\nThat guy on the audience was very emotional. He was clearly triggered by fear of seeing rusr becoming the \"first class citizen\" in the Linux kernel. The other guy repeated several times \"WE ARE NOT FORCING ANYONE TO USE RUST\"\n\nBut implicitly, they are forcing him to use Rust. As a maintainer responsible for kernel module after refactoring he needs to fix all 'users' of API he maintains which also includes rust bridge which takes C API through FFI and transforms it into strong Rust types through safe wrappers. To 'fix' them, he must now go outside his 'C' domain and understand Rust code.\n\nThere is a real discussion to be had about this and plans on how to deal with breakage but without all these emotions.\n\n&gt; But implicitly, they are forcing him to use Rust. As a maintainer responsible for kernel module after refactoring he needs to fix all 'users' of API he maintains which also includes rust bridge which takes C API through FFI and transforms it into strong Rust types through safe wrappers. To 'fix' them, he must now go outside his 'C' domain and understand Rust code.\n\nDid you watch the presentation? The Rust people said, *multiple times*, that they would be happy to take care of fixing Rust stuff when C interfaces change.\n\nA huge amount of exhausting discourse is people replying to things they imagined rather than what was actually said. Just look at this thread, the comment you replied too is not the only one...\n\nIf I had the option of world peace or fixing people imagining what other people think, I would solve every problem ever by choosing the latter.\n\nEdit: spelling\n\nI imagine you were thinking of \"latter\"\n\nThx, not my first language\n\nI usually blame the cat walking on my keyboard. People usually believe that, knowing how sneaky cats can be.\n\nIf I had the option of world peace or fixing people imagining what other people think, I would solve every problem ever by choosing the later\n\nI'm skeptical whether the Rust people will be able to keep up.\n\nThat really doesn't seem practical. Like, what if I just want to try something? How do I experiment with changing C interfaces on my local machine if I need somebody else to come fix up the dependent Rust code? How can I be productive if my changes won't even compile without you making corresponding changes?\n\nBecause the rust code isn‚Äôt going to block kernel development when it breaks.\n\n[deleted]\n\nThey are justified in being concerned, but I don't think they are justified in acting the way the person did in the video.\nBeing the intelligent people they are I think they can work out who has which responsibilities. If people want Rust in the Kernel, they have to work hard for it and might get little help. But  actively bullying people out of their passion is just plain rude\n\n&gt; I think they can work out who has which responsibilities.\n\nBeing intelligent and being able to solve all kinds of problems does not seem to go hand in hand. Example: Two rust devs. unable to stop a derail, which is one \"would you kindly continue this discussion at the end of the presentation\" away. \n\nAlso this is a problem that probably should have been solved at that point. It has been four years since the start of the rust for linux project, having a fleshed out process that was discussed with the people involved seems reasonable.\n\nI don't blame them for not being able to perfectly argue on the spot or moderate such a heated situation. Moderating is really hard. I don't think they were prepared to debate people (but I have to admit debating against someone who is angry is easier). And one of the presenters is stuttering.\n\nI think the best solution would be if they had a person that is moderating the questions section. Someone with experience that can shut situations like this down as fast as possible\n\nNah, dude was a bully the response should have been ‚Äúwe didn‚Äôt say that. Don‚Äôt stick words in our mouths. If you can be reasonable then sit the fuck down and let us finish‚Äù.\n\nNot gonna get anywhere by just letting a bully walk all over you.\n\nAnd sometimes people just quit, and maintainers inherit the code until they find someone to put in charge of it. A C maintainer having to fully maintain a large Rust project sounds like a nightmare.\n\nSo every time the C maintainer changes the C API, he has to get the Rust maintainer to fix the Rust layer *before the kernel will even build*? Before he can test his changes? Will he pair program with the Rust maintainer?\n\nI don't think so, if there's a C API changes anyway, then there would be a change in the codebase, and he don't have to \"get\" the Rust maintainer, the Rust maintainer understand and would do it on their own, it's their job, and why would he need to wait to test his change? just test and push, if his change can't be tested because there's something blocking it, I dont think the absence of Rust would eliminate it, it would just be a blocker anyway, let the Rust maintainer do their job next and test their stuff, you just unnecessarily making it more complicated than it has to be\n\n&gt;  that they would be happy to take care of fixing Rust stuff when C interfaces change.\n\nThey also mention outright that they will need the input of the C developers for that at the beginning of the presentation. Turning a fine tuned process of managing thousands of commits and merge request that the guy can do by himself into a coordinated effort where any merge might require scheduling meetings, preparing an ELI5 summary of the changes that covers every possible change of semantics and herding cats who seem to think that one large breaking change is the best chance to run wild with the kernel naming convention and leaking implementation details into a public interface.\n\nDid YOU watch the video? You seem to have a selective memory because the presenter first stated that the binding should be fixed by who broke it and relented when the response was that other won‚Äôt be forced to learn rust.\n\nI'm no kernel developer but, it \"should\", not \"have to\", if the user of the binding, e.g the rust developer is free and can help, why refuse such help? sounds like a good reason to off load the work‚Ä¶\n\n&gt;But implicitly, they are forcing him to use Rust.\n\n\nIsnt *Linus* forcing them to use rust by¬†allowing rust in the kernel? Why are we blaming rust devs when Linus made the call?\n\n\nI feel like the solution here is the same as any job:¬†stop making excuses and just learn the language expected of you.¬†\n\nLinus is ok with Rust existing, especially out-of-tree. He might not be ok with every change being held up by the Rust people.\n\nTo add to that the rust guys had just presented an example API for one function and gotten the types and behavior wrong.\n\nIt's unclear what they thought they were presenting. It could have been a hypothetical, or a statement of how they think the code actually behaves, but it doesn't give the C maintainers confidence when the rust maintainers don't get the base interface correct. \n\nWho will be responsible? The C programmers who don't know how rust works? The rust programmers who don't know the details of the C code?\n\nMaybe I'm wrong, but I thought the code was just one example of matching the logic of C code that is actually used in some file systems. But different filesystems model the lifecycles of inodes differently, so the example is not generally applicable to them.\nSo in the end they should have invested in a taller wall to show the \"rewrite\" of ALL inode functionality in ALL filesystem ever on a single slide\n\n&gt;  So in the end they should have invested in a taller wall to show the \"rewrite\" of ALL inode functionality in ALL filesystem ever on a single slide\n\nWhich is also the wrong outcome. From what I understand the function is part of an interface that is currently filesystem agnostic, as in there should only be one interface for all ALL inode functionallity, not a wall filled with interfaces for each specific implementation.\n\nWow, the comments in phoronix article are really proving his point.\n\nMan the comments on that article make me really glad I have no interest in kernel development.\n\nSo many people who think somehow C is the only language that could ever be suitable for writing the linux kernel in, for no real reason other than Linus Torvald's bashing of C++ several decades ago.\n\nThey're basically the programming equivalents of MAGA nutjobs.\n\n&gt; Man the comments on that article make me really glad I have no interest in kernel development.\n\nIf comments on news articles where anything to go by life in general would not be worth living.\n\nThere was a guy in there complaining about rust being too woke and calling the EU nazis.\n\nInsane place. \n\nAnd of course during all of this insane behavior they insist the problem is that rust people are too toxic.\n\n[removed]\n\nYeah, at worst most pro Rust people just seem to be really excited and passionate about a tool they believe in. Even when it becomes a little much, it‚Äôs hard to fault people too much for being passionate about something.\n\nThere was a while there where every crypto gronk was trying to get onto the rust bandwagon. Made parts of the community kinda uncomfortable. Thankfully most of that seems to have gone away now\n\nObviously something from 20 years ago isn't very relevant to today, since people change their opinions over time, but there's actually an extra level of irony in Linus's C++ bashing:\n\n&gt; If you want a VCS that is written in C++, go play with Monotone. Really. They use a \"real database\". They use \"nice object-oriented libraries\". They use \"nice C++ abstractions\". And quite frankly, as a result of all these design decisions that sound so appealing to some CS people, the end result is a horrible and unmaintainable mess.\n&gt;\n&gt; But I'm sure you'd like it more than git.\n\nMonotone was written by Graydon Hoare\n\nGoogle has been bringing more Rust into Android and their Fuchsia OS , and has basically found 0 memory releated bugs or CVEs reported against the Rust code.\n\nThat's pretty damn huge if you ask me.\n\n\"But memory bugs are only a fraction of total bugs\"\n\nYes, but its like 25% and they tend to be most customer/user impacting, either security or stability.\n\nI thought it was something like 70% of CVEs, did I hear the wrong number?\n\nNope you are right, but C devs feel personally attacked if god forbid someone says anything\n\nthat‚Äôs number from Microsofts internal stats, not necessarily all that relevant to entirely different OS, but beyond that CVEs make up very small fraction of all bugs, so it‚Äôs not that 70% of bugs are memory bugs.\n\nIt was MS, google, and Mozilla all claiming similar numbers.\n\n[deleted]\n\nIn school, we had a Chrome dev come give a talk about what Chrome development is like, and what kind of things they have to frequently debug and the strategies they use to do so. I had just started going through the Rust Book at the time, and noticed that none of the bugs would compile in Rust. That was my \"ah ha\" moment.\n\nAdding another language does add to complexity. It shouldn't be dismissed; it's not a technical problem it's an organizational problem. Typically organizational problems make or break your product if you actually have a sellable product.\n\nForgive me but I‚Äôm wondering what the performance overhead of using rust vs c is. Because rust is compiled I assume it‚Äôs virtually unnoticeable but I‚Äôm not a kernel dev or a rust programmer.\n\nThere are some variations in runtime performance, although the main overhead is compilation times - Rust code is much slower to compile than the equivalent C/C++ code, because the compiler performs various checks for correctness during compilation.\n\nedit: see /u/bik1230's comment below for more nuance\n\n&gt; Rust code is much slower to compile than the equivalent C/C++ code, because the compiler performs various checks for correctness during compilation.\n\nThan the equivalent C code, not C++ code. The checks are very fast. What's slow is generics and macros, which generate tons of work for the compiler. C++ has the exact same problem with templates. How bad any given C++ or Rust code base is to compile is going to depend on the extent to which they use tons of templates/generics/macros.\n\n[deleted]\n\nThis is a common myth but the \"huge amount of checks\" rustc does is not really why compilation is slow. The proof is that `cargo check` (which does the same amount of \"checks\" as a real build) is many times faster than doing an actual build (especially a release build).\n\nThe real reason rustc is slow is because generics tend to generate a huge amount of LLVM code which rustc relies on LLVM to eliminate, which is slow.\n\n[deleted]\n\nOutside of LLVM, there are other parts that slow things down. Macro expansion is on the slower side, as is trait resolution. So those will impact compile times in codebases that make heavy use of macros or trait system.\n\nIn addition to that, the rustc frontend is currently running single-threaded, and can't actually feed LLVM fast enough to make full use of all of its threads. So while LLVM is slow, rustc itself isn't helping. \n\nThere is ongoing work to make the frontend multi-threaded, and the compiler actually runs that infrastructure limited to a single thread, but there are currently bugs related to actually using multiple threads.\n\nI haven't written any non-trivial Rust, but there are a couple such as array and vector bounds checks by default in Rust (where C would happily index into garbage if you ask it to) and (in debug mode, which you probably would not use for production) detection of integer overflow/wrap etc.\n\nConversely, Rust theoretically allows stronger [aliasing optimizations](https://stackoverflow.com/questions/9709261/what-is-aliasing-and-how-does-it-affect-performance) to be made than C (unless you want to add 'restrict' keyword everywhere), historically there was trouble with [LLVM bugs](https://users.rust-lang.org/t/possible-rust-specific-optimizations/79895/5) in that area though.\n\nYou can also skip the bounds-checking in situations where ultimate performance is required and/or the checks have been profiled and found to be too slow under your specific setup. This means delving into `unsafe` territory though, so the programmer is responsible to ensure out-of-bounds access doesn't happen. \n\nSee the docs here: [Slice::get_unchecked](https://doc.rust-lang.org/std/primitive.slice.html#method.get_unchecked)\n\n&gt; Forgive me but I‚Äôm wondering what the performance overhead of using rust vs c is\n\nBasically none assuming competent developers, except in obscure situations.\n\nI had to double check that i was reading comments posted in 2024. Incredible.\n\nI don‚Äôt know why people have such strong reactions to Rust lol. The idea of using a different language is seen to be like religious evangelism when that language is Rust instead of just another technical decision. In other cases people constantly make jokey allusions to being forced into transgenderism when Rust is mentioned? Like this language in particular is seen as some kind of political or religious statement instead of a language lol..\n\nI have written a bunch of Rust code in my personal time and it‚Äôs just a great language albeit with a steep initial learning curve. It‚Äôs not a cult, just a good language that fills a gap in the space and brings a lot of modern language niceties to the systems space.\n\nI personally think developers that have strong feelings about languages are really immature. Every tool has a niche. The answer to the question is always \"*it depends\".* Anyone speaking in absolutes will have a strong tendency for bias and incorrectness. The problem-set and requirements should dictate the tool not the other way around.\n\n\"Try not to make things about politics challenge\" - impossible\n\n\"Rust is a Religion\" but people cling to C like it's some kind of Messiah. They are just programming languages, chill\n\n&gt; I don‚Äôt know why people have such strong reactions to Rust lol.\n\nIt's not Rust, it's Rust users. Check how every single comment critical of the language is in the -40s of downvotes, that should give you a good idea of the zealotry.\n\n&gt; Check how every single comment critical of the language is in the -40s of downvotes\n\nDo you mean in this thread, or others? The only comment I've seen here that matches that description starts with \"Rust is not a normal language for normal people.\" which really isn't \"critical of\" as much as \"shitting on\".\n\nMost \\*good\\* critical comments about Rust are actually upvoted in r/rust. Take the discussions about async and function coloring, for example: it's constantly discussed and it's never donwvoted to oblivion. The \"critical\" comments that are downvoted are normally from people that don't understand Rust and what it's trying to achieve. There are soooo many people thinking that the presence of the unsafe blocks makes Rust as unsafe as C and you should just use C, which is completely misguided in my opinion.\n\nYou‚Äôre telling me the Linux community is toxic and unfriendly to new things??? No way!\n\nYou posted about how you're excited to see a Youtuber burn in hell because he didn't reaffirm the position you have on some retarded drama. I'm sure you're not toxic at all lol.\n\nI can only imagine the discussion if we were talking about a rust project that had dotnet or java bindings that had to be kept in sync together with their dependencies. :)\n\nThe \"C guy\" sounds whiny for good reason... he suddenly has to keep the rust code in mind when making changes to the code he's responsible for. I've heard \"don't worry, do your thing and we'll take care of it\" way too many times during my career to know it sounds more like \"you'll be left waiting or in a continuous string of meetings and discussions so you're better off just avoiding us\".\n\nI have no doubt the rust team means well but...\n\nFrom the youtube he linked I can't tell if the nontechnical nonsense is pushback on people seen as pushing 'the Rust religion' or the tone in which they do it, but I found this bit interesting: \"we will find out whether or not this concept of encoding huge amounts of semantics into the type system is a good thing or a bad thing\" when I talk to static typing people they take that being a good thing as a truism.  It's definitely hard to make progress with people who have spent a lifetime learning the intricacies of C and C++ who tend to be very defensive about them, and it's probably even worse in a project that doesn't take security particularly seriously like the linux kernel.\n\nA bit off-topic, but why do you say that the Linux kernel project doesn't take security particularly seriously? Were there security incidents that could have been prevented had the kernel devs been more vigilant or security-minded?\n\nYeah I don‚Äôt follow that comment at all.\n\nSo many companies use and rely on the linux kernel, it gets audited to hell and back. It's difficult to imagine anyone thinking it's not security focussed.\n\nTorvalds has long held that security bugs are just bugs.\n\nHe's right, why are you booing him?\n\nNot OP but:\n\nLinux (Linus specifically) has long had a policy of \"security vulnerabilities are just bugs\" - which while true, puts aside that security vulnerabilities often have extra impact to users, and so instead they are treated and prioritised without any special attention.\n\nFurthermore, recently the Linux org became able to publish and reserve CVE numbers - this is a system which is designed to inform people which vulnerabilities they have patched by giving each a number. What Linux instead proceeds to do is give nearly every commit to the kernel its own CVE irrespective of whether any actual vulnerability is present, which is poisoning the well and throwing off normal statistics and decision making.\n\nAdditionally, Linux has a history of pushback at any security mitigations or hardenings, especially ones that would have even a negligible performance impact. Today this is a little more relaxed but still very much exists.\n\nCVEs are just numbers, so people talk about the same issues instead of every vendor invents its own numbers.\n\nThe security \"industry\" came up with the grand idea to consider any CVE in a component important and spamming people with HIGH, CRITICAL security alerts all over the place, when all you have is an issue in a commandline tool that is explicitly just used in some test and totally irrelevant for 99.999999% of all users of that library. Might leave a few users if you happen to develop Android, okay. Thank you for wasting everyone elses time.\n\nLike, imagine to have a public bug tracker. Now some clueless horde of attention seekers starts to file all kinds of hillarious bugs there. And can set the \"severity\" externally. And then the same crowd tries to convince you to totally absolutely treat their specific issues with super high priority, because its seehhhcuuuurityyyy, and obvious HIGH, because they said so. And if you don't react, they go to some social media, press or whatever and present their scandals and critical problems. Thats the current CVE system. 95% noise.\n\nHmm, regarding the CVEs, are there any particular examples of an irrelevant CVE?\n\nI haven‚Äôt looked deeply into it but it has always seemed to me that they publish proactive CVEs when they patch a security class bug. \n\nShould they use a higher CVSS as threshold or are there a lot of egregious CVEs I‚Äôve just not seen (since I haven‚Äôt actively been looking).\n\nSo far this year Linux has published nearly 3000 CVEs, nearly none of them are actual vulnerabilities.\n\nInstead of any effort to publish security vulnerabilities, org is actively undermining the system by publishing practically any bug fix as a CVE.\n\nLinus is quoted saying \"Bugs will happen, and anything can be a security bug [‚Ä¶]\"\n\nEdit: reading this article gives a much more charitable perspective and changed my mind a bit https://lwn.net/Articles/978711/ but imo the process is still very flawed.\n\nThere's a whole other side to the story though, with abuse of the CVE system by \"vulnerability\" and \"security\" scanner companies to drive sales, and by a whole Compliance‚Ñ¢ industry around it. Combined with some security researchers being much more interested in CV-padding than finding genuine issues, we've landed up in a situation where the CVE database is full of noise, seeverities are inflated, and it can be actively unhelpful.\n\nThe Linux maintainers are reacting to the resulting high churn environment full of meaningless noise and demands for rushed urgent fixes for non-vulnerabilities some code scanner flagged, before some company who sure isn't paying the maintainer for the work exceeds some arbitrary remediation deadline set by their tech-ignorant corporate compliance team, baked into external contracts, or even into industry regulations or law.\n\nAs usual - capitalism ruins everything.\n\nAh I see, I‚Äôve probably only paid attention to the ‚Äúrelevant‚Äù ones so to speak, that definitely sounds like a blatant misuse of the system.\n\nEdit: Cool addition with the link, thanks!\n\n&gt;What Linux instead proceeds to do is give nearly every commit to the kernel its own CVE irrespective of whether any actual vulnerability is present, which is poisoning the well and throwing off normal statistics and decision making.\n\nJesus Christ this has to be one of the most idiotic movements I've ever seen.\n\n&gt; Security vulnerabilities are bugs\n\nOK. I can stand living with that idea if someone wants to see it that way even though it doesn't work like that in reality.\n\nBut then using a system that's **exclusively** for security, to register all bugs...that's just being idiot.\n\nIt's not idiotic when you consider that environmental CVSS scores are now a thing. It was always a bad idea to create automations that read from the CVE system that don't do any filtering whatsoever, and the Linux kernel is just adapting to this reality. The kernel team essentially DoSing the CVE system with noise is a blessing in disguise, and is actively improving the situation by weeding out automation tools that were already prone to information overload. The CVE system was never intended as a list of all severe problems to pay attention to, it is just a way to make sure a non-overlapping number is assigned to each security issues so that they can be discussed without confusion.\n\nThere's more to it than it sounds like.\n\nA bunch of companies have created automation around CVEs to scan code and infrastructure. Which was be handy and a good idea until a whole industry grew  around blindly and slavishly following the scanner results, using them to \"prove\" your product or service is \"secure\", etc. Now it's routine to have to do an urgent upgrade of some library you use becuse an unrelated feature you don't use is vulnerable to a theoretical exploit by a local user even though you only use the library in container images anyway.\n\nThis industry has been successful at lobbying to get use of their products encoded into industry compliance standards like PCI/DSS, into government procurement, and in some places even into law. All nuance has gone with it, and it's now common to just blindly follow the scanner.\n\nI've had to fork upstream projects or libraries and back port fixes myself in cases where a direct upgrade wasn't feasible in the time allowed. For something completely irrelevant, where a sane process should only have required an inspection and sign-off that the component is unaffected by the issue with a suitably justification.\n\nThen there's the issue that a significant number or security researchers are CV-padding using CVEs; they will try to find any way they can to get high severity CVEs to their name. Its actual risk or significance isn't a concern. This has led to a huge spike in nonsense higher severity CVEs, which drowns the real ones in noise.\n\nThis wears out maintainers, who are then deluged by these minor code linter complaints dressed up as security issues, and by bugs raised by companies using these scanners about the need to upgrade some \"vulnerable\" component. Urgently of course, but without a patch or PR.\n\nIt's also creating a high code churn environment that makes it WAY too easy to sneak in malicious changes because nobody has time to even look properly over \"PR: bump libfoobar to v1.9.79999 for CVE-ABCD-12342234\".\n\nMaybe they're referring to the maintainers, and sometimes even Linus', ambivalence toward grsecurity and their patches.\n\nIn their defense almost all of the changes they had while still free were eventually adopted in some form.\n\nLinus famously said 'security problems are just bugs'; it's been an article of faith among security people for ever and in the present that if you have a local shell on a Linux box you've got root; grsecurity and pax have never gotten upstreamed (though spender ain't exactly the easiest person to work with; neither are Linus and Co.).  You can see what a security focus looks like in a project like OpenBSD; Linux for better or worse leaves a lot of this up to third parties.\n\n&gt;¬†Linus famously said 'security problems are just bugs'\n\nThat's a good approach if you want to keep developers on your open source project, since you need to defend their egos (and they already have Linus yelling at them.) Security offense researchers are unique among bug reporters because they're extremely annoying and self-important and when they find a bug in your code they go around giving conference talks about it, giving themselves prizes, making up logos for it, getting bounty programs to give them a million dollars etc.¬†\n\nNobody's doing that for the guy who put the bug in even if you needed the feature he wrote!\n\nOpenBSD is not really very good at security because they don't actually engage with vulnerability research. They maintain some projects in the security category, but their OS mitigations aren't good and aren't based on realistic priorities. They basically just make up defenses for imaginary attacks and put them in there.\n\nhttps://isopenbsdsecu.re/quotes/\n\n¬†iOS and Android have the most effort put into them since they have the most real-world attacks. It helps that ARMv8 is the only hardware ISA with useful security features regularly being added.\n\nThe kernel is filled with CVEs. \n\nBut what's worse, the kernel has had vuln regressions because they didn't introduce tests alongside fixes. \n\nThe linux kernel is an incredibly complicated piece of software, but it is probably also the most important piece of software on the planet when it comes to the world's security posture. The kernel developers aren't totally blase about security, but they definitely aren't taking an approach that prioritizes security whenever possible. \n\nI know a number of people who have spent careers trying to find ways to change the culture within the kernel community and ultimately failed.\n\nWatching the story arc of the spectre / meltdown etc fixes certainly gave me that impression. I recall intel giving guidance to MS and the Linux devs on how to fix it; Microsoft took their approach but Linus rejected it as a crap idea due to the performance implications.\n\nSometime around 2022-2023 a new variant came around which Windows was immune to, having baked Intel's suggestions in years prior, while new releases (Ubuntu 23.04?) were hit. This resulted in the linux kernel having to implement those fixes after all, performance regressions and all.\n\nI also recall that a lot of the anti-exploit features that Windows has been implementing for years now were historically available with grsecurity but generally rejected as not necessary.\n\nBeyond that (not all of these are kernel but go to the general anti-security vibe)\n\n * sudo /setuid is a security dumpster fire\n * Things like SELinux user constraint that might help are generally not used\n * Secureboot has been a dumpster fire for years as well, which is only recently starting to get fixed with UKIs\n\n&gt; \"we will find out whether or not this concept of encoding huge amounts of semantics into the type system is a good thing or a bad thing\" when I talk to static typing people they take that being a good thing as a truism.\n\nWell, sure. I mean, we figured out the answer was yes in the 80s. In 2009 they gave Barbara Liskov a Turing award for her part in figuring this out. (Pop articles often talk about object-oriented programming for her Turing award, but oddly enough I find the above quote to actually be a more accurate of a description of Liskov's contribution than anything \"OO.\")\n\nMaybe we could read a lot into the word \"huge\", because there's certainly room to critique, say, dependently typed languages as maybe going \"too far.\" But Rust's type system is really quite conservatively designed.\n\nSometimes we do actually figure things out, and the industry isn't just a morass of \"well that's just your opinion man.\"\n\nC programmers prefer not to acknowledge any PL options and theory that‚Äôs from beyond the 70s.\n\nActually it‚Äôs pretty funny how they went from one unhinged whine fest about rust to immediately a weird tangential whine fest about Java.\n\nJust a toxic group. \n\nIt‚Äôs kind of funny how Torvalds got shit on so much for being toxic but on this topic he‚Äôs been reasonable and pragmatic.\n\n&gt; when I talk to static typing people they take that being a good thing as a truism.\n\nIt's strong typing people. C obviously has static typing, but proficient C programmers love how weak C's type system is, which is why Rust is seen in such a bad light by them.\n\nThe whole embedded field is based on the fact that C is weakly typed. There are some ‚Äútricks‚Äù(or hacks) that low level programmers (ab)use to do their job. Unfortunately the change is just too big\n\nAda exists and is strong typed and is embedded friendly. Way more than C, actually. Strong typing is not equal memory safety.\n\nYeah most embedded devices are dealing with memory mapped IO which usually requires manipulating individual bits.  Unfortunately, most control registers don't really have a fundamental type as they just mash everything together.\n\nThat being said it's certainly possible to use safer typed languages like Rust, modern C++ in embedded no problem, just have to encapsulate the bit fiddling and then don't touch it.\n\nGetting embedded devs to do anything except old school C is sometimes like pulling teeth though.\n\nI‚Äôm not sure that there‚Äôs anything inherent in the embedded field that requires the use of weak typing. I‚Äôm sure embedded programmers, as mentioned before, love using C‚Äôs weak typing to get things done, but I‚Äôm not sure that that‚Äôs evidence that it‚Äôs *required*. There are plenty of embedded programmers using Rust with very strict typing systems.\n\nIronically, based on the specification, you might call Rust weaker typed. It doesn't come with type-based alias analysis in the language (C/C++) nor an object model (C++). The strongest typing influences are atomics where all memory models including that of llvm require parallel access to the same memory to use the exact same atomic size to avoid data races; the kernel chooses to ignore this and does relaxed reads of u8 size from a u64 slot. I'm sure nothing will ever go wrong if a large project is ignoring the compiler's main operational semantic model, right? Everything else you can type extremely weakly in Rust if you know what you're doing. And leverage proc-macros to make working with mixed type sematics surprisingly pleasant (e.g. Google's [`zerocopy`](https://github.com/google/zerocopy)).\n\nI could take an opinion in favor of C serious if they jumped at a need for volatile atomics, which Rust doesn't provide as types. Alas people complaining loudly don't seem to have the technical depth to bring this up. How strange.\n\nIt sounds like a handful of contributors lashed out at them instead of addressing their own shortcomings. A more reasonable response would be to simply ask someone familiar with rust for their input.\n\n&gt;\"we will find out whether or not this concept of encoding huge amounts of semantics into the type system is a good thing or a bad thing\"¬†\n\nIt's funny that the person who said this claimed the Rust devs were \"religious\".  This kind of attitude is certainly not something from an impartial engineer.  Imagine going to a civil engineer and stating \"we'll see if this process which catches more imperfections in bridge building material turns out to be good or bad!\" or a doctor and saying \"we'll see if this test which has less false negatives is good or bad!\".\n\nThere is one important practical subtlety in this particular discussion that only occurs at the boundary between languages, because language semantics never line up perfectly in practice: the rules embedded in the type system on one side are mirroring a convention on the other side of the bindings. The only way to ensure that the two of them are in sync is through manual effort. This is especially troublesome if the interface is intricate and subject to change. It's easy to get into one of two situations in this case:\n\n1. The type based interface is not adjusted to mirror a convention change or misses a subtlety in the convention and therefore encourages/enforces wrong use of the interface.\n\n2. A change in the bound function is of a nature such that the types used to express the constraints of the interface need to change drastically to keep up. This would drive up the refactoring effort to keep the strictly typed side in sync.\n\nI didn't read the article because of the gigantic cookie popup that cannot easily be declined."
  },
  {
    "title": "Linux Creator Torvalds Says Rust Adoption in Kernel Lags Expectations ",
    "body": "",
    "score": 1166,
    "url": "",
    "created_utc": 1724508034.0,
    "author": "unixmachine",
    "permalink": "/r/programming/comments/1f05yrf/linux_creator_torvalds_says_rust_adoption_in/",
    "all_comment_text": "Here is all that is mentioned about Rust\n\n\n&gt;Switching to a more modern topic, the introduction of the Rust language into Linux, Torvalds is disappointed that its adoption isn't going faster. \"I was expecting updates to be faster, but part of the problem is that old-time kernel developers are used to C and don't know Rust. They're not exactly excited about having to learn a new language that is, in some respects, very different. So there's been some pushback on Rust.\"\n\n\n&gt;On top of that, Torvalds commented, \"Another reason has been the Rust infrastructure itself has not been super stable.\"\n\n&gt;On top of that, Torvalds commented, \"Another reason has been the Rust infrastructure itself has not been super stable.\"\n\nWhat does he mean by this?\n\n[removed]\n\nI'm no expert, but this doesn't seem like a situation to be using nightly features?\n\nlook through the list, (it's plausible that) they actually need them, and are not not just testing some fancy upcoming syntax sugar\n\nThe Rust project goals for 2024 include getting these into stable.\n\nhttps://blog.rust-lang.org/2024/08/12/Project-goals.html\n\nthe \"largest gaps\", yes hopefully, but I'd expect a bunch of them lingering in the nightly for longer\n\nThey have a specific list of things which would be nice to get done this year for Rust for Linux on stable but may be stretch goals, as it were: https://rust-lang.github.io/rust-project-goals/2024h2/rfl_stable.html#the-shiny-future-we-are-working-towards\n\nThey also say:\n\n&gt; The primary goal is to offer stable support for the particular use cases that the Linux kernel requires. Wherever possible we aim to stabilize features completely, but if necessary, we can try to stabilize a subset of functionality that meets the kernel developers' needs while leaving other aspects unstable.\n\nAlso they [want to get RFL into the Rust project's CI](https://rust-lang.github.io/rust-project-goals/2024h2/rfl_stable.html#rfl-on-rust-ci) which could spot breakages to RFL when changes are made to rustc.\n\nLinux is a highly stable project. The idea of using nightly features in kernel should be met with extreme skepticism.\n\nIf Rust is truly the future then the diff between this year and 2 years from now is irrelevant. If Rust isn't the future, it shouldn't be used anyways.\n\nThey use stable versions of the compiler and force them to allow using \"unstable\" (read: not stabilized, prone to change) features.\n\nDon't confuse it with using nightly versions or unexpected behavior.\n\nIt's not entirely uncommon for Rust-based projects to depend on nightly features.  That said, there's usually a strong push to either stabilize those features or migrate away at the earliest opportunity.\n\nIf features you need for a shipping product are only implemented in a language in nightlies, you really shouldn't be using that language yet.\n\nYou‚Äôre right, it‚Äôs not. The kernel wants these features to be in a stable Rust release so that Rust support can move out of experimental status\n\nA lot of the replies seem to not understand that for certain things they *need* unstable features to get Rust to work at all for what they want to do as `varen0k` also pointed out.\n\nHere's a talk from RustNL from a few months ago that examines one case of needing to use unstable features to get the job done: [https://www.youtube.com/watch?v=gr9v0FFXaZ8](https://www.youtube.com/watch?v=gr9v0FFXaZ8)\n\n&gt;A lot of the replies seem to not understand that for certain things they need unstable features to get Rust to work at all for what they want to do as varen0k also pointed out.\n\nIf you _need_ unstable features in your usually stable software product, maybe it's too early to start using the tech you're looking at...\n\nThere is nothing wrong with waiting until the software you want to start using is stable enough to do so.\n\nThe kernel using these features might be the primary motivation for stabilizing them though. Seems like the kernel has a lot of needs that most user space software doesn't.\n\nLinus was hoping the nightly features would be moving into stable faster, that's all\n\nNothing to be done about it, `allocator_api`, `new_uninit`, `get_mut_unchecked` and so forth are going to be required. A lot of things have to be invented, like support for the memory model and ways of performing practical things like pinned initialization (placement new...), because a lot of what you need to do in low level code like operating systems is antithetical to the way the Rust core team thinks code should be structured, so things like receiving a resource that is already constructed in heap memory and never moves for example is just not in the working model of what Rust wants programs to deal with. In Rust by default you don't create objects in heap memory, you create things on the stack and they immediately start being moved around, even simple things like initializing a Vec without copying it from the stack on initialization is arcane. That type of thing isn't what you want for kernel code. A lot of things coming out of the Rust for Linux work will eventually be in core Rust, but for now the project will have to [crawl before it walks](https://docs.rs/crate/pinned-init).\n\n&gt;  so things like receiving a resource that is already constructed in heap memory and never moves for example is just not in the working model of what Rust wants programs to deal with.\n\nHow do Rust programs deal with shared memory and OpenGL or CUDA buffers? Mapping existing structures into a process seems like it should be a basic requirement.\n\nCurious about this too, because the last time I used Rust for those years ago, it was just C++ bindings for RS. (aka you couldn't at this time)\n\nPretty much the exact same way C or C++ do. You get a pointer and a size to the buffer and cast it to an appropriate slice. This step must of course be done in an unsafe block in Rust, but once you have your slice, it's just an array you can read from or write to.\n\nIf the CPU and GPU/external device/other process can read/write at the same time and it's not just being handed back and forth, you'll need to use atomic operations to avoid UB. Rust just copied the C++ atomics model because that's what LLVM expects, so the UB semantics and required atomics are also the same.\n\nYou get a ‚Äò&amp;mut‚Äô and do your best to avoid undefined behavior.\n\nThe title literally has \"needed\" in it...\n\nOther people have answered a bit about what this is. Thankfully, improving this is one of the few [official project goals for the rest of 2024](https://blog.rust-lang.org/2024/08/12/Project-goals.html). (And probably beyond.)\n\nThat official post should also help clarify this specific issue about Rust for Linux stability.\n\nOr I can just copy the paragraph.\n\n&gt;[Rust for Linux](https://rust-lang.github.io/rust-project-goals/2024h2/rfl_stable.html). The [experimental support for Rust development in the Linux kernel](https://rust-for-linux.com/) is a watershed moment for Rust, demonstrating to the world that Rust is indeed capable of targeting all manner of low-level systems applications. And yet today that support rests on a [number of unstable features](https://github.com/Rust-for-Linux/linux/issues/2), blocking the effort from ever going beyond experimental status. For 2024H2 we will work to close the [largest gaps that block support](https://rust-lang.github.io/rust-project-goals/2024h2/rfl_stable.html#the-next-six-months).\n\nThose links provide more detail about what needs to be improved.\n\nVIP-like comment right here.\n\nMy guess is that this is a lack of stability in the infrastructure still changing a lot, which would make sense with how new it is.\n\nLanguages like C and C++ have a clear standard that is discussed in working groups of industry giants then can be implemented by compiler vendors and programmed against by programmers. Projects like Linux also may commit to a certain version of the standard and only switch when there is no (major) impact by a switch and the relevant compiler(s) fully supports your new version. Also deprecations, removals or breaking changes of existing language feature are a huge topic and only done when there is a lot of buy in and no major stakeholder is opposing it. (e.g. there are proposals to C++ that may require a change to the ABI and being blocked because of that)\n\nAfaik Rust on the other hand is more like a living standard and whatever the Rust compiler deems correct. There are ongoing efforts to create an official spec but idk what the state of that is.\n\nIn fairness the way the Rust compiler team operate is more open and with most discussions than how you sound. They aren‚Äôt like say Google, where a big new feature is discussed in private, and then released in public all of a sudden out of nowhere.\n\nIn Rust big features take a long time, with a lot of\ndiscussions posted openly. They are often available as macros first to allow feedback (like asyn/await).\n\nThe Linux kernel doesn't care about language standards though, only about what compilers actually implement. Linux notoriously used many nonstandard gcc extensions, which slowed down enabling the use of clang. AFAIK there are still a handful of extensions used (different ones for each compiler).\n\nC/C++/Rust all have a strong no breaking change policy. Rust's default ABI is explicitly unstable, but the kernel (and most other projects) don't care.\n\nRust doesn't have a C/C++-like ISO spec, but it is much more strongly specified than you describe. There are way more explicitly-undefined behaviours in the C++ spec than implementation-defined behaviours in rustc. Unstable features implemented by rustc much be explicitly opted into, no risk of accidental use like in C/C++. And because there is only have one relevant Rust vendor, there is no [headache figuring out what you can use](https://en.cppreference.com/w/cpp/compiler_support).\n\nI never ever took a look at any linux mailing list, but if even you say it was notoriously used in the past, then maybe it's not surprising that today there's some bad feelings about using non-standard stufff\n\n&gt;Languages like C and C++ have a clear standard that is discussed in working groups of industry giants then can be implemented by compiler vendors and programmed against by programmers. Projects like Linux also may commit to a certain version of the standard and only switch when there is no (major) impact by a switch and the relevant compiler(s) fully supports your new version. Also deprecations, removals or breaking changes of existing language feature are a huge topic and only done when there is a lot of buy in and no major stakeholder is opposing it. (e.g. there are proposals to C++ that may require a change to the ABI and being blocked because of that)\n\nAnd yet, the final result is giant mess of developer-hostile programming environment.\n\nI remember seeing a post where someone had old code that wouldn't compile anymore, despite his best efforts. \n\nIt would compile on his old laptop with a particular setup\n\nAfter some digging, he seems to be referring to infrastructure (for Rust) _in the kernel_.\n\nIt's unclear whether this means build-system or APIs, however. Both are reportedly unstable.\n\nIn terms of build-system, for a long time the Rust For Linux branch was using the nightly compiler, pinned to a particular version. There was no attempt at being compatible with any other version, so contributors may have been finding it hard to keep-up. The situation is better now, the latest Linux release is based on the stable compiler release (1.78) though compiled in bootstrap mode to use the unstable features still.\n\nIn terms of API, it is my understanding that they've been in flux, which is not unexpected as there's a LOT to do, and to get right, but does mean that any attempt at building on top of those may be frustrating. Building on shifting sands is never easy. I'm not sure if it's gotten better. I would expect it'll take them to shake them out.\n\nHe means it changes, not that it crashes.\n\nI seem to be the minority here, but I interpreted this to mean the *kernels* Rust infrastructure, the kernel-specific crates and wrappers and APIs they're writing and all the infrastructure around it, as being unstable. Its all new, in flux, what the APIs should look like in question, etc.\n\nTo me this also makes the most practical sense, because the kernel pins their nightly version, nothing is changing that they dont want to change, and the \"unstable\"(as in not in Rust stable, not necessarily as in buggy or constantly changing APIs) features it depends on are, I would think, either pretty solid at this point, or changing at the kernels own request to better fit their needs.\n\nIf this quote is really the entirety of what he said during the whole talk, i dont think theres enough detail to know what he actually means and itd be nice to get clarification sometime\n\n----\n\nedit: after seeing a more detailed quote from the [/r/linux post](https://www.reddit.com/r/linux/comments/1f05xoe/linux_creator_torvalds_says_rust_adoption_in/) from [this article](https://diginomica.com/kubecon-china-33-and-third-linux-long-player-so-why-does-linus-torvalds-hate-ai), I believe its more clear\n\n&gt; Another reason has been the Rust infrastructure itself has not been super stable. So, in the last release I made, we finally got to the point where the Rust compiler that we can use for the kernel is the standard upstream Rust compiler, so we don't need to have extra version checks and things like that.\n\nThe kernels Rust infrastructure was unstable and in-flux, but now thanks to work on both sides they're able to use a standard compiler without issue. [Specifically Rust 1.78.0, starting in Kernel 6.11](https://rust-for-linux.com/rust-version-policy)\n\nNote that they've always used stable rustc versions. The recent improvement (which involved work both in Linux and in Rust and rustc's CI) is that they can use a range of versions instead of a single pined one.\n\nHuh.. That raises more questions\n\nSo if I understand it right, before they were using a single pinned one? And now they're more free to use any newer ones since [every Rust change is tested against what the kernel needs in CI now?](https://rust-for-linux.com/rust-version-policy)? But they're still using stable?(oh god.. they must also be using RUSTC_BOOTSTRAP then huh)\n\nBut if it was pinned before then what \"extra version checks and things like that\" did they need and now remove??\n\nYes, they use RUSTC_BOOTSTRAP. It's better than choosing a particular nightly and forcing it on users.\n\nThey [removed the \"is rustc/bindgen too new ?\" checks](https://github.com/torvalds/linux/commit/63b27f4a0074bc6ef987a44ee9ad8bf960b568c2) and kept the \"is it new enough\" ones. This is essentially a documentation/process change, no actual kernel code changed. But arriving at that point required adding RFL to rustc's build-check CI (so that if a change to an unstable breaks RFL, it can be either reverted from rustc or handled in RFL), and improvements in the alloc crate and corresponding RFL code so that RFL no longer needs to copy-fork it inside RFL (and therefore be tied to the rustc version it's copied from).\n\n&gt; Yes, they use RUSTC_BOOTSTRAP. It's better than choosing a particular nightly and forcing it on users.\n\nWhy is it better?\n\n...oh, is it because of distros inability to support multiple versions? distros want to package rust system wide, the kernel wants to use this and it isnt worth fighting distros, which means a single *stable* version, instead of the normal way where its trivial to use and test against multiple versions, stable, nightly, custom built ones, concurrently?\n\nEven ignoring distros, people are more likely to have a particular stable already installed than a particular nightly. Also, the stables (and betas) get more real-life testing, should be less buggy. And lastly, it simplifies the \"when should we update and to which version\" decision process.\n\nThe Rust infrastructure has not been super stable!!!\n\nI mean is that really surprising? From what I‚Äôve seen there are only a few real-world projects using Rust for Linux right now‚Äîafaik just Android's Binder, Asahi's M-series GPU driver, and RedHat's Nova NVIDIA driver. As more use cases for Rust arrive, more abstractions will be fleshed out, and the design will naturally become more stable.\n\nAfter all the more users there are, the harder it is to make changes to the API without impacting everyone, which will lead to a more solid foundation over time\n\nAnother relevant point from this report:\n\n&gt;So, when AI people came in, that was wonderful, because it meant somebody at NVIDIA had got much more involved on the kernel side, and NVIDIA went from being on my list of companies who are not good to my list of people who are doing really good work.\n\nHo, so \"Fuck you\" expired?\n\nFuck you was highly dependent on them being assholes. When their customers forced them to stop being assholes everything changed.\n\nSuper relevant: https://blog.rust-lang.org/2024/08/12/Project-goals.html\n\nThe relevant part of the super relevant link:\n\n&gt; Rust for Linux. The experimental support for Rust development in the Linux kernel is a watershed moment for Rust, demonstrating to the world that Rust is indeed capable of targeting all manner of low-level systems applications. And yet today that support rests on a number of unstable features, blocking the effort from ever going beyond experimental status. For 2024H2 we will work to close the largest gaps that block support.\n\nWith links\n\n&gt;[Rust for Linux](https://rust-lang.github.io/rust-project-goals/2024h2/rfl_stable.html). The [experimental support for Rust development in the Linux kernel](https://rust-for-linux.com/) is a watershed moment for Rust, demonstrating to the world that Rust is indeed capable of targeting all manner of low-level systems applications. And yet today that support rests on a [number of unstable features](https://github.com/Rust-for-Linux/linux/issues/2), blocking the effort from ever going beyond experimental status. For 2024H2 we will work to close the [largest gaps that block support](https://rust-lang.github.io/rust-project-goals/2024h2/rfl_stable.html#the-next-six-months).\n\nErgonomic ref counting has me super excited!\n\nI wish they could add more features wrt raw pointer ergonomics, like adopting -&gt; syntax from C++, as well as `ref raw const` and `ref raw mut` syntax in let-binding and pattern matching. This would make writing say a linked list in rust, albeit unsafe, much easier.\n\nNot yet pattern matching I think. But progress nonetheless: [https://github.com/rust-lang/rust/pull/127679](https://github.com/rust-lang/rust/pull/127679)\n\ntl;dr Old-time kernel developers are used to C and don‚Äôt know Rust. ‚Ä¶ Another reason has been the Rust infrastructure itself has not been super stable.\n\nSo basically the same problems of introducing any new language to the kernel\n\nKernel development in JavaScript üëÅÔ∏èüëÉüëÅÔ∏è\n\nMy DE is in Javascript. Why? I don't know. I really don't know.\n\nhttps://blog.fishsoup.net/2008/10/22/implementing-the-next-gnome-shell/\n\nAssuming you mean Gnome, it's really not a bad choice. You need a scripting language, you want it to be low dependency, and you want it to be something a lot of people know.\n\nThey were also looking at Mono/C# and Vala at the time. Other choices would've been Python or Lua. I think JavaScript was the right choice.\n\nQt QML uses JavaScript as well. It's a widely used language with a choice of several fast, secure, and well tested interpreters. Perfectly reasonable choice when used in low doses.\n\nExactly!!\n\nI think there's a Javascript engine for practically every operating system that has run on a computer in the past 20 years outside of, like, SIM cards (which run Java).\n\nIt probably was, although I kinda like the larger scale you can muster with languages like C#/Dart.\n\nMy big issue with C# is the dev tooling is pretty abysmal, even in 2024, unless you're using Visual Studio on Windows. (Even the C# plugin for VSC breaks regularly!)\n\nI can't imagine being a Linux dev in 2008 using C#, pre-Roslyn, pre-LSP. etc.\n\nOh sure, I wouldn't touch C# with a ten feet pole these days (when Dart exists) it's in a very chaotic state of affairs (archaic old standard along side modern ones).\n\nNo.. not like that üôàüòµ\n\nCompiling to webasm so you can run your OS in your browser?\n\nTechnically you can run your OS from your browser now using a Web extension and Native Messaging.\n\nJust curious: would it have access to the local system's file structure, RAM memory, and ports?\n\nYes.\n\nNative Messaging is a protocol that browsers use to communicate with a local shell script, program, or application the browser launches.\n\nSee https://github.com/guest271314/NativeMessagingHosts?tab=readme-ov-file#native-messaging-documentation\n\n&gt; Chrome starts each native messaging host in a separate process and communicates with it using standard input (stdin) and standard output (stdout). The same format is used to send messages in both directions; each message is serialized using JSON, UTF-8 encoded and is preceded with 32-bit message length in native byte order. The maximum size of a single message from the native messaging host is 1 MB, mainly to protect Chrome from misbehaving native applications. The maximum size of the message sent to the native messaging host is 4 GB.\n\nYou can do whatever you want in your local program; some examples https://github.com/guest271314/NativeMessagingHosts?tab=readme-ov-file#examples.\n\nNo, there is definitely a difference how steep the change of using different languages is. For example, while this probably neve will happen, kernel developers probably would have an (at least short-term) easier time to switch to C++ instead of Rust.\n\nThe infrastructure as in the IDE tooling, or some other aspect? Genuinely curious\n\nRust stable itself is relatively stable but kernel Rust relies on a fairly significant number of nightly features.¬†\n\nEven regular Rust can take ages for features to stabilize, I still remember the huge gulf of time using map_err to log while inspect_err was nightly only.\n\n[anyhow](https://lib.rs/anyhow)'s\n\n    result.context(\"reticulating splines failed\")?;\n\nis cleaner and creates a nice chain of causes when printing the error.\n\n    Error: reticulating splines failed\n    Caused by:\n        No such file or directory (os error 2)\n\nAnyhow is very nice and solves a specific but common use case, however inspect\\_err is a much simpler \"building block\" for a huge swath of error handling, and doesn't require pulling in another dependency.\n\nA example for the latter case is calling a fallible function, you may then want to emit a tracing event if it fails but then return a default value.\n\n`let viewer = User::from_id(id)`  \n`.inspect_err(|_| event!(Level::INFO, format!(\"Invalid User: {}\", id)))`  \n`.unwrap_or(USER_GUEST);`\n\nThis just effectively logs the error into whatever tracing subscribers are set up, and continues with normal program flow; obviously the specific requirements determine implementation (falling back to a guest user may NOT be acceptable in some programs) ‚Äì but this is just a minimal demonstration where inspect\\_err is satisfactory, and where map\\_err would've been used historically.\n\nThat's less of a \"stability\" issue and more of features not getting (fully) developed fast enough\n\nSorry Linus, Rust developers are too busy writing Game engines that no one uses and \"X but in Rust\" software.\n\nThe kernel is also a project that is much harder to contribute to than other programming projects.\n\ngdb consistently terrifies me\n\n50 game engines, 0 games\n\nI know you're joking, but games using rust have been released\n\nAny examples? I know of Veloren from it's early inceptions.\n\nme and the homies playing https://store.steampowered.com/app/1448820/Hydrofoil_Generation\n\ne: also just remembered https://store.steampowered.com/app/2286390/Tunnet  \nidk ithose are the only two i know of\n\nRust too https://store.steampowered.com/app/1032170/Robo_Instructus/\n\n[\\(the\\) Gnorp Apologue](https://store.steampowered.com/app/1473350/the_Gnorp_Apologue/) is written in Rust and was created because the developer was [experimenting with the language](https://store.steampowered.com/news/app/1473350/view/3908626109443485222)\n\nI thought you would control a crab. Nope.\n\nI Ctrl+F \"in rust.\" No result.\n\nI don't know what I expected.\n\nsorry to disappoint, [i know of this game where you play as a crab](https://store.steampowered.com/app/774801/Crab_Champions) , but it is in unreal\n\nDon't forget [Another Crab's Treasure](https://store.steampowered.com/app/1887840/Another_Crabs_Treasure/). Made in Unity though.\n\nThis is embarrassing. I should make a game in Zig where you play as an iguana while rustaceans are distracted.\n\nThat game looks awesome, by the way.\n\nI know you're joking but I'm somewhat relieved that the steam pages don't contain \"in rust\", because it shows that Rust is maturing enough to the point where people are writing software where the fact that it is written in Rust is not a big selling point. I mean there's always been useful software written in Rust, but my first impression of the Rust community is that they cared more about the language than their product.\n\n## Released\n[Fields of Mistria](https://store.steampowered.com/app/2142790/Fields_of_Mistria/)\n\n[the Gnorp Apologue](https://store.steampowered.com/app/1473350/the_Gnorp_Apologue/)\n\n[BITGUN](https://store.steampowered.com/app/1673940/BITGUN/)\n\n[Unrelaxing Quacks](https://store.steampowered.com/app/2331980/Unrelaxing_Quacks/)\n\n[Hydrofoil generation](https://store.steampowered.com/app/1448820/Hydrofoil_Generation/)\n\n\n[Factor Y](https://store.steampowered.com/app/2220850/Factor_Y/)\n\n[Tunnet](https://store.steampowered.com/app/2286390/Tunnet/)\n\n[USG](https://store.steampowered.com/app/2837160/USG/)\n\n## Work in Progress\n[Tiny Glade](https://store.steampowered.com/app/2198150/Tiny_Glade/)\n\n[Times of Progress](https://store.steampowered.com/app/2628450/Times_of_Progress/)\n\n[Linksider](https://store.steampowered.com/app/2995150/Linksider/)\n\n[GUNRUN](https://store.steampowered.com/app/2561650/GUNRUN/)\n\n[deleted]\n\nIt uses libraries made with Rust for the actual game and internal Rust tools. BITGUN is a Godot game that was written with external Rust bindings as well.\n\n[deleted]\n\nRust Game Dev Discord. You can search for the game and find a bunch of posts of one of the devs. They also have a [GitHub](https://github.com/NPC-Studio). Keep in mind that these repos are not all their Rust code. It's only the parts that they made public.\n\nThey also had a job ad in 2022 that said: \n\n&gt; Come work with me! This is a GameMaker Studio 2 job primarily, not a Rust job, but we use several Rust DLLs in-game, and multiple external Rust tools, all of which you can get your hand in.\n\nThese examples are specifically made in Bevy. It has to be noted, Bevy just turned 4 yo and is not yet production ready, yet it's api is now considered mostly stable and according to the lead dev's birthday post the official editor plugin and scene file format is expected to be released soon (edit: within a year) which would be a huge step towards production readiness. In my opinion bevy provides the best game architecture on the market aside the fact that it's free and open source plus the usual range of advantages of rust.\n\nAnyway here are some notable games done in Bevy:\n\n- https://store.steampowered.com/app/2198150/Tiny_Glade/ (This one is really impressive, at least judging its trailer)\n- https://store.steampowered.com/app/2628450/Times_of_Progress/\n- https://puzzled-squid.itch.io/tunnet\n\nTiny Glade isn't made with Bevy, it's a custom engine. They use the ECS from Bevy though. [Information from their FAQ](https://steamcommunity.com/app/2198150/discussions/0/3709306945109116212/):\n\n&gt; ‚ùî What engine did you build it in?\n\n&gt; We‚Äôre using our own home-made engine written in the Rust language. At some point, we were wondering - are we crazy? Well, yes! But the game uses so much custom technology that we concluded it was actually a pretty sane choice :) We also benefit from a lot of open source software, including Bevy's Entity Component System (ECS).\n\nOk thanks, didn't know that!\n\nHowever what does this mean? I would interpret this as them using Bevy without (many) Plugins.\n\nTiny glade looks dope, I'll check that one out\n\nIkenfell is Rust IIRC.\n\nIt's not, Chevy used C# for Ikenfell. He moved over to Rust though for his next game.\n\nbut rust isn't a game using rust\n\nMeanwhile the rather obscure programming language called \"Beef\" has at least one major shipped game (Penny's Big Breakaway)\n\n&gt;\"X but in Rust\" software\n\nI thought this is about \"Linux but in Rust\"?\n\n&gt;\"X but in Rust\" software\n\nthat no one uses as well.\n\nMost of those are hobby projects that people really shouldn't use, but one wildly successful example that comes to mind is [ripgrep](https://github.com/BurntSushi/ripgrep).\n\nLemmy is also written in Rust.\n\nAnd some I can think of that I use: hyperfine, eza, bat, oxipng, alacritty, ruff (on web pages), inferno (flamegraph).\n\nThen there's some very popular projects trying to replace ubiqutous software like typst vs latex, uv vs {poetry, pip, pipx, pyenv}, and jj vs git\n\nHaven't heard any of these.\n\n[aura](https://github.com/fosskers/aura/) is being ported from haskell to rust as well\n\nPeople often abandon those hobby projects. It is not just a problem in Rust, though one can see it more clearly in Rust: dude picks up Rust, writes something to tickle his fancies, then abandons it at lightning speed.\n\nNot really though. There's quite a few popular ones. Like the recently release `uv` seems to have gotten quite popular by just being python tooling but 100x faster. The \"written in rust\" marketing does occasionally make a lot of sense. Same goes for typst that actually enables live editing just by being way way faster than latex.\n\nThere's also a ton of smaller tools that are definitely not unpopular\n\nTypst is such a game changer. It's still early days, do it doesn't yet cover the entire breadth of LaTeX's options. But if you *can* use it, it's so much better.\n\nRuff is good\n\nDo you actually believe this or are you just using hyperbole?\n\nAlacritty is quite popular, and so is ruff\n\nRust isn't available everywhere Linux is, which is also a problem.\n\nNote that a lot of Linux C code can't run everywhere Linux runs either. There's comparatively little kernel code that *must* run on absolutely all platforms.\n\nthat is improving with rustc_codegen_gcc, that is using GCC as a backend for rustc\n\n&gt; Rust isn't available everywhere Linux is\n\nErm... have you got an example?\n\nSuperH architecture and derivatives, particularly SH4.\n\nA platform that, as far as I can see, is on it's way out of the market.\n\nEventually old platforms can just run old versions of Linux.\n\nHey now, I want to run kernel 6 on my dreamcast. ;)\n\nCan you not use the normal rustc on Linux?\n\nNot on all architectures. LLVM supports less architectures than GCC.\n\nThat only matters if they use it for something that is available on the platform where rust isn't available. The platforms where Rust doesn't run tend to be old systems that aren't receiving hardware changes. That code will get removed when those systems eventually disappear.\n\nHow about elixir adoption at the kernel?\n\nHilarious\n\nLol. The fact you have so many upvotes and I don‚Äôt probably means people didn‚Äôt really get the joke.\n\nI figured you were joking.\n\n[deleted]\n\nI generally write my Typescript with very strong types and declaratively. I had to change to only introduce those strong types once requirements become more stable, but ultimately those strong types have made the code more robust. Additionally, introducing Result/Either helped a lot too. \n\nThe killer with TS is the lack of functional constructs like pipes and partial application (currying sucks in TS)\n\nIf TS had pipe operator, pattern matching and custom types (ADT), half of functional languages would slowly disappear.\n\nIt has ADTs. It really needs higher-kinded types. For pattern matching I use ts-pattern, but yea, not built into the language, and because of the lack of HKTs ts-pattern struggles with generic containers.\n\nin what ways were you limited, do you have examples? im learning elixir and i like everything about it so far\n\n[deleted]\n\nwouldnt it be a state machine type pattern in elixir that holds the various states it could be and just return the one you need? also for mutability in elixir, cant you use ets_table? its like a mutable map\n\nYou just shove the state in the genserver and use that to persist for the duration of the interaction. That's literally what liveview does out of the box\n\nThe grass is always greener. Ever changing requirements is not a discipline Rust excels at.\n\nüòÇ\n\ni dont think they want the kernel running in the BEAM or any VM since its supposed to interact with hardware directly. but it would be neat as an isolation step maybe\n\ncause rust sucks?\n\nRust is not easy or fun to develop with, its rigid coding standards make it a nightmare to work with. I don't see it superseding C or C++ anytime soon. The Rust community is also toxic IMHO.\n\nPretty sure kernel developers will not shy away from a little toxicity.\n\nNot all toxicity is the same tho. Going to be interesting to see Rust furry toxicity mix with Linux boomer toxicity.\n\nOlder Linux developers are more Gen X than boomers I would think.\n\nDo you mind expanding on why you think Rust is a nightmare to work with? This has not been my experience at all. It's definitely not simple in the sense that Python is simple, but it's a powerful and versatile tool for an experienced developer with much to offer in terms of program correctness.\n\nI use it professionally. The main issue is that the BC is pedantic. My quintessential example is, try getting two mutable references to two disjoint indices in an array.\n\nYou know that they are disjoint, but the BC considers it a double borrow of the same type.\n\nSimilar pedantic points of friction occur constantly.\n\nMaybe I didn't understand your problem, but you can do it in at least 2 ways: [in stable rust](https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2021&amp;gist=d5956d5db428cc47c7a32dec8ebae2d3) and more ergonomic, but [unstable version](https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2021&amp;gist=c4605e4e02c328af428c7c4f32381424).\n\n[There is work to be done](https://smallcultfollowing.com/babysteps/blog/2024/06/02/the-borrow-checker-within/) to make Rust better, but your example has already been solved.\n\nThis is just an example. The point is not that this specific problem cannot be solved. It's to show how the conservative nature of the borrow checker leads to situations where the programmer is certain everything is fine, but the BC can't prove it.\n\nThis forces the programmer to become sidetracked in making the BC happy rather than focusing on whatever pragmatic problem needs to be solved.\n\n&gt; programmer is certain everything is fine\n\nI've seen too many \"everything is fine\" code that breaks after some changes in the completely different part of the code. Borrow checker allows you to make sure that it's not only fine now, but it'll be fine in the future. I'm so tired of fixing bugs that could have been prevented with BC.\n\n&gt; I've seen too many \"everything is fine\" code that breaks after some changes in the completely different part of the code\n\nI hate this line, it's such an obtuse response. The standard library for rust uses unsafe in many, many places. The entire point of unsafe is that many times the programmer DOES KNOW BETTER than the BC.\n\nThe language has a mechanism to bypass the BC precisely because it is aware that many situations call for things that are sound but that the BC cannot prove.\n\nffs, I really want the rust community to stop repeating this line like if it was a religious mantra. The BC helps, the BC also gets in the way.\n\n&gt; many times the programmer DOES KNOW BETTER than the BC\n\nFor regular code it's not true for 99% of the time. Most of the time people don't know enough to understand that they, in fact, do not \"KNOW BETTER\", e.g. [Rust std bug](https://faultlore.com/blah/everyone-poops/). Two completely separated parts of the code, but if you use them together - they explode. \n\nMaybe because Rust moved from \"trust me bro\" to \"prove it's correct\" it's [70 times less likely to introduce vulnerabilities](https://cypherpunks.ca/~iang/pubs/gradingcurve-secdev23.pdf).\n\nYes, no one is arguing the BC is not useful. But you need to understand that some problems require you to bypass the BC. This is precisely why unsafe exists.\n\nIt's pedantic about things that could be bugs. If you're actually a good developer, you'd need to either account for the potential bugs yourself or (like a lot of C developers) simply pretend it's all just skill issues.\n\nPlease read the rest of this thread. I don't want to re-state all of the prior arguments.\n\nhttps://doc.rust-lang.org/std/vec/struct.Vec.html#method.split_at_mut\n\nThe desire to keep two mutable references around seems rare. Do you have an example?\n\nBecause it's not as restrictive as you make it seem: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2021&amp;gist=6f7e2ed422726fef5e8cdf457c6a31b9\n\nIt happens a lot in single threaded graph based data structures, which is something that I need to work with on the regular due to my specialization.\n\nAlmost everything I do is linked-list like graphs, and there's no other way to do it. As you can imagine, this often leads to situations where the BC is not happy.\n\nIn low level code Rust is simply antithetical to the types of things you often need to do in order to get your job done, like receive and work with a heap initialized object that never moves. You end up with programs full of zero sized types in order to pass information around the rust compiler, so your code becomes a mess of information purely for the compiler and not about your actual task/goal you're programming for. Collaboration goes out the window, because only very experienced Rust engineers can follow your code and you're now tied to nightly releases necessarily. For a 17 year old language that's meant for systems programming the offering is simply not very friendly/enabling for low level engineering work.\n\nIt's not even ten years old (Graydon Hoare's experiments ended in Rust, sure, but the language was completely unrecognizable until 2014), and it was created for use in web browsers, where you already have quite a bit of abstraction from the hardware. Rust-in-Linux was a pipedream until a few years ago, and I wouldn't be surprised if it takes several more years to stabilize, but clearly steps have been and are being taken.\n\nNot OP, but I found Rust's syntax very complex so I gave up on it. Then I tried Zig and it was very easy. Until I had to deal with basic arithmetic, then it was a nightmare.\n\nWas thinking of looking at learning Zig, can you elaborate?\n\nZig takes \"no hidden control flow\" seriously, which means that \"x + y\" doesn't implicitly cast unless it's trivial to do so.\n\nYou can't event divide an integer by another integer in zig. [https://www.reddit.com/r/Zig/comments/12kg2up/signed\\_integer\\_division\\_why/](https://www.reddit.com/r/Zig/comments/12kg2up/signed_integer_division_why/)\n\nBecause 2 / 3 could be 1 or 1.5, so you need to use @ divTrunc (space because Reddit makes it an user link), which isn't a normal function, but a compiler function.\n\nThe syntax to cast things is ridiculously long. You need to use as(type, value). But as doesn't cast, it just sets the target for the compiler. So you would need as(i32, floor(value)) for example.\n\nThis can get so ridiculous and verbose that when I tried to make a game with SDL, I could barely read the formulas that I was writing because 90% of the line was casts. It's really not readable at all, and I don't think they'll ever want to fix that.\n\nAlso note that part of Zig's design is that the AST can parse any line without looking at other lines. Which means there are no multi-line comments or multi-line strings. The official suggestion seems to be just surrounding a block with if(false) which makes the compiler ignore it, but that doesn't help with any syntax errors you may have in the code. That sucks, to be honest.\n\nBut it compiles REALLY fast, so you just ignore these minor inconveniences like these because whatever time you waste with it you would have wasted waiting for other low-level languages to compile. So it's worth it.\n\n&gt;  (space because Reddit makes it an user link)\n\nif you type \\`@divTrunc\\`, you'll get `@divTrunc`\n\nedit: apparently typing \\\\\\`@divTrunc\\\\\\` would also make it not user link\n\nRust is easier now than it used to be 5 years ago. You should try again. You can write a lot of code without using a single lifetime, for example. Not that lifetimes are difficult to understand, but I know a lot of people are afraid of them.\n\nI bounced off Rust and have been learning Go and Zig for similar reasons.\n\nHave you worked with C or C++ professionally? In large parts Rust just makes the stuff explicit that you have to deal with either way (be it during development, testing and review or debugging)\n\nHave you ever worked on a large team project before? Rigid coding standards are a godsend to prevent the code from becoming a spaghetti monster.\n\nI like Rust's rigid coding standards.  Much better than C, because instead of compiler error in Rust, I always get segfaults in C, and not just because I misused memory (sometimes that's true).  Usually there are so many libraries are poorly documented and assume a degree of familiarity with C I figure that I'll never reach at this point.\n\nI'm trying to write a jack audio program right now, and it's surprising to me how extremely annoying and difficult it is to write something that won't segfault, is hard realtime capable, and can pass data to a main thread (which doesn't need to be realtime capable) without violating those hard realtime constraints.  I've standardized on using GLib for strings, at least, because that's usually where I question life when I hit C code.\n\nI'm about to drop it and figure out how to write what I want in Rust or Ada (specifically with the SPARK subset) calling out to the libraries I need.  I've tried to figure out C on and off for over a decade (mainly because of the issues I run into whenever I use it), and it just isn't compatible with my brain.\n\nOn the flipside, I can return to a Rust project that's been sitting on my drive for a few years and pick up where I left off, and if I happen to cause a panic, I know exactly where it was (no need to compiled with `-fsanitize=address` to figure out where the crash is).\n\nIf you end up writing it in Rust, would you mind give an update just to show what was the process and how did you ended feeling throughout the development process VS what you did in C? üòÑ\n\nRust community? Toxic?\n\nCompared to Linus, this community is tame.\n\nLinus will chew you out and call you names your mother would be offended by on a public forum.\n\nKernel devs, via survivorship bias, have super thick skin.\n\n&gt; Linus will chew you out and call you names your mother would be offended by on a public forum.\n\nWhen was the last time that happened?\n\nI think it's a good thing for the kernel that Linus maintains high standards even if he's an ass hole. He's not being an ass hole to purely be mean to someone, he's being an ass hole because the kernel is a massively important piece of software that he obviously cares deeply about.\n\n&gt;The Rust community is also toxic IMHO.\n\nWoah, be careful talking about the rust community, you might get tens of downvotes.\n\nHeaven forbid we make r/programming mad by stating an opinion that they don‚Äôt understand. That would be terrible. We‚Äôd have to quit our jobs and become hermits.\n\nZig is more C-like than Rust and has pluggable memory allocators, more natural for use with the kernel.   But the language is not ready yet and by the time it matures Rust would have taken the spot.  Life is unfair.\n\nBut it does not provide most of the memory safety rust provides, which is the main reason to switch away from C.\n\nZig is not even 1.0 yet. Without syntax stability guarantees, beyond the memory safety issue others bring up, I wouldn't use it in the kernel either.\n\nZig is also memory-unsafe, so does not have one of major benefits of using Rust in the kernel.\n\nMemory safety is not binary. It's a matter of degree, and Zig's memory safety is much closer to Rust's than to C's. The question then becomes whether the pieces it lacks compared to Rust in memory safety are offset by its benefits.\n\nsure, but \"use after free is impossible at a fundamental level\" being a feature of Rust is pretty amazing.\n\n(yes, I know that there are ways to do it, but you have to try *really* hard)\n\nZig doesn't have the same strictness that Rust provides though. Really, the point of Rust is to allow high level abstractions, safety and performance that is simply not possible for C or C++ due to fundamental constraints with the language design. In theory, it's ideal for an operating system.\n\nThe downside is, as always, an accrued level of complexity that results in a fairly steep learning curve. Rust is a mix of ideas, some of which have worked great and others not so well. It's far from a perfect language but it does represent a significant evolutionary step in programming languages.\n\nIn the far future, we'll all be using functional/declarative languages anyway.\n\nWhat even is the point of using Zig if C exists in the kernel? No ROI. At least Rust has much much more stronger guarantees, even in something like the kernel. Don't be ridiculous.\n\n99% of the Rust community online is made up of Rust hopefuls who don't have a chance of understanding the language but enjoy bashing others for not using it anyway\n\nIndeed, and they will ultimately fatigue. And the language is already losing momentum.\n\nJust stick to C man üò≠\n\nRust Evangelism Strike Force struck and moved on?\n\nRust is already rusted"
  },
  {
    "title": "Main maintainer of ldapjs has decommissioned the project after an hateful email he received ",
    "body": "",
    "score": 1172,
    "url": "",
    "created_utc": 1715947912.0,
    "author": "[deleted]",
    "permalink": "/r/programming/comments/1cu3l1t/main_maintainer_of_ldapjs_has_decommissioned_the/",
    "all_comment_text": "Unfortunately, receiving abuse is a standard part of running an open source project. In the 20 years I've run [PortableApps.com](http://PortableApps.com) I've gotten death threats, rape threats, been doxxed, called just about any name or slur you can think of, been accused of donating a kidney to my Dad for clout, pocketing money from the project to support a lavish lifestyle (in my 1 bedroom apt), etc. Some days, I have to step back for my own mental health.\n\nIt could be just doing anything 'good' online gets you backlash. No good deed and all. I got backlash for [WorldTradeAftermath.com](http://WorldTradeAftermath.com) in the form of 9/11 \"truthers\" accusing me of playing a role in the attack.\n\nI'm still at a loss at how anyone could be so upset at you for portable apps. It's been a great resource to me and many people I know. Maybe we all need to share positive feedback more to reduce the ratio of this kind of bad vibes.\n\nIt's not always about being upset, some people just want to be hateful for kicks, like the email in the OP.\n\nI've started thumbs-upping YouTube videos and leaving pleasant comments. I know I like seeing nice things/feeling appreciated. No reason it has to be localized within YouTube\n\n&gt; how anyone could be so upset at you\n\nMental problems and the fact that you are not seeing 100k of people who are happy with the product, 20 who contribute and 2 who are just dicks.\n\nGo out and just be outside doing something (painting, play instrument, do mime) you will see how many people dont care but you will encounter one or two deranged folks.\n\nIn the past the community could deal with them. Today they are given protection by system but not get corrected because the system does not care.\n\nHuh, never in my life would have I thought I would come across the creator of one of the things I've been using for a long time in a random Reddit thread.\n\nThanks a lot for your work on PortableApps - they were a godsend in the pre-cloud storage era! Some of them still live inside my Dropbox account :)\n\nI've been around on reddit since 2010, so I pop into random threads here and there :) You're welcome!\n\nSame.\n\nHoly shit haha, I used portable apps about 17 years ago to run Firefox on school computers. Thanks for that, it was awesome and great to see it's still about.\n\nYou're welcome! I'm glad they've been helpful. Still about and kicking with a cloud folder focus.\n\nBruh, Portable Apps is the GOAT!\n\nI haven't used it for years and years, but it was a lifesaver several times over a decade and more ago.\n\nThank you so much for it, I think it definitely made the world a better place\n\nYou're welcome and thanks for the compliment! Glad it's helped you out!\n\nWith the IT team I have. Ty for portable apps\n\nYou're welcome!\n\n&gt; been accused of donating a kidney to my Dad for clout\n\nThis is so absurd. I'm sorry you had to experience it.\n\nWell, well, well ...we meet again Mr. I-Gave-A-Kidney-To-My-Dad. I have a bone to pick with you.\n\nAhem. You have an _organ_ to pick with him.\n\nHmm. I get the comment, but I remember when I was surprised that blood is also called an organ (its totality + function). So, perhaps we can say that the sceletto-system is also acting like an organ. After all bone is not entirely static but grows or shrinks too.)\n\nI just don't understand that stuff. Like, sure, okay, you don't like a project, think it's garbage and shit and incompetently maintained....why would any of the other things even come up if you're going to rant about it?\n\nNot maintained an OS project, but I've done free software with a significant userbase, and even when that group would get toxic, it tended to be about the software and design decisions, not personal typically.\n\nPart of the problem is that you never really know what you‚Äôre going to get and the outliers are just bonkers. A lot of projects only have sensible interactions and might be uneventful for years but then you might get unlucky and get the guy who thinks he has a platinum enterprise support contract, or has some political vendetta or mental illness, or thinks your forum is a dating site, or is actively trying to subvert your users. Even if those people are relatively rare, they‚Äôre far more memorable.¬†\n\n[deleted]\n\nI think it‚Äôs especially bad in tech because so many bad behaviors have been tolerated due to skill shortages, so a certain percentage never really experience consequences for being rude or abusive.¬†\n\n&gt; if you're going to rant about it?\n\nIt would not strike my head either, but some people are just strange and some are just troublemakers. The Joker said that best in the movie The Dark Knight.\n\nWe are now directly connected to any lunatic who can find our address. In the past, distance and effort would dissuade all but the looniest, but everybody‚Äôs smooshed together on the Internet.\n\nWtf. PortableApps????? You are a legend\n\nThanks!\n\nomg I have not seen that site in years. thank you for your contribution to the world.\n\nYou're welcome!\n\nI used to heavily use portable apps in the early 2010s when internet access was still limited but USB drives were cheap. Thank you for leading such an important project!\n\nYou're welcome! I'm glad it helped you out\n\nYou're like a software celebrity and I just want to say your site is great, thank you for running it all these years! \n\nAlso screw the haters\n\nYou're welcome!\n\nPortableApps was so helpful when I was in high school on PCs with locked down admin privileges. Surprised at the hate.\n\nDidn't expect to meet the creator on reddit either as well! ü§£\n\nI used to use it around 15 years ago, so I want to say thank you for your contributions. It was quite a useful set of tools for me in high school!\n\nYou're welcome!\n\nOh hey, shout out, I've been using your site since I was a 14yr nerd amazed what I could put on a USB.\n\nShout back!\n\nSounds like just an hour of playing League of Legends.\n\nPortable apps is neat (and when everything was on a flashdrive, it was very useful) and anyone who abuses someone else for a project that they're not even paying for needs to touch grass.\n\nI'm sorry you went through that.\n\nThanks for your dedication to the project - it's been a lifesaver in a few occasions\n\nI've still got a USB (and a directory on a few machines) that still run it. I've enjoyed keeping a set of apps entirely in userspace for when the time comes\n\nIt really just goes to show just how bad humanity can be at times.... You really don't deserve the hate and I wish you all the best :)\n\nYou're welcome! And thanks!\n\nPortable apps has been a great part of internet history. It was a great way to get able to run tools without installing stuff, which I know is literally the purpose, but still. It was very cool have a usb that can just have its own start menu with all the apps you added onto it. GG\n\nThanks for the kind words.\n\nI built cvstats.net, which was supposed to hel pblind people when there was no alternative to consuming CVStats data. Basically I wanted to know how dangerous my area was and a ton of other people loved it. The death threats for \"spreading misinformation,\" promises of \"copying the site to provide fake data and spread misinformation to help show covid as a hoax,\" and so much more was overwhelming and not what I expected. I genuinely don't know if I would've published it knowing the nonsense I would've received. Granted it was like 5% of the feedback, but that 5% can really bring you down.\n\nI'll also add from myself that I used to love portableapps - when using a locked university computer, I even got inspired by your effords, found a non-erasable network folder, and was able to turn some popular game to its portable version (if I remember correctly it was easy - install it on your personal PC and just copy the folder). Then I also used the auto load functionality to directly have some sort of on-usb desktop with many of your apps. Thanks :)\n\nYou're welcome, I'm glad it helped you out!\n\nThank you for portable Apps - I have no need for it personally, but it fulfills an important role for students and people under restrictive it\n\nWhat do people have against open source projects?! The fuck?\n\nThankyou for your service!\n\nYou're welcome!\n\nI would like to say that your software saved my butt far more times than I can remember, especially when I was still in Middle and High School. ‚ô•Ô∏è\n\nGlad to hear it helped you!\n\nHello there.\n\n\nI'll add myself to the growing list of people who want to tell you that I find portableapps to be very useful. Thank you!\n\nYou're welcome.\n\nThank you for PortableApps!\nI'm sorry to hear about that level of hate, and I just wanted to remember you how great is your work.\n\nYou're welcome. I've learned to deal with it better. Realizing most of the anger has nothing to do with me helps.\n\nYou are my hero!\n\nYou're welcome!\n\nI never knew of your work and now that I do I'ma share it to all my friends. It's so nice.\n\nYou're welcome!\n\nI built a social network once, got quite big. Got regular threats / abuse.\n\nSome people are animals.\n\nWow thanks for your service and sorry people suck.\n\nProbably people upset about \"shadow IT\" taking it out on you rather than serving their organisation's needs\n\nYou're welcome!\n\nOh shit\n\nPortsbleapps got me through high school\n\nCool!\n\nOhh mate that's terrible to hear, for what it's worth I used to use this alot back in the day and I'm very grateful to this day... Thank you\n\nYou're welcome!\n\nFuck them demented haters, portable apps was amazing!\n\nHope you're in a better place now\n\nI'm pretty good thanks. Life stuff. Planning career things. And still running PortableApps.com. Plus doing improv.\n\nI feel like I'm in the midst of a celebrity haha, thank you for the work on PortableApps!¬†\n\nYou're welcome. It's funny I never thought of that angle until some high school kids wanted me to sign their flash drives at a computer show one year. Cool.\n\nOP thank you for that awesome Resource. i know i appreciate it and you for contributing. haters going to hate!!\n\nYou're welcome!\n\nYou made my life at school so much better. Thank you for your service.\n\nYou're welcome!\n\nTY for portableapps. Your service is among the hall of heroes as far as I'm concerned.\n\nYou're welcome!\n\nWha‚Ä¶who‚Ä¶why‚Ä¶ I haven‚Äôt even had the pleasure of running my own open source project yet and you‚Äôre scaring the ever living shit out of me! I assumed this happens to teachers, but OSI maintainers??\n\nthanks for your work, portable apps has been very useful in the corporate it environment\n\nYou're welcome!\n\nI for one absolutely love your work and used it for years!\n\nYou're welcome!\n\nJust gotta say thank you so much made my computing life so much better, such an awesome app / resource.\n\nYou're welcome!\n\nHey thanks for your work.\n\nWhen in college i didn't have a Pc but i had a memory stick with a few portable apps working the way i liked because of you\n\nYou're welcome!\n\nThank you for your hard work. People suck. :)\n\nYou're welcome! Some people do, most do not. Don't let the small number that do mess with your ability to connect with all the awesome ones who do not.\n\nI hope your kidney donation got you some clout with Dad, at least.\n\nIt did. I'd occasionally tell him to get me something in the kitchen because my kidney was tired. And we always joked it was a lease to own. He'd own it once he'd had it a single day more than I did. Sadly we didn't quite make it.\n\nLove your work.\n\nJFC, what an email. What a piece of shit that person is\n\nSo what‚Äôs interesting about this in terms of the post-xz attack analysis - pundits have speculated that it‚Äôs not just trolls doing this, it is also state level actors setting up supply chain attacks. I don‚Äôt know enough about this particular project to make any comments but it is interesting how complicated and challenging the world of open source is for people who are just doing it as a hobby.\n\nUltimately this maintainer needs to do what is best for their own mental health. The industry has major problems with how we treat open source projects beyond this particular example.\n\nThis is really the only explanation that makes sense to me in a post-XZ world:\n\n1. Bully a maintainer of a library that you can use as an attack vector\n\n2. Contribute, take it over, and/or create an alternative library.\n\n3. ???\n\n4. Profit\n\n  \n(I mean sure - could just be people being dicks &amp; trolls, that's always a possibility too.)\n\nCertainly plausible with the security implications of an LDAP lib.\n\nit's actually terrifying that we have this problem. A supply chain attack is definitely a possibility.\n\nThere are entire teams, state sponsored that sit around all day and play thru these scenarios. The find all kinds of non-conventional ways to compromise anything they can. That is their sole goal is to compromise, once they do, then they evaluate how it could be used effectively for intel harvesting.  The net has become the dystopian vision of what we did not want it to become.\n\nSadly in today's world, it is best to create unrelated personas for anything like open source contribution, something you can disconnect from and cannot be tied by to the real world you.\n\n&gt; (I mean sure - could just be people being dicks &amp; trolls, that's always a possibility too.)\n\nI mean, Occam's razor would suggest this is the most likely scenario.\n\nThis just feels like a run of the mill dumbfuck trolling on the internet.\n\nI totally understand not wanting to maintain a project while being attacked, but at the same time, I've gotten more offensive spam than this thing.  Just block and move on, you really do need a thick skin in general when working with the general public like this.  Not that this excuses being the target of abuse, so don't think I'm saying that either.\n\nHe did block and move on. He moved on from the project, because seriously, who needs that in their life?\n\n&gt; you really do need a thick skin in general when working with the general public like this.\n\nAgain, why has it become acceptable that people have to adapt themselves to let the assholes be assholes?\n\nWhat can you do though? In email there's no mods to complain to, the words are there on your screen entering your brain so if you're vulnerable to them then someone can attack you.\n\nThis is an example of someone being sensitive and the attack being overt and immoral, but the problem is bigger than assholes. In the general case there's an \"email space\" of all possible character combinations, and presumably a large number of them in there could make you quit a project, send a password, leak information, even kill yourself. And deliberately hitting small targets in a large problem space is the definition of intelligence, and LLMs seem pretty intelligent and up to that task.\n\nWe're gonna need webs of trust and information filtering if we want to be safe from AI. We're in for a rough ride for sure.\n\n[deleted]\n\n‚Ä¶ there have always been assholes. You have to have thick skin because that‚Äôs just how it is.¬†\n\nNeurology is still a black hole. Some people are born with mental issues. Some people have bad lives. Some people hit their head and lose their mind.¬†\n\nThat doesn‚Äôt even include things like cultural differences, basic misunderstandings, or even just subjective opinion on what defines asshole.¬†\n\nMaking threats is pretty cut and dry for sure, but enforcing that on the internet? The methods needed to do that bring up ethical questions let alone how nearly impossible it would be.\n\nYou raise a really interesting point. Open Source, Free software is a wonderful paradigm for raising the floor on software around the globe. I've contributed to FSF under the auspice that free software _should_ somehow contribute to improved standard of living for everyone as it lowers the cost and improves the quality of so much around us. However, as larger and larger amounts of it end up in public service, public infrastructure &amp; defence projects it is a mounting security risk. Especially those maintained by individuals like this.  \n  \nI don't know if I'm mad, but I can imagine a world where we have National Source owned and maintained by governments and even perhaps shared between strategic allies.\n\n[deleted]\n\n[deleted]\n\nPerhaps I didn't explain myself fully. I totally understand what Open Source is for, and its benefits. I don't think it should go away.  \n  \nIn the UK where I live I am well aware of how much software and particularly Open Source is included in government services (tax, immigration, passports, driving licenses, blah blah). It's getting more complex and expensive to handle Open Source vulnerabilities and the patch/update cycle around them. If Threat Actors become clever, persistent and targeted enough I can see a point where the costs outweigh the benefits (at least on smaller, newer tools/libraries, not so much GNU type tools where there is a mature, robust, and large community of people involved) and it makes sense to leverage common code within nations or across specific allied nations which is kept secure and obfuscated from those Threat Actors.  \n  \nArmchair reddit only speculation though!\n\nClosed source software has the issues with supply chain, patching etc. the difference with closed source is you sign a contract with a vendor. With open source you may try to manage it yourself or you may pay specialists to manage it for you. Solar Winds for example was a victim of a nation state level attack, despite being a commercial org.\n\nThe main flaw with open source is that I can‚Äôt pay someone for a library even if I wanted to. There‚Äôs no market for commecial modules because they compete with free. And without the money, Open Source cannot provide the level of service that is needed to really make commercial software. Some companies try a hybrid approach to split the difference, which we also complain about.\n\nIf you don‚Äôt pretend to love the former then you get shit on by the Internet. \n\nUltimately this is a thirty to forty year old finance problem that we kicked down the road by trying to replace payware. Most of us use OSS because nobody with the checkbook can lord it over us that they won‚Äôt pay for the tools we need.\n\nYou totally can pay for a library if you want. But if you're the only one paying for it, you're probably not going to want to pay the required amount. \n\nThere are heaps of freelance coders who are more than happy to maintain or extend open source code for money (I'm currently working for a company where this is a large part of our business model). But the kicker is they're not magically cheaper just because they're working on OSS code - you're looking at $500-$1000 per day per coder.\n\nGovernments using paid agents to harass people into stopping what they are doing is definitely nothing new but I had never thought about this being used in such a targeted way for cyber security reasons.\n\nBut yeah, it does make a lot of sense.\n\nPoe‚Äôs law in action.  It‚Äôs so bad that it almost feels like parody.\n\nNa it's just terminal 4chan poisoning.  The email address is the giveaway.\n\nsqueal wrong snobbish sand upbeat snatch simplistic thought wipe gullible\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*\n\nYeah, if I got an email like that I'd probably delete it before I'd finished reading the first five words.\n\nThat said, this highlights an important reason why a lot of people don't want to maintain open source software. Way too many assholes out there.\n\nHonestly, I'd probably laugh my arse off and re-publish it somewhere as a testimonial.\n\nBut growing up as the little nerd with the surname Trout rather inured me to this sort of shit and this is not in any way a suggestion that being as upset as he clearly was isn't an entirely reasonable response.\n\nIn the end the mail was just a final straw that broke the camels back, but I still somewhat dislike that it sends the signal that you can just bully people into submission. That dumb-fuck who wrote the mail has essentially won :-/\n\nIt sucks to admit, but cyberbullying works *really* well against basically everyone. We are all susceptible to being treated like shit and having a bad day and making real, consequential choices because of it.\n\nWhile I'm loathe to admit it, when I get into an online discussion that turns against me, it gets to me.  It won't change my life, but my mood can go south over a bad comment from a keyboard warrior that won't ever touch the same grass as me.\n\nHow much harder to be providing a service, only to have someone crap all over it and everything about myself?  I don't envy high-profile project maintainers.\n\nEven downvotes on reddit get to me. I hate that it does, but I kinda can't escape it either.\n\nYou can. Don‚Äôt look at your vote counts, add an addon to hide them or delete your account. I‚Äòm basically one motivational afternoon away from exporting my saved comments and posts and deleting mine. There is almost no value in social media, let alone participating in it.¬†\n\nI delete mine every couple of years, my entire history on this site. I find overtime my views have changed and certain things I said 2 years ago aren't as relevant and there are plenty of people on this page who will do nothing buy dig through comment histories to poke holes in anything you say.\n\nI was going to go upvote some of your comments but I don't speak German. I'll just upvote this one instead\n\nPeople like you are why I am stuck here on reddit ... the good and funny encounters offset the few bad ones and the bad ones typically just have a short time where they affect one. Maybe it's also a chance to learn to deal with it.\n\nI guess my problem is that I often think I have a good point and in my head all makes sense, so the downvotes feel like not being understood correctly, which in turn makes me feel helpless that I can't find the right words to express my real intent. Even though I know that downvotes sometimes are kind of automatic. Once you get downvotes a bit, others read your comment with a much more negative view and then tend to disagree even more.\n\nAh damn, now I am overthinking it again.\n\nAnyway: I'll try to improve and to not let it get to me :)\n\nOh yeah the downvote train. Seems like people love nothing more than misinterpreting a comment and punching down.\n\nThe way I deal with it is disable notifications on any risky comment, or when I want to \"have the last word.\" If I never get notified of a reply then I win the argument right?\n\nThe hardest part is when I wonder \"am I actually a piece of shit?\" because either 80 humans are wrong, or one autistic midwestern American.\n\nFeel free to message or otherwise connect, we seem like kindred spirits.\n\n&gt; The hardest part is when I wonder \"am I actually a piece of shit?\" because either 80 humans are wrong, or one autistic midwestern American.\n\nSometimes, if I'm writing a particularly heated response, I'll just go to the bathroom before I post it. At least that way, I know I'm not full of shit when I do.\n\nI laughed. Thank you.\n\nHuman brain doesn‚Äôt make a distinction between physical violence and social rejection. Downvotes are literally processed as pain.\n\nHonestly, most of the time I just delete comments that get downvoted. Once a comment gets one or two it'll often just get more and more for no really good reason (people love to pile on I guess), and eventually abusive replies as the only people that will see it are people looking for a fight. I've long since come to the conclusion that it's not worth it.\n\nSometimes I leave them there if it's a hill I'm particularly willing to die on, and very occasionally they'll bounce back which is kinda gratifying.\n\nBut most of the time deleting them simultaneously stops the problem and means I don't have to look at it any more so I can move on.\n\nLikewise.  It did result in me changing my behaviour a bit in response though.  I routinely upvote posts I like, but rarely downvote posts I don't like or I disagree with.  I reserve it solely for posts which are grossly abusive or obviously incorrect.\n\nSame. I try to differentiate between \"bad intention\" and \"different opinion\". I may disagree with what someone says, but that doesn't mean I have to downvote. Instead of downvote I simply not upvote and leave a comment then.\n\nNot all of us have such thin skin. Some of us don't give two shits what some random Joe Blow nobody thinks of us or says to us. We can just block/ban/file-as-spam/etc and move on.\n\n[deleted]\n\nHe did not win. He has a project that needs this library, and now that library doesn't have support. That email cost him time and effort.\n\nWhat support? The library already provided a working primitive. Just because it's decomissioned/not being actively worked on/complete, does not mean that you must throw that library out the window and go on to the next integration.\n\nYou aren't wrong, but neither am I. The last maintainer only started doing it because his company needed it for a project. It was a good working primitive and didn't want to throw it out the window. It cost them to maintain it that's my point.\n\nWell, maybe some \"friend of him\" would take over in a sort of xz-Style.\n\nYou assume the troll's goal is to have the library updated rather than intentionally unmaintained.\n\nYeah, you should always consider the possibility that things are not what they seem in such cases. This could be a social engineering hack hoping to get maintainers to abandon projects so they can be picked up by bad actors posing as people offering to help maintain abandoned projects. It might sound far-fetched but look at what happend with the XZ exploit.\n\nDoes he though? The email and name look like a disposable email. The example code might be contrived to *look* like it's needed.\n\nJust tells me he doesn't want that nasty email publicly attributed to him. Or maybe you are right, just you and me guessing at this point?\n\nIf he was getting paid for the project, sure. I think the problem is that billion dollar businesses are using this person's work for free without kicking anything back. Open-source needs to fix that problem.\n\nWe should really hold the CEO of Open-source accountable at some point.\n\nBest response to this is \"Cool. üëç\"\n\nBest response it to delete the email and get on with your life.\n\nYeah, this email was just average noise on the internet from the shitheads who have infested it since about 1996. Having a thin skin isn't really going to make this world fun to live in.\n\n‚ÄúI‚Äôll just assume you forgot to take your meds today, aneurism is a real threat. Take care, man‚Äù\n\nReading the repo don't think the guy won anything as the author doesn't express any resentment but just wanted to expose the asshole. They can't maintain the project so archive status is best to indicate correct status.\n\nThat's what I meant with \"final straw\". They could and maybe should have archived it without giving that asshole any attention.\n\nIt _might_ be that the asshole gets negativity out of his action now. But knowing trolls, I fear they don't and even get satisfaction from it, which would just reinforce such behavior.\n\n(Just in case: I don't blame the author. Their repo, their life and their choice. I also don't have hard evidence for my claims. I simply wanted to express my concern and maybe discuss it.)\n\n&gt; That dumb-fuck who wrote the mail has essentially won :-/\n\nI'm glad I'm not the only one who sees this.   This is essentially the worst thing someone can do on the internet, but it's his choice. \n\nI hate saying it but to be in the public eye or the point of contact person for anything you pretty much have to have a thick skin because you will eventually get hate thrown at you.\n\nand is likely thrilled, and boasting about it. And will now go and try the same thing on other projects, and so will others.\n\nKinda shit. We need a new internet without the trolls.\n\nSpecial place in hell reserved for people who act with such entitlement as the author of that horrid email\n\nif they didn't like the code, a simple PR could solve the problem. But lets go mental instead....\n\n[deleted]\n\nThat email is just pathetic. Talk about a motivational killer to contribute to open source.\n\nIt was pathetic, and it was from pathetic. Look at things like this a verbal (or text) manifestation of the pain that people are feeling. It‚Äôs one of the only ways you know someone else is hurt. If they tell you honestly (rare) or they lash out in kind (common). When you practice seeing this stuff through this lens you start to feel sorry for people instead of being offended and bad about yourself.\n\nIt‚Äôs a life skill to be able to find the constructive criticism buried in a rant.\n\nThere's a special place reserved in hell for people who send hateful mails to open source maintainers like this.\n\nFull solidarity with this guy. That he even maintained this project even though he himself didn‚Äôt need it anymore was great of him. That after such an asshole email he decides it‚Äôs the final straw? 100% understandable. I‚Äôm a FOSS developer myself and have developed a thick skin, but I can so much feel how not everyone has that, and that is absolutely fine. Developing should not come with an unpaid hobby burnout attached.\n\nreeks of 4chan\n\nI dunno if it's just me but I wouldn't have even opened that email, I'd have deleted it on sight from the subject line and carried on with my life.¬†Obviously if I was getting loads even that would become untenable, but assuming it's only the odd crackpot (otherwise, presumably, the maintainer would have taken this action earlier) this personally seems like an overreaction to me and, perhaps, they were already looking for an excuse or reason to get out.¬†\n\n\nEveryone's different and the maintainer is obviously perfectly within their rights to take this action; this isn't intended to invalidate their reaction or experience or criticise their response. It's merely my own reflection, albeit not as someone who's personally put themselves out their in this way or had to deal with such things.\n\nWhile this is indeed pathetic, If I received this email I am quite certain I would have marked as spam / blocked and archived just by reading the subject line and not even bothered to read it.\n\nExactly my point. Why this guy felt so personally offended by this is a little beyond me. It's such a mindlessly troll. Mark spam and ignore and carry on with life.\n\nAs somebody being involved in the development of a decently popular open source app, it's not a single email like this that makes you throw the towel. It's the constant unproductive whining and temper tantrums of entitled dumbasses thinking the fact that they use your (free) tool makes **you** owe them free labour as well. It adds up over time.\n\nYeah the word vomit looked just like a general spam email trying to get me to click a link.\n\nHardly elicits this level of response, but I understand this could just be the straw that broke the camel's back.\n\nI'm gay and I laughed my ass off reading the dude's rant. So much condensed seething rage over an allegedly bad API is nothing worth losing sleep about. \n\nEven less decommissioning an entire project and potentially penalize everyone depending on it.\n\n[deleted]\n\nIf you Google the email address that sent the email, which you can find on the GitHub page and I will not post here, you‚Äôll find [a thread about this on 4chan](https://boards.4chan.org/g/thread/100492437), where they are (unsurprisingly) blaming the maintainer and email recipient for overreacting as opposed to the sender for being a jerk.\n\nI do hope the email was just a ‚Äújoke,‚Äù in however poor taste, as opposed to a legitimate threat, but emails like this are just beyond the pale. They‚Äôre not funny, they‚Äôre not helpful, and they‚Äôre certainly not how you treat someone who has freely given you their time and energy in the form of open source software. \n\nI think GitHub should reconsider listing people‚Äôs email addresses in the clear for all to see, even if users provide an email address. It‚Äôs one thing to get a PR like this, but another entirely to receive emails in your own inbox.\n\nOn that last point github already do that, you can change your email settings to private and github will create an noreply email for you that you can use to comment and sign your commits so that your real email doesn't get leaked\n\nYeah, but you have to do this before you contribute to anything.  Even rewriting the history of any public repos that you own is a lot of work, but any old commits merged through a pull request will retain the original author information.\n\nThat‚Äôs great info! Thanks for posting.\n\nmister jewstein is on 4chan? I am shocked.\n\nthat swear vocabulary and ability to chain all that shit in one single sentence is actually quite amusing. (but dont do that pls)\n\nIt's like the author watched 2008-era Zero Punctuation on loop for ten days straight while refusing to engage with any of the newer stuff because it's too woke.\n\ndunno what is zero punctuation, i hope i am not missing anything significant\n\nIt's a video game review YouTube series that's been running for 17 years now. Fast-paced, with colorful and imaginative sweary language. Technically it's now called Fully Ramblomatic due to corporate fuckery.\n\nNot something that's important to know, but overall it's fairly big and influential.\n\nThey used to not be on YouTube for a long time. To be able to monetize through their own website.\n\nTo quote another comment in this thread, the email vocabulary is awful to the point of parody. \n\nOr someone had a mental breakdown when they were working on a deadline and decided to take it out on an OSS maintainer.\n\nmaybe I'm alone and thinking this, but that email is so outlandishly comically over the top and stupid how could anyone possibly take it seriously? I mean this is the sort of classic mindless trolling that's been going on in the Internet for literally over 20 years. I could hop on call of duty right now and hear the exact same thing from a four-year-old within five minutes. Sureit's stupid, but that's the end of it. I just don't see how anyone could ever possibly take this personally or even waste a second of their brain space caring about it.\n\nI will never understand why people label comments like this as death threats. I get being angry at abuse and calling it out. But pretending that you are concerned over your safety from comments like this is baffling. I could see being concerned if it was done with mentions of doxx or attending some con. But that is never part of the messages that people concern troll over.\n\nThis is most likely a supply chain attack than someone actually doing that.\n\nThis is actually MUCH WORSE than someone being an ass.\n\nDevil‚Äôs advocate; here‚Äôs how it could work‚Ä¶\n\nEmail author wants to take advantage of a third party library that uses this LDAP library. Email author writes a ‚Äúdrop-in, supported replacement‚Äù and the third party library migrates. The drop-in replacement has a backdoor in it.\n\nBy targeting this library, the attacker ensures access to credentials and entire organization directories if the bugged replacement is ever brought in.\n\nEven if this isn‚Äôt targeted at one organization, it could get a valuable foothold in some orgs that use LDAP/AD and exfiltrate lots of PII.\n\nI doubt it. Unfortunately, there's way more assholes than spies on the internet.\n\nIs that unfortunate?\n\nI guess so, if there were fewer assholes spies would have a harder life and the total number would be much lower than today.\n\nYup, \n\nIt'd be lovely if we had 0 assholes and 0 spies, but spies are always going to be there.  Assholes don't have to.\n\nReally? That's more likely than someone just being an ass to someone on the internet?\n\nsorry, but tbh since xz somehow every email and comment is supposed to be a supply chain attack. i don't think anyone would write such a bullshit letter with this much of condensed and even creative swearing in it, in an honest attempt to do something evil.\n\nSince xz it would be prudent to assume the worst intentions from scenarios like these.\n\nHonestly the mail has me intrigued if the api is really that bad\n\nI'm convinced that:\n\n* hitting the delete key, or\n* hitting the downvote and/or hide button(s), or\n* swiping left,\n\nare the most empowering actions that any user can and ought to be able to take to keep their sanity.\n\nThis sucks on every level, not least that somewhere there's a troll grinning like a maniac and touching themselves over this reaction.\n\nink spark wild mysterious physical marble flowery airport grandfather frame\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*\n\nI don't understand how mature person can burn all bridges because someone who he do not even know sends him some random bullshit.\n\nIn moments like that, I really feel that there are devs that love their job because if anything gets them out of comfort zone, they can just close the computer and forget about it instead of confront it\n\nI still can't wrap my head around how someone could get hate for contributing their time and knowledge to help humanity for free. It makes me lose hope in humanity.\n\nFree labor\n\nNobody ever mentions that open source is free labor that is used by multi million dollar companies for profit and as their infrastructure. For example Linux kernel is in all android phones and 99.999999% of the people disregard it, etc\n\nWhen there is so much dependency on free labor and these people stop working and there is no plan B then we see how shitty, precarious and broken the technology world is. Risk management assessments never takes this into consideration."
  },
  {
    "title": "I'm a programmer and I'm stupid",
    "body": "",
    "score": 1162,
    "url": "",
    "created_utc": 1713855936.0,
    "author": "fagnerbrack",
    "permalink": "/r/programming/comments/1cay7xw/im_a_programmer_and_im_stupid/",
    "all_comment_text": "Reminds me of https://grugbrain.dev/\n\nActually both articles read like experienced developers giving their advice in a humorous way.\n\n&gt; end to end tests good, show whole system work, but! hard to understand when break and drive grug crazy very often, sometimes grugs just end up ignoring because \"oh, that break all time\" very bad!\n\nOh man... This hits home.\n\n&gt; javascript developers call very special complexity demon spirit in javascript \"callback hell\" because too much closure used by javascript libraries very sad but also javascript developer get what deserved let grug be frank\n\nNow that was just uncalled for.\n\nAs a backend dev that sometimes has to jump in and help out the front end team from time to time - it‚Äôs definitely called for.\n\n&gt; inexperienced big brain developer see nested loop and often say \"O(n^2)? Not on my watch!\"\n\nFuck, I just did exactly that today, way to call me out grug\n\nAm I the only one who thinks it makes sense for watches as they are kind of underpowered?\n\nWell, it's called \"**Premature** optimization is the root of all evil\" for a reason. If you program for low power devices, inefficient code will show its inefficiencies sooner than on your average desktop PC for example.\n\nIn my case I was reviewing some code that will likely not run on large amounts of data and will also run on devices that are fairly powerful. So it won't be much of a problem if it's a bit inefficient.\n\nIn my opinion, it's a trade-off between readability/maintainability and performance. If the code is super performance critical, it might make sense to sacrifice \"nice code\" to get performant code. If it's not really that much of a deal, it's better to ensure you and others can still understand the code in a few months.\n\n+1 You're perfectly right. That said, you know mine was a joke based on the double meaning of \"watch\", right? (\"Not on my watch!\")\n\nWell, I do now xD\n\nAlso worth considering how often it will be executed. \n\nI‚Äôve actually seen someone take my code that processed data in 20 minutes, rewrite it so that it ran in 5 minutes. \n\nCongratulations! Well done! Wow! You‚Äôre superior!!!\n\nTook him 2 hours. It was to be used only once, ever. \n\nSo if it‚Äôs a process that runs once a year or something, don‚Äôt fret over a few minutes.\n\nI agree with your point, so none of this is meant as a rebuttal. It depends on circumstance. It just triggered a memory that's a fun story for me. It's nothing novel, but it was the first time this ever really slapped me in the face and how absolutely stark the difference was was funny to me at the time.\n\nWe were doing a table with selectable rows on a webpage that could display up to 10,000 rows. We had to do some customized behavior for the select all behavior. For, reasons\\*, the table didn't natively support this, but did provide plenty of event hooks so we could do it ourselves. We'd done something like this on a previous project where there was only about a max of 50 rows, so basically what i had it do, like in the earlier project, was when you clicked a row, it checked all the other rows to determine the check-all status. When you clicked check all, it did have the unfortunate effect of running that check for every row, so n-1 checks for n rows, hence n\\^2. Not optimal, but meh, no one noticed.\n\nBack to the big table. I did the same thing because I still had access to the old code and I'm lazy. Get it done and time to test. 10 rows: fine. 50 rows: fine. 100 rows: fine. Ok, so far so good. Let's load test. 10,000 rows: whole webpage locks up. I let it sit for a bit. Still locked up. Obviously, it's not acceptable for prod, but at this point I'm curious, so I decide to let it chug for a bit. I go get some tea and talk to one of my coworkers in the break room. Get back, and it's still locked up. At that point I think it'd been about 15-20 minutes. Since I do have things to do, I kill the page and start refactoring. Maybe about an hour and some squirreled away table-level state later, I have it at n time. Try 10 rows just make sure the logic works. It does, so I move on to the 10,000 case. Finishes in about 0.5 seconds; there's a semi-perceptible delay if you're really paying attention to it, but if you're not you don't notice it.\n\n\\*The table did support this, but only the paid version. I'd talked to my boss about getting approval for said paid version which wasn't terribly expensive, but we weren't sure it'd be approved in time for our release deadline, and I didn't really have the time to look for a new table library that supported this for free as well as rework all the other tables in the app so look and feel were consistent. I really hope they got that approval finally and threw away my jank.\n\nOh my god i love this üòÇ\n\nGreat article tbh\n\n&gt; ... javascript developer get what deserved let grug be frank\n\nGiggity\n\nMy working life is a constant duality of being grug-brained and having a grug sticker on my laptop, while also working in Typescript\n\nGrug is way funnier to me.\n\nironically I'm too stupid to understand this (too many layers of meta). I like the OP more\n\nmaybe same grug maybe not but this good [big yell](https://dynomight.net/grug/) on other subject\n\nLiterally came here to post this.\n\nSo I've been coding with an LLM lately, and I made a character sheet which is Grug through which I route all my assistance requests. I love it, he keeps me in check.\n\nI miss Primate Programming Inc.\n\n&gt; world is ugly and gronky many times and so also must code be\n\nHard-to-swallow pill\n\nGrug taught CS at my college. Nice guy\n\nProgramming made me so dumb that I ended up a manager üôÉ\n\nHey! That's me you're talking about!\n\nHow was the switch? I really enjoy programming but I‚Äôm also kind of looking forward in my career and realizing that maybe I actually don‚Äôt want to be an IC my whole career.\n\nI‚Äôm decently technically minded but there are certainly better engineers than me where I work. I tend to excel at working with product owners and really nailing down wtf they actually want and explaining the pros and cons of different possible solutions.\n\nI made the switch, so I can speak about this. I will start by saying that I think I'm a fairly decent programmer, but I moved into management relatively young (age 27). So I'm in the position you describe: I am by no means a better programmer than most of the people on my team.\n\nI think that if you excel at working with product owners and other \"soft skills\", then management might be for you. A manager who can argue for good outcomes for their team while being respected within their company is rare and cherished by their employees. That said, there's a good chance you'll end up missing coding. It's so fun, and managing can't replicate the problem solving high, in my experience.\n\nIt likely depends on what size of team you manage. I really enjoyed managing a team of 5-6 engineers, because I found enough time to code and help guide them. Now I manage managers and get almost no time to code. You have to be very mindful of graduating to that point and making sure it's the right move for you.\n\nI wish I had coworkers like this person.\n\nEverything has to be the most complex it can be nowadays. And coming into a new team and project you‚Äôre instantly overloaded, because nowadays we don‚Äôt just have a pipeline, we have a terraform, gitops and argocd. \nWe don‚Äôt just have logging, we have a prometheus, grafana and jaeger. \nWe don‚Äôt just have APIs, we have graphQL, with dapr in front, and a CQRS pattern to call what happens after. \n\nIt‚Äôs all great tech, but it‚Äôs a LOT!\nI wish I could write code and not spend all my time fixing configuration.\n\nThe best programmers choose the simplest solution that solves the problem. Always. \n\nThat said, at least most of the technologies you bring up are high quality products that when used in an appropriate environment, will help you solve very real problems. It's just that the majority of people don't actually *have* the problems that require microservices, GraphQL, NoSQL, Prometheus, Grafana, or Terraform to solve. They just think that the big boys (e.g. Google or Facebook) use those things, so they must be good. But unless you're processing Petabytes of data, and many millions QPS across multiple continents, most of those techs are inappropriate.\n\n&gt; The best programmers choose the simplest solution that solves the problem. Always. \n\nThe problem is that people don't always agree on what's simple. For example, some people will argue that dynamically typed languages are simpler because you don't have to think about types, and other people will argue that statically typed languages are simpler because the type checker will catch errors for you, allowing you to use your limited brain power to worry about other things. Some people will argue that large frameworks or languages with large standard libraries are simpler, because they already do everything you need. Other people will argue that they are too complicated to understand and writing what you need or using smaller individual libraries that only do what you need results in simpler code because you aren't paying for complexity you aren't using.\n\nThis seems to scale almost infinitely in both directions. I've heard first time programmers earnestly argue that functions and modules are too complicated and it's much simpler to just write all of your code as a stream of consciousness in one file. At the other end of the spectrum you have \"a monad is just a monoid in the category of endofunctors, what's the problem?\".\n\nIt seems to me like ultimately it comes down to the blub paradox. A ton of things are simpler once you understand them, and the industry as a whole seems to largely have settled on something somewhere in the middle as the \"correct\" level and everything above it is too complicated.\n\n&gt; For example, some people will argue that dynamically typed languages are simpler because you don't have to think about types, and other people will argue that statically typed languages are simpler because the type checker will catch errors for you, allowing you to use your limited brain power to worry about other things. \n\nSure, but some of those people are wrong.\n\nUntil you try to prove they're wrong and realize it's basically impossible.\nI am totally on the statically-typed languages side, but then you see Clojure/Common Lisp/Elixir people writing large software just as reliably as the Haskell people and you've got to question that.\n\nIt's usually the same with every one of these never-ending arguments, which is why they're not (and will likely never be) settled.\n\n&gt; A ton of things are simpler once you understand them,\n\nEven better: things are simpler when you don't have to understand them to use them.\n\nNot necessarily. There are ideas that can simplify the way you think about problems, but understanding the idea still requires effort. This is the nature of abstraction. Sometimes it's possible to use an abstraction without knowing what you're doing, but I don't think that's always desirable, and requiring that someone understand an abstraction isn't necessarily bad.\n\nThink about programming languages. They are an abstraction over the way the computer works, and people would generally agree that writing in a modern language is simpler than trying to build an entire program in assembly. Still, you have to understand how the language you're working with works if you want to build programs with it.\n\nAnd other engineering professions. KISS (Keep It Simple, Stupid) in some variant has been around and is a good principle to follow.\n\nAny engineer can build a bridge that stands, it takes a great engineer to build a bridge that just barely stands\n\nAnd it takes a g-d miracle worker to due it within cost and schedule targets!\n\noh so instead of being one of those who think it is not okay to write \"god\" (even though it is not their god's name), and so they write \"g-d\", you are using it as \"god damn\"? That'll put a spicy twist into the conversation.\n\nThe funny part of that to me is that \"taking the lords name in vain\" is not saying god or Jesus, or inri, or Muhammad, or elohim or whatever, it's hiding under the cover of faith while not practicing the tenants, so most \"religious\" people who don't donate their wealth, heal the sick, welcome the stranger, etc.\n\nIt's masking your callous disregard for life and kindness under the vanity of \"the lords name\"\n\nI hadn‚Äôt considered the - as a letter placeholder but I‚Äôm all for spicing up the conversation if possible.\n\nG dash D damn it, Hammer!\n\nKeep it Stupid, Simple. Wait.\n\nYou need to  be processing petabytes of data before using Prometheus, Grafana, or Terraform? So what do you do before that? Deploy everything manually and don't monitor shit?\n\nI work in one of those companies that *do* process petabytes and have been for a decade, so my knowledge on the latest and greatest in small scale monitoring is out of date. Back when, I used to use Munin, Zabbix and Nagios for monitoring. They're all a great deal easier to get going than Grafana and Prometheus, but I'd be disappointed if they haven't been replaced by something better. Not my field to know what, though. \n\nAnd yes, Terraform/gitops is complete overkill if all you have is a few dozen servers. Ansible or Puppet will give you to the same place with one tenth the work.\n\nI didn't use Grafana myself but I've used Prometheus and it seems easy enough to use.\n\nI've used a bit Ansible and IMO it's not the same use cases as Terraform. Is there a state in Ansible? Can you deploy most cloud resources using Ansible?\n\nTerraform is as exactly as complicated as you tell it to be. It‚Äôs absolutely fine for small-scale cloud-based projects.\n\nAfter having worked on a codebase with tens of millions lines of overcomplicated code and none of these tools I've reversed my position on this. I believe more of it comes from not properly pruning shit. All of these technologies save maybe complex metrics setups and graphql can be pretty damn useful when used correctly at ANY scale. The real problems arise when team members or managers aren't drinking the same Kool aid and don't properly buy in and learn. \n\nThe earlier in a product's lifecycle you learn to implement a lot of these tools the easier it is too.\n\nFair, except terraform is so goooood and worth it even for a single server and a single domain name.\n\nJust like we had a financial crisis in 2007 because people were overloaded with loans, I think some businesses in the future will be overloaded with code complexity.\n\n They will not be able to compete or will not be able to recover from a system breakdown.\n\nLol ... SOME COMPANIES use that as a Strategy\n\nResume driven development\n\nWhich is a fair thing for inexperienced devs to do. All jobs they want to apply for require all of those fancy techs, so if they don't get to learn at least some of them where they are, they may get stuck for a long time.\n\nTerrible for the company though. Which is why the company needs to have experienced people making these decisions.\n\nThey told me these tools would make me write less code. What they didn't tell me was that I'd be writing configurations instead\n\nSo writing code to code?\n\n&gt; I wish I could write code and not spend all my time fixing configuration.\n\nSo true.\n\n[deleted]\n\n[deleted]\n\n[deleted]\n\nNothing wrong with distributed tracing. When you've got a browser, a backend, and a database, that's already a distributed system with three moving parts - being able to profile a request from start to finish can save you tons of headache.\n\nThere's a reason it's mostly called \"tracing\" these days. It's just a better way to instrument any system\n\nFrom a point of view from mid size corporate.... How is that an issue really? \n\nIt's not my job to handle the ELK stack, or do DevOps, or run the K8s stuff. There's specialized people to do that. I currently make SPAs, and that's all I need to work on. If I had to ship the app myself, I would ship some static bundle. Even writing a dockerfile or making a simple pipeline is easy enough to be a 2 hour task.\n\nI get how things connect to each other, I don't really care about writing configs every day because it's more often than not a one and done deal.\n\nThats alright then, it‚Äôs a multi-team landscape and is big enough that the devOps topics are mostly covered by dedicated teams, it‚Äôs not really a problem.\nBut when you have a single team project, then that techstack is just wayyy too much.\n\nCurrently actually my team has approximately the infrastructure I mentioned within the team, so we do have to handle it all, and finding bugs that could be anywhere in any configuration or code, oftentimes in a system you never saw before, becomes really annoying.\n\n&gt; there s specialized people to do that\n\nthat is the problem,  a role called devops shouldnt even be this important at the first place.\n\nThe ‚Äúeverybody devops‚Äù track is honestly awful. I hate the idea of having to know everything about every tool. I DE at a small shop and having to learn each tool because our devops guy was overloaded has been very time consuming and ate into a lot of my project times and blew multiple deadlines when I had to figure out details of k8s or EC2 that I would have gladly handed off. \nI can‚Äôt imagine what it‚Äôd be like with more complex systems. \n\nDevops, platform engineers etc should be ‚Äúthis important‚Äù. They provide consistency in deployment, consistency in expense, and consistency in reliability. Leaving that to all the individual teams and throwing yet another style document at them sounds like a recipe for disaster\n\nI wish. Apparently, according to some people, dev teams doing their own devops is a good thing. So now every team at my company has to figure out the same dozen of technologies. What a waste of effort.\n\nIf you have hundreds of applications and services online, perhaps it is. Someone still has to make sure that the infrastructure works, that there is accountancy on what's going on. You can't just ship and pray, and most developers don't have system or network skills, and rightfully so.\n\nRight but maybe hundreds of micro services is part of the problem too?\n\nIt's hundreds of micro services when you have two dozen products in production, if you just assume there is at least a small number to take for granted (at least one user related service to handle sessions, some core domain service that is rarely just one, some sort of gateway, some sort of static file proxy say from a bucket, the FE service handling the UI) when doing a micro service architecture. \n\nMy current project uses half a dozen products from three major cloud and saas providers plus calls out to multiple different micro services from other products and those require additional processes. We developers didn't pick them, I didn't even pick the client lol.\n\nComplexity is real when you have dozens of thousands of users, many businesses relying on it for critical internal processes and need to adhere to strict data handling regulations.\n\n&gt; If you have hundreds of applications and services online, perhaps it is. \n\nMost companies that shovel all of that crap into their system usually don't. It's definitely a cargo cult at this point, at least in some places.\n\nI pity those who do their jobs as a years long resume filling activity, yes.\n\nI wish. Apparently, according to some people, dev teams doing their own devops is a good thing. So now every team at my company has to figure out the same dozen of technologies. What a waste of effort.\n\n&gt; So now every team at my company has to figure out the same dozen of technologies.\n\nWith no training, of course - you should just be magically familiar with their infrastructure from day one.\n\nYeah, maintaining all this overengineered infrastructure is going to be a blast in 10 years.\n\nCompanies who use 50 microservices deployed in kubernetes but they have like 500 users.. I mean, stuff like Kubernetes exist for a reason, it's the enormous companies that could benefit from them but they are only adding complexity to everyone else that uses them pretty much. That's a hill I'm willing to die on.\n\nMost stuff out there today could probably be a monolith that is easier to build; maintain and continue to develop.\n\nThis hits hard. Cloud is very useful but as a developer I've grown to hate it.\n\nConfiguration IS code. These tools exist to solve real problems, especially when scaling. The complexity would honestly be much higher at the current scale of many platforms if it wasn't for these tools.\n\nDoes your company's promotion process involve having technically complex systems as a requirement?\n\nIf so, your company rewarded and incentivized folks for making things worse in this exact way!\n\nWorking 6 years as a paid Python software dev. I can only hope to be as stupid as you are in 9 years. #stupidpeoplearepeopletoo\n\nI will always hire a honest and self aware developer than a FAANG reject with a chip on his shoulder. I am not sure this Anton fella is stupid because his approach reminds mine and I am pretty sure not stupid (not very smart either, just enough to survive and enjoy)\n\nIn my experience the most important skill in software is perseverance\n\nYea. As a survivor of a major burnout that still enjoys coding, for sure\n\nftfy: In my experience the most important skill is perseverance\n\nYes, you need a certain amount of intelligence. But that's only a necessary component, not sufficient. Going on and on in the face of whatever your job throws at you is the most important thing.\n\nAfter reading this post, I don't know if I'm his version of stupid or just plain stupid. I've been in this industry for 17 years myself. Was a Ruby backend developer during the Ruby craze in the late 2000s, and at some point in my career got shoved in Python and DevOps and can't escape now.\n\nwelcome to the club.. I am the dumbest idiot to ever write a line of code, I only do it because for some reason I find it \"fun\"\n\nNo no, I'm the dumbest idiot to write a line of code.\n\nyou haven't read my code\n\nIf writing dumb code is cool, then consider me Miles Davis\n\nI more or less agree on everything he's doing except the microservices, but I will admit that there's a HUGE AMOUNT of microservice abuse where they make things more complicated because they're far too tightly coupled to one another.\n\nUltimately I feel the best solution is the simplest viable solution. If SQL is good enough for your scale, goddamn use it. And any kind of code that is \"magical\" should just get the hell out of here. It should be quickly apparent where behavior comes from and a lot of the \"tricks\" languages allow you to do now are great at solving todays problems at the cost of tomorrow.\n\nSE radio had a good interview with Casey Muratori where Casey made the argument that microservices introduce code complexity (and performance bottlenecks) to solve an organizational problem. They're a good solution for that, but if your org doesn't need them, then they aren't worth the code and infrastructure overhead.\n\nThis sounds like a developer [Grug](https://grugbrain.dev/) would approve of.\n\nI agree with most of that except his comment about rust. I use rust for my hobby projects because the rust compiler catches errors that I'm to stupid to catch myself.\n\nYes, but if you generally know how to fix the errors the compiler mercilessly throws at you at every dumb line you write, then you must be really smart.\n\nOr just do a lot of trial and error and use stackoverflow a lot\n\nI am really smart, future me is the moron.\n\n&gt; I use the simplest mainstream language available (Go)\n\nPretty sure Go is not the simplest programming language out there. It has so many quirks I almost surrender. Dealing with json is painful, dealing with SQL is painful, dealing with any interface is painful, dealing with default values is painful, thousands if err != nil, mock here mock there, not to mention a tons of generated code, etc etc.\n\nAre you sure?\n\nBut at least it has generics now, which is nice.\n\n[deleted]\n\nI've seen more companies/teams that don't actually need kubernetes than the other way around.\n\nI thought Postgres was good for everything until I had to design and write an MVP for an app dealing with financial data; turns out timeseries databases exist for a reason :D\n\nTimescaleDB is proof that Postgres really *is* good for everything.\n\nI use one Postgres‚Äôs db and store time series, LLM vector data and GIS data together and have systems that join all 3. It‚Äôs divine!\n\nOut of curiosity, did you land on something like InfluxDB for financial data?\n\nThe idea, I think, is more that it‚Äôs harder to retrofit scalability than it is to build it in from the start, and the productivity loss from complexity will be made up later on. (These points are debatable.)\n\nMost companies never need the scalability, but given that many of them are startups trying to hit it big, if you don‚Äôt think you‚Äôre going to reach that point you might as well not bother at all.\n\n[deleted]\n\nTo take the perspective of someone who thinks scaling early is crucial (not that I necessarily agree - IMO it‚Äôs extremely dependent on the type of application) the concern is that you won‚Äôt get to the point where you can hire an army of developers if you can‚Äôt already scale. If you‚Äôre hunting for VC cash, the investors are going to want to see that you can scale before signing up. If you‚Äôre looking to get bought up, the buying company is going to want to roll your app out worldwide across all their users/customers on a short timetable which doesn‚Äôt allow for onboarding a large number of people (if they wanted it to take a year, they‚Äôd do it themselves). If you‚Äôre looking to grow organically and have an IPO, you might have more time - but you might also randomly go viral  and if nobody can use your service your brand is toast. The thing that changed Airbnb from yet another ‚ÄúUber for X‚Äù startups to a household name and ultimately a unicorn was hurricane Sandy flooding New York. Opportunity may only knock once and if you‚Äôre serving 503s instead of answering the door you may not get another shot.\n\nBut as I said, you have to know your product and your market. I‚Äôve worked on on-premise products where the customers don‚Äôt want horizontal scaling because they prefer a steady pace and predictable costs to shorter processing times but potentially large cloud bills.\n\n\\*shards aggressively\\*\n\nI've been in a company where a team applied the \"Postgres is the way\" mantra, and before you know it we were spending a few millions a month for 15 PG clusters on AWS RDS.\n\nThe company could afford it, but the department looked really bad because of it. We were spending much more than other departments without the corresponding revenues.\n\n&gt; a few millions a month for 15 PG clusters on AWS RDS.\n\nCalling bullshit on this.\n\nTake one of the most expensive PG offerings in RDS: Aurora serverless. Running a single 128 ACU serverless instance is only $15k/m. Even with 15 clusters, multi-az and/or multiple readers, you aren't even getting close to a million. And again, thats one of the most expensive options. Provisioned RIs are going to be less than half that. So the instances themselves, aren't why.\n\nA petabyte of storage is still only $230k. This is the *only* way you're going to be reaching millions of dollars in RDS spent with PG, and you'd basically need to have on the order of 10+ petabytes in postgres. The serious architecture design problem aside, that is impossible with PG in RDS. The Aurora cluster limit is 128Tb, and standard PG even less. \n\nSo even if you pushing the absolute limits of RDS, you'd barely be getting a $1 million RDS spend on 15 clusters. Yeah, there are other billing facets (like cross-az traffic), but several times that, is far beyond questionable. Thats extreme negligence or even just pure fraud somewhere in the company\n\n\n&gt; but the department looked really bad because of it. \n\nAs they should. Thats some serious mismanagement.\n\n15 clusters does not seem like a lot, though? I mean, if you have the kind of data where a single PG cluster *won't* cut it, paying for 15 servers doesn't seem insane... that's barely a single rack!\n\nI think that's the point of comparing it to revenue - They were taking in a ton of data because they wanted to lean so heavily on PG that they felt it was their strength and that's where they wanted to invest their engineering effort. But they weren't taking in the cash to justify that kind of infra expense.\n\nCould you please explain what did they do wrong and how could one go about solving this?\n\n\nSorry, I haven't got much experience with databases:)\n\nAll that less-is-more goes right out the window at 3 9s SLA. At 4 or 5 nines you have systems of those systems. I guess you could write it yourself, no dependencies, flat file structure, then write it to your floppy disc and put it in the drawer for the night.\n\nLife is not a blog post.\n\n&gt; There seems to be a recurring strawman in software engineering claiming nobody needs those, and they just bring complexity for no good reason.\n\nStuff like that happens on Reddit all the time. While it happens in software engineering it also happens for other stuff as well. Lots of people promote self-serving narratives. An example of something of that general structure might be like:\n\n&gt; Nobody uses {thing that's hard or that I happen to not be good at}. Everybody uses {thing that's easy or that's hard but that I happen to be good at}\n\nThere are many projects within mid-sized and FAANGs that don't need it though. I've been involved in several over-engineered projects that were, in the end, used by less than 100 internal users.\n\nWait, how do you think that most need Kubernetes?\n\nReality is the other way around.\n\nYou don't need a full-blown cluster at all, either VMs managed with Ansible, or just Docker containers.\n\nHigh availability is non-negotiable for me, because I don‚Äôt like early-morning phone calls.\n\nAs I explained to my wife (girlfriend at the time), programming is just what I call ‚Äúapplied laziness‚Äù. I write code in an effort to not have to write more later. Tests, best practices, etc. are just tools to allow me to be lazier in the future.\n\nThe whole point of computers is that you tell them how to do something once and they can do it over and over and over again. The whole point of programmers is to do the telling.\n\nThe number of programmers I encounter who are happy performing a rote set of actions every day or every few days is just nuts.\n\nThis piece is an excellent demonstration of the difference between intelligence and wisdom. You're stuck with the intelligence you're born with, but wisdom is learned and can be intentionally cultivated if you're willing to expand your horizons.\n\nIntelligence's effect is tactical. Wisdom's is strategic.  Wisdom can plan for the failure of intelligence, but intelligence cannot plan for the failure of wisdom.\n\nThe author may feel they've not started their careers with as much intelligence as their peers, but they've developed the wisdom to build systems that don't rely on high-level intelligence to function or maintain - which are vastly more valuable than the alternative provided that the project's goals are fulfilled. Not every system needs to be a sports car, and there's no need for every programmer to be Dale Earnhart. \n\nAnd it's a fact that the world needs more truckers than it does race car drivers.\n\n&gt; Intelligence's effect is tactical. Wisdom's is strategic.  Wisdom can plan for the failure of intelligence, but intelligence cannot plan for the failure of wisdom.\n\nThat alone is the best insight I‚Äôve seen for a number of weeks now.\n\nWell said.\n\nie. \"The simplest thing that works, but no simpler.\"\n\nIt's been my mantra my whole coding career (decades). Code I wrote 20 years ago is still running / being maintained to this day.\n\nSame author: [Idempotent close in Go](https://antonz.org/idempotent-close/)\n\nDo not confuse his humblebrags with actual stupidity. He knows what he's doing albeit with terrible taste in languages.\n\nYou're calling Go a terrible language?\n\nI do.\n\nIt absolutely is. I recommend [this article](https://fasterthanli.me/articles/i-want-off-mr-golangs-wild-ride).\n\n&gt; I like to remind everyone that we're not out there cheering for sports team, just discussing our tools.\n\nGold\n\nThe concept of idempotence isn't really complex for what that article demonstrates.\n\nShould use a sync.Once instead of bool + sync.Mutex\n\nDo you think he‚Äôs really a humblebrag? I mean I get where he‚Äôs coming from and can understand calling yourself stupid with all this difficult modern technology..\n\n&gt; I can't really follow complex dependencies in a code base.\n\nI don't think anyone can, right ... though some developers seem to be more confident in their *assumptions* than others.\n\nOnly those that designed it and only if it happened within the last year and only if they are still active in this code base\n\nStarted on a project in the past year.  I know mostly how it works from blackbox test / seeing how it works from the UI perspective.  Had to show the group a code review to a new team lead.  I was sad because as I was going to through the code, I quickly realized how big of a mess it was.  Lots of indirection and abstractions that really could have been boiled down to a simple pipeline.  There I realized that the original authors intent was lost.  Sometimes people bolt on things so much and lose track of the purpose.  Got to keep the intent simple and easy to convey in the code and architecture so new people can come in and understand.\n\n[deleted]\n\nI cant believe the author uses zero external dependencies.  Some are needed for web development and all sorts of things.  I doubt they are talking about writing that.  But I see it as the case of JavaScript libraries like lodash that have many functions that do the same thing as built in functions.  Like you said, I don‚Äôt want to write code I don‚Äôt have to.\n\nBut is the author just describing not wanting to learn about new technology, which is super important in our field?  Or do they just don‚Äôt want to be bleeding edge?\n\nTheoretically, you can actually write a full stack app in Go with only one dependency (you need a database driver).\n\nBut does it make sense to, and can you do a lot without external packages?\n\nI‚Äôm starting to think the author isn‚Äôt a programmer but uses programming to do the job they need.\n\nIt does in some way and it is prevalent in the Go community. This is what I am doing right now with Go templates. Your code will not be outdated in 5 years. Whereas if you do use lots of packages, most of them will be outdated in 5 years.\n\nLearning Go made me a better developer imho. If I now have a problem I try to first solve it with the standard library and if that is too complicated and bug prone, then I use a package.\n\nIs this just a humble brag post in disguise?\n\nHow is\n\n&gt; my mental capacity is very limited. I find even easier Leetcode problems challenging. Reading about a basic consensus algorithm makes my head explode. I can't really follow complex dependencies in a code base. I can't learn a fancy language like Rust (I tried, but honestly, it's too much). I hate microservices and modern frontends because there are so many moving parts, I can't keep track of them all\n\na brag?\n\nIt's the 4000 IQ reverse-brag, you make it seem like you are in fact really stupid but.. you discovered something unique and you are special in contrast to all the other sheep that don't even know they don't need those shiny new tools, you have a special intuitive understanding that no one else has.. which in fact makes you the smarter one.\n\nNo. A lot of points are valid. I wish all the big brains I know and worked with read and digest this article\n\nThis just reads to me like \"I'm actually the biggest brain because I'm smart enough to figure out things that I don't need to use\"..\n\nSeems like the bar is pretty low if you consider someone explaining that their job role doesn't require a complicated tech stack to be humble bragging. Just seems like a person explaining that their simple problem only requires a simple solution.\n\nis this a made up personality to call out as many bad traits about the reader as possible\n\n**Snapshot summary:**\n\nThis post candidly explores the author's self-professed limitations in understanding complex programming concepts, despite 15 years of experience. Admitting struggles with advanced algorithms, dependencies, and languages like Rust, the author emphasizes simplicity in their work. By using mainstream languages like Go and Python, avoiding deep abstractions, and minimizing external dependencies, they craft understandable and maintainable code. The author also values clear module design, basic resilience patterns, and thorough documentation. Despite their simplicity, the software they develop meets user and business needs effectively, proving that embracing one's limitations can lead to success.\n\nIf you don't like the summary, just downvote and I'll try to delete the comment eventually üëç\n\n[^(Click here for more info, I read all comments)](https://www.reddit.com/user/fagnerbrack/comments/195jgst/faq_are_you_a_bot/)\n\nReal talk this reads nothing like ‚ÄòI‚Äôm stupid‚Äô and everything like ‚ÄòI‚Äôm allergic to complexity‚Äô. Unfortunately modern software engineering is all about making everything as complicated as possible to fit some ‚Äòoptimal‚Äô abstraction.\n\n&gt; Unfortunately modern software engineering is all about making everything as complicated as possible to fit some ‚Äòoptimal‚Äô abstraction.\n\nA lot of the time it's just a dickwaving competition\n\nPremature abstraction is the root of all evil!!!\n\nWorking with smart developers is a nightmare. I thought I was somewhat smart until a really smart and senior developer told me I'm an idiot. From the top of his lungs.\n\nThe smart or \"clever\" developer will write clever code. And when it gets hard for the average developer to understand, read, refactor, maintain, then the clever developer throws a fit and tells everyone how stupid they are. Then they usually do the thing themselves all by their lonesome, because that is faster.\n\nHaving smart developers who write clever code is expensive. The smart ones cost more to begin with, and you need more smart ones to follow the other smart ones you already have. The pool of smart developers is tiny, for obvious reasons, which just makes them even more expensive. They are also detrimental to morale, productivity, and collaboration.\n\nI found that the average developer is the best, and the smart developer is the worst. I even prefer a dumb developer to the smart one.\n\nUnless it is a really smart one who code as if they are average, and show me how to do things if I don't get it. I love those. Throw money at those.\n\nDoesn‚Äôt sound like the problem is smart or dumb, sounds like people need to be humble and accept feedback.\n\nYes, I think that might be my point, clumsily made, and stupidly written :(\n\nA smart developer writes code that's clear to someone with enough knowledge. If they are writing \"clever\" code that's hard to read and hard to maintain they aren't smart\n\nIf the code is smart but unmaintainable then it‚Äôs not smart at all. There‚Äôs really a very very limited set of jobs where you need to create ultra performant coding masterpieces. In all other applications maintainability and feature development time are much much more valuable. Worst case you just throw money at the problem more often than not it‚Äôs cheaper than some dev‚Äôs time spent optimizing ü§∑‚Äç‚ôÇÔ∏è\n\n&gt;I hate microservices and modern frontends because there are so many moving parts, I can't keep track of them all  \n  \nThis guy might be on to something\n\nCan you please replace my coworkers\n\nSometimes I feel like developers want to follow any principle - whether it's SOLID or something else - except for one: KISS. And then you get \"clear code\" (according to some made-up rules) that is actually complicated\n\nI‚Äôm super dumb. I still code in Perl and see no reason to change. It does what I need it to do.\n\nFinally, true stupidity!  I commend you, sir.\n\nSerious question, are you older than 45?\n\nReverse that number.\n\nSo, you're 211.  Got it!\n\n&gt;!Decimal: 45!&lt;\n\n&gt;!Binary: 0010 1101!&lt;\n\n&gt;!Complement: 1101 0011!&lt;\n\n&gt;!Decimal: 211!&lt;\n\n40 years professional experience, never only coding but still. I am even more stupid but some of my code runs 19 years now.\n\n&gt;but some of my code runs 19 years now\n\nBecause it's to complex that nobody dares to touch it ?\n\nJust kidding ;)  \nI have some running for 13 years and it's still going strong.\n\nAfter 8 years or so in Python, man I feel this. \n\nI'm so sad to see Python quickly going the way of JavaScript in terms of complexity and dependencies.\n\nThis is just a humble flex, I feel being taken advantage of- the culture of us, stupid people is not your LinkedIn feel good story.\n\nCan someone explain to me what he means by \"I always choose composition over inheritance or mixins\"? Ya, I'm stupid...\n\nIf you‚Äôre making something that is similar, but a bit different, to something else, you basically have three choices:\n- Rewrite; rewrite it from scratch or copy it\n- Inheritance; write code that inherits from the original code (e.g. make a subclass)\n- Composition; write code that uses/wraps the original code\n\nI know I'm late, but I don't much like any of the explanations. They're a bit too focused on the philosophy rather than explaining what the difference is. Also, none actually address mixins.\n\nBy inheritance, the author likely means class subtyping, as opposed to interface subtyping. Composition is where you nest classes that you would use as parent classes and delegate calls to them by using a common parent interface. I'll use Java-ish code and a \"file system\" to illustrate. First you have your interface:\n\n    interface FileSystem {\n        String readFile(String fileName)\n        void writeFile(String fileName, String contents)\n    }\n\nSay you need to support Windows, and Linux. Windows has 7 and 10 which share some behavior. Linux has Ubuntu and Arch. I'm going to focus on Windows since Linux would be pretty much identical. In inheritance:\n\n    abstract class WindowsFS implements FileSystem { \n        String readFile(String fileName) { \n            // shared logic \n        } \n        void writeFile(String fileName, String contents) { \n            // shared logic \n        } \n    }\n    \n    public class Windows7FS extends WindowsFS {\n        String readFile(String fileName) {\n            // custom logic\n            return super.readFile(fileName)\n        }\n    }\n    \n    class Windows10FS extends WindowsFS {\n        String writeFile(String fileName, String contents) {\n            // custom logic\n            super.writeFile(fileName, contents)\n        }\n    }\n\nEach subclass only overrides the method it needs to customize. This reduces duplicated code and lets you transparently inherit extensions to the parent class. The two problems are this can be overdone so you end up with complex inheritance structures and don't know which class in the inheritance call chain is actually handling the behavior, and sometimes you don't want to transparently inherit extensions.\n\nIn composition:\n\n    class WindowsFS implements FileSystem {\n        String readFile(String fileName) {\n            // shared logic\n        }\n    \n        void writeFile(String fileName, String contents) {\n            // shared logic\n        }\n    }\n    \n    class Windows7FS implements FileSystem {\n        private const windowsFS = new WindowsFS();\n    \n        String readFile(String fileName) {\n            // custom logic\n            return windowsFS.readFile(fileName);\n        }\n    \n        void writeFile(String fileName, String contents) {\n            windowsFS.writeFile(fileName, contents);\n        }\n    }\n    \n    class Windows10FS extends WindowsFS {\n        private const windowsFS = new WindowsFS()\n    \n        String readFile(String fileName) {\n             return windowsFS.readFile(fileName)\n        }\n    \n        void writeFile(String fileName, String contents) {\n            // custom logic\n            windowsFS.writeFile(fileName, contents)\n        }\n    }\n\nThere's more code. But the advantages are that there's a visible chain of delegation, not as much risk of ending up with complex inheritance hierarchies, and if someone modifies `WindowsFS`, it's not automatically exposed.\n\nNow mixins. Java doesn't have them, so this is more made up. I'm also basing this on Ruby, which I'm not an expert in, so some of this may be a bit off, and languages may differ. Generally speaking, mixins are a way of simulating multiple inheritance. Keeping with the FS example, say you also have an `OpenBSDFS` class. Turns out both Ubutu and OpenBSD need a `boolean probe(String fileName)` that happens to be identical behavior. You'd like to reuse that behavior in Ubutu, but OpenBSD isn't Linux and vice versa so it doesn't make sense to inherit either way, so you use mixins. First pass:\n\nclass UbuntuFS extends LinuxFS { mixin OpenBSDFS\n\n        String readFile(String fileName) {\n            var contents = super.readFile(String fileName)\n            // custom logic\n            return contents\n        }\n    }\n\nThe problem is mixins take priority. So you end up with `OpenBSDFS`'s `writeFile` behvioar. A second pass:\n\n    class UbuntuFS implements FileSystem {\n        mixin LinuxFS\n        mixin OpenBSDFS\n    \n        String readFile(String fileName) {\n            var contents = mixin.readFile(String fileName)\n            // custom logic\n            return contents\n        }\n    }\n\nTurns out the last declared mixin takes priority, so you still have the same issue. Even worse, you're actually using `OpenBSDFS`'s `readFile` behavior too. Finally, a working one:\n\n    class UbuntuFS implements FileSystem {\n        mixin OpenBSDFS\n        mixin LinuxFS\n        \n        String readFile(String fileName) {\n            var contents = mixin.readFile(String fileName)\n            // custom logic\n            return contents\n        }\n    }\n\nYou still have the same issues as with inheritance. There's not a visible delegation hierarchy, and if someone implements `probe` on `LinuxFS`, your code breaks.\n\nIn composition:\n\n    class UbuntuFS implements FileSystem {\n        private const openBSDFS = new OpenBSDFS()\n        private const linuxFS = new LinuxFS()\n        \n        String readFile(String fileName) {\n            var contents = linuxFS.readFile(String fileName)\n            // custom logic\n            return contents\n        }\n    \n        void writeFile(String fileName, String contents) {\n            linuxFS.writeFile(fileName, contents)\n        }\n    \n        public boolean probeFile(String fileName) {\n            return openBSDFS.probeFile(fileName)\n        }\n    }\n\nMore code, but there's a visible delegation path and you don't have to worry about `probe` being added to `LinuxFS`.\n\nThe part other people have mentioned about \"is a\" and \"has a\" is about when each is appropriate. I also suspect that's not necessarily what the original author of the blog post had in mind as there's been a strong swing against class inheritance to the point where some languages like [Go intentionally don't support it](https://go.dev/doc/faq#inheritance).\n\nAnyway, I'm getting sidetracked. In the case of the \"is a\" and \"has a\" advice, Windows 7 and 10 are Windows file systems, and same for Ubuntu, Arch, and Linux, so the advice would suggest inheritance. By contrast, `UbuntuFS` might have a list of existing files to make sure you can only read files that exist; in this case, the advice would suggest using composition. Mixins actually don't factor into this advice because they're not super common, but they'd probably fall into a gray area between \"is a\" and \"has a.\"\n\nThat was longer than intended, but sunk cost and whatnot. If you have any questions, feel free to ask.\n\n\"Welcome to the party, pal!\"\n\nNo matter how smart you think you are, there's always going to be someone around that's smarter.\n\nThis stuff might not come easily to you, and *that's OK.* Do what you can with what you have.  You don't have to be the smartest guy in the room to succeed.\n\nI want to take coffee breaks with Grug\n\nI feel like I could have written this.\n\nI like it a lot but I prefer languages that have type and variable name in the correct order so I avoid Go, Scala, etc. That's a preference, it's easier on my brain.\n\nI tend to mostly only use inheritance in one place these days. In tests, I create a TestBase which houses common methods that all or most of my tests use to avoid repeating them in each test class (DRY).\n\nI don't use nginx, not for any logical or technological reason, merely because it was made by Russians (or at least one Russian) so I use Apache. It's not sleek or sexy, it's a work horse.\n\nI've never used GraphQL so I can't say I wouldn't ever use it though I do know REST/JSON work so well it's difficult to say whether I'd ever warm up to GraphQL, perhaps.\n\nI do like microservices and queues. They are more complex but by distributing logic and work using them, it makes it ~~easier~~ more tenable, to update/upgrade code over a long time with engineers (like me) who job hop a lot, for what we at least think are principled reasons.\n\nOverall good blog post, simple is almost always better.\n\nI have never felt so *seen*.\n\nA tool exists because there is a use case, which you might or might not have. As always, you shouldn't default to overcomplicating things, but don't reinvent the wheel either\n\nAre you saying I should not put each letter of Hello, world! into its own microservice and run it in a distributed system so that my users can enjoy the fastest response there is?\n\n&gt; Hello, wnullrld!\n\nThis is actually one very nice and refreshing article. Unique of a kind. And straight to the point. And what else is notable here ? The fact that person who wrote the article, actually really wrote a lots of manuals, docs and howTo's, as it is stated. In the short story.\n\nOk.\n\nYeah we know. We all are.\n\nGet to the back of the line.\n\n(This isn't facetious/sarcasm right? Or am I the dumb one?)\n\nI have doubts that they're actually stupid. Or they really didn't seem to give any sufficient evidence for it.\n\nJust seems to be low self confidence, imposter syndrome, or even humble, and probably a KISS advocate.\n\nProgramming is inherently an intellectual action that is probably only viable for like the top 20% of people or something. At best he's only dumb for a programmer of that much experience in that field or something (which is very specific).\n\nThe simplicity in the tech stack approach is refreshing. It reminds us that not every project needs to scale like Google's to be successful.\n\nWhen you need a solution KISS - Keep It Simple Stupid.  A convoluted method to do these things aren't always faster because of the complexities in creating it while Go, R or Python may be easier to get it done.\n\nI wish we had more dumb people like you at our company\n\n&gt; I apply basic resilience patterns like timeouts, circuit breakers, and backpressure\n\n\nHow is backpressure handled in this context?\n\n&gt; It won't impress a Google engineer, that's for sure. \n\nYou'd be surprised, what is described here is basically Google's approach to software too - why do you think they all use Go? Because the code needs to be picked up and worked on by many different people who don't have time to understand it super deeply, mostly contractors.\n\nMe too\n\nI'm computer smart but everything else stupid"
  },
  {
    "title": "Microsoft has open sourced its new cross-platform virtual machine layer written in Rust",
    "body": "",
    "score": 1158,
    "url": "",
    "created_utc": 1729148154.0,
    "author": "mareek",
    "permalink": "/r/programming/comments/1g5kxl2/microsoft_has_open_sourced_its_new_crossplatform/",
    "all_comment_text": "This is very cool, and a valuable learning opportunity as well (reading its code and how they do some complex stuff) even if you don't plan to use this package!\n\nedit: This [`unsafe` code policy](https://openvmm.dev/dev_guide/contrib/code.html#unsafe-code-policy) is a great demonstration of how useful it is having such code contained to explicitly defined areas that are readily searchable and thus identifiable for putting additional scrutiny to that code. In particular, this part:\n&gt;Editing a file containing unsafe code will trigger CI to automatically add the OpenVMM Unsafe Approvers group to your PR. This is to ensure that all unsafe code is audited for correctness by area experts.\n\nQ: I scanned the repository but couldn't find this easily -- do we know where the rules that CI enforces are encoded?\n\n.github/scripts/add_unsafe_reviewers/add-unsafe-reviewers.py\n\nI think that's a different part, where they add the reviewers. I was talking about [this check](https://openvmm.dev/dev_guide/contrib/code.html#unsafe-code-policy):\n\n&gt; These requirements are enforced by CI, and will cause the build to fail if required documentation is missing.\n\nI think your link enforces this check:\n\n&gt; Editing a file containing unsafe code will trigger CI to automatically add the OpenVMM Unsafe Approvers group to your PR. This is to ensure that all unsafe code is audited for correctness by area experts.\n\n`SAFETY` comments are enforced via clippy/lints.\n\nhttps://github.com/microsoft/openvmm/blob/e3b4401a48014716eb18cdd2b773f740128faca0/openhcl/hcl/src/lib.rs#L7-L9\n\n‚ÄúIt looks like you‚Äôre trying to write some unsafe code‚Äù\n\n[deleted]\n\nGot it, and thank you for the clarification. So it's not that CI is doing something special to check this specifically (which explains why I couldn't find anything), it's just that clippy will fail.\n\nAs the comment above said the SAFETY comments are enforced by clippy. However the UNSAFETY comments are a custom lint living in https://github.com/microsoft/openvmm/blob/32d2c07cdbdadbe3c1c6aea452aa5f3c4d7ec305/xtask/src/tasks/fmt/house_rules/unsafe_code_comment.rs\n\nNo, sorry! I had trouble finding it in a quick look, too, too unfamiliar with the layout. The workflows seems to be controlled by the `flowey` module, but as to the actual CI config (presumably, parameters for calling into flowey), I couldn't find it.\n\nIs it possible that it's not in the repo, because it contains API keys also? Just a thought. I'm not sure how GitHub works when it comes to CI, having never used it there.\n\nIt's actually the other way around - `flowey` is a Rust framework for writing workflows that can run locally, as well as be \"compiled\" to YAML.\n\nThe source for our primary PR and CI pipelines are in https://github.com/microsoft/openvmm/blob/main/flowey/flowey_hvlite/src/pipelines/checkin_gates.rs\n\nThat‚Äôs even cooler than I thought then üëç nice\n\n[deleted]\n\nI agree, that is indeed much more likely. I mentioned it only for completeness, really.\n\n[deleted]\n\nAh, nice, yes that is an extensive workflow script indeed...\n\nAnyway, I think I found the unsafe code review bit: https://github.com/microsoft/openvmm/blob/main/.github/workflows/unsafe-reviewers.yml\n\nIt calls https://github.com/microsoft/openvmm/blob/main/.github/scripts/add_unsafe_reviewers/add-unsafe-reviewers.py for the actual keywork check\n\n&gt; This is to ensure that all unsafe code is audited for correctness by area experts.\n\nwell that's one way to get compliance from your developers. I approve, this way they know damn well to avoid anything unsafe unless they really *really* know what they're doing\n\nI‚Äôd stamp everything\n\nedge abundant safe silky familiar fine screw domineering nutty market\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*\n\nIt is because it is C APIs that cannot verify automatically that you use them correctly. It is possible to write a safe wrapper around them, for example, std library of Rust is a such wrapper for many APIs.\n\nHey all, one of the devs here! We didn't expect this to hit reddit so quickly haha, but we'll be paying attention and answering your questions. We're very excited to finally be able to share this with the world.\n\nI think context is needed for people who aren't well versed in the Rust ecosystem.\n\nhttps://techcommunity.microsoft.com/t5/windows-os-platform-blog/openhcl-the-new-open-source-paravisor/ba-p/4273172 just got published!\n\nYou're killing it, smalis!\n\nI'm curious, is it at all connected with the recent news I saw about MS sending code to Linux to make it work as Dom0 on Hyper-V? Or are these separate projects?\n\nCare to comment on how this differs from Amazon‚Äôs [Firecracker](https://firecracker-microvm.github.io/), in particular with regard to performance and security?\n\nGoing to just copy /u/gigastarks's comment here:\n\nPerhaps the most important thing, compared to other Rust-based VMMs, is that OpenVMM has a unique threading model, more suitable to running in a paravisor environment. In a paravisor, you really want to make sure that if you're doing work on behalf of guest virtual CPU #3, you're doing it _on CPU #3_, and not jumping around to other cores in the meantime. Otherwise, you end up stalling work on other CPUs, leading to all kinds of performance problems in the guest.\n\nWe achieve this by using Rust's `async` throughout the codebase. Combined with a per-CPU executor (built on io-uring), we get cheap, fine grained control over where tasks run. So far, other Rust-based VMMs have used a more traditional threading model, without `async`.\n\nWe hope to write up a blog entry on this in the coming weeks.\n\nGreat work! Do you think it will eventually replace/extend Hyper-V, or is it designed primarily with cloud support in mind?\n\nWe have no plans to replace or deprecate Hyper-V\n\nAny context about the usage scenarios? Read the documentation but still at a loss why someone would want a mid-layer-VM like OpenHCL. Is it more like Xen or more like libvirt? Why not just do all the tasks on host instead?\n\nWell,  there are the associated changes to split guests into further fine-grained multiple privilege levels (these show up as vCPU facilties, though there's no physical processor with VTLs)\n\nMicrosoft are calling them VTL0,VTL1, VTL2... with higher numbers not lower ones meaning higher privilege, arguably unconventionally but it's probably mostly just a quirk of our timeline that we tend to consider lower numbers higher privilege.  I'm not sure the intent is for VTL2 to be precisely analogous to a real device \"ring -2\" in x86-64 terms or anything, mind (ring -2? classic ring 0 stopped being the highest (lowest-numbered) privilege of today's [pre-pwned x86-64](https://en.wikipedia.org/wiki/Protection_ring#Miscellaneous) quite some time ago, with ring -1 being  hw virt, ring -2 smm mode and ring -3 mr. creepy ime/psp \\)\n\nNotably e.g. OpenHCL can run in the more privileged guest layer VTL1/VTL2 to e.g. act as a \"vTPM\"  for the final guest in VTL0.  that vTPM can also be *different* for each final guest.   I would strongly suspect this is really like 90% about the TPMs for them  :-/,  though they also talk about securing now-familiar sr-iov type device passthrus a bit better (and again different for each guest).   \n\ni.e. So they can offer signed cloud execution environments - though that's not really secure (and very different to holy-grail surprisingly-possible-but-currently-inefficient [fully-homomorphic encrypted](https://en.wikipedia.org/wiki/Homomorphic_encryption#Fully_homomorphic_encryption) secure remote computing) - after all the cloud host can clearly still break the security, more a box-ticking exercise for people who mistake bureaucratic compliance with security policy for security.\n\n\"attestation\" in the diagram. TCtastic.\n\n* https://openvmm.dev/user_guide/openhcl.html\n* https://openvmm.dev/reference/architecture/_images/openhcl.png\n* https://techcommunity.microsoft.com/t5/windows-os-platform-blog/openhcl-evolving-azure-s-virtualization-model/ba-p/4248345\n* https://thenewstack.io/microsoft-open-sources-openhcl-a-linux-based-paravisor/\n\nNote microsoft also intends api enabling these virtual privileged guest to be added to official Linux kernel KVM, see \"Heki\" (though actually the kvm devs may go with later very recent amazon work in same area mentioned [other comment](/r/programming/comments/1g5kxl2/microsoft_has_open_sourced_its_new_crossplatform/lsdvett/)? I dunno)\n\n* https://github.com/heki-linux\n* https://lore.kernel.org/all/20240503131910.307630-2-mic@digikod.net/\n\nI feel like there may be some conceptual overlap with just doing some full nested virtualization, but that's probably higher-overheads.  https://docs.fedoraproject.org/en-US/quick-docs/using-nested-virtualization-in-kvm/\n\nNote I'm also not saying this is intrinsically bad. Main problem with TPM is just when we the nominal owners don't have root signing keys and the Corpies do. So they own \"our\" devices and we don't.\n\nThanks for the explanations. So... it's kind of a mix between Xen and QEMU? Putting the larger-attack-surface device emulation inside the \"paravisor\" to reduce attack surface?\n\nBut doesn't having a Windows host defeat the point? After all, the device emulation are written in Rust and likely both smaller and more secure than the Windows host and Hyper-V stuff. And won't the guest slow down everything enough and render any host-OpenHCL level acceleration pointless?\n\nLooks more like box-ticking than something actually useful. The Rust device emulation could have made much more difference if put in QEMU instead.\n\n&gt; But doesn't having a Windows host defeat the point?\n\nIt's actively not windows host specific *in principle* I think - though required linux host side changes appear to be still at some PoC / \"RFC v3\" level, don't appear to be upstreamed yet - details clearly still being workshopped including very basic decisions/debates such as whether kvm would provide an api modelled directly on hyper-v's [vsm/vtls](https://learn.microsoft.com/en-us/virtualization/hyper-v-on-windows/tlfs/vsm#virtual-trust-level-vtl) or something more divergent but still allowing building something functionally equivalent, as of May 2024 - https://lore.kernel.org/linux-hardening/20240514.OoPohLaejai6@digikod.net/\n\nIt doesn't *look* like a lip-service thing where they'd accidentally never finish the linux kvm physical host changes, leaving only windows hyper-v physical hosts possible.\n\nAlso relevant- Amazon apparently also working on adding hyper-v-like vsm/vtl support to qemu+kvm https://kvm-forum.qemu.org/2024/KVM_Forum_2024_-_VBSVSM_WSXE3pb.pdf  anyway, presumably for approximately the same cloudy reasons.  Probably some consensus on any required changes to linux kvm host side will emerge.  https://lore.kernel.org/kvm/D47UPV0JIIMY.35CRZ8ZNZCGA1@amazon.com/  - getting into Sep 2024 with that.... [Oct 2024](https://lore.kernel.org/kvm/20241004140810.34231-1-nikwip@amazon.de/) apparently now enough to boot windows server 2019 *with* its vsm usage under outer qemu+kvm...  Anyway, point is appears to be Coming.\n\n&gt; And won't the guest slow down everything enough and render any host-OpenHCL level acceleration pointless?\n\nNote OpenHCL is running in the guest VTL2 layer not the host.  Perhaps some overhead but not total, assuming sr-iov passthru to the vtl2, and sufficiently efficient paravirt upcalls from vtl0 to vtl2.\n\nNote diagram https://openvmm.dev/reference/architecture/_images/openhcl.png  - note the diagram's \"hypervisor and hardware\" could be *either* a linux kvm host or windows hyper-v host AFAICS, and not to be confused with the other openhcl+linux-kernel in vtl2 of the guest.  Then could then be another guest linux again or a guest windows in vtl0 of the guest.\n\nAt present I do still feel like [full nested vms](https://www.linux-kvm.org/page/Nested_Guests) are a conceptually cleaner model than these partitioned guests, though have their own problems of course...    \n\nAnd not that it's rare for some conceptual clarity / clean abstraction to be sacrificed at the altar of real-world efficiency.\n\nMicrosoft seems to be going towards Linux as dom0 on Hyper-V, at least according to a headline I saw on Phoronix.  They did send enablement patches to the mailing list.\n\nhttps://techcommunity.microsoft.com/t5/windows-os-platform-blog/openhcl-the-new-open-source-paravisor/ba-p/4273172 just got posted!\n\nI love these kind of projects, well done to the teams who worked on this!\n\nA personal congratulations to the amazing individuals who made this happen. It really is an incredible feat of engineering and you all should be proud.\n\nThat said it is too little, too late to keep me in Microsoft ecosystem after Window 10 EOL, but I‚Äôll cheers its developers for building cool things all day long.\n\n[deleted]\n\nThis is incorrect. OpenVMM builds natively on both Windows and Linux (WSL2 is entirely optional).\n\nThat said, OpenHCL (AKA, the more specialized paravisor configuration) does indeed require Linux to build at the moment.\n\nAhhh, I must have mixed them up when reading. Admittedly that was at like 2am haha\n\nIt's supposed to be cross platform and has an MIT license. I'm always torn on such projects. It does come from Microsoft, but on the other hand that doesn't make it automatically evil, might be worth a chance\n\nIn most cases the MIT license would convince me but it feels moot when immense financial pressure, underlying platform ownership, and business connections are available to influence regardless.\n\nI trust by example and when Recall was raised as an ‚Äúin-demand feature‚Äù, it was moderately concerning (beyond adverts in OS, telemetry, etc). The way they handled the backlash of it felt more confirmation of ill-intention speculation than clarification or qualified substantiation in my opinion.\n\nThe important part is to be open source, imo. We've seen open source projects and libraries insert ads, viruses, Russian spyware, all sorts of things. When it comes down to it, open source devs aren't any more trustworthy than corporate devs. What you're relying on, in either case, is the ability to identify any malicious/abusive changes as they are created, and the potential for someone to fork the project should it happen.\n\nMIT licenses protect software developers not consumers.  You can close source an MIT project whenever you want for any future development.  I'm not going to touch any *platform* isn't at least GPLv2.  Honestly we won't touch any library for an *application* that is GPL at work for the same reason (unless we want to open source it), because management wants that leverage that MIT gives you.\n\nEven with GPL companies like RedHat like to try shenanigans, but they are restricted in how far they can go.  They'll try to get you on the vendor lock-in, then slam the door shut if they can make money off it.\n\nWith a permissive licence like MIT though, isn't there always the option to fork it to GPLv2 yourself if you so wish?\n\nAs I understand it yes you can change licenses to a more restrictive one generally, although only for the changes you make going forward of course.  That's what happened to Bash on OSX they changed from GPLv2 to GPLv3 and so Apple kept using the old version for ages before switching to Zsh.\n\nIf you compile against anything that's GPL though you are bound by the GPL license, so once you have GPL in your code base and you're compiling against it the whole thing is GPL.  So it's really hard to go backwards because you end up using a lot of tools that are GPL.\n\nActually you can close-source a GPL codebase going forward (although only for the new bits, exactly like with the MIT licence) with the agreement of all contributors. This is much easier with a Contributor Licencing Agreement (which many GPL projects do have) or if you're a company that has corporate ownership of your whole codebase even though you have multiple devs\n\nRight, with the agreement of all the contributors via CLA or otherwise.  I suppose it would depend on the project, but if you get sucked into the GPL ecosystem it could be difficult to extricate yourself without a large re-write (i've been part of a fairly major rewrite *just* to get rid of BASH due to GPLv3).  If the GPL code is all internal, sure it might not be too hard... good luck getting projects written by open source community or even other companies to agree to that though.  \n\nThere's no perfect solution, but your protections with GPL are a lot stronger.\n\n[deleted]\n\ndotnet folk seem to be reasonably open\n\nIdk man every PR I've opened they've taken in or discussed and then closed.\n\nIt just takes them time since most employees balance multiple projects and duties\n\nAre you meaning \"public contributions\" to mean bug fixing? Or are you meaning adding features?\n\nBecause I mean.. simply being OSS is pretty huge. The community doesn't get to dictate the direction they go - that would be ridiculous, surely.\n\nAnd adding features, from public contributions, would add a substantial layer of responsibility on their part that's non-trivial - which would inherently explain why it's rare.\n\nOut-right bugs or security fixes, on the other hand...\n\nsource-available has a definition my dude, and something licenced under MIT does not meet it\n\nAll open source should be somewhat source available.¬†\n\nNot all source available is open source.\n\nThe main difference being licensing the usage. If a corporation cannot exploit your work for free, you are not open source.¬†\n\n&gt;Source-available software¬†is¬†software¬†released through a¬†source code¬†distribution model that includes arrangements where the source can be viewed, and in some cases modified, but without necessarily meeting the criteria to be called¬†open-source.\n\nhttps://en.m.wikipedia.org/wiki/Source-available_software\n\nExactly what I wrote!\n\nThe primary cause of software losing the ‚Äúopen source‚Äù title is people licensing such that corporations have to pay their fair share.¬†\n\nThis is why there is such strong propaganda against source available vs open source. Open Source is a corporate bootlicker title. Your software does not need it.¬†\n\n[deleted]\n\nNah, being open source but with shitty business practices isn't the same as being source-available. That's the exact argument that companies use to justify closing off their open source projects (for example: ElasticSearch) by arguing that what they're doing is 'in the spirit of open source'\n\nAs if you're the one in charge of tooling at your workplace lol, thanks for the daily cringe\n\nI'm a bit confused about the concept of a \"virtual machine monitor\" - If I'm understanding right, all this does is manage virtual machines? But are those guest operating systems being emulated with OpenVMM, or are they being emulated with something else like QEMU?\n\nIs this just a VM? Are there languages that generate code for it? Why use this instead of. Net?\n\nThis is a VMM, a virtual machine _monitor_. A VMM essentially allows you to run VMs on a host. A comparable existing VMM is QEMU or hyper-v.\n\nThis has nothing to do with languages that run in a VM like .Net or Java.\n\nI missed that extra letter, thanks for the clarification!\n\n[deleted]\n\nI think the main difference between a hypervisor and this paravisor are the innate execution privilege levels. Hypervisors are ultimately root-like processes, while this paravisor runs on top of an OS (which is not necessarily Windows). I don't know much about this area, but it seems like the idea in general is better safety, portability, and various other cloud infrastructure-related benefits.\n\nRead https://openvmm.dev/user_guide/openvmm.html if you're curious\n\n&gt; Why use this instead of. Net?\n\nHow *dare* you! \n\nThat's our lord and savior Rust you're questioning\n\nI don't have a problem with Rust, it's my main language. \n\nI don't care about the language this VM is written in, none of my questions were related to that. \n\nI'm just asking clarifications on the purpose of this VM because the README says nothing.\n\nYou may have missed that the github links the website https://openvmm.dev/ which seems go go into a lot more detail.\n\nSorry, was a sarcastic comment because you were getting downvoted like crazy - I'm also not sure\n\nrust haters are weird man\n\nBut, I uh... I don't hate Rust\n\nI'll wear the downvotes with pride for daring to make a joke at Rust's expense\n\nI think the problem is plenty say this totally unironically. So your joke is indistinguishable from your average garden-variety deranged hater :p\n\nTwo words: garbage collector.\n\nSo what is the future of Hyper-V?\n\nMicrosoft needs to be split up.  It's a monopoly.\n\nWhat do you think it has a monopoly in?\n\nOriginal Monopoly is very East Coast. We need a West Coast Monopoly with properties such as Bellevue, Mission District and Compton.\n\n# Microsoft Desktop OS Dominance\n\n**Market Dominance**: According to various sources, including court findings and expert opinions, Microsoft has maintained a significant market share dominance in the desktop operating system market for an extended period. The search results indicate that Microsoft‚Äôs Windows operating system has held over 90% market share for over a decade, with some periods reaching above 95%.\n\n**Monopoly Power**: The search results also suggest that Microsoft has been accused of exercising monopoly power in the market. The U.S. government, in the 1998 antitrust case, declared that Microsoft possessed monopoly power in the market for personal computer operating systems. Similarly, a 2024 court finding stated that Microsoft enjoys monopoly power in the relevant market.\n\n**Bundling and Exclusionary Practices**: Microsoft‚Äôs bundling of Internet Explorer with Windows and restrictions on OEMs and users to uninstall IE have been criticized as exclusionary practices aimed at protecting its Windows monopoly. These practices have hindered competitors‚Äô ability to gain traction in the market.\n\n**Challenges to Dominance**: Despite Microsoft‚Äôs dominance, there have been and continue to be challenges from alternative operating systems, such as Linux and macOS. However, these alternatives have not yet managed to significantly erode Microsoft‚Äôs market share.\n\n**Conclusion**: Based on the search results, it appears that Microsoft has a significant market share dominance in the desktop operating system market, and its business practices have been accused of exercising monopoly power. While there are competitors and alternatives, Microsoft‚Äôs Windows operating system remains the dominant player in the market.\n\nget thee behind me, bot\n\nBreaking up a company is really the solution of last resort. I'll be honest, you're not entirely wrong about their market dominance with Windows... but it's an increasingly irrelevant market. Where do most people spend their time? Phones. Where is the bulk of the world infrastructure built on? Linux. Even within Windows, I'd pretty much guarantee you that most people spend most of their time in a web browser... and not Microsoft's browser at that. \n\nTo me, you're suggesting that we should break up the red shoe company because they make 90% of the world's red shoes. Sure... it's a dominant market share.... but who really cares about red shoes?\n\n[deleted]\n\nThe import commit says it‚Äôs 5 years worth of work from ~120 contributors inside Microsoft.\n\nThe public website indicates that it used in production systems as part of Azure\n\nOut of curiosity, what did the person above wrote ? Did they say it was something akin to a pet project?\n\nThey were complaining that this project appeared to be \"pre-alpha\" and so was not worthy of being announced this early.\n\nDefinitely better than keeping it closed source. I am just wondering whether people really interact much with Microsoft-derived software; to me it seems all geared towards e. g. Windows. I'd much prefer to remain fully committed within, say, the Linux ecosystem instead.\n\nCool way to keep code safe More projects should try this Thoughts\n\n[deleted]\n\nIt's not a VM.\n\nThey already have a Java-competitive VM ‚Äî it's called CLR. This is for managing VMs that virtualize hardware.\n\nAs others have pointed out it's basically a rust based alternative to virtual box or QEMU.\n\nBut I just wanted to point out that Microsoft maintains their own build of OpenJDK.\n\nIn fact there are multiple companies that maintain OpenJDK builds outside of Oracle, if you really need Java.\n\nEEE\n\nOMG rust!!! fapfapfapfap \\*pewpewpew\\* \\*face shot\\*\n\nThis project is the exact sort of thing Rust is *actually* good for\n\nwhy do you think my pleasure over this news means i don't like this or something? WEIRD TAKE\n\nSo Microsoft releasing their own (free and open source) alternative to Virtual Box or QEMU deserves a meme response because of the language it's written in?\n\nhow is my pleasure in this project a meme response? i love rust"
  },
  {
    "title": "Dev rejects CVE severity, makes his GitHub repo read-only",
    "body": "",
    "score": 1155,
    "url": "",
    "created_utc": 1719764885.0,
    "author": "lelanthran",
    "permalink": "/r/programming/comments/1ds5csl/dev_rejects_cve_severity_makes_his_github_repo/",
    "all_comment_text": "Time for CVEs on CVEs\n\nI'm not well-up on CVSS, but could we spin \"it is possible to submit bogus CVEs and harass developers until they close the issue tracker/take the project down\" as a denial of service attack?\n\nPer [a NIST calculator](https://nvd.nist.gov/vuln-metrics/cvss/v3-calculator), the current state of the CVE process has a vulnerability with a **9.3 - Severe** score.\n\n---\n\n**Attack Vector: Network**\n\nThe attack can be trivially performed over HTTP or SMTP.\n\n**Attack Complexity: Low**\n\nAnyone who can write a coherent sentence is able to submit a CVE.\n\n**Privileges Required: None**\n\nIt is possible to submit a CVE anonymously. \n\n**User Interaction: None**\n\nOnce the bogus CVE is submitted, the CVE may be published with no input from the target required.\n\n**Scope: Changed**\n\nA bogus CVE can cause damage to systems that are not owned by the target, [as demonstrated in the case of cURL](https://daniel.haxx.se/blog/2023/04/24/deleting-system32curl-exe/), though this extended attack may require user interaction.\n\n**Confidentiality Impact: None**\n\nHandling a CVE, bogus or otherwise, does not require disclosure of confidential information. Confidential information may be disclosed to disprove the alleged vulnerability, but the CVE by itself does not cause the release of confidential information.\n\n**Integrity Impact: Low**\n\nThe attacker can cause the creation of unwanted data and modification of affected projects:\n\n* A successfully-submitted bogus CVE will pollute the CVE list. No other CVEs will be affected.\n\n* A bogus CVE may a targeted library or application to be modified to appease the attacker and/or other parties. The target may also create documentation refuting or disputing the CVE. The attacker has limited control over the content of such changes or documentation.\n\n**Availability Impact: High**\n\nIn all cases, the target must spend resources dealing with the reputational damage from the bogus CVE.\n\n[It has been demonstrated](https://old.reddit.com/r/programming/comments/1ds5csl/dev_rejects_cve_severity_makes_his_github_repo/) that a target can be so burdened by handling a bogus CVE that they remove the ability to submit tickets for all issues.\n\nIt is not inconceivable that a coordinated attack of sufficient size could cause support for or continued development of a target to be stopped altogether.\n\nGiven that taking over a trusted OSS repo from a burned out maintainer is a great way of setting up a supply chain attack then in all seriousness this should be looked at as an actual security issue.\n\nSeems like a great way for an enterprising attacker to leverage a *real* undiscovered vulnerability. File bogus reports against releases that came out before the relevant vuln was introduced. If the target shuts down the project, their exploit is unlikely to be addressed for quite some time. If the target transfers ownership of the project, they can add backdoors in the same release that addresses the bogus CVEs.\n\nI mean the maintainer wrote this so ü§∑\n&gt;I'd be happy to give contributor bits and npm ownership to a person who has a track of maintaining some packages with reasonable download count. Thanks so much for raising this topic!\n\nGood point. If the Integrity Impact is increased to High (because the attacker can attempt to take over the targetted repo and make arbitrary changes) the score becomes 10. Well, it probably becomes more than 10, but the score is clamped between 0 and 10.\n\nI could see a reasonable argument that the Confidentiality Impact should be higher than None, too, but I don't want to weaken the argument by being unnecessarily hyperbolic.\n\n[deleted]\n\nThe reporter doesnt get to specify the cvss score.\n\nStill. Report bogus CVEs? Get blacklisted.\n\nThe level of severity has been bullshit for a few years now. It's like every RCE gets 9.x even if exploiting it means you have to use actual magic.\n\nThe folk reporting bugs as CVEs get to say \"I discovered six &gt;9 severity CVEs\" on their resume\n\nAnd I thought it was bad when QA people would enter feature requests as bugs.\n\nWe had to take away the \"blocker\" status in our bug report system. When 50% of the tickets coming in are \"drop everything else going on and get these customers running again,\" but our biggest clients are happily working without issues, the severity selections aren't helpful\n\nI've tried explaining to my support team that if everything is a show stopper or a blocker, then nothing is. A single customer with a particular issue, yelling at them, doesn't make something a blocker.\n\nFor the past 2-3 months, our UAT testers have been in the habit of logging minor bugs found in prod as P0 blocking defects.\n\nI'm starting to think they are just doing this because they think the issues they raise will be addressed quicker.\n\nWhat i tried (without success unfortunately), is to let the support team put their reported bugs in a list ordered by what they believe is important. It's not a status or a field, but an ordering. This way, i thought, they must put one ahead of another bug, despite saying both are \"equally important\". \n\nUnfortunately, what ended up  happening is that each new support engineer simply put _their_ current customer's bug at the top, and since turnover is high in the support team, old bugs that reappear or the customer re-complains about, gets moved back to the top. \n\nIt's basically completely useless to allow support team to prioritize bugs, regardless of the system used.\n\nYou're using one field for two ideas. A blocker just means it prevents work from being done somehow. It might be a blocker for the customer, sure, but that doesn't mean it needs to be prioritized as a blocker for the developers. In fact, it is by definition NOT a blocker for developers unless its preventing THEM from doing their work.\n\n\"Blocker\" by itself doesn't even imply high priority. If X blocks Y, but Y is a very low priority task, then we only know that X's priority is at least just above Y's. It doesn't tell us anything else.\n\nAlso, you can't call rightly something a blocker unless you can state WHAT its blocking.\n\nAnd why is your support team prioritizing things? That's the project manager's job. They're doing it wrong because they're probably not qualified to do that. Your support staff should be assisting customers and taking objective reports.\n\nOne of the insights I‚Äôve had about customers is that many are perfectly fine knowing when their pains will be fixed. \n\nOne of the better places I worked we had customers who were missing features they really wanted but they trusted that we would eventually get them. They bought into the story of us being competent but new. I‚Äôve tried to push three or four other places into this model with limited success. \n\nIt can be better to sound clueful and have self esteem than to rush features and give off a vibe of impostor syndrome.\n\nThis is why status definitions are important. I am big fan of Debian's status tags, the only release blockers are license ones.\n\nAt one place I know the severity of incidents was graded like this:\n\n- critical - the CIO must be paged immediately\n- very high - the department head must be paged immediately, and the CIO must see it listed in his daily report\n- high - the department head must see it listed in his daily report\n- medium\n- low\n\nFor some reason very few things became actually critical when these rules were implemented.\n\n‚ÄúThis is a severe ZERO DAY!!‚Äù\n\nConditions for exploit: must be running Windows 2000, Netscape, Java 21, and League of Legends\n\nIt drives me crazy how \"zero day\" became some meaningless bullshit buzzword.\nIts actual meaning is \"the public became aware of the vulnerability on the same day that the devs became aware of it\".\nThat's it.\nThere's nothing exciting or scandalous about a zero day vulnerability, especially if there's no RCE vulnerability.\n\nWhite hat: reports vulnerability to company privately\n\nCompany: does nothing\n\nWhite hat: contacts news outlet after 6 months\n\nNews outlet: ZERO DAY VULNERABILITY FOUND IN [XY]!!!\n\nThis might be my ignorance, but I've understood it to mean a vulnerability that is exploited on the same day the vulnerable code is released or deployed. But maybe that's only applicable to the DRM-cracking community.\n\nIt refers to there being 0 days to prepare a patch because it was leaked or exploited before the developers were aware of it.\n\nI always thought it was the time the Devs have to fix it before it is released.\n\n&gt;Conditions for exploit: must be running Windows 2000, Netscape, Java 21, and League of Legends \n\nOS has have been booted more than 800 days ago, contain an odd number of MBs of memory and have a desktop wallpaper in tiled bmp format.\n\nMalicious actors may gain access if they can rub their tummy clockwise while patting their head and licking their elbow all at once.\n\nAlso requires physical access to the machine!!!\n\nThis has been virtually every security issue that I‚Äôve seen raised that our team has had to address the last 3 years. ‚ÄúIf the user has compromised access to the network and has root access, they can leverage X to do ‚Ä¶‚Äù yeah of course they could congrats.\n\nSecurity people call it \"defense in depth\", and it makes me want to pull my hair out whenever they use it as an argument.\n\nWhy not, but not as an emergency.\n\nIt reminds me of the good practice of \"not using the String class for password in Java\" because a String can persist in memory even when there is not r√©f√©rence remaining references to it.\n\nYeah, yeah, if an attacker can read the raw memory of the JVM, I probably have a bigger problem than that. \n\nI'm ok to change it but it certainly doesn't require an hotfix.\n\nBecause you're assuming they are reading memory using appropriately privileged system interfaces, not taking advantage of the 13 other \"probably not a big deal\" CVEs your org decided to ignore.\n\nif you are at any point where attacker can read app's memory, you're fucked.\n\nThe severity 9 issue is reading the memory, not using String class.\n\nIt's the issue to fix eventually in next refactor, not security problem to fix now\n\nMost of them are checkbox tickers with no actual useful knowledge about making secure systems.\n\n\"We think it isn't secure. We can't describe well why or how to fix it, but change it so it passes our checklist\"\n\nWe had to implement password rotation scheme to a bunch of servers we already used hardware token  to access..\n\nSame places routinely give insane whitelist access to \"privileged individuals\" aka \"team players\" aka \"the one who ultimately blows a hole in the uuhhh hull\".\n\n&gt; It rather involved being on the other side of this airtight hatchway\n\n\nhttps://devblogs.microsoft.com/oldnewthing/20060508-22/?p=31283\n\n[deleted]\n\nWe just got bought and the new \"attack surface reduction team\" is giving us shit because we occasionally use a tool that uses Log4j v1 something. It's a local application, not a server. And Log4j v1 is not vulnerable to the Log4Shell vulnerability (granted, it has some other minor vulns)\n\n[deleted]\n\nYeah it was awful. Just a bunch of IT jabronis doing full text search for any string matching log4j without verifying JVM or library versions. We received a few reports of people who were using a 2.x version of our desktop app, we're now on 4.x (almost a decade later), and no longer use log4j.\n\nAt the place I was working, the lead IT person took the log4j vulnerability as an argument against *all open-source software*, and said we had to remove everything from all of our systems. Eventually I pointed out that one of our main proprietary closed-source development tools actually *included a vulnerable copy of log4j*, and they didn't have a fix yet. He didn't really have an answer to that.\n\nThankfully, he pursued the \"eradicate open-source software\" task with the same amount of effort that he pursued most of his duties, and we never heard another thing about it.\n\nDid you mention Windows' original TCP/IP stack was copied almost verbatim from FreeBSD?  Better stop using Windows.\n\nHah, I remember a client freaking out about it. I told them that our systems are on such old versions of Java that it really wasn't an issue\n\nwell I guess that's ok then... \n\nhold up\n\nLol, yep. They've got money for maintenance, but not for upgrades\n\nUpgrades should be in maintenance imo\n\nI got told to fix it on Log4Net. There's nothing to fix.\n\nTo be fair, that one was pretty trivial to exploit if using a vulnerable version. You could demonstrate PoC by just opening a socket with netcat and sending a JDNI string to that socket\n\nSome of my coworkers worked through the company Christmas break to fix that one. Shitty handling all around.\n\nSecurity in my company is equally as inept. \n\nThey recently raised a \"vulnerability\" that said a client demonstrated to them that if an admin left their session open, someone could come by and make a request, copy the session information from that request, and then escalate themselves to admin with those session keys. Then claimed it was a vital vulnerability that needed to be fixed. \n\nLike, if someone leaves the keys hanging on the door, that's not a problem with the lock. For all the random business lingo crap they force us to do twice a year, they seem to have no idea what a threat model actually is lol\n\nWithout knowing more about that specific issue, that actually does sound like a vulnerability, if that exploit allows permanent escalation privileges.\n\n\nIt's mitigated by using some sort of short lived credential.\n\n\nIf the credentials were already temporary then yeah I agree it's a nonsensical vulnerability.\n\nThe ticket said nothing about session lifetimes, I don't think it's anywhere on their radar. But they're old school stateful server sessions with invalidation on logout and relatively short session timeouts, I think we're good there. What concerned them was the transferability of a session. \"This session should only work on device A, this user copied it onto device B and resumed the session!!!!\" \n\nLike... yeah. A session is just a byte string that gets shoved along with the request. Security is all about establishing secure channels that protect these tokens, and proper encryption to make them non-guessable. \"Physical access copy\" is a ridiculous (and impossible) thing to try to guard against. \n\nTheir \"fix\" was to just also include a check against the user agent, as if that wasn't also spoofable lol. \n\nBut on the topic of session lifetimes, I actually *did* catch a vulnerability a coworker in a previous job tried to push out. We had our own JWT/Refresh thing going on, and we wanted user spoofing as a feature (all logging will be the actual logged in user, but all data lookups acted under a target user's permissions). Coworker tried to make a new endpoint to generate a \"spoofed user\" access token, but didn't require a stateful proof (e.g. password or refresh token) alongside that generation. In this case an attacker *would* have been able to keep any arbitrary token alive forever by generating new spoof tokens indefinitely, even if the user changed their password or invalidated their refresh tokens. Fortunately I caught it in code review, but that one would've been nasty.\n\n[deleted]\n\nYou're not measuring risk in enough dimensions.  *Just* a CVE/CSSS score is nearly meaningless without assigning a risk score that includes impact to your business.  You don't use Java in your enterprise?  All CVEs for Java instantly get set to zero: zero risk.  You need to include business impact based on their goals (avoid SOC1 risk, avoid customer-impacting events, avoid going down if us-east-1 goes kabloooie) and then take the intersection of CVEs against that. Otherwise you get caught up in blanket statements (AVOID ALL RISK) that are about as sensible as assuming if you never drive on the road you'll never get a flat tire.  Great, but we're a trucking company, boss.\n\nWhich tool are you using which provides compensating controls for CVEs detected?\n\nI agree critical CVEs might not impact your code, but it's also hard to keep track of exceptions. Someone could start using a vulnerable feature at any time, long after advisories have been processed by relevant people. Highly siloed projects (which I don't personally encourage) with dedicated security teams might also not trust developers to take such decisions and be aware of such caveats. It's often easier to just upgrade and if your code lags a lot behind you should consider formalizing some form of regular maintenance or switching to a more reliable (which is also debatable, it might just be that it gets less attention) / LTS implementation. Plausible attack vectors might also be beyond the pay grade of the security team and, while some proficiency can be argued for certain simple cases, there can be terribly difficult ones too so this approach can definitely result in ignoring important risks.\n\nI'd personally default to \"just upgrade\" and make exceptions in very limited cases.\n\nCybersecurity teams in orgs have become little more than spreadsheet chasers. It literally doesn't matter if it's a bogus critical (as has been happening) or doesn't actually apply for the conditions described. They need that 'remediated', it's pretty sad that so many of them joining the field are distant from actual software development. The more experienced ones tend to get promoted to uselessness.\n\nI mean this happens because orgs higher cheap Nessus scan runners rather than people with skills in vulnerability research.\n\nCan you imagine how the other side feels?\n\n‚ÄúWe‚Äôve given you 8 hours to pwn the app - why aren‚Äôt there any findings?‚Äù\n\nOrgs do this to themselves because they want cheap engineers to rubber stamp their security rather than actual high quality investigation of their security posture.\n\nWe need that last sentence embroidered on a pillow.\n\n&gt;At some point it got escalated to the CTO\n\nI'd have escalated to the CTO immediately. Two teams that most likely both report into your CTO. One team is decreasing productivity in engineering, I'm sure your CTO would want to know about that straight away. Ultimately they are accountable for _both_ the security _and_ the productivity of their org. At least let your CTO make the decision of where the balance should be.\n\nOurs just caved because the customers are now demanding it. Their security team doesn't care and certainly doesn't trust ours so it's become zero tolerance.\n\nI'm not even sure that severity scoring is even good to have at all.  Especially for libraries it depends on how the code that is using that library uses it how severe the problem is. It is the resposibility of anyone that uses third party code to always read all CVEs to evaluate if further action is required. Makring some issues as non severe might lead to people to not reading them when they actually can be much more secvere for their own sofware than another critical issue is.\n\nMy favorite 2 examples of this.\n\n1. A zlib vulnerability in an extension portion of the code that I'm certain almost nobody knew about.  Basically if you used that extension to open a file you could RCE.\n\n2. pip executes code when installing packages, so if you tell it to install code from an untrusted source it can do something malicious... (seriously...).  So obviously that means everything that has python installed is now at risk even if there's no path to execute pip.\n\nOh do we have fun with the first one. RedHat reduced the value because they do not compile the module, but updated the lib never the less. Debian reduced the value but did not update the library. Our security team is not happy with the Debian in one container image.\n\nYeah, Debian¬†always backports patches to the versions in the stable release which means the version numbers don't change.\n\n\nThis occasionally gives inexperienced security teams conniptions when they find a Debian image with a zillion \"insecure\" package versions.\n\nThe second one is a fairly common issue for package managers, build systems and even toolchains, as building requires some form of arbitrary code execution in many ecosystems (e.g. Makefiles, code generation and so on). Obviously the final binary could also be compromised no matter what you do, if you cannot verify authenticity in some way, or maybe the toolchain isn't hardened enough against arbitrary source code. But I still think it's worth at some level to close those other gaps.\n\nI think it needs to be split into \"severity if exploited\" and \"chance for exploiting\".\n\nAFAIK those both *are* rated separately and are the major components of the final CVE. But nobody looks past the single number.\n\nA great example are privilege escalations which require a preexisting RCE.\n\nI didn't even know there were multiple numbers. I just see these numbers thrown around and they never make sense.\n\nThat's another systemic failure. Many people, probably including many \"security experts\" just don't know what goes into a CVE or how it's assigned.\n\nAnd well... Vulnerabilities are also rarely absolute. Often they will have some conditions for exploitation that just never occur. Fuck, you probably remember log4j, that one was very difficult to exploit if you didn't log user supplied data. Or you could have disabled the niche feature which included the vulnerability by changing some configs.\n\nBut people will take a binary yes/no approach because it's easier, or because compliance or insurance requires them to.\n\nWhat? Security experts have to assign cvss scores. We do it rationally via a calculation, this is all related in the cvssV2 string.\n\nUnless you were massively bullshitting your job you would know how the system works.\n\nThe problem is that if that one feature that causes the library to be vulnerable isn‚Äôt used today the devs might use it tomorrow.\n\n&gt; Unless you were massively bullshitting your job you would know how the system works.\n\nThis could never, ever happen in business.\n\nOne of the problems with evaluating \"chance of being exploited\" is that often the risk of exploitation depends on the presence of other vulnerabilities - most security breaches take advantage of vulnerability chains, not single vulnerabilities.\n\nThis is non-trivial to estimate because exploitable vulnerabilities travel in packs. A system that has one exploitable vulnerability is likely to have many different exploitable vulnerabilities.\n\nFor example, you're unlikely to find a system that stores passwords in plaintext but has no other serious security issues, because that sort of system wouldn't store passwords in plaintext! Instead, you're likely to find plaintext password storage on the same system that allows arbitrary incoming connections to its production database, has `admin:password` as its admin credentials, and is completely devoid of any logging or monitoring to detect suspicious behavior.\n\n[EPSS score](https://www.first.org/epss/) aims to estimate likelihood of exploitation for any given CVE\n\nWhat would be more useful is simply listing the actual conditions for exploitation, instead of packing it into a number.\n\nA score of \"4.5 exploitables\" isn't really meaningful, compared to \"you must call this function on a Tuesday\" and the appropriate developers confirming this isn't their use case.\n\nThere should be a flag for \"related to a specific feature that may or may not be in use\" vs \"if you use this at all you are vulnerable\".\n\n\nLike, if Python has a security issue that requires the use of the IP address module, then the flag is set. If it's in core Python (or something widely used like io or os), then that shouldnt have it applied. Users could then more easily say this CVE isn't an issue because that feature isnt in use.\n\nIMHO that's hard to do. In a sufficiently large organization it can't be expected that every developer knows all CVEs of a library. I don't even know all the libraries I'm using because I'm so many layers away from them in our code base. So if there is a CVE in a library the repository is using it gets patched, no matter the relevance to the current code base. If it's a small project maintained by 2-3 folks that care about security, then that's another thing and might work. But somehow I doubt that this works on a grand scale.\n\nStill. I agree that more detailed information can't hurt.\n\nMITRE and NVD always score worst-case possible scenario because the US government could be running this code on public servers. It‚Äôs a joke that anyone relies on this data at all and I‚Äôm constantly fighting with security people about their bullshit scan results which just regurgitate all that noise while offering nothing to maintainers to actually improve their code‚Äôs security.¬†\n\nEveryone wants to make an impact and gain a reputation. I field public vuln reports all the time where I'm at. Every single report I've ever reviewed had a greatly exaggerated severity. \n\nI think the most worthless report I ever received was a dude who uploaded the output of an open-source scanning tool, but didn't even remotely understand the results and didn't know how to decipher it. Rated it as critical, and then asked for money.\n\nThe NVD is a joke, the punchline is that the alternative is worse.\n\nIt's the same thing with all technology.\n\nUpdate your dependencies to replace known vulnerabilities by unknown vulnerabilities.\n\nPretty sure I saw a CVE within the last few years for a RCE with a 9.x severity rating and the \"remote\" code execution required physical access to the machine.\n\nReally? Which Caves got &gt;9 and are questionable? I didn't see them\n\nThe PHP one for starters. CVE-2024-4577\n\nThat severity is an absolute joke. It was only possible for bad production setups with some Asian alphabets.\n\nThe doom and gloom on that CVE when it broke out was CS undergrad brain rot because it was \"le php lol amirite\".\n\nIn cybersecurity, one man's magic is another's daily toolbox.\n\nThere is need for some level of indication to know which problems to tackle first. It just has been mismanaged to the level of uselessness.\n\nA 9.8? There's bugs that allow for remote code execution in ring 0 without interaction from the victim and they don't even get a score that high.\n\nIt is pretty shitty that most people complaining about CVEs are coming from people working in fortune 500 companies that have vulnerabilities scans that require their employees to action on it.\n\nAll these stupid vulnerability scan tools that companies buy into are just adding more stress to open source developers without actually addressing most real issues, nor helping providing the resources to fix real issues.\n\nIt does address *some* issues. Companies like that will often just *never* update a dependency if they can avoid it. Having a scan that tells them they *must* upgrade is sometimes the only reason upgrades ever happen! Even if 90% of those vulnerabilities aren't that secure, this might be the only way they ever patch the other 10%.\n\nIMO the bigger problem is the lack of resources. Instead of just piling onto a bug tracker, what if they actually sent patches? They could contribute to the project, get credit, *and* limit the impact to their own systems.\n\nWorked at one of those companies. I feel like there's some companies where careers go to die or cash in the experience for that last role before retirement or moving on. I want to work with a team of motivated engineers. Yes we all get our burnout phases. Yet overall working with people who want to make good software and who challenge each other is what I want to do. \n\nThere have been those companies where it's like a lot of people just doing the bare minimum. It's not a problem until somehow it is. At the very least some of these alerts prompt other people to ask what's doing on. That's like hell. Living in just keep the lights on mode. Nobody wants to work cross team. Everyone exists in their silos. \n\nThe worst part is when the domain knowledge experts in those silos feel somehow challenged. Like maybe their processes can be improved. Even highlighting a suggestion. You get massive pushback because it wasn't their idea. They have been working in the system for X amount of years and feel they know better. No discussion. Just zero response. You weren't trying to challenge them or attack them. It's just maybe you have come across a similar problem at a previous job and you can provide more insight. Nope. That won't work.\n\nThat's one way this can show up...\n\nHere's another: Plenty of cross-team work, plenty of discussion, and plenty of people care... about building and launching stuff. Even if people *want* to work on maintenance or quality control, there is never any time in the schedule for tech debt, and it's no one's job to track dependencies.\n\nSo, tragedy of the commons: No one has time to work on anything that isn't directly their job. The only way this stuff ever happens is if you get lucky and have one particularly-obsessive person who's willing to sacrifice their own career progression to clean up this shit... *or* if you can convince someone that your overall lack of security here is an existential threat to the company.\n\nThe nice thing about a vulnerability-scanner is how little time and effort it takes to get it to start reporting stuff. It'll take time and effort to *investigate,* to work out which CVEs are false positives and such, but you can at least generate a report that can force the company to start moving.\n\nAgreed. And someone who's effectively and proactively managing problems and tech debt is someone who is neither releasing new features, driving new revenue, nor fixing high profile problems / helping SLT avoid looking like assholes. Which is a recipe for obscurity and getting quietly downsized next time there's a restructure.\n\nYou'd think this would be an easy concept to explain to management, though: That's a force multiplier. Letting them go, aside from murdering team morale, is also going to make all of the people you know about less effective.\n\nBut... evidently not. More than all the other layoffs lately, the one that confuses me the most is [Google letting go of their Python team](https://news.ycombinator.com/item?id=40176338).\n\nMy current side project is finding and patching vulnerable work stations for a 80 something person company. I have a giant spreadsheet to go through. I started with my workstations and hoping to find a common denominator that can be automated to reduce our vulnerability count.\n\n&gt; They could contribute to the project, get credit, and limit the impact to their own systems.\n\nWhy contribute to third party libraries that are in the open and will continue to get flagged until the end of time. Keeping third party libraries around only asks for future work. Zip is compromised? Roll your own compression algorithm. OpenSSL had a bug? Ask your CEOs demented step child to code up something in K&amp;R C. No one will ever look at that code and more importantly, no one will ever raise a CVE for it because no one outside of your company uses it.\n\nDepends who's asking.\n\nAs leadership, why would you approve someone using third-party libraries instead of rolling your own? Because it's still vulnerable even if no one raises a CVE for it, and breaches will cost you money and trust when someone finds them. Security through obscurity won't save you.\n\nAs an individual contributor... what's the problem with future work? Yes, you will continue to patch them until the end of time, generating a nice profile of open source contributions and using the vuln-scanner tool to demonstrate the value of this to your boss. And this new job you've created for yourself sounds way more interesting than rolling your own, shittier versions of everything and then getting back to that CRUD app.\n\nMeasure: Number of CVEs in our product.\n\nTarget: Minimize the number of CVEs in our product.\n\n[Goodhart's law ensues](https://en.wikipedia.org/wiki/Goodhart's_law).  It's not a smart decision for everyone involved, but the metrics are going to look good until that golden parachute will deploy for management, if it ever needs to.\n\nFor the individual contributor, usually there's other things they'd rather be working on.  Or, they're expected to patch everything *on top of* their normal duties.  And because it's security, I expect a lot of CVE activities in larger organizations are massively bureaucratic, meeting-dense, or both, and I don't blame people for avoiding meetings that could just be emails or not about actual issues.\n\nMeanwhile, Daniel Steinberg: makes `curl` its own CNA with the power to reject CVEs.\n\nMeanwhile: kernel.org becomes its own CNA and floods the dysfunctional system with hundreds of CVEs. (https://sigma-star.at/blog/2024/03/linux-kernel-cna/ )\n\nI knew how they became a CNA, didn't know that's how it turned out. Makes sense tbh.\n\nThe main stupidity there is to take the **Base** CVSS score instead of the adjusted environmental CVSS. The CVSS 4.0 version tries to address that issue a bit more.\nThe scanners just dump the base score in the lap of the admins and they do not adjust it for their environment due to stupid policies.\n\nI hate them.\n\nWe have \"vulnerabilities\" rated critical because a component we build into an os/less container pulls the golang gRPC proto package from some massive monorepo that also contains an executable with a completely unrelated issue. We don't build or use the executable. Still have to go through full emergency patch response because stupid tooling is stupid, and our customers demand that their own stupid tooling must report clean scans on our container images etc.\n\nOur code is shitty and insecure. But it's Vulnerability (TM) Free!\n\n&gt; Our code is shitty and insecure. But it's Vulnerability (TM) Free!\n\nI feel that in my bones.\n\n\"I'm not saying we don't have problems; we just don't have _those_ problems. And time spent on those problems is time not spent working on our _actual_ problems. So time spent on fixing that 'vulnerability' actually makes us actively less secure\"\n\nAnd they buy into those scanners because insurance and/or compliance basically dictates it.\n\nIt‚Äôs a whole cyclical industry to just suck money and resources out of IT without doing anything to address real issues\n\nThird party vendor basically made me \"prove\" to them that sonarqube wasn't finding glaring security problems in our code.\n\nThey made me reinstall with _their_ copy of the software.\n\nThey _still_ told us we weren't secure enough for their liking because ???.  Every quarter my boss asks me what we can do to get them to play ball and I tell him \"buy their company\".\n\nLet's not sell them short. They're adding more stress to *everyone*. I had to upgrade some software on our entire production environment over a flag for a vulnerability that not only would never happen, but it was falsely flagged for a version of the software we didn't even have to begin with.\n\nUgh, tell me about it. Our scans flag `react-scripts` because they dont bother updating the fucking transitive dependencies in that repo, so we have to enter a whole bunch of exceptions into the scanning tools.\n\nOr the cyber insurance outsourcing their vulnerability scans that ignore any kind of common sense.  \n\nSuch as threatening to raise our rates because we are using MS exchange and Exchange had an unpatched vulnerability when Abe Lincoln used it in 1860 instead of realizing and listening that we‚Äôre on O365. \n\nConstant stupid crap like that?\n\nGreat article on how bullshit CVEs have become: https://www.sqlite.org/cves.html\n\nThere's also https://daniel.haxx.se/blog/2023/08/26/cve-2020-19909-is-everything-that-is-wrong-with-cves/\n\nCurl actually [became a CNA](https://daniel.haxx.se/blog/2024/01/16/curl-is-a-cna/) to mitigate that bullshit.\n\nYo dawg, I heard you like CVEs, so I put some CVEs in your CV so you can expose vulnerabilities while you expose your experience!\n\nOk  so the root of this CVE is that a function that returns whether an IP address is public or private will incorrectly return public for some oddly-formatted private IPs.\n\n*How is this a vulnerability?*\n\nEven if this function was being used improperly as a security measure, *even if* it was the only gate on accessing a privileged resource, and *EVEN IF* the attacker is somehow able to control the content and format of his IP address with great precision, then surely this function is failing safe. Surely the programmer would have granted access to the goodies on private IPs, not public ones.\n\nImagine a string compare function that incorrectly claims that strings containing zalgo-text don't match, even when they do. Imagine claiming that this is a catastrophic vulnerability, because someone could use this string comparison in a login system that logs you in if the passwords *don't* match. \n\nFucking resume-padding bullshit.\n\n&gt; Surely the programmer would have granted access to the goodies on private IPs, not public ones.\n\nThe Synapse server for Matrix has a URL preview function, which will fetch and render (preview) links in chat messages. In its configuration, there is an IP blacklist that is pre-populated with RFC1918 private addresses, which are not allowed to be previewed. The intention here is that a public address is fair game, but internal/private addresses should not be exposed by this (chat) server.\n\nThis is a real-world scenario where you would want to allow access only to public resources, and not private ones. It is conceivable that a library public/private function could be used in place of this explicit blacklist.\n\nAll that said, I don't think this should be counted as a *security vulnerability* against the library, as this does not serve a security function within the library. It's just a more standard bug.\n\nPreviewing private network IPs could quickly turn into an SSRF so it's especially important to handle correctly\n\nImagine having to ‚Äúfix‚Äù CVEs that only exist if the code is executed on a linux/unix OS and your employer still makes you do it in your complete Windows environment.\n\nMy company has a severely strict security team, to the point it gets in the way of doing the actual job almost on a daily basis, but they still have the sense of analysing and then ignoring CVEs which are harmless to our specific architecture.\n\nthat actually happened once to me, but the other way around (something about on Windows, fopen is case-insensitive, but on Linux, it's case sensitive.. don't remember much more than that sorry)\n\nTecccccccœá·µ™œá·µ™œá·µ™œácccchnically Linux leaves it up to the filesystem driver‚Äîe.g., V/-FAT is not case-sensitive by default, but ext2/3/4(/5?/6? do we have a 6 yet?) and most others are. Often case-handling is configured at mount time, so it‚Äôs mostly up to Mr. Root (Ô∑∫) in practice.\n\nFun fact: DOS, Windows, WinNT, and various older UNIXes also have a rather terrifying situation regarding filename (and sometimes pathname) truncation.\n\nIdeally, attempting to access an overlong file- or pathname should raise an error (e.g., `ENAMETOOLONG`), but various OSes will silently lop off anything beyond the limits and sally glibly forth as if nothing were wrong. DOS, DOSsy Windows, and AFAIK older NT truncate filenames; DOS also truncates extensions, so `myspoonistoobig.com-capture.htm` might become `myspooni.com`, which is distinctly unsettling.\n\nModern NT doesn‚Äôt truncate *filenames* at least, and IIRC modern POSIX requires the NOTRUNC option (indicating an API-level promise to return an error if an erroneous input is fed in), but older systems may require you to check functionality for individual paths with `f`-/`pathconf`, or might just not tell you at all whether truncation will occur (iow, FAFO and one-offery are the only detection methods).\n\nHowever, everything must be twice as complicated as it ought to be when you‚Äôre Microsoft, and therefore NT pathnames support resource fork names or WETF MS calls them (Apple called them that on HFS IIRC, at least), and *those* do still truncate silently.\n\nSeeing as to how most stuff just uses files and directories or container formats when it wants forkyness, I assume fucking nothing outside MS‚Äôs own software, malware, and MS‚Äôs own malware uses this feature. ‚ÄîI mean, I know the forkjobbies are used regardless, but not named in any explicit fashion. In any event, as long as an attacker doesn‚Äôt control pathnames too directly it shouldn‚Äôt matter. Just another small hole left open, and the terse ‚ÄúCaution: Holes (Intentional)‚Äù sign at the entrance to the park will surely suffice to keep tourists from sinking their ankle in and faceplanting.\n\n&gt; resource fork names or WETF MS calls them\n\nI believe you're talking about Alternate Data Streams?\n\nThe only place I've seen them used in reality are for the zone identifier, i.e. to mark a file as having been downloaded from an external source and therefore apply additional security restrictions on it (the famous \"unblock\" dialog). All modern browsers add this ADS to downloaded files. I believe macOS uses an extended attribute for the same functionality.\n\nI'm surprised that the stream name can be silently truncated, though.\n\n&gt; oddly-formatted private IPs.\n\nIPs are ... strange. \"Oddly formatted\" means nothing when \"normally formatted\" can look like `0xc1.0627.2799` or `3232242671`.\n\nUsing regexes to decode an IP from a string is just broken - you can't do it for all representations of an IP address. You have to parse it into individual octets and *then* check it.\n\n[EDIT: Those examples above are IP4 (4-byte), not IP6]\n\n&gt; Using regexes to decode an IP from a string is just broken\n\nI tend to agree. For reference here's how it's done in:\n\n- [Python](https://github.com/python/cpython/blob/1a84bdc2371ada60c01c72493caba62c9860007b/Lib/ipaddress.py#L1079-L1093) with [constants here](https://github.com/python/cpython/blob/1a84bdc2371ada60c01c72493caba62c9860007b/Lib/ipaddress.py#L1588-L1610)\n- [Ruby](https://github.com/ruby/ipaddr/blob/036836d910473aa56d224eb22c8518e1df41013c/lib/ipaddr.rb#L277-L298)\n- [Golang](https://github.com/golang/go/blob/82c371a307116450e9ab4dbce1853da3e69f4061/src/net/ip.go#L133-L150)\n- [Rust](https://github.com/rust-lang/rust/blob/ef3d6fd7002500af0a985f70d3ac5152623c1396/library/core/src/net/ip_addr.rs#L628-L662) with [IPv6 here](https://github.com/rust-lang/rust/blob/ef3d6fd7002500af0a985f70d3ac5152623c1396/library/core/src/net/ip_addr.rs#L1525-L1547)\n\nWorth noting that all of the above ship with their respective language.\n\nThat said, open source developers owe us nothing, and I don't fault them for getting burnt out. The regex-based solution might have worked just fine for the dev's original use-case. IMHO, companies that rely on OSS need to contribute more to lift some of the burden off volunteers.\n\nIPv4 had a reasonably sensible address scheme and I assume it was intended by it's designer to be human readable.  \n  \nBy comparison IPv6 addresses are absolutely nightmarish, especially when you add all the other craziness.\n\nv4 addresses are 32bit binary strings; dotted quad notation (1.2.3.4 form) is a human readable transform. 192.168.0.254 is equally validly 3232235774, 0b11000000101010000000000011111110, 0xc0.a8.0.fe or 0300.250.0.376, and of those the 'most correct' is the binary one, because that's what's actually used on the network.\n\nv6 addresses are the same, they're just 128bit strings rather than 32bit, and we've settled on colon-seperated hex rather than dot-separated decimal as the human readable version\n\nYep; IPv4 addresses are 32bit binary strings. Anything else you're looking at is a convenience transform. \n\nThis is a fact that an awful lot of networking instructionals ignore (I'm looking at you, Cisco), leading to people getting way too hung up on byte boundaries (no, you don't have a class C network. No-one has class C networks any more. You really really never have a class C network in 10. space) and trying to get their head around truly awful maths by doing net mask comparison in dotted-quad form.\n\nAlso... we can say that if a software is relying on that function as a security mechanism it's vulnerable in the first place. I mean security shall be enforced with firewalls, not something that tells \"no you can't make this request, it's a private address\".\n\n&gt; Surely the programmer would have granted access to the goodies on private IPs, not public ones.\n\nCrazily enough, I have on my machine a program that I *only* want running when connected to a *connection* I've labeled as Public in Windows. It transmits/receives only when connected to a Public network rather than Private. \n\nSo I use Firewall rules to only Allow the program to run when I'm connected to networks I've told Windows are Public.\n\nNow, obviously this is NOT referring to the IP designation stuff referred to in the article? I'm instead referring to Windows' method of letting you distinguish between connecting to (for example) your home network vs your local McDonald's WiFi for determining whether or not you're doing file sharing and printer sharing, etc?\n\nI leverage that same designation method to make a program *only* transmit/share data on a network I've labeled Public in that fashion. \n\nAm I weird? Yes.  \nIs this an extremely oddball edge case? Yes.  \nAm I going to be more specific about why? Nooooope.  \nIs there possibly/probably a better solution? Yeah, maybe. This, at least, utilizes built in core-Windows features to do traffic control in a way that doesn't rely on 3rd party software.\n\nBut considering how fucking weird I am? I can't discount the possibility that someone, somewhere, wrote code that uses the public/private distinction to control data *and* used it in a way where they only want data being transmitted to IPs designated as Public. \n\nBecause there's more than a billion people in the world, and that's a lot of screwball oddities that can happen.\n\nhttps://xkcd.com/1172/\n\nI had that comic in my head the moment I thought about writing my reply. üòÇ\n\nIt's [Hyrum‚Äôs Law](https://www.hyrumslaw.com/)\n\nNot weird.  This prevents a compromised device or application from scanning the local network.\n\nMany wireless access points do this by default - you can only talk to the big-I Internet.\n\nOk yea. But also no.\n\nI think the salient point you miss here is that all machines have a public and private ip and are free to self address as public. That is, it‚Äôs nonsense to say ‚Äòonly allow public ips‚Äô, because that is just all machines. \n\nPut another way , you can say ‚Äòno cops allowed‚Äô and that makes sense but to say ‚Äòonly humans‚Äô and try to argue that that means no cops is silly. Public ip is all ips.\n\nThe only way that this is an exploit is if the person implementing it think is if the person implementing super misunderstood what public vs private ip meant, at which point this is not an exploit it‚Äôs just bad code.\n\n&gt;  Public ip is all ips.\n\nUh, what?\n\nI had the understanding that some IPs were public, and some were private, but none were both. Like, specifically for example `10.*.*.*` is private. It's *not* public, so far as I understand.\n\nYeah, I'm not following. The specific code seems to be determining whether it falls into the IANA's category of public or private, and that seems very strictly delineated in a way where *not* all IPs are Public, in their eyes? Or so I'm interpreting what I'm double checking online? ü§∑‚Äç‚ôÇÔ∏è\n\n&gt; all machines have a public and private ip\n\nHuh? Uh... wait, really? That... doesn't *sound* right, but I admit I'm not an expert in this field. \n\nI'm currently sitting on my local machine poking around trying to figure out what public IP address it has assigned to it, and I'm not finding anything. All I see is 192.168.1.3. And that's Private according to the IANA. \n\nGot a way for me to get my Windows machine to cough up what Public IP address it has been assigned? And no, I don't mean the [public IP address for my network](https://www.google.com/search?q=what's+my+IP+google), which is (as far as I'm aware) assigned to my *router* and not my PC.\n\n&gt; all machines have a public and private ip \n\nv4 or v6? Because most machines very emphatically don't have both.\n\nNone of the machines on my home network (other than the edge firewall) have a public v4 address assigned to them. Yes, they can reach the wider internet via NAT on that firewall, but they have no knowledge of or control over that NAT - they just know that if they send traffic destined to 8.8.8.8 to 192.168.1.1, they get a response back, and that's all they care about.\n\nIt should be fixed, documented as a limitation or it should return an error when parsing fails, IMO. It's far from straightforward to claim it's safe anyway when calling code could be falling back in a larger if-elif-else based on some reasonable assumptions according to the standard (\"if it's neither public nor multicast nor... then it must be a private address\" which is obviously quite debatable in code, but it makes sense according to the spec).\n\nI think it's reasonable to try and get people to write code that is primarily correct and reduce scope if needed. I also agree with what people like Linus have said that most bugs may have wider implications, but I'd rather make more of a fuss about regular bugs than doubt CVEs.\n\nThat's very much not failing safe. I'd wager, based on my experience performing source code review for security, it's much more common to be using an isPrivate function to filter _outbound_ traffic. \n\nI don't think this is a critical issue on its own, for sure, but it could easily lead to one layer of \"defense in depth\" being broken.\n\nA concrete example for the down-voters: Your service calls a customer-supplied webhook to notify them when some event has occurred. You want to prevent this feature from being used to probe your internal network so you use this package to disallow the entry of URLs with private IPs (DNS names will be handled by a custom resolver).\n\nThe risk is that you may make calls outside your internal network, thereby exporting the contents of a request that aren't intended to be seen elsewhere.\n\nE.g. \"create user\" request that passes all of a user's PII, and is now sent randomly elsewhere in the internet.\n\nI think his point was that it's okay, but not great if it tells you that one of your private IPs is in fact public.\n\nI.e. you wouldn't be using it.\n\nSo now those developing possibly competing products can raise bogus CVEs against the FOSS equivaldnt to force it out of business? Surely that system needs reform\n\nThis is open source. The problem isn't Machiavellian it's that too many low end devs are bounty hunting because it raises their profile. In a sense the employment situation in the field is probably driving some of the uptick. I agree the system is broken; it's just not broken in the way everything else is.\n\nDidn‚Äôt Torvalds declare war on a CS department that was trying to inject vulnerabilities into Linux for ‚Äúresearch‚Äù?\n\n[The University of Minnesota](https://www.reddit.com/r/HobbyDrama/comments/nku6bt/kernel_development_that_time_linux_banned_the/).\n\nGreat lesson on not blindly trusting bombastic research papers just because the paper says so.\n\nGreat lesson on how departments other than the Psychology Department need oversight for ethics violations in experimental settings.\n\nFrom the above link:\n\n&gt; That investigation is still ongoing but revealed that the Internal Review Board (in charge of research ethics) had determined that the research was not human experimentation and thus did not need further scrutiny.\n\nFinally, definitive proof that OS maintainers are subhuman.\n\nYeah I saw that. That needs a follow-up. Way to double down.\n\nIdk about war in as much as that all commits from that universities email are autodenied\n\nHe blackballed an entire college to make his point about just how egregiously unethical their process was. \n\nRed teams have prior consent from the targets. There are ways to compartmentalize so that some responsible individuals are aware and others are not if you're worried about awareness spoiling outcomes.\n\nHilariously the way they tried to inject the vulnerability was similar to what was used to compromise XZ Utils. \n\n\n\n\"oh, OSS projects would catch any hostile contributions so there is no need to check if that is true? Time to see about that.\"\n\n\nI've always wondered how the timelines line up.\n\nEdit: Yeah, its a near match. The Github account that compromised XZ  after the kernel fiasco.\n\nhttps://github.com/JiaT75?tab=overview&amp;from=2021-06-01&amp;to=2021-06-30\n\nStart contributing to open source weeks after the story broke.\n\nThat's sort of the same vibe as that friend of a friend who is an asshole and defends themselves with \"hey I'm just being honest. If you can't handle it that's your problem.\" Nobody knows why your friend likes this person and you all wonder what's wrong with them.\n\nI once had someone point out that I had my shirt on inside out by telling me he needed to ask me a question after a meeting and then after everyone filtered out he said, \"Are you the sort of person who wants someone to point out that their shirt is inside out?\"  Same guy later dabbled in local politics and I think that was not a bad call. Maybe I should convince him to work in security...\n\nIt's not even those developing competing products many times. I saw a company just the other day that got credentialed to issue CVE numbers that provides expensive paid support and updates for old libraries and frameworks. I would be willing to bet money they go issue a high severity CVE soon for something like a vulnerability that only affects IE knowing that corporate security rules will force fixing it and either upgrading or buying a contract with them even though you've got way more serious issues if your users are running IE \n\nThere are also people out looking for bogus CVEs to pad their resumes since to some people it's very impressive you found an 8 or 9 CVE.\n\nGithub should really have better community management tools.\n\nAlthough I don‚Äôt have any specific reason to suspect this is happening intentionally, I can also see how this trend complicates existing supply chain attack problems. A flood of bogus high-sev CVEs will stochastically reduce attention given to legitimate vulnerabilities across the board.\n\nI think the problem lies in that any individual can submit for a CVE without peer review. If there's truly a security issue, it should pass a review by committee. Only then should it be recorded. Committee can mean various things here and doesn't necessarily have to place the onus on any one group, but the path from lazy dev seeking resume material to full blown CVE seems a lot less difficult that perhaps it should be.\n\nStupid shit like this just makes it harder to give people nice things.\n\nIf it's such a big issue then fork it.\n\nBut then you can't profit off of the self reliant open source software. You have to invest ACTUAL work into it.\n\nOpen Source is so thank less\n\nSounds like the severity scoring has become just another leaderboard.\n\nThis made me think. \n\nOpen source software often comes with zero warranty, and the developer cannot be compelled to write an update if they don't want to.\n\nSure, someone else can fork the repo and submit a fix, but what is the best way to distribute that fork?\n\nYou could always PR it into the original repo. Sometimes with dead repos though, I'll look at the forks and try to find one that has the most or best changes on it\n\nHalf dead is almost worse. I have an open PR from a year ago for a company I don‚Äôt even work at anymore. It‚Äôs the 3rd of 4th PR I filed and the rest have landed.\n\nA severe security rating should have always required a working proof of concept exploitation. If you cannot show beyond reasonable doubt that the flaw in some software is a severe vulnerability it should not be marked as such. I've known a lot of researchers, and frankly even many of the ones who are actively showing how things can be exploited are attention seeking personalities, but what they unequivocally were not was: lazy. These days there are a great number of lazy attention seekers, and that's a bad situation for security audits in general.\n\n&gt; Disputing a CVE is no straightforward task either, as a GitHub security team member explained. It requires a project maintainer to chase the CVE Numbering Authorities (CNA) that had originally issued the CVE.\n\nThis is what we need to be addressing, or if the situation keeps going like this, we'll see a lack of trust in the system. Which is already eroding. Maintainers are often not included in the original process, yet it's somehow on _them_ to correct a CNA's work. The CNAs ought to be given reputation strikes for lack of thorough testing and communication.\n\nReading the article, and the comments here, I think we need to more often actually look whether a CVE is even applicable.\n\nThere was an insane shitstorm in the Rust ecosystem sometime back about vulnerabilities in time handling crates which only ever applied if someone set environmental variables in a multithreaded program. Yeah.\n\nMy attitude on that has shifted over the years. The reality is there‚Äôs a lot of legitimate vulnerabilities where a naive developer will convince himself it‚Äôs not a real issue because he‚Äôs not smart enough to connect the dots and see how badly it could be exploited. I‚Äôve heard people say of XSS vulnerabilities, ‚Äúgreat you can make it pop up an alert dialog. So what?‚Äù\n\nThere was a famous Reddit thread a couple years ago where a guy objected that browsers labeled his login page as insecure for not using https, then in the comments he defended himself by talking about how he had implemented his own authentication system so he was confident it was secure‚Ä¶ and people just hacked the hell out of his web site to prove him wrong.  \n\nThe moral of the story is it‚Äôs usually better to just change what the alert says rather than worrying about whether it‚Äôs necessary.\n\n&gt; There was a famous Reddit thread a couple years ago where a guy objected that browsers labeled his login page as insecure for not using https, then in the comments he defended himself by talking about how he had implemented his own authentication system so he was confident it was secure‚Ä¶ and people just hacked the hell out of his web site to prove him wrong. \n\n[This started on Firefox's bug tracker, actually](https://arstechnica.com/information-technology/2017/03/firefox-gets-complaint-for-labeling-unencrypted-login-page-insecure/)\n\nThe counterpoint however (paraphrasing a Linus Torvalds quote I can't quite remember) is that nearly every bug is a security vulnerability given enough effort. If the standard becomes \"with sufficient effort a skilled attacker could craft a custom exploit\" well that applies nearly anywhere there's a bug.\n\nThe bug mentioned in the article is quite obviously just a plain bug, a function returns the wrong value when passed weird but still technically valid data. Yes, it could lead to other software that relies upon it having a vulnerability but it is not, in and of itself, in any way shape or form, an exploitable vulnerability.\n\nExactly, a function that returns a wrong result if it's feed a wrong input? Basically we would need to assign a CVE on most of the C standard library, and let's not talk about PHP, there are a ton of functions that if they are feed with unexpected input they just behave wrongly. So what? \n\nThis is if we want may not even be a bug, the author could just have updated the documentation saying \"this function assumes that the IP address is provided in the decimal dotted form, other inputs are undefined behavior\".\n\nJust have to look at everyone in this very thread (and the top comment at the time of me writing this comment) saying that a function that wrongly identifies an IP address as \"public\" is a fail-safe and not an issue... these people have clearly never heard of SSRF, and yet they confidantly comment on a security issue like they know what they are talking about.\n\nMost developers have zero security understanding whatsoever.\n\n&gt;I‚Äôve heard people say of XSS vulnerabilities, ‚Äúgreat you can make it pop up an alert dialog. So what?‚Äù\n\nThere's literally a guy in one of these issue links saying that a function just returning 'false' instead of 'true' doesn't make a vulnerability. I can't understand how programmers could seriously agree with something so shortsighted.\n\nI sympathize with the `node-ip` developer. They were saddled with a BS CVE - and all of the annoyance and abuse that comes with it - and had no realistic recourse except to archive the repo.\n\nBut:\n\n&gt; Yet another npm project, micromatch which gets 64 million weekly downloads has had 'high' severity ReDoS vulnerabilities reported against it with its creators being chased by community members inquiring about the issues.\n\n&gt; \"Can you point out at least one library that implements micromatch or braces that is susceptible to the vulnerability so we can see how it's actually a vulnerability in the real world, and not just theoretical?\" asked Jon Schlinkert, reacting to CVE-2024-4067 filed for his project, micromatch.\n\nYou know how you sometimes `npm install` a simple package, and it insanely has transitive dependencies on dozens of other packages, and you investigate and find that it depends on lots of tiny packages like `pad-left` and `has-value` and `sort-desc` and `is-whitespace`? A lot of those are from Schlinkert and [his 1,458 npm packages](https://www.npmjs.com/~jonschlinkert). So he's, let's say, a subject matter expert on people creating large numbers of arguably unnecessary entries into a public registry that others rely on.\n\nDan Abramov (React Core) wrote about that [a while ago.](https://overreacted.io/npm-audit-broken-by-design/) Almost all \"critical vulnerabilities\" on npm are ReDoS, which can only happen if:\n\n1. You run RegEx queries from unsanitized user input. (Your fault, not the library's fault...)\n2. The attacker already has access to your system and modifies your program to execute a slow RegEx. (Uh... not sure that's what an attacker with full access would do, buddy...)\n\nnpm audit is now useless because people keep filling ReDoS vulnerability on every project and real vulnerabilities are drowned in a sea of false positives.\n\nA lot of projects just started bundling their dependencies, so that they wouldn't be flagged as vulnerable by npm if one of their dependencies or transitive dependencies got falsely flagged.\n\nThat's very true, and I think Abramov is mostly correct here. Though he has much more faith in developers than I do (emphasis his):\n\n&gt; Let‚Äôs look at the `webpack-dev-server` &gt; `chokidar` &gt; `glob-parent` dependency chain. Here, `webpack-dev-server` is a **development-only** server that‚Äôs used to quickly serve your app **locally**.\n\nCorrection: `webpack-dev-server` *should* be a development-only server that is used locally. It tells you that it's a development-only server. It tells you not to use it for production systems. But it's used in production systems anyways.\n\nI think the argument would go like: there's an \"exploit magnetism\" phenomenon where, if you find one exploitable vulnerability caused by poor development and deployment practices, you're likely to find other exploitable vulnerabilities too. (Named after [crank magnetism](https://rationalwiki.org/wiki/Crank_magnetism), the same idea applied to conspiracy theories.)\n\nSo security professionals should assume that software is likely to be used incorrectly - because the systems most at risk are precisely those that do things incorrectly.\n\nSo:\n\n&gt; it uses glob-parent in order to extract a part of the filesystem path from a filesystem watch pattern. Unfortunately, glob-parent is vulnerable! If an attacker supplies a specially crafted filepath, it could make this function exponentially slow, which would‚Ä¶\n\nIf we wrote a script designed to activate the ReDoS vulnerability if the target is a running `webpack-dev-server` instance that accepts arbitrary incoming connections *and* uses the request's path to map to a path on the local file system to serve *and* never sanitizes the input, I bet we'd find vulnerable systems out there - if the system serves a production app with `webpack-dev-server`, then it's exactly the sort of system that would use unsanitized user input to serve files from the local file system by path.\n\nNote - I don't know if even that would activate this particular vulnerability, it's just an example to justify why \"I'm not exposed to this vulnerability because it's a dev tool\" is not the same as \"this isn't a vulnerability because it's a dev tool\".\n\n-----\n\nAlso:\n\n&gt; Why would they add SVG files into my app, unless you can mine bitcoins with SVG?\n\n[Should we tell him?](https://shkspr.mobi/blog/2018/02/this-svg-always-shows-todays-date/)\n\nWell I'll be taking cve with a grain of salt.\n\nThey turned it into a boy who cried wolf.\n\nThere are not [one](https://github.com/indutny/node-ip/issues/136) not [two](https://github.com/indutny/node-ip/issues/147) but [three](https://github.com/indutny/node-ip/issues/150) duplicate issues about the questionable CVE in question, either because people turn their brain off and do not do basic things like \"search before reporting an issue\" when CVEs pop up, or because they're intentionally trying to spam the issue tracker \"because it's high severity and I need the fix!\" or something.\n\nOne issue comment responds to a \"To be fair, if `node-ip` is your only line of defense, you have bigger fish to fry\" sentiment with \"Many projects use automated security scanners as a first line of defense and so this issue is [**blocking** a lot of people](https://github.com/indutny/node-ip/issues/128#issuecomment-1940603895)\". First, non-sequitur, and also-- a line in your automated security scanner is *blocking?*\n\n[Issue 112](https://github.com/indutny/node-ip/issues/112) on node-ip is someone running an automated security scanner and reporting ReDoS vulnerabilities against code only in `devDependencies`. node-ip doesn't have any non-dev dependencies. Who's S are you D-ing? What are you gonna do, make your test suite slow?\n\nWhat are we... doing here?\n\nSay NO to doing free labor for multi-million dollar corporations\n\nThey are the ones that decided to use this library because it is free. The library may be free but that doesn't mean that they are entitled to free maintenance and they deciding the priority\n\nThe entitlement of these corporations is absurd.\n\nWe had a severe CVE reported for an old chrome/cypress image that only runs our e2e in an airlocked environment. Took a while to explain why a ‚Äúsevere‚Äù CVE doesn‚Äôt mean shit to us.\n\nI don't like that bone or the headlines for this mention that the CVE was bogus, they make it sound like the response isn't just the correct thing to do.\n\nI get why it might be an issue, but I can't of the life of me work out how it could be exploited?\n\nLet's say your server accepts an arbitrary url to load some content (eg: thumbnail image, content summary, etc...). You would not want to return internal content by a malicious actor sending a private ip address, so you would use that library to check if the submitted IP is public before fetching the data... but the library incorrectly returns that a private IP is public, so now attackers have a way to request / send data to your internal services. \n\nThat's a classic case of SSRF, and depending on what kind of services you are running internally, it can be trivial to escalate to an RCE from there.\n\nThat being said the given score is still absurdly high for that kind of vulnerability, but it is a vulnerability nonetheless.\n\nYou‚Äôre exactly right, this is server side request forgery.  Although SSRF is not restricted to accessing private IP addresses, this is the typical abuse.  \n\nThere may be some circumstances where the score makes sense, I.e. a developer is checking that the IP address is private and rejecting it, and the AWS metadata endpoint V1 is exposed via the SSRF vulnerability.  But the extreme rating is conditional.  The typical severity might be much less.  \n\nNot sure what the answer is here.  The problem definitely can lead to a severe vulnerability in some circumstances.  It really should be fixed, but maybe we need to be very explicit on the conditions where the severity is so high.\n\nMost here seem to think this is not an issue but this is an issue unless I misunderstood the vulnerability description.\n\nIt is called SSRF and e.g. a GitLab RCE exploit caused by a vulnerability like this was found before. Here is a video showing such an exploit. That exploit in the video also used another exploit to work but this shows that such exploits are valid as the 2nd exploit was only necessary due to redis, there could be another attack target that is not redis which would not need a second exploit. https://www.youtube.com/watch?v=LrLJuyAdoAg\n\nI'm not a fan of Schlinkert due to how he'd gamed the Node ecosystem, but in this case, I'm fully on his side. That CVE is so dumb that it deserves to be memoryholed.\n\nI had one of these CVE's on one of my OSS projects. The severity was some alarmingly high score and the \"fix\" was just a note in the documentation. I thought about rejecting it but what is the harm? Everyone gets to pat themselves on the back and an undergrad security researcher gets his or her wings.\n\nI opened some of the linked bad cve's and a lot of them are opened by people that work at companies that sell software to detect vulnerabilities, they conviniently mention that they found the vulnerability by using their software without disclosing they work for them, the \"vulnerabilities\" they find are just small optimizations or non issues that could only be exploited if you had full access.\n\nSo it seems like the CVE system is being abused to create shitty ads for these scummy companies.\n\nThis is because of the all the SecOps fart sniffers that become SMEs in snakeoil solutions like CrowdStrike Falcon sensor, VMware carbon black, McAfee/Trellix, Trend Micro DSA, etc. These people are like cancer and go around pushing garbage software within their orgs while mostly having surface level knowledge themselves.\n\nI see this as a definite bug in the package and a potential vulnerability depending on the circumstances, but not a critical vulnerability.\n\nI think this also highlights a problem with having such spartan standard libraries that developers are forced to rely on single-author modules‚Äîoften portly written‚Äîfor key functions.\n\n&gt;\"I asked for examples of how a real-world library would encounter these 'vulnerabilities' and you never responding with an example.\"\n\nI have to err on the side of the cybersecurity professionals as some of these devs don't seem to know the difference between something being vulnerable and something being exploitable. I heavily agree that the ratings on some of these make no sense.\n\nThis topic pains every library and every application alike. What an absolute waste of time. It's a political agenda in most organizations. Program managers spend hours discuss in and around it to conclude they have to upgrade a 3PP to solve it\n\nnpm audit is trash, so, anyway ...\n\nlol they CVE‚Äôd Fedor Indutny? What were they thinking?"
  },
  {
    "title": "Write code that is easy to delete, not easy to extend",
    "body": "",
    "score": 1125,
    "url": "",
    "created_utc": 1730087733.0,
    "author": "stackoverflooooooow",
    "permalink": "/r/programming/comments/1gdtd6q/write_code_that_is_easy_to_delete_not_easy_to/",
    "all_comment_text": "Deleting code is my favorite activity\n\nI got to delete a bunch of code the other day because I found out a way to achieve its goal in a much nicer way, and on boy is it a good feeling\n\nHey I too restart projects from the ground up! I haven‚Äôt released a single thing\n\nI have never restarted a project from the ground up. Refactoring code that can be improved should be a part of any development cycle.\n\nI always get all giddy when I see a PR that is mostly red!!!\n\nit's a great way to get your code to compile cleanly\n\nSome people's job is basically deleting code while watching the reaction of the ones who wrote it.  \nThey're pieces of shift.\n\nLmfao... I want the job\n\nDeleting a module is my favourite thing. Deleting a module is my favourite‚Ä¶ thing!\n\nMy PM keep delete our code randomly until it stops working, then revert it.\n\nA man of culture\n\nI don‚Äôt really get the attitude that deleting code is more fun than writing it. ¬†If I didn‚Äôt enjoy writing code i wouldn‚Äôt be a programmer\n\nAt least in my experience, deleting code usually comes _after_ replacing it with something better that you've written. In that case, it's the final dopamine rush before committing and finding out you've broken the production server.\n\nRight haha. ¬†Maybe some people get to delete code for features that get dropped more often than I do. ¬†Usually I have the same amount of feature requirements to maintain, even if I delete code because I try to simplify something - so I don‚Äôt often have moments where I feel sure I nixed a whole slew of maintenance burdens\n\nOf course it‚Äôs fun write code. But at some point you have so much code to maintain that the joy of reducing that maintenance outweighs the joy of writing code\n\nI guess that‚Äôs true in general, though I‚Äôve been able to mitigate some of the pain by using codemod tools to change large amounts of code when doing it by hand would be painful, which is also satisfying\n\nI suspect you're a bit early in your career. The downvotes are a bit aggressive,  but a common mantra for technical leadership is 'Code is a liability'. More code = more liability. If you're using automation to edit code at scale the first word comes to mind is: 'oof'\n\nDoesnt mean you can't have fun writing it though!\n\nI‚Äôve been working professionally for 13 years and coding for like twice as much. ¬†I totally think more code == more concern‚Ä¶ Had plenty of times I replaced code with something better or that I felt reduced liability, I dunno, I just didn‚Äôt get the same satisfaction out of deleting the old thing as I did writing the thing to replace it.\n\nI'm sorry for jumping to conclusions then!\n\nIt comes from constantly battling complexity, trying to keep a codebase healthy and remove all the static that confuses other people diving in.  \n  \nI like solving the problems too, but future me (&amp; team) loves that the codebase is now a bit easier to navigate and clutter free.\n\nI‚Äôm always trying to keep complexity down and deleting things from time to time, but I think I usually enjoy the rewriting I have to do first more than deleting the old, more complex code\n\nI wonder if some people here get to just delete entire features that got dropped in their jobs\n\nYep\n\nTo delete something, you need to write something.\n\nCleaning up a mess by deleting it often feels more satisfying than building something new that you can only hope will be good.\n\nYou must have never had the pleasure of removing thousands of lines of spaghetti, after writing a coherent solution with less code.\n\n&gt;Write code that is easy to delete, not easy to extend\n\nUpvoted because it sounds cool.\n\nThis feels similar to \"Maximize work not done\".\n\n- Hey Chris, you should aim to write code that is easy to delete not easy to extend. \n- Hmm yeah, that sounds actually like a good strategy. \n- Oh, no no, it‚Äôs not a strategy for us but *you* should definitely do that!\n\nOne of the few decent articles on this sub\n\nAnd it's an ancient repost¬†\n\nAnother smart programmer that moved to bird watching or smt\n\nI met tef years ago. Good at computers but also a bit of a cunt\n\nSounds like someone who's good at computers\n\nAbsolute hood classic\n\nIt's like how we have lost all the skilled sculptors and now we get statues like Dywane Wade's¬†\n\nThis is the first time I've read this one, and it's really, really great.\n\n&gt; repeat yourself to avoid creating dependencies\n\nSo true.\n\nDRY was a mistake. Or to put it more diplomatically, the mistake was treating DRY as a universal principle. It's situational.\n\nAnd yes, I know the rest of their statement was\n\n&gt; but don‚Äôt repeat yourself to manage them\n\nBut that doesn't disrupt what I said.\n\nA related Go proverb is \"A little copying is better than a little dependency\".\n\nNice, although I really hope this wasn't used to justify the lack of generics for so many years\n\n100% it was.\n\nI doubt it. This is about dependency, whereas genetics is about repetition and maintainability. Since genetics is built in, your dependency surface doesn't increase when you use it.\n\nI like this.\n\nHow about a lot of copying? Is that better than a little dependency?\n\nOne of the worst things I saw was a combo of DRY and microservices architecture. Basically, how to kill an independent deployment 101.\n\nThe nuance is whether there is incidental or intentional duplication. Coupling accidental duplication is a big mistake. The question is whether if one implementation changes the other should as well.\n\nWhen in doubt, make it WET\n\nIf they solve different problems, then they aren‚Äôt the same, even if they look the same.\n\n&gt; When in doubt, make it WET\n\nthis applies outside of programming too\n\nThe biggest issue is that a lot of code repetition is coincidental repetition, not intrinsic repetition.\n\nIt's the same concept as a database. You don't want the same intrinsic knowledge in multiple places, but that doesn't mean that any repetition at all is inherently bad.\n\nBut most programmers learn dry before they learn how to tell the difference between those two types of repetition.\n\nThings which look the same solve the same problem.\n\nHow about this?\n\n```\n// Full name validation\nstring currentEmployeeName = \"John Doe\";\n\n// Birthday greeting (code in some other place)\nstring employeeName = \"John Doe\";\n```\n\nDev: Wow, that \"John Doe\" looks like duplicate code, no worries I'll follow DRY and fix it with `GetEmployeeFullName()`\n\nJust a simple example, but I can't think of a really good one.\n\nIt's an interesting example, I'll admit. The way I respond is that DRY applies more strictly to code versus data. I can agree it's possible for two pieces of data to be incidentally the same: my height is 182cm, my country was founded 182 yrs ago, etc.\n\nHowever, I don't agree that it's possible for two pieces of code to be incidentally the same. For example, an algorithm which takes the end of an array and appends it to the front of the same array. It doesn't matter in what context that is occurring or why - the algorithm is always doing the same thing conceptually, and that should be represented via an abstraction.\n\nI'm not sure if that is really an inconsistency in my viewpoint. My understanding of DRY was always that it applied to algorithms, not data. However, I can see that may appear as inconsistent because in some sense algorithms can be thought of as data. I think the distinction is that algorithms are always general and apply to data indiscriminately, so they exist in an abstract realm. Meanwhile, data can refer to real things which we know may not have a relation to each other. So in that sense, we can know that two pieces of data are unrelated to each other despite being identical. Meanwhile, if two algorithms are identical, then they are implicitly the same.\n\nHow about this (in pseudocode):\n\n\n```\nreturn sortBy(users, user =&gt; user.name)\n```\n\n\n```\nreturn sortBy(files, file =&gt; file.name)\n```\n\n\nWe could make it so both a \"user\" and a \"file\" conform to a \"hasName\" interface, and then write a generic sortByName function to DRY it, but what's the point? While the code is technically the same, the context is completely different - you're not gaining any of the benefit of DRY code by combining these unrelated chunks of code.\n\n\nI'll also commonly duplicate code when writing validation logic - both usernames and group names might both follow the same rules today, but we might want to change the validation rules for one of those entity types without touching the other.\n\nIn many languages, you don't need to define any interface to use generics. \n\nI would say the reason not to do it in that case might be because the line is too short/too small, which is an altogether different issue. \n\n&gt;both usernames and group names might both follow the same rules today, but we might want to change the validation rules for one of those entity types without touching the other.\n\nOr... you might change one and forget to change the other. Re inserting duplication is easy. It's easier to forget that code was duplicated and miss all the duplication instances.\n\n&gt; I would say the reason not to do it in that case might be because the line is too short/too small, which is an altogether different issue.\n\nWhen talking about two pieces of code that happen to be related, we're usually talking about smaller pieces of code. The more code there is, the less likely the two will happen to be the same.\n\nThat being said, you may still run into larger examples - here's one such possible scenario:\n\n```\nasync function fetchUsers () {\n  const rawUserList = parseXml(await sendGetUsersRequest());\n  return extractListFromParsedXmlField(rawUserList.users);\n}\n\nfunction extractListFromParsedXmlField(parsedField) {\n  if (parsedField === undefined) {\n    return [];\n  } else if (!Array.isArray(parsedField)) {\n    return [parsedField];\n  } else {\n    return parsedField;\n  }\n}\n```\n\nHere we're using an XML parsing utility, not unlike one I've (unfortunetally) used in the past, where under its default configuration, list-like content can come back in one of three different shapes, and you have to do the above dance to convert it into a real list. Because I do this \"dance\" so often, I typically stick this list-extraction logic into it's own helper function as shown above, and then use it any time I need to extract a list from parsed XML data. I wouldn't, however, try and DRY the above list-extraction logic with a function like the one shown below.\n\n```\nasync function getConfiguredPaths () {\n  if (configFile.paths === undefined) {\n    return [];\n  } else if (!Array.isArray(configFile.path)) {\n    return [configFile.path];\n  } else {\n    return configFile.path;\n  }\n}\n```\n\nThe timeline for this hypothetical config file might look something like this:\n* Originally, you could either define a \"path\" property and set it to a string, or you could leave out the \"path\" property entirely.\n* Later, we realized that it would be useful if you could specify multiple paths, so we added support for providing a list of paths as well. The above getConfiguredPaths() function's implementation shows what it looked like at this point in time.\n* In the future, they're toying around with the idea of also letting you set \"path\" to an object that has an \"includes\" and \"excludes\" key, in case you want even finer-grain control, which may require furtehr changes to the above function, and those using the function.\n\nEven though `extractListFromParsedXmlField()` and `getConfiguredPaths()` technically do the exact same thing, the reason why they do those things are very, very different. Because there's no overlap in the reasoning behind the logic, there really no reason to try and make the code overlap (i.e. DRY it).\n\n&gt;  we're usually talking about smaller pieces of code. The more code there is, the less likely the two will happen to be the same.\n\nThat's not really how DRY works. It's not about searching the code for instances of duplication, and then finding ones that just happen to be the same (\"...less likely...\"). It occurs when you find that you want to re-use a section of code in two different contexts, in which case the length could be anything. Then you have the choice of whether to copy it or apply DRY. You can also apply DRY to code which follows a parallel evolution.\n\nAs for your code, there are some formatting problems, but I was able to extract it from the comment so I could read it. I don't see why this shouldn't be something which could be DRY-ed.\n\n&gt;technically do the exact same thing, the reason why they do those things are very, very different.\n\nThis is the fundamental difference of opinion between you and me. The reasons why they do those things is irrelevant. The function encodes the \"doing.\" It doesn't encode the reason why it is done. This applies to all functions. For example, pretty much all languages provide a \"sort\" function. The reason why you're sorting is irrelevant - the point is that the function does that specific thing.\n\nMy opinion is that you are overly focusing on the context in which a function is used. I think functions should stand on their own. Obviously we can't ignore the context since the function's behavior ultimately serves its context, but I think all functions should be understandable on their own without consideration for their context.\n\n&gt;Because there's no overlap in the reasoning behind the logic\n\nI disagree, in my view the reasoning is the same. You want to take in a variable and process it in some defined way. There's three cases: undefined, array-like and value-like. So your function compresses 3 different possible types of input into one type of output. And that behavior is useful in two different situations, but that is no coincidence. Those two scenarios share the same constraints: they produce situations where there are those 3 possible types of input, and you want to convert it to the more narrowly constrained output.\n\nNow, whether you actually do DRY that code or not relies on practical questions. Specifically, you could consider the code to be too short to DRY. Or perhaps these are in two separate modules and it is difficult to ensure they both have access to the function (how your project is setup). Or any number of other reasons. DRY is not without some cons and I am not in favor of applying DRY to every single thing that it in theory could be. But what I do disagree, and I think we are mostly discussing, is the idea that you shouldn't apply DRY in the case where code is \"coincidentally\" (\"incidentally\") the same. And this is a fundamental disagreement in philosophy. I don't believe that code can be incidentally the same.\n\nI really believe that this idea: \"code can be incidentally the same,\" ends up applying to every function. People have called this hyperbole, but from a logical perspective I don't see why not. Thus you end up with an extreme philosophy of \"always repeat yourself.\" I know there are few people that believe that (although some exist). My point is that there is a cognitive dissonance in the opinion that code can be incidentally the same, but at the same time extracting functions is a valid practice. The reason it's a problem is that it allows people to argue in practice that any particular piece of code should be duplicated because they \"feel\" it is incidental. Stated another way: there is no objective test that can determine if a piece of code is incidental. It's a sort of manufactured feeling that doesn't exist at the logic level.\n\nI've been more subscribed to u/theScottyJam's perspective on this but you make a good point. I think, to put it shortly, that it might be wise to avoid DRY if two or more pieces have different *reasons* for change. (I suppose that from the extreme philosophy, you mean two pieces of code always have different reasons for change?). The abstraction to apply DRY today might make sense, but later down the road it might not.\n\n&gt; &gt;   repeat yourself to avoid creating dependencies\n&gt; \n&gt; So true.\n&gt; \n&gt; DRY was a mistake.\n\nEh..   It depends on complexity.\n\nHaving the same logic copy-pasted 5, or 50 times, so you have to hunt around for every place when fixing a bug, or worse having a change/bugfix some places but not all...   That's very very bad.\n\nOn the other hand, don't make an abstraction because you might need it in the future.\n\nAnd if you need to map between config parametres, internal variables, database field names or CSS class.  Don't make that clever macro that works if the names are the same.\n\nThe worst part is that when the code does need to be changed it will only be changed in one place. Coders will all assume the rest of the copypasta was slightly different or served a different purpose and won't touch it. \n\nAlso they won't touch it because they won't even know copies exist.\n\nAlso they won't touch it because it wasn't specified in the ticket to touch that part of the code.\n\nand, it's why I \"hate\"  copied code...\n\n&gt;  It depends on complexity\n\nYeah, that's why the next part of my statement was about how it was situational.\n\nSandi Metz's duplication is better than the wrong abstraction is one of my favorite pieces of software writing.\n\nAnd DRY, with the right abstraction, is better than duplication.\n\nThat article is in favor of DRY. They suggest to follow DRY, but reintroduce duplication when necessary.\n\nWhy is DRY wrong though? We avoid duplication via DRY. I don't understand why that would suddenly be wrong.\n\nIt sounds like one of those curves from novice to expert.\n\nNovice: Copy pastes everything\n\nAdvanced: Learns DRY, copy pastes nothing\n\nExpert: Sometimes copy pastes to avoid other evils\n\nBecause a bad abstraction is worse than duplication. It will often happen that two things look similar, and at first are implemented the same, but in actual fact are different processes. Then down the track you get a new requirement to change one of the code paths, and now you either have to unwind your abstraction or have an if (code path 1) else (code path 2) in there, which becomes a pain to maintain\n\nThis makes no fucking sense. Every library you use is an example of DRY. What kind of garbage coding leads to such brain dead arguments that DRY is bad.\n\nNobody said DRY is bad. They said treating it as a universal principle is bad, because it leads to inexperienced developers trying to abstract things that should not be abstracted\n\nBeing a universal principle is part of DRY. So you are saying DRY is bad.\n\nIt's much more common for inexperienced programmers to have the opposite problem - copying code everywhere. It's rare for them to write unnecessary abstractions. Yes, they write bad abstractions.\n\nYou have to learn by doing. Arguing against DRY is just so unbelievably dumb. I can fix a bad abstraction a thousand times easier than I can copy and pasted code that‚Äôs all got its own specific additions. I‚Äôve done both. Many times. Over decades. This is pure conjecture and pure nonsense spouted by people with no real sense of the impact of these hive mind rants. Good grief.\n\nA jumbo jet could hit you and you'd still miss it. \nThey're saying in a lot of situations the business logic or domain might initially look similar, but if you dive into abstraction and DRY immediately you will often find that in fact the business process or domain was not the same and now you have a shitty abstraction with conditional paths that are hidden away from the logic they belong to. \n\nYou're making this weird argument that all code which looks similar must somehow also always be updated the same way when everyone is trying to point out it's just not the case.\n\nLike if you had two methods that are part of different logic flows that needed to take a number, square it and add one, you might abstract that into a class \"mathifier\". But if one of the methods then needed to multiple by the number-1, your abstraction now needs to have forking logic. \"If method 1 then, else\". \nThis is garbage. It would have been better to recognise that the two initial methods were different in the first place and just repeated yourself a little bit.\nIt would have been easier to read, easier to understand and ultimately better because you didn't create a pointless coupling in your codebase.\n\nNo one has said DRY is always bad, just that it's often bad. And a great deal of people with a great deal more experience than you or I have repeatedly pointed out that early abstraction is a trap to avoid like the plague, how do you avoid it? By ignoring DRY occasionally.\n\n&gt;You're making this weird argument that all code which looks similar must somehow also always be updated the same way when everyone is trying to point out it's just not the case.\n\nWhat you fail to understand is that if the code needs to be updated differently, you are welcome to copy the code at that point. Copying the code from the outset is just lazy. You're justifying laziness. Your view is anti DRY. It applies to all duplicated code.\n\n&gt;But if one of the methods then needed to multiple by the number-1, your abstraction now needs to have forking logic.\n\nWrong. One of the methods no longer uses the \"mathify\" logic. So it should no longer use that function. \n\n&gt;It would have been better to recognise that the two initial methods were different in the first place and just repeated yourself a little bit.\n\nThey weren't different. You said yourself they were the same initially. Your view applies to all duplicated code equally. Any duplicated code could in the future deviate from each other. \n\n&gt;And a great deal of people with a great deal more experience\n\nGreat minds think alike - but often so do idiots.\n\nI fully agree, and I'm frightened that so many developers are praising duplication and negating DRY.\n\nI'm seeing here so often that weird argument:\n\n&gt; duplicated code is often only similar, or it is the same, but it will diverge in the future, thus don't DRY\n\nI only have one decade of experience, but I fixed many bugs because of somebody's lazy duplication, often emerging as missing non-functional requirements. and when there were some problematic abstractions, or logic that needed to be different other places, there were no problems of doing that - it's for what they are paying me...\n\nhowever, I'm working in a decade old product code base, which is constantly developed and maintained. but I guess, for disposable software, or if one changes projects every season, thus consequences will not reach you, then you can YOLO your code.\n\nliquid quaint paltry angle smoggy slimy outgoing berserk tap coherent\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*\n\nUnderstanding the nuance of these situations is one of the most important skills you can gain as a developer\n\ncats makeshift fertile impolite snails rain bored ten six offbeat\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*\n\nYou did, though.\n\nflag homeless sleep long jar governor workable license historical direction\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*\n\nBecause contrarian statements get upvotes on reddit.\n\nDRY came about because copy paste duplication causes lots of problems. After years of applying DRY some people noticed there were a few cases where it caused problems. A smarter person would have found a different way to fix / address these problems, but instead decided to coin \"WET\" - \"write everything twice\". A few years down the road, people are going to recognize the problems that DRY is supposed to fix and the pendulum will swing again.\n\nI don't know.  As a rule of thumb the [rule](https://en.wikipedia.org/wiki/Rule_of_three_(computer_programming\\)) that you refactor to prevent duplication on the third instance seems like the best rule of thumb to have, though particular circumstance might make you do it earlier or later.  And with that you do Write Everything Twice (but not three times).\n\nWelcome to modern programming.\n\nMaybe if you could read, you'd see what the actual issue is, instead of lashing out like a child.\n\nIT'S NOT ALWAYS WRONG, IT'S SITUATIONAL \n\nWhich means \"it depends\", not all duplication is bad all the time. \n\nI agree with grandparent, every article you read about DRY makes it look like it's an universal principle. Coupling for coupling sake is one the hardest and avoidable issues to solve when maintaining or modifying systems.\n\nThat's the correct answer to 99% of questions in software, including whether it's the right answer to 99% of questions in software.\n\nThe only question is how much does each decision cost. If it gains more (in something that matters, not things like useless performance gains) than it costs, then you have to consider it. But, it might also cause compromises in adjacent stuff so the cost has to be considered non-locally as well. And the long term debt considerations, that it may gain more than it costs now, but over time will cost more than it gains. Obviously consistency is a goal in general, and sometimes you consensually give up gains to maintain consistency, because that's less long term debt.\n\nWhich is all to say, \"It depends\", which BTW, is the answer to 99% of all software questions, but it kind of depends.\n\nOne area of business logic:\n\ny = x + 1\n\nAnother area:\n\nz = m + 1\n\nHmm why not make a function?\n\ndef f(x): return x+1\n\nBingo!\n\nHey Mate we need that y = x + 1 to be y = x + 2.  ::Deletes function goes back to old way because it was incidental repetition.::\n\nWhenever you hear people argue in favor of this view, they always use meaningless toy examples like you just did. Nobody is applying DRY to remove \"+ 1.\"\n\nBasically just a strawman fallacy\n\nFair enough but the real world scenarios that end up biting you are significantly more convoluted to describe, OP seemed to not understand when DRY could fail you at all.\n\nI have gotten into these discussions numerous times and I still do not understand how DRY could \"bite you.\" I'm convinced there's nothing to it besides laziness and incompetence.\n\nThe lack of ability for people to articulate their argument for why DRY might be bad in certain situations is to me a good indication that it's irrational.\n\nI think when it goes off the rails its not just because of innappropriate DRY its DRY after you've already mistepped and the DRY step canonizes the mistake and causes that new function/class whatever to blossom into a big mess.  If I gave a specific example you'd easily point out the earlier mistake and say thats not the fault of DRY.  I'm surprised you've never seen premature DRY cause an issue, even a small one.\n\nReversing DRY is easy - you just inline the function. However, DRYing code after the fact is challenging. Therefore, it is always better to first DRY and then later reverse if necessary. And in my experience 99% of the time you won't reverse it. And if you need to, it's easy. That's why I don't understand why it would ever bite me, because it's a non-issue even in the event where it was originally a mistake.\n\nThe mistake is not DRY - it's causing your function/class to blossom into a big mess. But that's an entirely different, pretty much unrelated mistake.\n\nThe think about DRY is that it's the heart of all programming. It's the basic concept of a function. Taking this anti-DRY thought process to its limit will cause all code to be written into one huge main function, never re-using anything.\n\nIt sounds absurd to say that, but I truly believe that is the end result of following this mentality. The idea is \"don't prematurely remove duplication because it might be a mistake and you may need to add it back in the future.\" However, I believe that logic applies to all functions.\n\nHoly shit dude, the whole point is that this is a corner case to be watchful for. If it was trivial you'd have a linter do it on commit. No one is saying always repeat everything, program with NOR gates only!! This isn't \"anti DRY\" it's \"for the most part DRY but be careful\". There's more anti patterns to unwind than a simple function, there's patterns of encapsulation (classes) that can also wind up encumbered by naive DRY.\n\nMy point is that there is no such corner case.\n\nI don't know what you're referring to with regards to linter. The linter would reverse DRY code? I don't get it. \n\n&gt; No one is saying always repeat everything\n\nI know that. I'm saying that's the logical conclusion to the argument.\n\nI half-agree with you. I think people rely on thought-terminating clich√©s when arguing their liked/disliked programming paradigms. But I honestly think (hope) it's just a vocal minority of people that think DRY is bad, or not applicable in most scenarios.\n\nBut dude, you can't take the human element out of programming. Sure, you can forgo the abstraction if you find your specific case doesn't quite match, but when you introduce that abstraction in the first place, you're doing the following:\n- You're telling other developers that this is the quintessential abstraction that SHOULD be used. Social pressure, baby!\n- You're digging a hole of technical debt. Ever heard of \"sunk cost\" fallacy? Ignoring a useful abstraction just so you can repeat most of the logic with minor changes is psychogically hard to swallow. Removing the abstraction entirely is even harder. That requires undoing another dev's work.\n- This leaves the option of augmenting the abstraction, which happens more than you think. When people say DRY isn't universal, what they're saying is that it can lead to this Frankenstein abstraction if not properly justified and foreseen.\n\nI hope I explained it better.\n\nI understand what you're saying. It's just that the solution is different from what everyone is proposing as a response to this issue.\n\nThe mistake made in the scenario you're describing has nothing to do with DRY. The mistake is that bad code is written out of fear of modifying another developer's work. Basically, it's a misunderstanding of DRY. In the scenario where a developer needs a bunch of conditionals in order to make a piece of code work in two places DRY wouldn't apply because the code would not have been duplicated had it been inlined.\n\nIn response, people say \"avoid DRY.\" But they aren't even talking about DRY because the code isn't even duplicated. In reality what they're doing is trying to make one function do two separate things that are roughly related.\n\nSo I agree we need to contend with the reality that programmers are humans, but the solution is to help them understand that you can undo DRY if necessary, not to avoid DRY altogether.\n\nHere's a full blog written on th concept by a notorious windbag, which he calls [compression-oriented programming](https://caseymuratori.com/blog_0015)\n\nA lot of times making code reusable requires a high degree of abstraction that adds lots of unnecessary complexity. What people are saying is that DRY is usually good but in those specific circumstances where the reusable code becomes a hinderance just to adhere to DRY it is better to just have the repeated code.\n\nIt's not wrong in most cases, I can see the argument that the complexity to DRY *simple* things is bad, and there's DRY inside a project, and DRY for all projects you'll ever make forever.  The latter is a lot harder.\n\nSandi Metz has a great talk about this where she points out that duplication is better than the wrong abstraction.\n\nWhy is the code you write not a dependency when the next developer picks up the project?\n\nThis is a big reason to hate inheritance chains.  Whoops, that needs an extra argument.  Well, hope you're ready to change 20 classes instead of 1 because you decided to go with inheritance instead of composing\n\nInheritance should be avoided like the plague because of coupling. Completely agree that composition always produces better, more maintainable, less spaghettified results.\n\nOOP has it's place, but rarely with inheritance does inheritance produce better solutions.\n\nInheritance is great for abstract base classes. I dint like inheriting from real classes.\n\nYeah agreed, I can think of lots of practical cases for inheritance in libraries with a clearly thought out ontology, but usually for UI concepts which are well established.\n\nEven then, a rewrite using composition is often possible.\n\nyea, And Julia has just that instead of regular inheritance\n\nInheritance isn't even a core feature of OOP honestly.\n\nIn the PL space it technically is!\n\nIf a language lacks it, it goes from OO to being \"Object-Based\" - although, this isn't a label used very often.\n\nIf I ever design a program language that includes classes, classes will be sealed by default.\n\nSo‚Ä¶a sum type? :D\n\nNo, not a sum type.\n\nI've been wanting to rediscover this article for ages. Actually pretty solid advice.\n\ni write all my code in a single file so i can delete it easily\n\n&gt;Go and write a mess the first time. Unless you‚Äôre psychic you won‚Äôt know how to split it up.\n\nYes, BUT do keep in mind that writing a mess incurs tech debt.\n\nIt may be easy after writing a mess to go \"well it's a mess, but it works\" and forgoe the \"splitting it up\" part, but you or your successor may regret that later.\n\nA mess that is isolated can be thrown away. A mess that is all over the code base like some tentacled kraken not so much. That is the point.\n\nOTOH, scratch-written replacements often end up just as messy as the systems they replaced. There's a whole lot less risk involved when you shore up deficiencies you already know about instead of betting big on the replacement having fewer/smaller deficiencies.\n\nPretty sure half of the devs at my company are writing code in Scratch with how slow things run.\n\nMaybe. But again: if the replacements are isolated they can be reasoned about. If they pollute the entire code base that's much more difficult.\n\nI feel like you're talking about something unrelated to what I am talking about...\n\n[deleted]\n\nAnd the causal relationship is what? I call bs.\n\nI think the wisdom implicit here is that you're gonna have a mess no matter what, because you don't yet know what should look like.\n\nSo it's better to isolate the mess initially, rather than building the mess into the rest of the system.\n\nEither way technical debt is unavoidable.\n\nAs programmers, we learn along the way.  As we're doing something, we learn how to do it better.  I rewrote a program 3 times, redesigning it and making it better each time.  The last one is the one I gave to the client.\n \nMost likely, it's the managers pushing them to get it working and skipping the rewrite part so they can get it out the door.  Unfortunately there's not much we can do about that.  Lots of smart people telling managers the right way to do things with very little support because it's also the slower way.\n\nTake a writing class and apply the lessons you learn to programming.\n\nWhat kind of lessons do you learn from a writing class? I try to implement an iterative approach to my programming, trying to balance momentum and speed to \"doing it the right way the first time\". Doing it perfectly the first time can add a lot of drag to implementing new features, but it has the chance of making things smoother later on -- often times knowing what's fully right isn't known until much later in the process though.\n\nGoing fast, however, requires a lot of discipline to review code written fast and refactoring it, but a bonus is having more knowledge of what I want and where I want to go with said quickly written code that I didn't have at the time. It's very hard forcing myself to touch code that I know is working but is less maintainable, but I know it's important to revisit.\n\nYou write lots of rough drafts. The point isn't to get the thing working and passing all test cases. The point is to understand the problem and build domain knowledge. When you know what you're doing it's trivial to do it right the first time, but you have to build up to that.\n\nModern programming practices try to accelerate in the short term, and always wind up stalling long term. They descend from employers having faithless attitudes about their programmers because there's no obvious way to understand what work is being done. There's little respect for the research side of R&amp;D. That's why there's so much ceremony around metrics, which puts us in a gross local minimum where your boss can kinda tell when you're not pulling your weight, but at the cost of making everything a thousand times slower and more expensive than it needs to be. Trying to move faster in that environment is like trying to run in molasses.\n\nSo focus on a handful of medium quality iterations at some decent pace, while avoiding metrics-based development in favor of better understanding what you're trying to accomplish?\n\nFocus on understanding the problem domain. Your rough drafts are just research tools until you know what you're actually trying to build.\n\nrefactoring done right.\n\nI'm quite proud that my LoC deleted is generally higher than my LoC added at most of my jobs. Definitely so if you exclude generated files.\n\nI think the premise is worded incorrectly.\n\nThat is, \"we must write code that is easy to delete\". But is this an objective in software design? Usually code fulfils a purpose, e. g. you add certain funtionality to a given code base, say, authentication of a user's credential upon logging in. Say that took you two days. So two days worth of code that was written with the intent to be easy to be deleted, lateron? Isn't that not a good investment of time?\n\nOf course I understand the underlying rationale: you don't want to be tied down by code that is problematic, has bugs, creates side effects, is complex and complicated, you name it. But none of that was the direct reason as to why code was written in the first place, if it was well written.\n\nThe alternative is to true to write code that predicts the future so it will never be deleted, fails to do so, but we‚Äôve invested so much time, energy, and face in writing it that we can‚Äôt let it fail so we just keep bandaging it over and over for years. \n\nSound familiar?\n\nThe title half-implies that Java reflection \"just put this annotation here and the runtime will find it (and if it doesn't you can go cry in a corner)\" is a good thing and I won't stand for it.\n\n(The article doesn't.)\n\nI never saw much crying in the corner, more than zero, but I have seen and felt a lot of ‚Äústare at the code until you notice something you missed‚Äù. \n\nConfiguration over code runs into this a lot. As a friend used to say, you can‚Äôt set a breakpoint in a [config file]. Imperative is better for tear reduction versus declarative. More discoverable with self directed learning. Which is a critical bottleneck for scaling a system and bus numbers.\n\nJust separate different types of logic from each other with modules. Works in every language. I think people have forgotten about why interfaces even exist to begin with.\n\nBest advice. Nearly accidentally's you into domain driven design.\n\nDDD is not a silver bullet. Why people try to push it everywhere?\n\nbecause it‚Äôs a hot topic, like microservices few years ago - it promises to solve a lot of problems, and devs sometimes doesn‚Äôt realize they don‚Äôt have these problems and a halfway implementation only causes more harm and even more new problems\n\nIt's not a silver bullet, just another tool in the tool belt. Use it when appropriate.\n\nSame mistake as every other virtually every other article I see on a wide range of topics. I don't suppose I can blame them - binary is easier to parse and talk about.\n\nSo take what you can from articles like these, but keep in mind seasoned programmers have a library of tools and techniques they can reach for to tackle various problems. There is no \"one-size fits all\". The problem is you can't really write one article about something like this. It's something that you learn by doing.\n\nTotally, when I was young and just started programming, I heard phrases like DRY, SOLID, methods should be no more than 4 lines of code and I followed them religiously. Until recently, after 10 years of development using many architectures, patterns, failing a lot of time, I learned that every principle, every rule, has a specific reason and is good and bad depending on the situation. \n\nI still see peers breaking code into general components because \"maybe I will need to do X\" when that components is used only in one place. I still see many doing mistakes, and sometimes it's not possible to explain to them because they are following rules religiously like me before\n\nThe more you work on this field the more you realize how bad Robert Martin‚Äôs ideas were. I‚Äôm not angry with him, though, the main problem is that _every_ computer science school in this planet unapologetically taught his ideas like some sort of dogma. So glad that even classic OOP languages such as Java or C# are trying to provide alternatives to this nonsense.\n\nIs there a catchy acronym to go with it?\n\nWCTISETODNETC\n\nrm -rf /path/to/code\n\nsimple as.\n\nThis sounds like a psycho yelling \"delete me, but do not delete me\", or \"copy me, but do not paste me\".\n\nNext articles that's going to be upvoted:\n\n* Don't write tests. Without tests, coding is simple.\n* Don't write any source-code. Without source-code, life is simple.\n* Don't build software. Life without software is simple.\n* Don't be a software engineer. Try other profession.\n\nOne of my tenets of good test writing is write tests that are easy to delete. Sunk code fallacy in tests is a huge time sink.\n\nIt's almost like you have to think about what you're doing rather than stupidly apply rules? The rules have value, but no rule is universally applicable. This is an article worth thinking about a little more.\n\nI delete my code all the time ‚Ä¶ others do too\n\nI‚Äôve also been deleting your code. Feels very satisfying.\n\nI just have an automated process that reverts their commits after every PR is merged in. That way it‚Äôs completely hands off.\n\nbu...but... job security...\n\nOh, I guarantee you, all code I ever wrote is easy to remove ... It's just a few button presses here and there, then it will be all gone.\n\nAnyway, on a more serious level: If you write code so that it is additive, then you can also remove it easily later.\n\n¬†Requests is a great example of a Facade. I feel like there were more design patterns discussed but not called out by name.¬†\n\nWe have a quite old code base and I've deleted plenty of code! Even my own code.\n\nWith the code I've deleted from other people, I've always wondered how they come up with such a complicated mess.\n\nNice read. I recall Greg Young‚Äôs talk from last year about this topic - following this advice gives you more flexibility to adjust your code to new models or ideas, as it might highlight places that could be coupled\n\nThe article is all over the place, but I agree with the title, I've found that \"deletability\" is a very useful property to consider when thinking about cohesion/coupling.\n\nThere is often a debate about what the Single Responsibility Principle means. \"A class should have only one reason to change\"? Ok, but that's very vague, there are tons of reasons why we make changes in a class. \"Only one reason to delete\" is much more concrete and useful IMO. A good question to ask: how likely is it that a business request to remove some feature from the application would result in the deletion of this whole class?\n\nCool article.  \nI believe most of the times you can \"predict\" if some code will eventually be used in many places, so often I end up writing a function as soon as I need to copy paste some code the first or second time.  \n  \nBut yeah, if the use cases are not well defined then I go for copy paste until it looks retarded.\n\nIf uncle bob had an evil twin\n\n&gt; repeat yourself to avoid creating dependencies, but don‚Äôt repeat yourself to manage them\n\nThis was for me the moment that Go as a language made click to me. Its package/dependency system that doesn't support the resolution of cyclic dependencies enforces you a lot to think about \"what is needed where\", which eventually leads to more modular code that can be used in an isolated manner from each other.\n\nI still don't agree with a whole lot of choices the language made, but the aspect of automation through conventions is where Go definitely shines at compared to all other languages.\n\nEverything points to simple functions that can be plugged in and out, instead of complex coupled classes. We all know this intrinsically. (John Carmack ahares this mentality.) Yet, we're always stuck in classical, enterprisey languages.\n\n\nWe're digging our own graves and complaining about it.\n\nWrite an app nobody uses.\n\nYou can delete its code at any time.\n\nI'm an experienced coder, but find that writing totally cryptic.\n\nOne example\n\n&gt; Layering is less about writing code we can delete later, but making the hard to delete code pleasant to use (without contaminating it with business logic).\n\nWhat is even better is starting with hardened images where all unused files are removed from day one. We use images from https://hub.rapidfort.com and we use the RF tools to automatically remove unused components\n\nI haven't read the article but this sounds like advice a web developer would give\n\nIt's very much *the opposite* of the things I dislike about web dev.\n\nWeb dev is where you'll see the most silly robotic dogma about poorly-understood \"clean code\" principles. This article is practically a counter-culture to all that.\n\nThe point I am trying to make here is that it doesn't matter what you do when making CRUD apps. It is just so trivial to do that all advice is generally useful\n\nThe title of the article could have been 'write code that is easy to extend...' and that would be somewhat good advice\n\nThat advice goes against YAGNI. I see \"future proof\" code that has never been extended all the time. It's easy to add complexity but hard to remove it. So ho for simple at first.\n\nExtremely stupid advice"
  },
  {
    "title": "1 bug, $50,000+ in bounties, how Zendesk intentionally left a backdoor in hundreds of Fortune 500 companies",
    "body": "",
    "score": 1105,
    "url": "",
    "created_utc": 1728807466.0,
    "author": "donutloop",
    "permalink": "/r/programming/comments/1g2kz9g/1_bug_50000_in_bounties_how_zendesk_intentionally/",
    "all_comment_text": "I find it ridiculous.They drop it as out of scope, you try to alert their customers, they finally realize the danger of the exploit and give you a $0 bounty because you raised awareness of the threat with their customers\n\nNext time, sell it to malicious actors.\n\nFuck companies who do these bad practices in bug bounty!\n\nThat's what has to happen. The only reason these bug bounty programs exist is so people can use their skills for good and make a living. if they take that away, people will find another way to get paid.\n\nIt sounds like you are implying that people who work on bug bounties would turn to actual crime if the bounties didn't exist. And that bug bounties are just whitewashed blackmail.\n\nOr they might just turn to your clients' bounty programs, which is completely legal. Might lose you some clients though, clients that pay for you to ensure your shit doesn't hack their shit. Bet they're paying you more than 10k too. So \"fuck you pay me\"\n\nWhen \"what has to happen\" is a crime, you are volunteering other people's bravery.\n\n&gt; The only reason these bug bounty programs exist is so people can use their skills for good and make a living.\n\nNo. The only reason these bug bounty programs exist is so companies can have their security bugs discovered and fixed by \"good\" actors before any \"bad\" actors manage to exploit them.  \nCompanies couldn't care less if people are able to make a living out of it or not.\n\nIf bug bounties didn't exist, the only ones trying to find vulnerabilities in your code would be hackers trying to exploit them for _potential_ gain (sell the exploit itself, sell your data, use it as a means to access other systems, etc.).  \nBy putting out these programs, companies are just incentivizing \"neutral\" hackers to proactively find any holes in their systems, notify the company and then keep their mouths shut until it's fixed, in exchange for _real_ $$$ gain.  \nIn other words, they are outsourcing their Security QA department. Way cheaper to pay 50k once a year to some random guy, than spending 300k/year on a couple of Security Engineers (or whatever the job title is). And, of course, it's way cheaper to pay 10k than to pay 50k, and way way cheaper to pay 0k.\n\nThe people claiming these bounties are not the same people who would sell the exploits on the darknet, and it's dumb to frame it like that. If they take the programs away, that people will just use other companies' programs, or get a more regular job if they don't already have one.\n\nWhich is a long way of saying it's in the best interests of the company to pay decent bounties. More \"eyes\" on their product, cheaper than employing a specialist team.\n\nBut let's not pretend there are _no_ actors who might be tempted to sell an exploit to bad actors if there's no way to legitimately benefit from it (hell, in some cases good actors reporting an issue for _no personal gain_ have been at least threatened with prosecution). The term \"grey hat\" wasn't invented by me (although its precise defintion varies depending on who you ask)...\n\nAnd also more efficient than paying a couple 300k security engineers, since you might have an inumerable amount of people working on it and who are very properly incentivized to actually provide something, find a bug\n\n&gt; The only reason these bug bounty programs exist is so people can use their skills for good and make a living.\n\nAlso so that companies can exploit you by simply not paying when you do the work. We are living in a world led by welchers who never get their comeuppances.\n\n[deleted]\n\nYeah, if they outsourced the bounty program they need to own it themselves when the company they outsourced to fucks up\n\nYeah, so dumb, as though they'd be overwhelmed by the bounty program. I'm sure they paid more for the horrible outsourcing than they'd pay in bounties\n\nIt sounds like he still managed to collect $50,000 from affected companies, without committing any felonies (well maybe logging into the Slack instances, but it sounds like they paid him for disclosing the issue so it was probably less likely to land him in prison than selling it on the Dark Web)\n\nYeah, jail exists\n\nIf you understand society at a systems level, you'd see that becoming a black hat hacker in retaliation undermines any influence you could have had. Stopping an individual hacker then counts as a solved problem in its own right, with no need to address whatever underlying issue motivated them.\n\nWant to influence companies to improve? Don't attack customers/users, directly or indirectly. That gives them an excuse to take on the role of defender, protecting customers from the evil hacker. Documenting how hard you tried to work with them to protect users, and showing how *the company* was the one who failed is necessary to make sure all the reputation damage lands on them properly, maximizing the motivation to improve.\n\nWhere in this scheme do I get paid?\n\nHopefully from future bounties, from companies who learn from the PR disaster.\n\nIt won't be a PR disaster if you go the black hat route and sell the vulnerability to third parties, though, so other companies won't learn. \"It's a hacker. Nothing we could do; hackers gonna hack.\"\n\nPlus there's the risk of negative money if caught.\n\n\"Rely on the other parties good behavior\" is pretty bad game theory\n\nIt's not relying on good behaviour, it's recognizing that becoming a bad actor yourself will provoke *worse* behaviour in return, not pressure them to improve.\n\nBefore bug bounty programs became commonplace, the status quo was companies not caring much about security anyway, and using the legal system to punish hackers when they could catch them. If you revert to the old ways, then they'll follow the old ways too.\n\nThis would require a poor bug bounty program to constitute a \"PR disaster.\" Given that this has never happened in the entire history of the world, that seems pretty fanciful.\n\nThe \"PR disaster\" is what follows a writeup of how shitty the company acted, posted as a blog.\n\nLike the very reddit post that was submitted here. And numerous others over the past decades, that each seriously harmed a company's reputation in the eyes of the security research community.\n\nA post on r/programming with a 100 comments is not a PR disaster. In three days, nobody is even going to remember this post existed. You'd literally be better off hoping the Ghost of Christmas Past changed their minds.\n\n&gt; A post on r/programming with a 100 comments is not a PR disaster.\n\nCorrect. At least not on its own. The post on reddit is just one of who-knows-how-many social media links, a seed for virality as the story spreads gradually. It's the spread *as a whole*, which becomes a disaster that'll influence the company's behaviour.\n\nAnd even if only a hundred redditors ever see it? Still more impact than selling the exploit on the darkweb would get, where chances are the company silently fixes the issue and the public never even hears of it.\n\nNone of what you're fantasizing has ever happened and there's no reason to believe it will magically start happening now. Don't believe me? Watch as this story's \"viral spread\" looks much more like a \"fizzle out,\" just like every article about a shitty bug bounty program before it. Bug bounty programs simply aren't a thing that 99.99999% of people care about.\n\nAnd screw over every company that happens to use Zendesk and possibly to those companies' customers? Do random harm to ostensibly innocent and uninvolved parties?\n\nWhy the hell is this upvoted?\n\nThis is not Red Cross or Our Lady of Mercy. Bug Bounty is a business, just like Zendesk. They played dirty with the researcher, so fuck them.\n\nI managed many H1 bug bounties in the past, and we never did shit like that. Pay your researchers accordingly when the finding is legit.\n\n&gt; This is not Red Cross or Our Lady of Mercy.\n\nAnd selling this doesn't just fuck over Zendesk, it fucks over a lot of other random people who don't have any say in how Zendesk handles their bug bounties.\n\nDon't be a shitty person and sell exploits that would inflict harm to a bunch of different parties because one party slighted you.\n\n[deleted]\n\nIn that regard, I don't find what the user who posted the article did wrong.\n\nPeople suggesting to sell the exploits to criminals, so that the backdoor can be exploited and those companies can randomly get pantsed for using what they thought was a widely used and trusted 3rd party software, are being crappy.\n\nIt's not about being saint. It's about not empowering criminals to randomly commit identity theft, ip theft, and fraud against other random companies whose only apparent *crime* is using Zendesk.\n\nIt's not about being a saint. It's about not selling lock picks to criminals because a company that sells locks slighted you.\n\nThen by that logic, Zendesk should have just paid out the bug bounty to the guy when first reported and they verified it gave access. They should have done right by their own customers who they owe it to. Instead they used the excuse of \"email spoofing\" doesn't count. You think hackers/criminals don't spoof emails/ips/phone numbers all the time? It should always be in scope if someone can easily fake basic information to get into a system they shouldn't have access to. They reported an issue to them first, responsibly, so they should have been paid, even if only partially due to \"not meeting every requirement exactly\". What they have shown is that honesty is not rewarded.\n\nBy what logic?\n\nMy whole point is that you shouldn't be causing harm to random Zendesk customers because of what Zendesk did.\n\nYes it would cause harm to Zendesk as well but that doesn't in any way excuse the collateral. Driving a truck into a crowd to hit one person.\n\nI'm not excusing Zendesk at all here, I'm saying that the original comment I replied to is taking a shitty stance, selling exploits to criminals that would catch random people up in harms way.\n\nAnd the fact that people can't see that here, and are even upvoting it and downvoting the sane responses calling it out is insane.\n\nBut this is reddit and no one reads the damn article so let me lay it out for everyone who didn't:\n\n* Zendesk had an exploit, the exploit was proven to compromise the Slack and ticket systems of **every company that uses Zendesk.**\n\n* Zendesk said, \"thank you for bringing it to our attention, but not a bug bounty,\" ostensibly downgrading the severity of the exploit, and quite possibly backlogging it, leaving **Zendesk's customers exposed and at risk.**\n\n* The bug hunter/article author reached out to those companies exposed with the exploit, notifying them and recieving individual bug bounties from those Zendesk customers. Some of those Zendesk customers stopped using Zendesk.\n\n* The article author helped the people Zendesk was putting at risk, and it seemingly caused some blowback as some of them likely stopped being Zendesk customers.\n\n* *Everybody lived happily ever after (except Zendesk).*\n\n**The above comment** I originally replied to wanted to instead screw over other companies using Zendesk for the crime of *using Zendesk.*\n\nThey suggested selling the exploit to criminals to steal and defraud **other** companies **who aren't** Zendesk.\n\nAll for the primary purpose of getting paid by criminals, because Zendesk didn't pay them.\n\nHopefully that makes the moral failing more clear.\n\nThe logic of, if you don't want people to turn to criminal methods then take care of them when they were looking out for you and your company/clients first. Instead they swept it under the rug, and thus OP (of the article) went to escalate it to people that would care about it. You don't get to fuck over someone then complain when they fuck you back.\n\n&gt; And selling this doesn't just fuck over Zendesk, it fucks over a lot of other random people who don't have any say in how Zendesk handles their bug bounties.\n\nMake no mistake, after Zendesk has pulled this stunt, me choosing to sell my new knowledge is not **me** fucking over Zendesk's customers, It's Zendesk fucking over those random people a second time. \n\nThis act that we're talking about--where they pull the bug and then offer $0 after their customers bitched about it--is **Zendesk** fucking over every single one of those random people that have a huge say in who they choose to use for a SaaS provider.\n\nBecause they are right.  Zendesk had many opportunities to do the right thing, and they repeatedly chose to sacrifice their customers.  If this dude found it, so could have the bad guys.\n\nIm unclear on this: didn't they just say it's out of scope for paying a bug bounty? That doesn't mean they didn't intend to fix it, right?\n\nThey used the \"informative\" status, which translates to:\n\n&gt; The report contains valid information, but the information provided doesn't require action. This state is often used for out-of-scope submissions or submissions against known issues disclosed on the program's security page, but it's also often used to imply accepted risk.\n\nHowever, based on the screenshots in the article, his report was never actually seen by Zendesk staff, and the decision was taken by a middleman (HackerOne) on behalf of Zendesk.\n\nBUT, regardless of who saw the report or what the response was, Zendesk was still technically justified in denying a bounty. The big problem with reporting security bugs through third-party platforms is that you waive your right to share the information in that report with anyone else, even if the report is clearly rejected. It's shitty, but it is what it is.\n\nsource: been on both sides of this kind of interaction\n\nHe emailed zendesk and they just denied his appeal. And he obviously wouldn‚Äôt receive a bounty from them, so he and decided to milk their contracted companies. Smart kid\n\nThe appeal was also rejected by HackerOne staff (\"Patrick | H1 Mediation\"). He didn't manage to get through to Zendesk until after contacting Zendesk clients.\n\nSo, basically Zendesk started listening when the finder realized the bureaucratic shitshow was on the level of Comcast and decided to do the morally correct thing?\n\nH1+ZD are practicing security theater bolstered by kafkaesque bureaucracy.\n\n&gt; Zendesk was still technically justified in denying a bounty.\n\nI disagree with this. Sure, they're technically justified within the scope of the third party platform's policy, but that ignores the fact that there is no justification for choosing a third party platform that has terrible policies, nor does it justify their own bad policy of SPF, DKIM and DMARC issues being ineligible for bounties.\n\nSeriously. Its gross how much \"well they passed the buck\" is accepted as an excuse for responsibility.\n\nAre we ignoring that this issue has nothing to do with SPF, DKIM, or DMARC?\n\nThe issue is that zendesk itself blindly relies on the to Field to authenticate an attempt to add someone to a ticket, and that to field relies on a guessable, sequential ticket ID.\n\nI have no doubt that the SPF, DKIM, and DMARC records for all the companies involved are impeccable. They had no bearing this issue.\n\nFTA\n&gt; By sending a fake email to support+id{id}@company.com from the requestor‚Äôs email address and CCing their own email, Zendesk would think the email was legitimate. \n\nPlease do correct me if I'm wrong I don't consider myself an expert in these areas, but\n\n1) If the \"requestor‚Äôs email address\" had SPF properly configured, you shouldn't be able to send a spoofed email from that domain unless you're on the correct IP, right?\n\n2) If DKIM were configured and the spoofed email didn't have the correct key, this exploit would fail as the message would be rejected I think.\n\n3) DMARC just needs to be configured correctly if messages pass the first two, so it seems it wasn't here.\n\nAlso FTA\n&gt; Because my bug relied on email spoofing\n\nAren't those three technologies specifically meant to prevent e-mail spoofing?\n\nAlso, the screenshot in the article makes it clear it was rejected because it was a \"SPF, DKIM, DMARC issue\".\n\nAnd, wouldn't the issue be with the configuration of the customer company, not Zendesk itself?\n\nI guess the bigger issue with the Slack takeover has nothing to do with this, but if they had the others configured would this guy never have found the Slack issue?  He got into Slack by sending a spoofed e-mail from appleid@id.apple.com to support@company.com.  Company.coms email server should just immediately reject that as I know Apple has them all configured correctly.\n\nAnd ultimately isn't the fix they implement yet just another layer of those same things:\n&gt; Suspending an email means putting it aside for further review. It's not necessarily spam. It's just not a ticket in Zendesk Support yet. It remains in limbo until somebody reviews it and decides whether to accept or reject it. We use two spam filters, Cloudmark and Rspamd EAP to help determine suspicious characteristics in messages.\n\nI think what's unclear here is what exactly is the email that Zendesk receives. If Zendesk is receiving the email from the attacker with the spoofed email address, then it's on Zendesk to validate. If the company's email server is the one that is receiving it and forwarding it to Zendesk, then it's on the company. Additionally, if the company doesn't have proper SPF/DKIM/DMARC for it's own emails, and thus they ask Zendesk to disable verifications for their domain, then it's again on the company.\n\nSo, it's possible that this is a problem with the company itself, but it can still be a problem with Zendesk. Not to mention, Zendesk could have thought ahead of time of a policy of rejecting emails at least from known large OAuth providers.\n\nFrom what I can find, it's up to the customer to handle receiving messages:\n\n&gt; \"For example, if you receive email from your customers at help@acme.com, and you've set up an automatic redirect to forward all email received there to Support, you can authorize Zendesk to send out notifications as if it originated from your own email address (for example: help@acme.com). That way you can preserve your branding throughout the entire process.\"\n\nhttps://support.zendesk.com/hc/en-us/articles/4408832543770-Allowing-Zendesk-to-send-email-on-behalf-of-your-email-domain\n\nAnd to the credit of Zendesk, they do have an article detailing the needed mail server configs, including sections on SPF, DMARC, and DKIM:\n&gt; **Recommendation 3: SPF records**\n&gt; \n&gt; Domains that send emails to Support should have a valid SPF record that authorizes IP addresses to send emails on behalf of the domain.\n&gt; \n&gt; Find below two examples of the correct SPF record for the following situation:\n&gt; \n&gt; *     domain.com\n&gt; *     SMTP servers with address 1.2.3.4\n&gt; *     MX record mail.domain.com pointing on 1.2.3.4.\n&gt; \n&gt; Both examples would enable 1.2.3.4 to send emails on behalf of domain.com.\n&gt; \n&gt; *     domain.com.          3600    IN      TXT     \"v=spf1 mx:domain.com ~all‚Äù\n&gt; *     domain.com.          3600    IN      TXT     \"v=spf1 ip4:1.2.3.4 ~all‚Äù \n&gt; \n&gt; **Recommendation 4: DMARC and DKIM**\n&gt; \n&gt; To decrease the number of spoofed emails and spam you receive, add an additional layer of security on your inbound emails by enabling Sender Authentication with SPF, DKIM, and DMARC alignment. For more information, see the article: Authenticating incoming email (SPF, DKIM, DMARC).\n\nhttps://support.zendesk.com/hc/en-us/articles/4412991936922-Workflow-Ensuring-email-system-compatibility-with-Zendesk\n\nEDIT: I searched more and found articles detailing email setups, but not sure if I care enough about this Reddit thread to read them:\n\nhttps://support.zendesk.com/hc/en-us/articles/4887918604058-A-complete-guide-to-understanding-email-in-Zendesk-Introduction\n\nhttps://support.zendesk.com/hc/en-us/articles/5612728377754-Understanding-the-default-email-setup-in-Zendesk\n\nWould that mean this kid is a liar or something is left out?\n\nNo, just not detailed enough.  We need to know how the emails are actually handled to determine where the issue is.  If the companies are self-hosting e-mail (or using a service that isn't Zendesk but are in control of their own DNS for it), then its the fault of the company and they had an insecure configuration that was used against a Zendesk install (and could be abused in any other number of ways).\n\nIf Zendesk is hosting the e-mail service on behalf of the companies, then Zendesk screwed up DNS configs and essentially allowed this to happen.\n\nGot it. How would the system prevent spoofing though? Guess I should learn more\n\n- SPF stands for Sender Policy Framework, and it's an email authentication method designed to prevent email spoofing. SPF allows the owner of a domain to specify which mail servers are permitted to send emails on behalf of that domain.  If the \"requestor\" e-mail host has it properly configured in their DNS records (such as Google for Gmail, a requestor being a customer creating a support ticket) AND the receiver (Company/Zendesk in this case) properly VERIFY the SPF record it would be rejected if it came from the wrong server.  This is mostly applicable to things like company e-mail addresses, beacuse if the requestor is on Gmail and you are also on Gmail, the spoofed mail is coming from the correct server (assuming Gmail lets you send messages as another gmail user, which I wouldn't think it does).\n\n- DKIM stands for DomainKeys Identified Mail, and it's an email authentication method designed to allow receiving mail servers to verify that an email has not been tampered with during transmission. It does this by attaching a digital signature to the email, which is linked to the sender‚Äôs domain, ensuring the integrity and authenticity of the message. Much like above, if the sender (like Gmail) has it properly configured its up to the receiver to verify it.  Also like SPF above, if you're both sending from the same server, you both have the same DKIM key (again, assuming Gmail allows you to spoof at all before it's even sent).\n\n- DMARC stands for Domain-based Message Authentication, Reporting, and Conformance, and it‚Äôs an email authentication protocol that builds on SPF (Sender Policy Framework) and DKIM (DomainKeys Identified Mail). DMARC allows domain owners to protect their domain from unauthorized use, such as email spoofing, by defining a policy that tells email receivers how to handle emails that fail SPF or DKIM checks. DMARC also provides reporting, so domain owners can monitor and track the use of their domain in email communications.  And like the above, it's up to the receiver to verify this information, which should be contained in the DNS records of the sending domain.  Here's Googles for example:\n\n&gt; * v=spf1 redirect=_spf.google.com (Google is HUGE, so this is a redirect to 3 other domains which include all of the many netblocks gmail sends from)\n&gt; * v=DKIM1; k=rsa; p=MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAntvSKT1hkqhKe0xcaZ0x+QbouDsJuBfby/S82jxsoC/SodmfmVs2D1KAH3mi1AqdMdU12h2VfETeOJkgGYq5ljd996AJ7ud2SyOLQmlhaNHH7Lx+Mdab8/zDN1SdxPARDgcM7AsRECHwQ15R20FaKUABGu4NTbR2fDKnYwiq5jQyBkLWP+LgGOgfUF4T4HZb2PY2bQtEP6QeqOtcW4rrsH24L7XhD+HSZb1hsitrE0VPbhJzxDwI4JF815XMnSVjZgYUXP8CxI1Y0FONlqtQYgsorZ9apoW1KPQe8brSSlRsi9sXB/tu56LmG7tEDNmrZ5XUwQYUUADBOu7t1niwXwIDAQAB\n&gt; * v=DMARC1; p=none; sp=quarantine; rua=mailto:mailauth-reports@google.com\n\nApple:\n&gt; * v=spf1 include:_spf.apple.com include:_spf-txn.apple.com ~all\n&gt; * v=DKIM1; k=rsa; h=sha256; p=MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAy4V3QZgjpUK3HSijzU+uGQlfBx8N40Ese/TaM0P8BES/kTKJS7OvtEfmA+ihMYcwh+vpvjK7aBIpV2CT49QnC/lXm8KwXad64VF18pgaCiuOW4rxC2L687Gn2BHEekcbl5FozRa716DLXpo07j5IX5sdvKPi6KylnmyOmjD/NqfvbLZf/lRlTb9pXf1N3fLu+W25vaotR4ZQpbrMQkKIANDafdL4KvPmfFOfYuZYiLpQfHfuJYok0aROsS5as1cEthN9MnkdSBAJHLG/f63+jNLgSC9x77YBWH2gPIDIqEanPVPFPJjs0yNh1zCWJUma9ihNXNwBP9GDclt042thAwIDAQAB\nv=DMARC1; p=quarantine; sp=reject; rua=mailto:d@rua.agari.com; ruf=mailto:d@ruf.agari.com;\n\nSo if my e-mail server receives a message from one of these domains, if I have it configured to, it will first check SPF to make sure the sender IP is an allowed IP, then DKIM to verify the key came from the correct domain, and if those fail it will follow the DMARC instructions to reject/quarantine and report.  You can see this all happening in your e-mail headers, which are usually hidden from view but would look like this (big chunks cut out for relevance) from a message Apple sent to my Gmail:\n\n\n    X-Dkim_Sign_Required: YES\n    ...\n    Authentication-Results: mx.google.com; spf=softfail (google.com: domain of transitioning no_reply@email.apple.com does not designate XXX.XXX.XXX.XXX as permitted sender) smtp.mailfrom=no_reply@email.apple.com; dkim=pass header.i=@email.apple.com header.s=email0517 header.b=QdlN3Fs1\n    ...\n    Dkim-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=email.apple.com; s=email0517; t=1728774388; bh=14zaRXDTfQLxvL04c6WtNG6a8zs6rDMsxSevFa/YN2g=; h=Date:From:To:Message-ID:Subject:Content-Type; b=QdlN3Fs1z695x6DeC5T0BC8AdslN6YXZASKk322PVWjPdh1oJoIp0vyNtMz9O8XqQ kNE6VXc1JbR11WcEOI7qRrlHqmnNmb/E8mlhf0qhQHY+/6vFKEoWwUR3zzRGvFi635 i5cRVPlq3CSeygbnY6aFDEwnmt8uI9NRlsYfOkWITrSfyylWzH0gEiHTNcxXNSr5IK GlyVxMuQZvATqKlrAmbsH2AFTU2okxuE0WLy48AM+RZtqdnwiy95BclGTgiEIDGKQb iPAS1aiaYD5v/ENyWVDTLNlwksDJVeURXzwzYf/p1EhRcmXgMtgl8VdyWUTVkiCSR7 Euq7cfMUmfMTQ==\n    ...\n    Received-Spf: softfail (google.com: domain of transitioning no_reply@email.apple.com does not designate XXX.XXX.XXX.XXX as permitted sender) client-ip=XXX.XXX.XXX.XXX;\n    Received-Spf: pass (mx-inbound19-53.us-east-2b.ess.aws.cudaops.com: domain of no_reply@email.apple.com designates 17.23.6.24 as permitted sender)\n    ...\n    X-Bess-Dmarc: no-action HeaderFrom:email.apple.com Record:\"v=DMARC1; p=reject; rua=mailto:d@rua.agari.com; ruf=mailto:d@ruf.agari.com;\" SPF:Pass(s) DKIM:email.apple.com(s) PCT(no-pct)\n\nPresumably if the company (not Zendesk) has set up DKIM correctly the spoofed email to add yourself to the ticket is denied by Zendesk.\n\nPresumably if that was the case, remediation for the customers he directly contacted would have been as easy as \"fix your records\", not \"disable a zendesk feature.\"\n\nIf the company wasn't smart enough to set up SPF/DKIM/DMARC in the first place it's not a surprise they'd tend to overreact and place the blame anywhere but themselves.\n\n&gt; The big problem with reporting security bugs through third-party platforms is that you waive your right to share the information in that report with anyone else, even if the report is clearly rejected.\n\nThis part seems *incredibly* shitty, to the point where it'd seem it defeats the purpose of a bug bounty program.\n\nI mean, the purpose of a bounty program is, first, to incentivize security researchers to bring reports to you instead of selling it to malicious actors, and second, to actually make software more secure.\n\nWhen that process is used to sit on a vulnerability instead of acting, obviously it makes everyone less secure, and it also removes any incentive for the researcher not to disclose anyway. After all, if it's going to be $0 bounty either way, there's no reason not to disclose it to third parties or publicly and still get $0. Or, for that matter, sell it to a malicious actor for more than $0.\n\n&gt;The big problem with reporting security bugs through third-party platforms is that you waive your right to share the information in that report with anyone else, even if the report is clearly rejected. It's shitty, but it is what it is.\n\nThat's very interesting. I wasn't aware of that, is that an implication of their [terms and conditions](https://www.hackerone.com/terms) somehow?\n\nFor HackerOne specifically, I think they cite their [CoC](https://www.hackerone.com/policies/code-of-conduct), with the caveat that \"vulnerability\" can also refer to disputed, unvalidated, or otherwise invalid vulnerabilities.\n\nThis is standard across the board, for example [Bugcrowd](https://www.bugcrowd.com/resources/hacker-resources/standard-disclosure-terms/#:~:text=ALL%20SUBMISSIONS%20ARE%20CONFIDENTIAL%20INFORMATION,has%20otherwise%20consented%20to%20disclosure.) communicates this better by referring to them as \"submissions\", which encompasses any and all report contents.\n\nWell, then they will sue the kid?\n\nHm, marking it \"informative\" you still have waived yiour right to share the information with anyone else?\n\nBased on how you describe \"informative\", that seems like a problem to be fixed. It seems to me marking an issue \"informative\" should mean this is not confidential/privileged information, it is information that is already publicly known or can be publicly known with no danger. Once it's been marked informative you should be free to share. \n\nIf they think otherwise, they should be giving you a bounty, right? That's what \"informative\" is for, no?\n\nWhat's the jutification for marking something \"informative\" that is required to be kept confidential for security reasons? What would be a justified case for that?\n\n&gt;What's the jutification for marking something \"informative\" that is required to be kept confidential for security reasons? What would be a justified case for that?\n\nUse-case clearly seems to be make the bug bounty program cost less money\n\nDid they take action on it? If so, it's not informative and they owe a bounty. That is the actual litmus test.\n\nThey did take action on it, they were working on a fix for two months and deployed it after two months. That highlights to me that it was actually being looked at even tagged as informative.\n\nHow did he waive that right? He signed no contract and I think he won't have legal troubles from this\n\nOh damn he broke the agreement he'll have to pay back his $0 from zendesk\n\nI mean, playing devils advocate, Daniel did come up with a much more serious attack than his original report. But Zendesk really should have taken a defense in depth approach and just accepted and fixed the original bug report.\n\nWhat do you mean, how did he come with a much more serious attack?\n\nLeveraged the bug to gain access to private Slack channels via SSO.\n\nHow did his inclusion of himself on the CC give him access to the private slack channels?\n\nThe method is detailed in the article, basically he was able to use it to verify an AppleID account at support@company.domain and then access Slack as if he had a legit company email address.\n\nI see. So he asked for it\n\nIt seems there is more nuance than that. Per the disclosures, the original issue is still considered out of scope and nothing has been done about it: if it's possible to send spoofed emails from a company, then you can still get added to tickets. What they've done is to add more layers to prevent OAuth confirmation emails from automatically opening tickets like this. This is fixing a vulnerability that he never even tried to disclose to Zendesk.\n\nUltimately it's unclear to me what Zendesk's responsibility even is. If the company server is accepting and forwarding spoofed emails to Zendesk, why is it this Zendesk's problem? Why isn't this something the company itself should fix, not relying on Zendesk to add spam filters to protect them from their bad email practices?\n\nThe original issue he reported was out of scope per the terms of the bug bounty.  While those terms are unfortunate, the simple fact remains that it was out of scope.\n\nHe then leveraged his issue with *another issue* (Zendesk not blocking automated email from `appleid@id.apple.com`) that he did *not* report to Zendesk. (Arguably it shouldn't be Zendesk's responsibility to block every possible sender email address used by every possible OAuth provider used by arbitrary third-party services such as Slack, but he didn't try to demonstrate this to Zendesk to prove how serious the original issue was.)\n\nIt's not the security researcher's job to come up with every possible way a vulnerability can be exploited. The researcher demonstrated information disclosure, and that's enough to prove a vuln exists.\n\nBreaking into Slack via Apple isn't even a Zendesk problem; the root issue is the information disclosure allowing a malicious actor to verify an Apple account under a company's domain, and that's exactly what was reported to Zendesk.\n\nI'm talking specifically about eligibility for the bounty.  I'm not claiming that information disclosure isn't a serious problem.\n\nThe *second* issue maybe would have been eligible had he reported it.\n\nThat's the thing though, it's the same issue.\n\nIt's not the same issue.  The first issue is what allows the second issue to exist.  If Zendesk blocked `appleid@id.apple.com` like it blocked `noreply@...` senders, then he wouldn't have been able to do what he did.\n\nAgain, I'm not downplaying the first issue.  Unintended information disclosure should have been treated seriously.  I also don't personally agree with the terms of the bug bounty, but those terms are what they are.\n\nThe reported information disclosure vuln is the one and only issue. Without ID, it doesn't much matter if they block appleid@id.apple.com or not.\n\n&gt; While those terms are unfortunate, the simple fact remains that it was out of scope.\n\nThis is something many executives need to learn.\n\nPay the white hats generously,or you will pay far more when the black hats do the same work. The only way to be notified is to pay for all of them, not to announce an exclusion to not pay out.\n\nIt is now likely with a PR backlash that they will pay out, but it is not before the company has paid with a PR problem and multiple lost contracts described in the article. They saved the money on a bounty in the short term, but are paying far more as a result, and will likely pay again as gray hats won't hesitate to get money from the bad actors after exploits like this are announced.\n\nToo bad for zendesk working for free was out of scope per his policy, huh?\n\nThis kid is a fucking beast. The fact that ZenDesk fucked up so bad and proably lost &gt; $100k in clients instead of just paying him is wild.\n\nIf Google can lose all the data of a billion dollar wealth management company, or Cyberstrike can take down millions of corporate computers at once, or the government can have every single person‚Äôs SSN stolen, I‚Äôm sure Zendesk will be alright. Just gotta pay the PR department a bonus.\n\n&gt;Cyberstrike\n\nCrowdstrike\n\nClownstrike\n\nFor extra fun, https://clownstrike.lol/\n\nNote the same \"it's not the crime, it's the coverup\" pattern as Zendesk exhibited here. I would never have heard of that website if it hadn't been hit with [a series of fraudulent DMCAs and other false positives](https://clownstrike.lol/crowdmad/) to try to bully it off the Internet.\n\nI noticed after commenting and wondered how long it would take someone to notice, apparently 3 hours lol\n\nits like when your mom called every game \"nintendo\".\n\nI'm telling your customers. Pay me\n\nI'm not saying ZenDesk will collapse but if they lose a couple of clients vs just paying the hacker a paltry sum. Even paying $50k is probably nothing comparatively.\n\n&gt; Just gotta pay the PR department a bonus.\n\nNot even that. Some companies are just too big to fail.\n\nI thought Google got all that data back, it just took a while (8 days or something)\n\nIs there any indication crowdstrike is even going to recover?\n\nCRWD stock has regained about 75% of what it lost in the 2 weeks following the outage.\n\nSure. It'll be a blip. They'll reband and move on.\n\nThere are no consequences to gross technical incompetence or massive mismanagement. See: Boeing.\n\nBoeing is necessary to the security of this country. Crowdstrike could be eliminated with a single PR from Microsoft.\n\n[deleted]\n\nHardly. The Google-built admin tool was created with a default account deletion after 1 year, and their engineers were supposed to manually override that insane default. Bad design.\n\nDid you read this somewhere? It's really the exact opposite of what happened.\n\nI'd be slightly more impressed with ZenDesk after this if they gave this person their WELL DESERVED bounty to show they really take this stuff seriously, as well as it being an admittance that their own response to the initial reports were not appropriate, as that directly led to the later action.\n\nThey may or may not have broken the guidelines depending on how you interpret things, but regardless, they simply didn't leave other avenues open.\n\nIF ZenDesk is claiming that a) they didn't want to go any further with that issue, and b) they didn't want it sharing with any other companies... THEN my conclusion is that they want to leave a bug unpatched without any of their customers knowing about it.\n\nAlso they are *disincentivizing* responsible disclosure after they turn down an initial report. Imagine the next time someone gets ignored by ZenDesk like this. Might as well sell your exploit if they're not gonna give you any money once you've (*responsibly, given the situation*) told at-risk customers.\n\nReally impressive work, either way.\n\nHmm, sounds a bit like if I discover something huge in Zendesk that opens them up to serious legal trouble, they're the last person I should try reporting it to.\n\nInstead I should contact their biggest clients. Not sure how else I'm meant to take their response to what should've been a quick turnaround time even when they acknowledged it, then telling the reporter to screw off: he's getting nothing.\n\nHahaha EXACTLY. You should just contact their biggest clients and Government regulators while you're at it. They're asking to be grinded\n\nthis kid will go far\n\nMaybe, maybe not.\n\nSometimes well meaning people who point out issues in vulnerable systems get hounded to [death](https://en.wikipedia.org/wiki/Aaron_Swartz).\n\nHe was looking down the barrel of a $1 million fine and 35 years in prison for the crime of downloading and redistributing JSTOR articles. Most research is in at least some part publicly funded, and paywalling it is morally heinous, never mind the very real costs of making future research harder and more expensive.\n\nLook, I agree that research papers should be free (especially those funded by gov't grants) and the Open Access movement.  If I'm on a jury, he's an easy case to go for nullification.  He was offered a plea deal of six months in minimum security prison for the downloads for pleading guilty (which his team rejected in favor of a trial).\n\nThat said like many other prodigies/geniuses, he did publicly write about his [severe depression](http://www.aaronsw.com/weblog/verysick) going back to 2007, well before the 2010-11 MIT JSTOR downloads and his 2011 arrest.\n\nYeah, High IQ and depression go hand in hand. Unless the person manages to mentally aspire to a higher World, they will be in big trouble. They absolutely CANNOT live among average or low IQ folks, lest they just see no point in the game of life and seek to obliterate themselves and others full of rage\n\nExactly. don't be a hero and if, do it under the protection of a company that actually works in this area vs doing it as a hobby.\n\nBut this young man is a hacker, a tough cookie, and is more likely to be sought after as an ethical hacker due to his history of exploits (as seen on his github profile) and his ability to work with literally Fortune 500 at 15, and make $50,000 off the whole thing. Aaron Swartz was an idealist, equally effective yes, but he wasn't pragmatic / practical in the way this young man is. I don't see a problem for this guy making it big, but I do see him being tested and tempted by money and power in the future. He already knows how to handle some types of serious power (major security bug, responsibly disclosed), so he seems to have a good start in that department.\n\nYou really don't know much about Aaron Swartz, then.\n\nYes, I think I need to read more about him. I knew only half the things he did.\n\nHe planted an illegal wiretap on campus to suck down data and distributed it for free. He got caught and couldn‚Äôt face the consequences. He‚Äôs not a saint. He was extremely misguided¬†\n\nTheir fix is to use RSpamD score and explicitly block Google and Apple reply-to emails. \n\nBut neither really prevent this attack? Craft an email that passes the spam filter, attack non Google and Apple SSO SaaS services. \n\nOnly something like `support@support.company.com` avoids this.\n\nOr randomize ticket IDs, so you can't just add yourself to someone else's ticket? That seems like the most obvious fix, and I don't understand why they wouldn't do it.\n\nYou don't have the randomize the ticket ID, just generate an additional ticket specific random token for email references only, and reject mail for which it does not match.\n\nsupport+ticket1242-GzHkkY@...\n\nand im pretty sure that still doesnt prevent an insider attacker from you know, using their own company email to read support tickets.\n\nI.e, join the company as an intern, gain access to data in violation of PoLP policies\n\nThis was written by a 15 year old? I have coworkers who can't write that well let alone jump through the hoops OP did. I hope OP gets a hell of a lot more than 50k from their future employments.\n\nIANAL but I would expect a sudden flurry of GDPR-related complaints against Zendesk - knowingly leaving a vulnerability of this severity open after being notified appears to violate Article 32: https://gdpr-info.eu/art-32-gdpr/\n\n&gt; the controller and the processor shall implement appropriate technical and organisational measures to ensure a level of security appropriate to the risk\n\n(although they have now remediated the issue, I'm not sure about the potential for back-dating complaints)\n\nGDPR, more broadly, just doesn't actually work how you think it does. There are notifications and remediation periods, etc\n\nAwesome job!\n\nAnd a very distasteful reply from zendesk in the comments, yuck.\n\nI refuse to believe a no-pfp, created-today account on GitHub is actually Zendesk.\n\nFair enough, but it's kind of bizarre that someone would fake that...\n\nIn any case, their official response is equally ugly - https://support.zendesk.com/hc/en-us/articles/8187090244506-Email-user-verification-bug-bounty-report-retrospective\n\n&gt; Although the researcher did initially submit the vulnerability through our established process, they violated key ethical principles by directly contacting third parties about their report prior to remediation.\n\nBullshit. Zendesk outright rejected the report, which means that they washed their hands of whatever he might do with it in the future. After all, it's \"not a vulnerability\", so why should he have to stay quiet about it?\n\n&gt; why should he have to stay quiet about it?\n\nbecause he agreed to that policy when he submitted the report. Anyway, \"out of scope\" doesn't mean \"won't be fixed\".\n\nWhen zendesk asked him to keep quiet, he should have replied: ‚Äúsorry, this bug is out of scope‚Äù.\n\nThat's what I thought. You said I don't have a bug in scope here and I informed, not reported. Then I tell individual companies and now you want to know how I escalated from email spoofing configuration issues, but that is still out of scope. \n\nTell your paying customers the bug they're reporting is out of scope and thank them for notifying.\n\nVery good read. Hunter fully earned his $50k. Impressive.\n\n\"Slack intoduced OAuth login just a few years ago and must have completely forgotten\"\n\nThat's another big company not coming out of this looking particularly good.\n\nman is 15, i‚Äôm 10 yrs older and have achieved nothing\n\nProbably isnt a redditor\n\nI'm 20 years older than you and I've done nothing of this scale. Some of us are just normies. It's ok. In fact it's good. If everyone were a genius, the world would be a very chaotic place.\n\nEveryone faulting ZenDesk for rejecting. It reads to me as if HackerOne was the one rejecting it, without any nuance. They even admit that it is a potential high-risk vulnerability and just sat on it? I would seriously rethink funneling all reports through HackerOne.\n\ncooing innate plants safe shrill screw chunky sand lavish lip\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*\n\n&gt; guy escalated to ZenDesk staff\n\nHe escalated to a HackerOne mediator, who rejected it.\n\nNo, this is 100% on Zendesk.\n\nFirst: Maybe H1 should've forwarded it, but they were acting on Zendesk's behalf. You can't absolve responsibility by contracting out to a third party and then blaming the third party.\n\nSecond: [Here's Zendesk's explanation of why they ultimately paid out $0](https://support.zendesk.com/hc/en-us/articles/8187090244506-Email-user-verification-bug-bounty-report-retrospective):\n\n&gt; Although the researcher did initially submit the vulnerability through our established process, they violated key ethical principles by directly contacting third parties about their report prior to remediation.\n\nThis is disingenuous, of course. The issue had been clearly marked \"out of scope\" and demoted to \"informational\". IMO that should be fair game to discuss *publicly* at that point, yet the researcher only contacted other companies impacted -- companies that were evidently more cooperative, as he ended up earning $50k from Zendesk *customers.*\n\nAt that point, the right move would be, first, for Zendesk to apologize and pay out an appropriate bounty. And second, if they wanted to distance themselves from H1, that was their opportunity -- instead, they essentially doubled down on H1's absurd policy of allowing companies to reject reports, but sit on them anyway.\n\nYes, it's a HackerOne person replying to him, not ZenDesk. I imagine they have a policy against SPF/DKIM/DMARC issues because of [beg bounties](https://blog.redsift.com/email/dmarc/what-is-a-beg-bounty-how-to-avoid-paying-out-for-dmarc-vulnerability/) which lead to a lot of noise. Unfortunately it also caught a legitimate vulnerability here. This part I'd say is not on ZenDesk, that's just kinda unfortunate.\n\nIt wasn't on Zendesk until Zendesk learned about it, and decided to double down on HackerOne's view on this. https://support.zendesk.com/hc/en-us/articles/8187090244506-Email-user-verification-bug-bounty-report-retrospective\n\n&gt; Although the researcher did initially submit the vulnerability through our established process, **they violated key ethical principles by directly contacting third parties about their report prior to remediation**. This was in violation of bug bounty terms of service, which are industry standard and intended to protect the white hat community while also supporting responsible disclosure.\n\nIn reality, if you outsource certain responsibilities to a third party, you cannot claim \"it's on the third party\". It's like claiming frivolous actions of Delta gate agent or flight attendants aren't on Delta. Sure they are. They act as an agent of the business, and are collectively responsible for the outcomes of their actions. \n\n\n&gt; This breach of trust resulted in the forfeiture of their reward, as we maintain strict standards for responsible disclosure.\n\nYeah, and this lack of care for security resulted in multiple Zendesk customers leaving, as they maintain strict standards for responsible disclosure.\n\nWhile beg bounties are clearly out of scope, this wasn't one. Thread forwarding is at the core of Zendesk's business. Zendesk &amp; HackerOne fucked up.\n\nGrim. It's frustrating because the loss of business was cost by HackerOne, not the teenager. Zendesk are a big enough company that they should pay the bounty and promise to discuss appropriate escalation with HackerOne. Would be cheaper than losing another couple clients, which this could easily do.\n\nYes, agreed\n\nI can't believe this is getting upvoted, it is so blatantly wrong.\n\nThey outsource the bug bounty program to HackerOne, and say we only want these specific things to be checked. There are a ton of reasons for this, from preventing people from spamming production servers, causing glitches, etc. You set a parameter list of what you want to be researched and exploited, and that's the only thing you want people to be looking at. This exploit should not have been tested from a white hack perspective, full stop, the author is in the wrong, regardless of how big or small of a vulnerability this was. This was not in the defined list, and people like this is why so many have continually limited what you can look at and going after those who can't, because you can't stay within the tape. This isn't even about sending out to the customers which was also VERY wrong as those customers can now literally use that to go and attack their competitors.\n\nAs he did find it, breaking the entire point of HackerOne, and he did want to report, he needed to escalate it to zendesk's internal team, NOT through HackerOne, and DEFINITELY not through customers.\n\nHackerone isn't in the wrong, zendesk isn't in the wrong, the author is 100% in the wrong. He broke every single rule imaginable. Now, it's great that he found it and he did need to forward it to ZenDesk, and if he had simply done that I'm sure he would have gotten compensation, but now he caused damage to EVERYONE involved.\n\nI don't care this is going to get downvoted this is actual insanity. HackerOne did it's job correctly, ZenDesk didn't like that the exploit was leaked to people who COULD then abuse it. This is so wrong on every level\n\nSorry, stiffing me on the bug means that confidentiality is now out of scope.  TYVM.\n\nNice job. He will get far. I'm rooting for him! :)\n\nIs that really a 15 year old?  Outside the the headings, it's like GTP wrote it.\n\nI don't think writing this text is beyond the capabilities of a smart high schooler.\n\nI'll reverse my position.  I read it further.  Later in the article the grammar and punctuation began to matched what was in the headers. The punctuation and grammar of the first couple paragraphs threw me.\n\nWhat have they got against SPF and DKIM? Do they want spoofed emails?\n\nZendesk isn't responsible for `company.com` SPF and DKIM\n\nBut they also don't have to accept emails that didn't pass.\n\nBut they did pass. that's why the fix is to properly enable SPF/DKIM/DMARC, so that mail doesn't pass. There are \"allow all\" settings that would let spoofed mail pass or various other ways a company could ignorantly allow spoofed mail.\n\nAs per https://support.zendesk.com/hc/en-us/articles/8187090244506-Email-user-verification-bug-bounty-report-retrospective\n\n&gt; Although the researcher did initially submit the vulnerability through our established process, they violated key ethical principles by directly contacting third parties about their report prior to remediation. This was in violation of bug bounty terms of service, which are industry standard and intended to protect the white hat community while also supporting responsible disclosure. This breach of trust resulted in the forfeiture of their reward, as we maintain strict standards for responsible disclosure.\n\nThat isn't what happened at all. Researcher disclosed it, and it was responded to as informational. That's done then, ZenDesk have decided it's not important now.\n\nThe next thing the researcher did was discover a full supply chain attack, which utilises this bug. The original bug hadn't changed at this stage, there was nothing new to disclose. What had changed was specific companies' implementation of different software suites leaving them vulnerable. It would be immoral at this stage not to disclose that vulnerability to those companies.\n\nMaybe ZenDesk are right in their mind that this bug wasn't a big deal (they're not). But there was also an exploit with Slack OAuth here as well, which also got off scot-free. Both of those on their own might be insignificant to vendors, but when combined and presented to a company using both platforms, it does become a big risk for them.\n\nTechnically the researcher can still attempt to escalate this issue via in-band methods(HackerOne), before actually disclose to the search party.\n\nThat was a good read.¬†\nFvck Zendesk lol\n\nThis is crazy since Zendesk is a publicly traded company. Unfortunately, this is not the first time that I see this sort of thing. A lot of this larger companies with old outdated infrastructure, need to get their act together. With the whole AI revolution, it's the perfect time to disrupt some  of the dinosaurs out there.\n\nIf all that comes out of this a $0 bounty he should consider himself lucky.¬† Writing a script to commit Felony Unauthorized Access is not something I would do.\n\n\n&gt;¬†The wording of the CFAA is¬†so vague¬†that prosecutors have been able to successfully abuse the law to convict a wide array of offenders. Under federal law, the penalty for hacking includes high fines and sentences of up to 10 years of prison time.\n\nThen white-hat is probably not a career for you.\n\nI think you are naive about what the law is and how little good intentions matter to a US attorney general.  I think people on Reddit should remember what happened to Aaron Swartz.\n\nIn the US if you don't have consent to log into someone else's computer system that is a violation of the CFAA.  Which is what using an exploit to logon to a Zendesk's client's Slack without permission is.  \n\nDoesn't matter if you are hunting bug bounties, or even if someone emailed you a user name or password by mistake.  If you do not have permission to connect to someone else's system that is illegal.  Zendesk's clients are not participating in the bounty so that certainly doesn't qualify as white hat hacking anyway.\n\nHonestly, I kind of expected better from r/programming."
  },
  {
    "title": "Stack Overflow Survey: 80% of developers are unhappy",
    "body": "",
    "score": 1083,
    "url": "",
    "created_utc": 1726873422.0,
    "author": "fagnerbrack",
    "permalink": "/r/programming/comments/1flp3xt/stack_overflow_survey_80_of_developers_are_unhappy/",
    "all_comment_text": "For me it's the tech debt that's really bringing me down. We also have so many services and getting them up and running is such an annoying experience. So many things can go wrong and it can take hours of debugging just to get the service up before I can actually start doing work. It's painful and exhausting. I also think we are expected to do so much more and our responsibilities have increased from 4 years ago.\n\n[deleted]\n\nMicroservices need to die. 99% of the time it's the wrong architecture.\n\nFortunately 99% of the time it also isn't even micro services. It's just regular old services but someone threw the word 'micro' in front because it sounds cool\n\n[deleted]\n\nDon‚Äôt forget to serialize and parse the JSON!\n\n...that is in a different micro service\n\nhttps://youtu.be/y8OnoxKotPQ\n\nWe should all be lucky if they were only microseconds.\n\nSOA is a valid architecture style in my opinion, and definitely seen people for some reason stamp them as 'micro'.\n\nYeah, I have no problem with SOA. I don't have a problem with microservices, just the over-application. It's a weird feedback loop where people build an SOA and call it microservices and then the next group thinks they have to do microservices.\n\nDoesn't help there's tons of people peddling books and courses and pitting it against monoliths as an either/or proposition =(\n\nAbsolutely this is the issue. We need to coin the term ‚ÄúAppropriately Sized Services‚Äù. Unfortunately it‚Äôs not a great acronym.\n\nSame with Scrum.\n\n\"Yeah we do scrum.\"\n\n-- six months later --\n\n\"It's been a tough six months of training but we do scrum too now.  How did you get around the inherent differences in values of story points between developers' different disciplines, and planning sprint velocities?\"\n\n\"What?  We just have short update meetings at ten o'clock every morning and use Jira.  What's all that other stuff?\"\n\nAlso 1 point = 1 day, what‚Äôs the problem? My scrum master said that‚Äôs agile.\n\nMicroservices are an organizational structure that derives specifically from Domain Driven Design.\n\nSo if your business and organization is a dumpster fire that is way too coupled together where your bounded contexts are not properly scoped in the org, Conway's Law WILL fuck you.\n\nBut absolutely no one gives a shit about this\n\nI love DDD as a concept, but realistically its a lot easier to implement an anemic monolith and only create reusable abstractions when absolutely necessary. It doesn‚Äôt give you the same satisfaction and there‚Äôs a lot of duplicated code, but navigating layers and layers of badly named abstractions that are reused everywhere is a lot worse in my opinion.\n\nmy last company, the senior engineers didnt know the phrase domain driven design, when i brought up the books on it. i was not a senior. but i did learn to be very disappointed in what they consider senior. they did \"microservices\": the context was split across 3 services. and they did it over and over again. but i guess if they dont know what a context is, or a domain... \n\nbest defintion ive heard it described is that a microservice should encompass, at its smallest, an entire subdomain within a context. so yea they put the \"notification\" domain concept across 3 different services and they were supposed to work together, it was gross and it wasn't just that one, it was all of them. team of like maybe 15 people, split up 4 ways, managing 60 \"services\". lol was too funny watching them struggle while i got to work on a different and also shitty system they built. that one they put all the domains in the same context, so yea we had a lot of login issues with the domains getting mixed up\n\nNevertheless, all the whining about microservices is misplaced.\n\nThe real problem is you're being judged on your productivity while being told to maintain code written by someone who got fired for being incompetent. You ask them to let you rewrite it and they say no. Instead, they lay off 50% of the staff because the oligarch in charge is bitter about software engineers earning money, and now everyone has to maintain 20 other people's projects.  How does that make any sense?\n\nYep, try working at a retail company to see Conway's law in action.  MBAs as far as the eye can see waging war by carving out micro services as a kingdom, where each micro service duplicates bits of functionality in other micro services that are owned by other MBAs.  Conway's law results in really bad architecture decisions driven by which MBA is currently loved by the head MBA.  Meanwhile engineers just stand there holding the bag listening to some MBA or another is yelling about how the latest set of \"disruptive\" change is turning out to actually just disrupt our business.\n\n&amp;nbsp;\n\nThe ignorance is so thick that no rational discussion can penetrate.\n\nYees! Let make microservices, services again ffs. I still use services:\n- file storage\n- notifications (email+sms)\n- whatever else which can work async\nNever got microservices, at least how \"the book\" advertises them.\n\nBut Amazon makes a lot more money if you have more lambdas. So if you‚Äôre a true patriot you‚Äôd use pico services to grow the US economy.\n\nSo this. I can just tell most of the time some manager wanted to sound all clever and down with the new buzzword...\n\nYou need teams of people and massive scale issues to even remotely justify it.\n\nIf there are a lot of buzzwords being used I automatically assume they‚Äôre an idiot\n\nI've had to have some interesting arguments with some developers about this. One of the things that's pissed me off more than anything is the desperate hiring of young developers as Architects or Devops engineers. Those are not entry level roles.  Devops is a training and standards role its not even a developer or infrastructure role. In both cases you need to have years of experience before you hold such a position. I have had to argue with so many young developers who just go with whatever buzzword they heard last week its exhausting. I've had architect argue for microservice architectures for small teams that are working on potato's for laptops that aren't even able to support a docker instance or even run multiple instances of an IDE. They have no experience writing proper code because they cant be bothered to read a book on design patterns but they treat anything they read on reddit like its gospel.\n\nDevops Engineers m, in my experience, come from either software engineers or traditional Linux admin roles. It isn‚Äôt an entry level role. I had to explain to an engineer how DNS and subnetting once worked‚Ä¶\n\nOne of the best design decisions I took was specifically about solving this particular issue when planning the architecture of the start-up I work at.\n\nWe do have a lot of services, and an acyclic DAG of dependencies, and I knew it would be the case, thus central to the design are two key decisions:\n\n 1. Services are discovered via a registry -- nothing outstanding there -- and there is a simple way to bring up a local registry which mirrors the production one. This means local services register to the local registry, but will otherwise subscribe to _production_ services.\n 2. Which would be widely unsafe except for the fact that all services are _multicast_. Subscribing to a service doesn't involve sending one bit of data, and in fact services do NOT poll the connections they serve: they only send. Therefore, no matter who the subscribers are, subscribers cannot interfere with the functionality of the service, and scaling is effortless as all computed packets are simply sent to all subscribers.\n\nAs a result, locally running a service is just a two-steps process:\n\n 1. Launch the local registry, which makes a snapshot of the production one then receives notifications on change.\n 2. Launch the service you're interested in, it'll subscribe to whatever production service it needs.\n\n(The local registry also supports \"local first\" so you can run two local services and have the first one service the second one, useful to test non-local changes)\n\nI feel very lucky that this design worked for our business case, as I plainly realize it doesn't suit any request/respones model...\n\n... it's really such a comfortable design to work with.\n\nmicroservices without IaC is regarded. you should be able to spin up whatever you need by running an ansible playbook or two...\n\nIt‚Äôs simple af. I haven‚Äôt run a single service instance in 3 years. \n\nFor those who need starting up services for their development I‚Äôd recommend docker-compose or custom script that pulls and runs docker image or clones repository, builds it and wrap sources in docker containers. Then you might set up a tunnel from your local machine to staging environment database and start development - v‚Äôoila! Downturn is that companies have different network security policies and might not allow you to establish ssh connection with port forwarding to any machine. Another downturn is that you might screw staging database when executing migration scripts. You have to be very cautious.\n\nWhat I prefer is writing ‚Äúpseudo‚Äù integration tests that starts up service with test context (like spring does) and provide stubs for external services calls.  \nThere are libraries like test containers that allow you to setup production-like infrastructure in matter of seconds. You just try to call your services API or emit an event your service is meant to consume and see the results. That‚Äôs basically it.\n\nThe foundation of tests are of course unit tests. With approach from above you can ensure yourself that at least your service starts up flawlessly and communicates with services properly using stubs that matches stable service‚Äôs API at the moment of development. \n\nThere‚Äôs also option to write contract tests.\n\nTech debt. Undocumented tribal knowledge and the cognitive exhaustion. At the age of 55 and 30 of which as a developer I‚Äôm fucking cooked.\n\nwait until all your documentation switches from confluence to xwiki\n\nEveryone I know hates confluence.¬†\n\n\nJust use .md files in the repo it is documenting.¬†\n\n\nMaybe publish those .md files to a static website via CI.¬†\n\n\nBut fuck paying a dime to Atlassian.¬†\n\nOh man this hits home. We have three different versions of the wiki now. Wiki, new wiki and then now it is notion. ..\n\nCaveat that I'm in data science not software engineering...\n\nBut yeah this completely drags me down in my job. We only started working in RAPs using python last year shortly after I joined by giving the org no choice despite our managers kicking and screaming about doing things in the way 'theyve always been done.'\n\nOrg went from dealing with basically two (large) operational delivery streams 10 years ago to 20+ in the last two years, but they didn't hire 20x more people to sort out our data architecture or infrastructure during that. Total dinosaur if an org and I hate that we have to spend every day fighting for something that should just be small innovations. \n\nUnfortunately it's unlikely things will change until the top managers retire or resign, but then those people never do documentation so when they go the institutional knowledge base goes with them. \n\nWe'd essentially need a year-long pause on our operations just to fix the shitshow of data and infrastructure currently happening, and even then it'd be unlikely the org would listen to the people who know what they're doing. Executives would probably hire external consultants to upsell them on a worse solution that *sounds* impressive but is garbage in reality and will be abandoned within 5 years when the contract expires.\n\nSimilar numbers to you, 56 and 30+ years dev, I only work on projects where I control pretty much everything now, I found working for companies as an employee there was continuing role narrowing. \n\nI now freelance, do a lot of dev but like being an architect as well, so looking at the big picture for my clients, much more rewarding than being handed maintenance work in projects that have had so many hands in them its spaghetti code.\n\nI choose my tools, languages etc.\n\nIf the problem was accumulation of undocumented tribal knowledge, wouldn't being older be an advantage? You were there when the Deep Magic was written.\n\nThis is true for one of the divisions I worked in but recently moved into another division because of the work I did in the previous with respect to turning it around. The one I am in now is a complete nightmare. There are a few times a week where I just sit at my console and ask what the fuck were they thinking, were they thinking‚Ä¶ and then I get introspective and remember the days where I did things just to get it across the line.\n\nI just got switched from working on a Ruby monolith to a different section of my company that is a patch work of TS services in various frameworks (whichever one was hot when the service was created). \n\nI miss the monolith.\n\nMonoliths are super underrated. I use something called the Vertical Slice Architecture. I fucking love it. It‚Äôs like best of mircosevices and best of monoliths combined.\n\nI do prefer feature slices too even though cross cutting concerns still exist.\n\nIn my view the problem is one of power balance. In other industries, the practitioners also manage (lawyers law, civil engineers engineer, and the managers are from the same discipline). Not so much in software engineering.\n\nSoftware engineers are relegated to coding. This is not where the power nor the value lies. That is in product roadmaps, operating models that optimise for delivery (and for keeping the house in order!), etc.\n\nI would argue that the vast majority of software engineers could skill up to do these things. Further, I would argue, is that it‚Äôs asymmetric (people who are only skilled in these other things will find it very difficult to skill up in coding).\n\nSo in my view the solution here is the skill up and tilt the power balance. It‚Äôs not as hard as it looks and it worked for me.\n\n[deleted]\n\nInteresting! I‚Äôve seen in tech for 20 years. Started coding at age 10 (I‚Äôm now 46). I never made any attempt to move into Big Tech because I heard it was all red tape. Not so?\n\nIt would be naive to expect there are no downsides; but then, if you look at these Big Tech US companies, none of them had no engineer in the top of the food chain at one crucial point or another.\n\nMost of them still have. And as much issues people see with Musk, he once said a very interesting thing: He rejects applications from ‚ÄûMBA parachuters‚Äú, I just love that term.\n\nI agree in general, but I think a lot of the time it's not that experienced developers are \"relegated\" to coding. That's where they want to be. I've seen many developers advance into more management-type positions and most of them don't like it. The code is what they enjoy while their new roles feel like endless meetings. A good number I've seen go back to 'senior developer' roles because that lets them write code while still having some authority/respect.\n\nHow often do we see people on this subreddit complain about having to attend meetings when they could be doing 'real' work? But if you want to go into management and get power within an organisation that's what you have to get good at. Talking to people, presenting things, etc.\n\nI agree that the solution would be for developers to skill up and go into management. I agree that the vast majority of software engineers could skill up to do these things. The problem is that most of the time, they don't want to.\n\nYep, agree 100% with this. Valid observation.\n\nWhat you are saying is interesting because I think devs may have a chance to turn the tide.\n\nArmed with knowledge of a product domain, software development experience, and a good command of AI tools, devs are in a position to be real disruptors in the next few years.\n\nThere are so many top heavy bureaucratic organizations out there that are mired in process and meetings and deliberations over trivial matters.\n\nA nimble team of devs with the aforementioned skills and tools could lap much larger organizations very quickly, produce modern MVP‚Äôs and gain traction with customers.\n\nExactly. Also, with regard to process, engineers are well-positioned to know what needs to be known by whom and when. I have personally stripped down operating models and streamlined delivery.\n\nYou can not do that if you don‚Äôt know what should be being dealt with and in what order.\n\nI can‚Äôt emphasise that enough.\n\nTrue words that cannot be repeated often enough these days.\n\nSupervisory Developers is where it is at.  You get to do architecture level, deal directly with clients, and thus have a foot in the game.\n\n[deleted]\n\nI think a lot of companies don't even have QA anymore. That responsibility has been placed on the engineers.\n\nMy company introduced \"shift left\" thinking, wanted devs more in the testing process with the QA engs, and then fired all the QA engs.\n\nI usually prefer to do the demo myself, instead of QA.  \n\nIt's cringe to see QA explaining how a feature works.\n\n[deleted]\n\nYou leave the company with tech debt just to go fix tech debt at another company.  \nIt's the cycle of life.\n\nFear not! We will create some stories and tasks around this in the next four hour Agile refinement session!\n\nmy friends call me stupid because i just want to self host everything and always start of with SQLite and only if i absolutly need it go for a \"DB server\".  \n  \nI miss the old days when I could just upload an Access DB file to my ASP host and then hit refresh.  \nI don't need docker (I know how to make shit work on a Linux server) and think that it's insane I don't use GitHub actions... ma dude I'm just making a landing page for my mom (with a small CRUD system)  \n  \nnotepad++ (with the FTP plugin) gang rise up\n\nThe only way I've found to keep tech debt manageable is:\n\n- Have exclusively competent devs\n- Use very few 3rd party dependencies, implement most everything yourself\n- Do reasonably strict code reviews\n- Either plan effectively or use a language that lets you remain 'nimble'\n  - I literally mean use something like Clojure if you can't predict your future requirements\n- Prototype fast and often, but actually throw the prototypes away\n- Actually take some time to beat down accumulated tech debt occasionally\n\nFocus on your actual problems instead of digesting marketing bullshit. \n\nDevelop a strong code review culture.\n\nAttempt to solve problems completely instead of ignoring the root causes.\n\n&gt; Attempt to solve problems completely instead of ignoring the root causes.\n\nThis one's my favorite, although I think it works best when you have different types of people on a team.\n\nOne of my colleagues really does complete all sorts of tasks very quickly in a way that makes management very happy, but boy is he sloppy when it comes to root causing issues.\n\nI'm overly methodical, and I hate to walk past something behaving unexpectedly without understanding why it's doing what it is, because I know it's going to randomly bite us in the ass later. But I know I'm slower than the average dev for it.\n\nIt's good to be part of a team where other people can shore up eachother's weaknesses.\n\n&gt; Use very few 3rd party dependencies, implement most everything yourself\n\nI couldn't disagree more.\n\nThere is no way you can build a good product without tons of very high quality frameworks and third party tech.\n\nReinventing the wheel always sounds and feels good in the short term and it's always a disaster in the long term because of ownership and maintenance.\n\nIn a startup environment, you just never get enough resource to maintain the source code in a manageable state.\n\nIn my experience, you only need a handful of libraries and frameworks to build the core of your software around. So if you're using \"tons\" of third-party tools you are almost certainly using them for situations where you do not need them\n\nMany devs underestimate the extra costs that come with third-party tools. There is a cost to relying on code that you do not control\n\nI half agree, I definitely don't want to be inventing the wheel myself if I can avoid it but at the same time I'd consider alternative solutions before adding *another*  library. I mean, if I can solve the problem with the existing (standard) libraries by changing my approach to the problem, then I prefer that\n\nEvery single dependency you add bitrots if you let it sit long enough. Frameworks, doubly so. \"fast moving\" or shiny new frameworks 10x so. The best way to *reduce technical debt* is to not use frameworks and minimize the use of 3rd party libraries by choosing languages with strong standard libraries like Go or Clojure. Moving fast vs sustainable are mostly at odds with each other. You will almost always end up in a better position if you (or really, your team) actually understand all of the code you run. There are some cases where there's a really hard problem where correctness is critical, in that case choosing a library is the right choice. Some off the the top of my head: HTTP parsing, basically everything in numpy, scipy, and scikit, and almost any cryptographic library. Most other things are just... customizing to your particular needs which is either you know your problem or you don't. Most people wildly over-estimate the time savings from *not* implementing stuff yourself and underestimate the maintenance overhead in the long run and the artificial constraints you put on yourself.\n\nTo be clear, I'm not saying you should take this approach, I'm saying this is the approach you *must* take if your goals are to minimize the accumulation of technical debt. Simpler code is almost always better (as long as it still solves the problem), and dependencies add more complexity than *just* the code that make them up.\n\nI feel Scotty‚Äôs advice kicks in here - captains are like little kids, they don‚Äôt know what they need, they just want things and they want it now.\n\nSo, don‚Äôt lie, but Scotty wasn‚Äôt telling Kirk about the absolute hackiest barely defensible solution that might work, he gave him more expansive projections and estimations that accounted for time, maintenance, and overall ship and system health. ¬†\n\nDiving at the main reactor with duct tape is not plan A, management doesn‚Äôt hear that compared to a reasonable plan that costs twenty times more. That‚Äôs a misleading estimate. Scotty cares for the ship and his whole duties and gives holistic estimates that reflect management. ¬†They get a total cost estimate and judge from there.\n\nSo, no, we‚Äôre not gonna loosely discuss sustaining problems that are crippling us. ¬†We‚Äôre gonna factor the ‚Äúfix that shit‚Äù cost into our work so we‚Äôre more efficient. ¬†If fixing shit is too expensive we stop, we don‚Äôt spend our nut pretending. ¬†\n\nInstead of addressing the technical problems you can create another service! /s\n\nWhat got me was the accumulation of technical debt, but also what it represents: a business culture that prioritizes pointless milestones and useless features, with an eager willingness to have the people doing the real work suffer, because we don't matter.\n\nTechnical \"debt\" is a bit of a misnomer. It's never going to go away. The exponentially accruing interest is going to be paid in developer suffering, which the ones ruling the roost have an infinite willingness to tolerate because it's not them.\n\n&gt; *Technical debt is the number one cause of developer frustration*\n\nTechnical debt is the consequence of not having a proper software development process in place. The agile cult has axed requirement engineering, design/architecture, and conveniently forgets about refactoring (an XP practice). Having to improvise all those activities at the developer desk and being pressured to churn out complete features from the UI to the data layers results in the worst code possible. \"Agile\" has made two generations of developers miserable.\n\nIf your responsibilities don‚Äôt increase over a 4 year period, you‚Äôre doing it wrong\n\nNew technologies in software development do not bring about less work but more demand. As technologies progress we are able to implement more features at a higher quality with fewer bugs much more quickly...assuming you've been able to properly maintain an up to date tech stack with relatively little tech debt. But the business doesn't see that. They see what other companies are able to do with an application lifecycle that is not synchronous with yours using technologies that actually make development much quicker and sometimes utilizes good vendor solutions to offload work at a cost. The bottom line is they are comparing apples and oranges and not understanding why they can't make them taste the same. There is a cartoon I keep in my office and every time a project manager argues with me about prioritizing tech debt I point to it and have this conversation. Most of them don't understand it and sometimes they don't have a choice they are just communicating what was already dictated to them and are all to willing to ensure any failures to meet unrealistic expectations fall onto the means of production and not the business. Short-Term gains are embedded into corporate culture and any publicly traded business is going to always improperly prioritize for the long term every single time.\n\nThey want Devs to also be QA and DevOps¬†\n\nYes. When layoff or people quit position is not filled. That‚Äôs wats up.\n\nFar out in the uncharted backwaters of the unfashionable end of the Western Spiral arm of the Galaxy lies a small unregarded yellow sun. Orbiting this at a distance of roughly ninety-eight million miles is an utterly insignificant little blue-green planet whose ape-descended life forms are so amazingly primitive that they still think digital watches are a pretty neat idea. \n\nThis planet has‚Äîor rather had‚Äîa problem, which was this: most of the people living on it were unhappy for pretty much of the time. Many solutions were suggested for this problem, but most of these were largely concerned with the movements of small green pieces of paper, which is odd because on the whole it wasn‚Äôt the small green pieces of paper that were unhappy.\n\nAnd so the problem remained; lots of the people were mean, and most of them were miserable, even the ones with digital watches.\n\n--Douglas Adams\n\nThe story so far:  \nIn the beginning the Universe was created.\nThis has made a lot of people very angry and been widely regarded as a bad move.  \n\n--Douglas Adams\n\nPerfect timing for that passage, lovin' it.\n\nHahaah amazing\n\nIt sounds like you may not have read The Hitchhiker‚Äôs Guide To The Galaxy.\n\nIf this is the case, stop what you are doing and go to a bookstore.\n\nNow.\n\nI‚Äôll wait.\n\nThis is the one book I highly recommend the audio book over. If you havent listened, go get yourself some Stephan Fry goodness in you rn\n\nDid you try listening to the original BBC Radio version from back in the day? It is also on audible pretty sure. \n\nDouglas Adams wrote that radio show before turning it into the book I think. Personally I consider it the best version. Worth listening to it. The cast is amazing.\n\nPrevious discussion, last time it was submitted\n\nhttps://www.reddit.com/r/programming/comments/1egheo6/why_are_80_of_developers_unhappy_at_work/\n\nTL;DR The article is simply lying.\n\nThe actual results:\n\nNot Happy at Work 32.1%\n\nComplacent at Work 47.7%\n\nHappy at Work 20.2%\n\nIt's not lying, 80% are !happy :D\n\nAnd 68% are !Unhappy :D\n\nIt's the glass 80% empty or 80% full dillema. The author is 80% empty kind of guy :D\n\n`unhappy !== !happy`\n\nThe problem, as usual, is goal alignment. Most developers (probably the 80% mentioned in the article) want to do work they can be proud of. Most of their employers want them to do work with the highest monetary value. These goals are almost never aligned.\n\nThose goals should not be mutually exclusive, but they often are because neither knows what produces monetary value. Most of the time no-one even knows what the users of a product even find valuable\n\nAs a developer I find it awful to work on a product when I have no idea who actually uses it. I want to know who it is that I'm doing this for. It's a shame that so many managers/scrum masters/product owners don't see the need to talk about the people that use the product I create\n\nFeeling this right now. Have a parallel go live in a few weeks and we're still developing. I'll be developing for at least 2 more weeks. Way to close for comfort for me. Dead lines should be more flexible\n\nits not that hard to write good code. its literally when people don't stop for 5 minutes to think things over or roll with the first idea that pops in their head instead of  contemplating a bit that mess gets spawned\n\nWhile at my previous employer, when asked, I used to tell people I love my work, I just don't like my job.\n\n[deleted]\n\nInclude asshole colleagues who do none of the work, but want all of the credit\n\nColleagues send email and schedule zoom... Do none of the actual work\n\nNext standup: YEAH I WORKED WITH BLORB AND ZARP ON THE XYZ THING\n\nworked with? Dude you didn't do anything\n\n[deleted]\n\nnah I always answer honestly and fuck their numbers, I know they can identify me, but honestly, there's so many yes men in this industry, it's worth saying no sometimes.\n\n\nit might not do anything, but honestly they also won't fire you, unless you were a sore point already to them.\n\nI can't say it's beneficial to do it, since I didn't see any significant change, but it also didn't stop my promotions at least\n\nIt got me fired a lot\n\nthat's unfortunate and I guess the lesson here is that not all companies are the same and I guess I've been lucky\n\n&gt; Also, \"anonymous\" employee satisfaction surveys sent by employers are bullshit, especially those with a unique link sent to each separate email address.\n\nHaving sat in on the other side of those from a management perspective at a large 20,000+ person FinTech company, a lot of them really are anonymous. We used a number of different tool and each of them didn't give anyone individual data. Those links were just to avoid stuffing and there wasn't anything we could extract. \n\nHow do I know this? One of the executive leaders was incensed when someone called them out directly and demanded to know who it was. The only thing the team behind it could get was the 200-ish person department the comment came from. \n\nAll that said, you're spot on about the fear aspect. I've had to coach my teams to really, truly be honest on them and that if any of them got in trouble for something they said, I'd quit on the spot.\n\nNow, this part is totally company dependent, but for that gig, those areas of the business with lower \"engagement numbers\" had their managers grilled hard about what was going on and why it took a survey to expose the problem. We were all expected to have a finger on the pulse, so when people complained about pay, working hours, the company direction, not feeling engaged with the team, we took the heat for not bringing it up to senior/executive leadership sooner. So my experience with them is less toxic than others.\n\nAnd what percentage of other employees are unhappy?\n\nAbout half are \"highly satisfied\": [https://www.pewresearch.org/social-trends/2023/03/30/how-americans-view-their-jobs/](https://www.pewresearch.org/social-trends/2023/03/30/how-americans-view-their-jobs/)\n\nSounds a little high tbh but idk\n\n[deleted]\n\nI agree with the interchangeable aspect, but not so much the \"do the work you feel is appropriate for your salary\" stuff.¬† ¬†If you are intentionally under outputting and not challenging yourself during work hours,¬† I think this would lead to less satisfaction. How could you be proud of yourself and your work? And you won't grow as much\n\n\nAlso why would anyone see you as a programmer worth $X when you only ever output at $X - Y? Becoming a better programmer benefits you first and the company second, because you can take your skills to another company the second they are valued more¬† elsewhere.\n\nIf you do that, you'll keep getting replaced by developers who got fooled by the corporate bullcrap and tow the company line, regardless of your skills or \"unreplacability\". And every time you get replaced, your position on the job market weakens, until ultimately you'll have to compromise on the salary or have to do work that genuinely upsets you.\n\n[deleted]\n\nSee this, 80% of developers are unhappy, decide to google what the happiest profession is. It's software developers, apparently.\n\nLife is pain.\n\n[deleted]\n\nThat sounds amazing tbh, I‚Äôll love for an arrangement like that.  Can never have enough time.\n\nDoesn't that make you feel lonely?\n\nDon't you have friends and hobbies outside of work?\n\nA man went to the doctor one day\nHe said, \"Doc, I, I don't know what to do\nI don't know who to talk to, I'm completely depressed\nI don't know what to do with my life, it's full of uncertainty\nI wake up every day until\nI just, I can't see a light at the end of the tunnel\"\nAnd the doctor said, \"Well, it's great that you came in today of all days\nBecause the Great Clown Pagliacci is in town\nAnd he has a show tonight and nobody ever goes to his\nHis live performance and doesn't leave\nYou know, completely full of life\"\nAnd the man burst into tears and the doctor said\n\"Well, what's wrong?\" And he said\n\"Doctor, I am the Great Clown Pagliacci\"\n\n&gt; *Remember when you were young, you shone like the sun. Shine on you crazy diamond.*\n\n&gt; *Now there's a look in your eyes, like black holes in the sky. Shine on you crazy diamond.*\n\n&gt; *You were caught on the crossfire of childhood and stardom, Blown on the steel breeze. Come on you target for faraway laughter, Come on you stranger, you legend, you martyr, and shine!*\n\n&gt; *You reached for the secret too soon, you cried for the moon. Shine on you crazy diamond.*\n\n&gt; *Threatened by shadows at night, and exposed in the light. Shine on you crazy diamond.*\n\n&gt; *Well you wore out your welcome with random precision, Rode on the steel breeze.*\n\n&gt; *Come on you raver, you seer of visions, Come on you painter, you piper, you prisoner, and shine!*\n\nCrying with money meme\n\nDoesnt surprise me that people code outside of work. I used to work in VFX the artists almost always did art outside of work because an \"artist\" in VFX isnt really doing art at work, they're just a technically gifted tool to implement someone else's art. Same sort of thing is probably true of programmers\n\nI started to code for fun semi-recently and honestly it's been great for my mental health. I was starting to think I hated programming, and was in a slump because of that.\n\nPicked up typescript, taught myself how to animate and do fancier stuff with CSS, made some NLP stuff, and modded some games made in unity. Just did whatever the hell I wanted, at my own pace, no deadlines, no pressure.\n\nIt's easy to get caught up in the \"programming is work and I don't want to do any of it in my free time\" mentality, and then slowly let your job drain any and all passion you ever had for it.\n\nYes. This is why I try not to let any hobbies become my actual job - it would change from an interesting pastime into something I hate, and that someone else is driving the process/schedule/methods.\n\n&gt; Crying with money meme\n\nHonestly I think it's really 80 percent of people are underpaid. \n\nI was working government contracts, switched the a FAANG.  Went from heavily underpaid (about 160 for Orange County California) to extremely well off. \n\nI'm glad I made the change, but there's a LOT of programming jobs that tried to low ball me in the 170-180 range, for Senior and Staff positions.  Fuck 'em. \n\nBut also REALLY fuck those who are asking under 150k for SENIORS.  I saw one who said the range was 75k- 120k.  I know we just had that big tech layoff, but seriously go fuck yourself.\n\nPS. Third party recruiters who lowball offers also can get fucked.\n\n(And I know \"money doesn't buy happiness\" but man it has solved a few problems already...   And Knowing you're making 30-50 percent less than you should, doesn't help your mood)\n\nUnderpaid for the sector and position? Maybe. Underpaid compared to the average worker? Hell no. The lowest engineer salaries in my country are around the average, which doubles the minimum wage many workers get\n\nI like my job but I don‚Äôt code outside of work.  Sitting all day in front of a computer. Why would I want to do that when I am off ?\n\nBecause you like it. You like coding, having intellectual challenges, and you like making products, and selling them, and creating a community, and a startup, and making people happy, and making extra money.\n\nIf you don't like any of those, well...\n\nI‚Äôm in this camp. I have somewhat accepted that my coworkers will always be the ones introducing new things they‚Äôve discovered because I just‚Ä¶ don‚Äôt really care?\n\nLike don‚Äôt get me wrong I enjoy the work I‚Äôm doing and am down to struggle through the downsides for the salary I‚Äôm being paid. I‚Äôm also not going to disengage from the real world for longer than is absolutely needed by my employer.\n\nWow, that was a great point of view!\n\nI couldn‚Äôt have put it better\n\nI code outside of work all the time. At work I just don‚Äôt seem to scratch that itch\n\nThe funny part is when the product team is asking developers how the product works. It can go as far as asking the developer to write a specification on it. Question: isn't this your fucking job? How come product \"managers\" have become so lazy and useless? Their ticket description are atrocious. We, developers, are expected to write a design doc, get it peer reviewed,  while products just slabs two sentences without even thinking about existing functionality. Because, why not, the developer will figure it out. And how come you are so attracted to shiny things? Shiny new feature and the product is there like flies around shit. Old defects in the product, and they are nowhere to be found. How about opening the product sometimes, testing it out, improving old features? Ever heard of quality? No. Because all you do is for show and nothing else. Fuck you, product \"managers\".\n\nOr engineering \"managers\" that \"manage\" teams, are like politicians. They talk a lot but do shit. It's funny when a manager that doesn't come to dailies or has any idea what you are doing, starts giving you feedback on what to improve, says that the dev does \"easy\" tasks, and then somehow decides our salary increase. When is this shady, snaky, behind-the-back behavior going to stop? Why are many of you so fake to the developers you are \"managing\"? Again, fuck you \"managers\". \n\nAnd guess what, who gets the praise for work done. Of course,  the product team and the engineering managers. They kiss each other's asses in their Slack messages, \"Hey, Bob, Steve, nice job, what a nice feature delivered! Great leadership! Kudos\". Kudos my ass. In reality, the developers delivered it from specification to implementation.\n\nConclusion: fuck you, managers!\n\nBravo! üôå\n\n[deleted]\n\nYep - I‚Äôve been a developer for many years I‚Äôve also been a scrum master - after about 3-6 months when the team understand how to be self managing and they ‚Äòget it‚Äô - the scrum master role needs to die but some companies keep it a full time role and you basically sit around bored trying to look busy. It‚Äôs a horrible role in a full time position. Lots of pointless meetings that even I was bored at but had to because ‚Äòthe scrum guide said‚Äô.\n\n[deleted]\n\nCould you imagine if we got to all use our genius for good? Imagine the world we could create.\n\nInstead we are all implementing some sort of rent seeking behavior for some wealthy shareholders. We have completely lost the point of the story.\n\nThis is something that I hate about software development.  \nIt's a race between companies for money.  \n\nIf we would join forces to create a \"global\" solution for each problem, the Earth would be a better place. Instead, we have thousands shitty solutions for each problem.  \n\nIt is the same with countries and governments. Each country has its own systems and platforms, when it could've been a global/common one..\n\nYeah. It is the idea that everything needs to be a competitive advantage to someone or some company.  As if the new ERP system is going to change the world.  When really it will just reimplement the same things your competitors are trying to reimplement.  And any kind of shared knowledge is captured by a few massive suppliers.  \n\nI think a country scale payroll and timesheet system would be brilliant.  Record when people are working, how much they are paid for that work, if it is overtime etc.\n\nSame. From 2013 to 2023 I worked at multiple payment companies doing the same exact thing. I left the payments industry bc there is 0 innovation. Just trying to undercut the other guys with the same exact integrations, same business plans, same vc money all trying to get pennies on each other.\n\nWhat a pathetic use of time.\n\n80 percent of people who took the survey...   \n\nSo really who knows.  I doubt I'd take that survey.. but I also wouldn't hang around on Stack Overflow, seems like a miserable place... wait a second that might be the problem?\n\nIt's worse than that this article is just outright lying about the results.\n\nThe actual results:\n\nNot Happy at Work 32.1%\n\nComplacent at Work 47.7%\n\nHappy at Work 20.2%\n\nOh that old \"Negative + middle\"... when literally \"unhappy\" is the negative responses alone.\n\nThis was posted before. And like before, the headline is clickbait and unrepresentative of the survey results.\n\nThe survey question that this references had three options:\n\n1. Not Happy At Work\n2. Complacent At Work\n3. Happy At Work\n\nGuess what the percentage for \"not happy at work\" was? Were you thinking it was close to 80%? Were you thinking it was over 50%?\n\nNope. It was about 32% (slightly higher for ICs at 33%).\n\nhttps://survey.stackoverflow.co/2024/professional-developers#3-satisfied-at-current-job\n\nI guess you could try to lump \"not happy\" and \"complacent\" together as \"unhappy\". But I don't think that's fair. The middle option is clearly meant to be a middle ground - neither happy nor unhappy. \"I'm just here for the paycheck.\"\n\nI am really kinda disappointment by the lack of critical thinking in this sub when articles state what people want to hear.\n\nAlso 100% of Corporate Executives **give ZERO fucks** if their coders are happy.\n\ntoxic managers, managers with next to zero it knowledge, lack of ownership/control, fear of layoffs, and long fucking hours.\n\nToxic managers - I endured a workplace bully and made my life hell. Management didn‚Äôt care and they lost me in the end - it was satisfying when the team performance dropped after I left though. Can have all the perks and salary but a shitty team and management can‚Äôt be overcome.\n\nI am always surprised by the lack of critical thinking about results that people want to hear on this sub.\nThe title \"80% of developers\" is already wrong. It is 80% of Stack Overflow participants who voluntarily decided to fill in a survey.\n\n&gt;According to the Workplace Satisfaction Survey, 80% of professional programmers are unhappy. One in three respondents actively hates their job, while almost half survive in survival mode. This leaves only 20% of those who claim to be somewhat happy. Although programmers are well-paid and often able to work remotely, many are still dissatisfied. Why is that so? \n\nSo actually only 1/3rd actually said they hate their job. 746% are in \"survival mode\" which seems a rather ambiguous term that could mean vastly different things. Ohw wait the survey didn't use that term, they used \"Complacent at Work\", which means something vastly different so the article is just lying. \n\nThe actual results:\n\nNot Happy at Work 32.1%\n\nComplacent at Work 47.7%\n\nHappy at Work 20.2%\n\nIt is actually very easy to make devs happy.  Give them autonomy, deploy quickly and frequently, let them focus on outcomes don't tell them how, ditch the \"sprints\".\n\nWell I rather be depressed than not being able to afford my childhood an asthma pump inhaler lol\n\nBecause 80% of my job isn't development any more. It's fixing shit for the dev ops team, then doing the PM's job and writing their stories. Then holding the hands of offshore because of course we're finding the cheapest most desperate developers on the planet to backfill all the people that were just laid off. \n\nThen the meetings talking about the politics of solving an issue, then talking about how to problem solve, then talking about what kind of steps we need to get to the problem solving part, then maybe another meeting to talk about the problem. (I forgot the meeting about finding out who needs to be in these meetings). Cool I'm ready to write some code...oh...the priority changed and we start over. \n\nThe environment is just exhausting. I just want to code.\n\nI like programming, but hate the industry. \n\nI was a developer for around 8 years and touched most languages in that time and then moved to management for 5 years (and hated that). Now moving back to a dev again but I find the landscape has slowly changed. SE‚Äôs are now expected to be a one stop shop; backend, front end, QA, stakeholder interface, scrum master, BA. it drives me nuts. How can one person possibly play all of these roles?\n\nBurnout ‚Ä¶.. it‚Äôs rife now. I left for a career break (which I‚Äôm now on) and slowly getting passion back for it again but it frustrates me how saturated the market is now and then the expectation to be an IT department.\n\nI don‚Äôt 100% like the stuff that I build.\n\nI'll be honest, I'm unhappy 100% of the time (at work), but I'm only like 80% unhappy all of that time. Does that still count?\n\nThis thread's numerous comments makes me start to realize how \\*I\\* remain happy as a developer. \n\nMost here refer to the word salad that has emerged like a parasite alongside the software development industry - Agile (and its various offshoots), various design systems demanded by people who have never written a line of production code in their lives, as well as tools claimed \"for organization and efficiency\" which really are layers of control that take precious hours from real productivity. \n\nThe bulk of my work looks the same as it would have in the late 90s - C#, sql and vbs/SIMPLE javascript, no chasing the latest language or tool - things are broken down to simple modular tasks that provide real impact to users and I enjoy doing them without external fuss. Modern annoyances such as Jira have entered life, but business analysts are the ones working with it more than I, that really is \\*THEIR\\* job. They don't code, we shouldn't analyst.\n\nI guess I lucked out with my developer's version of Stardew, going back to basics where a programmer can spend their time programming rather than playing the FOMO catch-up game with increasing layers of BS put between you and the code.\n\nOld man (in our industry at least) rant over!\n\nI should note that this has been posted several times before on this subreddit\n\nAnd OP is apparently some kind of bot.\n\nHow many people in general say their happy with their job?\n\nAs a member of the 20% club, I don‚Äôt know if there‚Äôs a secret.  Maybe anti-depressants?  But really, after almost 20 years I think a few things keep me happy and fulfilled in this line of work:\n\n* Coworkers and leadership who I respect and like working with\n* Working on, and vastly improving, my communication skills over the years\n* My expectations are only for things entirely under my control\n* Accepting when it takes longer than normal to do something, and learning from the experience\n* In fact, never stop learning\n* Be pragmatic.  There‚Äôs usually more than one way to do something well\n* Celebrate wins, big and small\n* Stay humble\n\n&gt; Coworkers and leadership who I respect and like working with\n\nIn my 20 years of experience this is the thing that has that largest negative or positive effect on my level of satisfaction and one that is nearly impossible to control.\n\nAnd also almost impossible to find.\n\nThe other 20% are meh\n\nHey I'm in the 20% of something.\n\nPeople still go to stack overflow?\n\nI'm a bigger fan of the broader Stack Exchange extended universe at this point. Those people over in the cooking stack are bonkers.\n\nProbably because we didn't get raises\n\nDevs are just incredibly whiny. Go do roofing for a day and then come back and say you're unhappy.\n\nThe problem with devs is other devs. There is so much elitism that exists in the field it is exhausting.\n\nDoing a physically taxing, mentally simple job can make you unhappy, and doing a physically simple, mentally taxing job can make you unhappy. Whether or not you find the ability to work autonomously and find satisfaction in accomplishing things isn't really contingent on the specific nature of your work. \n\nI'm not saying physical labor can't be unpleasant too, but Office Space speaks to people for a reason. Dismissing the psychological distress that people find working in this industry is unreasonable.\n\nI worked on a farm before becoming a dev, definitely would rather be doing farm work. Just give me dev pay\n\nYeah, I just want to do something that I can just be done with at the end of the day and not stress about it.\n\nRoofing ain't bad, pay is shit though.\n\n[deleted]\n\nAlso the problems with agile/scrum come from their implementation: management has firm control, the team members have no say and just get badly prepared tasks thrown at them.\n\n&gt;If you do roofing you know what you get. Being a developer you never really know what you get until you start working at a company.\n\n\nThis is exactly what I'm talking about. You absolutely don't know what you're going to get working in construction or a lot of other jobs, not exclusive to dev work at all\n\n\n\n&gt;micromanagement, meetings and stress¬†\n\n\nAgain not at all exclusive to dev work only devs will be far higher compensated than other jobs in which this is daily life\n\nWhat‚Äôs so surprising about it?\n\nIt‚Äôs because of the toxic sub culture\n\nwe honestly as a society kind of suck at producing and especially maintaining software.\n\nimo it's because we treat programming to much like engineering dealing with endlessly complex and unique situation... and not enough of a math that can be refined to perfection. \n\nunlike real world engineering, software production has this unique problem where you can make arbitrarily complex solutions that can balloon out into arbitrary valueless complexity in ways the real world just isn't capable of.\n\nIt‚Äôs selection bias: happy programmers are less likely to complete surveys on Stack Overflow.\n\nWho the fuck is happy in this shitty world, regardless of their job lol\n\nOver engineering everywhere, abusive project management, stupid tech trends (crypto, AI, ‚ÄúUber but for X‚Äù, etc.), unethical practices (no privacy, data harvesting, systemic racism &amp; sexism, anti DEI), repugnant right wing tech billionaires (Musk, Gates, Thiel, Jobs, Ellison, Altman, etc.), TESCREAL, and so on. \n\nIt‚Äôs exhausting. The future sucks. Next go around let‚Äôs let the art kids run things.\n\nLike many you have people who are used to designing a monolithic architecture program and then shiny new microservices come into the picture and so the project ends up being a monolithic collection of microservices instead of individual microservices that can all operate independently.\n\nMore accurate title: 80% of developers who were on stackoverflow during a specific set of days and who felt strongly enough about the survey to respond, chose one of the negative responses.\n\nNo kidding. I've started this profession 25 years ago and watched it changing from \"code engineering\" to \"framework plumbing\". I've chosen to quit before anyone tries turning me into a \"prompt engineer\".\n\nProgramming starts out quite amazingly and you feel like the possibilities are endless. Then you start working for a company and they make you program new buttons, that fall apart every few months\n\nNobody promised job will be satisfactory. It pays bill and that's it. Life is suffering and then death. Lights off.\n\nWhat about non developers?\n\nyeah i was gonna come here and say i don't especially like my job\n\nbut i dislike it less than i disliked most other jobs i had so i guess im winning.\n\ntho the article said anecdotally plumbers and farmers hate their jobs less. id believe it, they prolly at least feel more useful doing jobs that actually have to be done by somebody\n\nim skeptical of the \"amount of technical debt\" reason tho, that sounds like just an excuse.\n\nThat's tough. I am fortunate to be in the other 20%\n\nI love engineering. I love solving problems. I love writing code. I love being surrounded by people passionate about the same thing. \n\nWhat I don‚Äôt love is meetings, consultants, bureaucracy, people in technical roles with no technical backgrounds, PMs who don‚Äôt do any work, leadership making decisions that completely conflict with hard, objective data and facts ‚Äî making everyone else‚Äôs lives a nightmare and generally tanking projects that were doing just fine. \n\nI‚Äôm ok with daily standup. I‚Äôm ok with focused conversations if we set aside time. I‚Äôm not a pain in the ass of a person, I just like efficiency that makes sense and respects everyone‚Äôs busy schedule. The corporate approach that typically goes against that 9/10 times is what makes me burnt out, unhappy, unable to concentrate, etc. It‚Äôs not catered to engineering, it‚Äôs catered to middle management that has nothing else better to do than be a helicopter mom all day.\n\nDidn‚Äôt realize this would send me into a mini rant. I suppose that inherently makes me unhappy? üòÇ\n\n80% of developers are weak-willed idiots\n\nShould be easy to fix. Only 20% to deal with."
  },
  {
    "title": "CSS finally adds vertical centering in 2024",
    "body": "",
    "score": 1062,
    "url": "",
    "created_utc": 1723989437.0,
    "author": "flat_earth_worm",
    "permalink": "/r/programming/comments/1ev9v7n/css_finally_adds_vertical_centering_in_2024/",
    "all_comment_text": "/r/nottheonion programming headline\n\nSubreddits I wish were real\n\nbut‚Ä¶. It is real\n\nPretty sure they mean a \"not the onion\" sub but just for programming.\n\nr/didnoteatnottheonion\n\nThe title of this post is a bit sensational, and misleading. But, the content is great and the enhancement added to the platform is great to see.\n\nFor those choosing to not read the article:\n\n&gt;In 2024, browsers have [implemented](https://web.dev/blog/align-content-block) `align-content` for *flow layout*.\n\nThe examples demonstrate why this matters. Great post!\n\nCan see more from Rachel Andrews via Chrome's blog: [https://developer.chrome.com/blog/align-content](https://developer.chrome.com/blog/align-content)\n\nhttp://howtocenterincss.com/ in shambles\n\nThe fact that a website was created for this nonsense is all you need to know about how stupid shit has been for the last two decades. \n\nYou don't see http://howtoboldincss.com do you? It should be as simple.\n\nDon‚Äôt bold in CSS. Use the ‚Äú&lt;b&gt;‚Äù tag from HTML.\n\nNow CSS is finally as good as tables.\n\n[deleted]\n\nYes, both `flex` and `grid` layout support centered content. The blog post actually shows all the ways in which content can be centered with CSS. But the recently added property works in the `flow` layout (the default), which makes it even simpler.\n\nYea, I've been vertically centering shit with `align-items: center` for like 10 years\n\nAnd IIRC before that you could do it with:\n\n    .wrapper {\n        display: table;\n    }\n    \n    .centered {\n        display: table-cell;\n        vertical-align: middle;\n    }\n\nEdit: Ah yeah, they mention it.\n\nThat was always a fun one in the ie6 / 7 days.\n\n`position: absolute; top: 50%; transform: translateY(-50%);`\n\nThat works too, but the table-cell hack predates the existence of the transform property. :D\n\nI always preferred negative margins for that but I‚Äôm old school.\n\nYes so many ways ...\n\nCSS used to be simple!\n\nNobody read the link. It's literally the second paragraph. Holy shit Reddit sucks. Everyone has a fucking opinion and nobody listens.\n\n[deleted]\n\nI don't know what there is to even participate in here though. There's like a post a day that actually gains any traction, and the rest of the time it's the same whinging over the same subjects of cloud bad, JS bad, managers / agile bad, clean code bad, etc. This is one of the most boring subs honestly.\n\n[deleted]\n\nExperience makes one a curmudgeon, as one observes crap, fads, bloat, and mayhem, and not *just* with Microsoft.\n\nIs every sub\n\nHumans are merely chatty over-caffeinated apes, whaddya expect? üêµ\n\nEnforce a rule that top-level comments must include a quote from the article and discuss the quote directly. Not fool-proof but should go a long way.\n\nThis is what the reddit algorithm is designed to do.\n\nI blame that on editors. They‚Äôve been breaking the social contract consistently and flagrantly for a decade and these are the consequences.\n\nI blame that on plumbers. In exactly the same way, plumbers have also been consistently and flagrantly breaking a social contract that I can't specify, and it's caused editors to behave this way for reasons I also can't specify.\n\nSo this is your first time talking about how article writers don‚Äôt get to  select their titles?\n\nIs this your first time encountering the idea of people being responsible for their own actions?\n\nSummary of very common hacker news conversation: The internet is dead, all titles are lies, editors are the devil, nobody clicks on the lies anymore.\n\nTurns out when the title sounds like bullshit, people don‚Äôt read the link. \n\nAlso if it‚Äôs a Sunday, or the sun is out, or it‚Äôs night time‚Ä¶\n\nBut we live in a world where titles are all bullshit and clickbait is everywhere. We‚Äôre gonna see if someone else got their heart broken before we click on a link.\n\nYou can just not click through to the thread if you aren't interested in reading and discussing the article. Nobody's forcing people to show their asses.\n\nLook man. I‚Äôm just telling you the kids are never gonna get off your lawn. \n\nIf you wanna keep screaming at them, that‚Äôs your business. But if you‚Äôre gonna talk about choice, you also made one, and you also could have walked away.\n\nYou talking out your ass is not me complaining about kids on my lawn.\n\nBullshit it isn‚Äôt. You‚Äôre participating in a conversation about how nobody reads anymore.\n\nI'm willfully ignorant, here's why it's someone else's fault\n\nAs I said, that‚Äôs your business. Enjoy being cranky at the world old man.\n\nThey could have used a better headline. \"A new CSS property to vertically align content in 2024\", etc.\n\nBut the property already existed.\n\n[deleted]\n\nBecause it was just added, as the article explains.\n\n&gt; CSS finally adds vertical centering in 2024 \n\nThis is blatantly disrespectful to [vertical-align](https://developer.mozilla.org/en-US/docs/Web/CSS/vertical-align), which was introduced in CSS1's spec (1996), and I will not stand for it.\n\nI don‚Äôt know if I‚Äôve ever gotten vertical-align to work properly\n\nIt works, but only with inline positioned elements. Basically it works well with text and images if they are inline. Because of the inline nature, the effect will be really small but it comes in handy for certain types of vertical alignment\n\nBecause vertical-align is for inline elements, clearly not what the articles refers too.\n\nIt was the simplest solution until now.\nI don't care it was considered legacy, or not semantic. It just worked and was short.\n\nMany other things were so much easier and dimension-independent with tables, until flexbox and css tables, and even then they were on par.\n\nEhhh. I agree that it is still the right tool for the right job sometimes, and I'm not aware of it being considered \"legacy\" but I would debate that. It's a perfectly valid property that does its job and you should use it when you need it. \n\nI disagree that things like flexbox haven't made things simpler. I wrote CSS fulltime in a time where CSS floats and tables were the norm and I would take flexbox and grid any day of the week.\n\nFloats and tables are on the antipodes of reliability: the former are a hack, the latter almost always work consistently and reliably. Flexbox and grid were too verbose and complex when they were introduced. Tables on the other hand can be remembered easily because they are simple.\n\nSimpler is better.\n\nSimple is contextual. I have an infinitely simpler time making a grid (a common UX ask) using CSS grid than I do tables.\n\nThere are [18  CSS grid properties](https://developer.mozilla.org/es/docs/Web/CSS/CSS_grid_layout) you need to remember, vs the basic `&lt;table&gt;`, `&lt;tr&gt;` and `&lt;td&gt;` triple plus 7 other tags you will probably never need, Table styling is way simpler, most CSS properties are shared with other elements. I'd say tables are quantitatively simpler (edit: at the cost of being less powerful).\n\nAdditional proof is in my short memory: I never remember grid or flexbox by heart unless I'm frequently working with them during a project, but tables I can recall them at any moment even without being immersed in a web project.\n\nYou really don't need to remember all of those to use Grid. Most layout problems can be solved with just the `grid: (rows) / (columns)` shorthand which is pretty easy to remember.\n\nExample, here's a balanced 3 column layout:\n\n    &lt;div style=\"display: grid; grid: auto / 1fr 1fr 1fr;\"&gt;\n        ...\n    &lt;/div&gt;\n\nI feel like that's pretty simple. I use Grid constantly, it's so useful.\n\nMaybe you should give them another try.\n\nOne thing I hate about front-end development is CSS.\n\nI believe this is a shared pain we all have unfortunately...\n\nCSS has some weird quirks we need to work around sometimes, nowadays it's waaay better with display flex and what not.\n\nthe root issue IMO is that the concept of \"web apps\" wasn't really the goal for when the web started to be a thing years ago, so because of that, they had to \"rush\" to allow the existing technologies to host that possibility.\n \nOne example is why it's so damn hard to make custom components accessible, because we lack a ton of \"complex\" html tags like &lt;modal&gt;, &lt;dropdown-with-search&gt; etc\n\nit's getting closer\n\nfinally\n\nafter literally an entire generation of web developers\n\nFor modals, there's a \\&lt;dialog\\&gt; tag.\n\n&gt; &lt;dropdown-with-search&gt;\n\nWell, we do have datalist... Fair, it's not a dropdown everywhere (Chrome Android puts it into the autocompletion bar), but it's better than nothing.\n\n&gt;&lt;modal&gt;\n\n`&lt;dialog&gt;`, popover API, top layer and CSS anchor positioning have made stuff significantly better in recent times.\n\nRight. CSS is actually really rather great for defining how to render content. It's just not an application UI definition language.\n\n&gt;\\[CSS\\] I believe this is a shared pain we all have unfortunately...\n\nThe time devs spend on UI because of the LSD-like DOM/CSS is unacceptable for typical CRUD apps. **WYSIWYG layout grids were KISS and quick.** Use a feature called \"stretch zones\"  or \"stretch columns\" and they can fit diff monitor sizes.\n\nA mobile layout is so different that different template should be used altogether. The best spacing/margin CSS for desktop versus phone are just too different to use as-is. Most internal biz apps don't use mobile anyhow, so it may not be worth paying the \"mobile-tax\": YAGNI. A \"linear\" phone form layout can be auto-generated based on field meta-data (model or data dictionary) as long as intermediate render event handlers can tweak it for custom stuff. Plus, mobile layouts waste screen real-estate to leave spacing for fingers, resulting in more scrolling.\n\nWeb slowed typical CRUD productivity waaaay down. \"Shuddup and learn CSS rocket science\" is not economical. **The industry de-evolved** üêµ, getting distracted by fads and hype.\n\n*We're doing it wrong!*\n\nI haven't had to deal with customer facing css in a bit. When you develop only internal facing stuff you just don't give a shit. Grid the whole thing, it's fine.\n\nBoxes relative to other boxes - that are relative to other boxes - that are relative to other boxes‚Ä¶.. fuck this - a guy that only do this - must be like a million times faster/better than a normal programmer\n\nJust use Tailwind for 98% of use cases and your life will improve.\n\nThat's just using CSS with extra steps.\n\nAnyone who hates writing css and just wants to declaratively apply styles to dom elements will find tailwind does almost everything they could need without having to maintain your own stylesheet.\n\nIt‚Äôs css with less steps.\n\nCongrats, now you need to learn an esoteric css dialect that is exclusively written inline instead of standard css.\n\nLmao\n\nGreat, can't wait for 2034 when I can use it on a website and not have to worry about compatibility\n\n[deleted]\n\n\"It doesn't look right on BlackBerry\" - one of my testers\n\n‚ÄúCan I see that?‚Äù\n\n&lt;one hand hidden behind back&gt;\n\nThere's many many reasons I hate vertical centering. Today I learned a new one:\n\n    &lt;!-- FAIL! --&gt;\n    &lt;div style=\"display: grid; align-content: center;\"&gt;\n      Content with &lt;em&gt;multiple&lt;/em&gt; nodes.\n    &lt;/div&gt;\n\nI'm going back to tables!\n\nTables are probably the only thing that haven't failed me when using HTML for printing.  \nA lot of layout functionality doesn't work or works differently across renderers when printing HTML. Table layouts have been consistent across browsers.\n\nThe number of CSS Zen garden pages that looked like complete garbage when you resized the window or the text was too high. \n\nThen too often when you found one that survived, you found they were setting the display mode of a div to table-cell.\n\n&gt; display mode of a div to table-cell\n\nLiterally laughed out loud.\n\nLucy and her goddamned football.  How did they center this!  Oh.\n\nTo be fair, that's because printers suck\n\n&gt; I'm going back to tables!\n\nBoo!\n\ndoes this solve the problems in https://tonsky.me/blog/centering/ ?\n\nThe fact people think web tech is an appropriate solution for a desktop  app just blows my mind. Desktop GUI toolkits have been able to do things web devs brag about for at least 30 years.\n\nVertical centering is a nice start, now how about a standard split pane component and a standard scrollpane component that resizes when the browser resizes?\n\nWeb layout is still a total abomination as it has been since the mid-90's. CSS Grid and FlexBox improved things slightly, but not near enough.\n\nAnd yet electron is so ubiquitous.  I mean, designing for a fixed window ratio is easier than having the same code render a good UI for both landscape, portrait and all kinds of weird things in between\n\nCSS is just peachy for describing how to render content for reading and general display. What it was designed for. It's far from perfect but generally does an impressive job.\n\nIt was designed to explicitly *not* be a pixel level layout, after all. It's about translating semantic markup for display.\n\nBut the web went in a different direction, toward these full apps in the browser. And they have just abused CSS into doing their bidding.\n\n[deleted]\n\n&gt; To this day, there still isn't no better alternative than something like Electron.\n\nJava Swing/JavaFX.\n\nYet we've settled on using HTML+CSS+JS. Which is somehow even worse, since instead of a single Java runtime installation, each electron app has its own CEF engine.\n\nThere's also GTK and Qt, and some other smaller cross platform toolkits. But I find most of the apps built with them end up being a little wonky. They're still typically faster/leaner than your typical electron shite though.\n\nSince I'm bored enough to nitpick, CEF and Chromium aren't really the same thing and Electron isn't using CEF.\n\nMost of the problems people have with CEF/Electron/Webview2 using \"So much RAM\" stem from needing to bundle the entirety of Chromium and the library you chose doesn't really make a difference because it will still probably need to use a bunch of memory to render webpages and execute javascript code.\n\nElectron (and NW.JS) interface with chromium directly, while CEF wraps everything chromium into it's own API that host programs have to interface with. CEF is fine if you have a project that uses C/C++ (or are willing to write bindings to the C API for such a project, such as with Python), but electron (and nw.js) is more convenient if you plan on writing everything in JavaScript or typescript. NW.JS also supports chrome platform APIs like what old chrome apps used to have.\n\nSteam uses CEF, as does Spotify.\n\nhttps://www.electronjs.org/blog/electron-internals-building-chromium-as-a-library\n\nI'm personally hoping that rust application development takes off, for the simple reason the vast majority of crates will probably be multiplatform by design, and even libraries like Tauri emphasize using the browser backend that's already in the OS. On windows that's microsoft's version of chromium, but on Mac and Linux it's Webkit.\n\nI think another solid option would be if .net got trendy with something like Avalonia.\n\nedit: Actually I think it would also be interesting if someone took a look at youtube's cobalt library and checked if something could be done with that, as a smaller runtime then Chromium.\n\nWe ‚Äúsettled‚Äù because you can use functionality without installing an app. HTML won long long before app stores existed, and continued to exist after app stores began to suck.\n\nThose other frameworks may be more performant, but they make writing UIs so much more painful than HTML and CSS.\n\nI don't like HTML, but looking at [GTK samples](https://docs.gtk.org/gtk4/class.Builder.html) makes me want to gouge my eyes out. \n\nAdd to that that Electron is the only one of those on which I've had no problem just running an app on Windows and Linux. It has no licensing issues because it is packaged up as MIT/BSD. I would love to write native apps, but electron based ones are just lightyears ahead in terms of developer accessibility.\n\nHTML is simply the least bad option when you want to get something done quickly.\n\nOnce upon a time someone tried to make a UI framework for desktop that used an HTML like markup. Wish I could remember what it was called.\n\nI mean Windows had this with C# and WPF and it was mostly fine for normal apps. Also Flex and Silverlight in that era at the start of the SPA craze.\n\nI think the important difference is whether it‚Äôs platform specific or cross. But yeah.\n\nMacromedia MXML, Microsoft XAML based technologies, Java FX are examples of that. Gtk has Glade and/or GtkBuilder (there was even Gtkaml), Qt has QML..\n\nGtk uses css.\n\n&gt; Which toolkits are you thinking about?\n\nSwing, JavaFX, wxWidgets, GTK, and QT.\n\nAmen! We **need a new stateful GUI markup standard**. [DOM/JS keeps failing](https://www.reddit.com/r/CRUDology/comments/10ze9hu/missing_or_defective_gui_idioms_in_htmldom/), and putting lipstick on that pig ain't working, just oinking. üêΩ\n\nI am convinced this posts gets upvoted by veteran devs and downvoted by younger devs.\n\nAlmost certainly.\n\nLol what? Is that the new circlejerk? For me it's the opposite, newer devs like to upvote \"web bad old crust framework good\". Like the comment you're replying to literally said that javafx is somehow better at building UIs, which is mind boggling to anyone who actually used it back then. JavaFX is a lot of things but it is absolutely more primitive at layouts. Same goes for QT for example. Unless you LOVE working with shitty Qt gridlayouts or the absolute pleasure that is sizing policies in qt. \n\n\nBut when you haven't used those, you think that web dev is just so bad and a horrible experience etc. Where CSS is actually still the least worse option out of all of them.\n\nI'm a XAML fanboy, never have the asinine sort of problems with trivial stuff as centering an item.\n\nMhmmmm to be honest I'm not familiar with XAML... my original comment was more a reaction to seeing the comment OP mentioning that javafx is better (lol) at layouts. \n\n\nHow is XAML for deeply nested layouts/parent child layout rules, etc? Is it still used with WinUI?\n\n&gt;JavaFX is a lot of things but it is absolutely more primitive at layouts...Same goes for QT\n\nMaybe you work on e-brochures, e-commerce, and/or social networks. You might have different needs there. \n\nIt could be one-size-does-NOT-fit-all. I don't propose doing away with HTML/CSS, only that we need another standard that's desktop/GUI/biz/state-friendly.  Web has been absolutely crappy for rank and file biz/admin CRUD.\n\n&gt; Desktop GUI toolkits have been able to do things web devs brag about for at least 30 years.\n\nAre they cross platform, easy to use and have massive community support as well? \n\n&gt; Web layout is still a total abomination as it has been since the mid-90's. CSS Grid and FlexBox improved things slightly, but not near enough.\n\n*Layout* is bad? What are you missing now that grid and flex are widespread?\n\n&gt; Layout is bad? What are you missing now that grid and flex are widespread?\n\nLike my original comment said, split panes and scroll panes (and I mean scroll panes that resize with their container).  \n\nI absolutely despise when I go to a web site that has scroll panes and when I resize my browser the scrollpane doesn't resize with it! That is worthless. And it is also a very common thing to see.\n\n&gt; Are they cross platform, easy to use \n\nYes, except for mobile. Although JavaFX can be used on mobile.\n\nYes. I've worked on multiple Projects that compile for Windows, Linux, Mac, iOS and Android from a single source tree without any #ifdef hoops or such. My current project is a Gtk3 (soon 4) project that works perfectly fine on all desktop OSes.  \nThe Gtk 3 layout system is the easiest thing I have ever worked with. The Gtk4 LayoutManager is a bit harder (and is giving me the occasional headache in the migration) but the features are amazing.\n\nGtk is good at creating simple layouts. But just like with QT it's absolutely horrible at anything more complex than grids or simple lists/panes.\n\nIt's an enterprise software. The layout is actually complex AF. I think we have like 50 custom widgets including completely custom comboboxes, multiple entries, an entry with custom IME, and custom lists with so many features we're afraid of refactoring them. in addition we made some widgets we felt were missing like tag cloud and graph editor.\n\nThat's pretty cool! I've rarely seen enterprise software written in gtk. I agree that most frameworks are fine for creating widgets, and the layout inside those widgets is also not super hard to figure out. In my experience, it's making all of those work together in a decent layout that's pretty hard. For example, in QT (not a lot of gtk experience), without qtquick, it's rather hard to make sure that an item in a list is always consistent regardless of where the list is placed, what the sizing policy of the parent widgets are, etc. Like, it's not impossible. But much harder than with stuff like CSS. \n\nIs it better with gtk? I rarely had to deal with nested layouts there (most of my gtk experience is on open source projects, not my actual day job)\n\nI used Qt only a little bit and made like 3 toy projects. for me gtk is definitely easier to work with. but Qt had a better typing system and standard library. Gtk has none of that. You make your own data structures and it's callback galore.\n\n&gt; Are they cross platform, easy to use and have massive community support as well? \n\nAre they not?\n\nWait a minute, did I hallucinate the flex system? Works flawlessly for me for many years.\n\nIt's wild that we didn't just create a `vertical-position` and `horizontal-positon` properly with percent as options (to allow for RTL languages) years ago in a way that just does exacty what it says on the tin.\n\nWell, okay, but what *does* it say on the tin?\n\nIs that the position of the top left corner? Or the position of the center of the element?\n\nI'm assuming, given the context, you mean the center point of the element?\n\n```\nvertical-position: 50%;\nhorizontal-position: 50%;\n```\n\ngreat, a perfectly centered element. but wait!\n\n```\nvertical-position: 0%;\nhorizontal-position: 0%;\n```\n\nfuck, now most of the element is outside the viewport and only the bottom right quarter is visible. Did you intend that?\n\nOkay... So maybe top left corner? But wait! That's just the same as\n\n```\nposition: absolute;\ntop: 0;\nleft: 0;\n```\n\nOr we could get really funky and say that the relevant point is the corner or center point that's closest, so 5% 12% is top left, 49% 51% is center, 80% 90% is bottom right, etc. But that seems a little complicated, doesn't it?\n\nAlternative proposal:\n\n```\nvertical-position: 50% center; // or top, bottom\nhorizontal-position: 50% center; // or left, right\n```\n\nIt's not that complicated if you don't intentionally make it complicated. \n\nAfter all, that's the problem of all the existing layout mechanisms already in CSS. They use abstract concepts that no one outside the CSS creators have seen before. \n\n`vertical-position: 0%; horizontal-position: 0%;` should be top left if your browser is set to the western reading direction, or top right if you are using a RTL language. The position % should limit the placement of the inner element to within the container. If you want to be a freak and place stuff outside the container (no one ever really wants this), you need to use a different rule (like negative margins or absolute positioning).\n\nIt‚Äôs strange. CSS is both over engineered and clumsy to use.\n\nThat is, unlike trying to make CSS a programming language, actually a good change. It used to be fairly annoying to try to align vertically. Aligning horizontally was simpler.\n\nHaving said that, CSS really has too many \"more than one way to do something\". Flexbox? How many same or almost-the-same ways exist for that? https://xkcd.com/927/\n\nAs an ex web dev, I never thought I would see the day...\n\n[deleted]\n\nwon't somebody think of the CSS \"frameworks\"?\n\nI thought margin auto worked as long as you supplied the height. Looks like you had to supply the height here too. It‚Äôs a small win. And yet another rule to remember. Tables were frowned on because of semantics but why didn‚Äôt we just create a layout tag that behaved as a table but could be ignored as a semantic value.   Clearly other items in html are not semantic. Everyone could figure out table layouts.  Tbh we shot ourself in the foot just so we could say the gun was empty.\n\ngreat, now i can fail on multiple axis's\n\nFeels strange to see Edge still get its own spot in the browser support section, when it's literally just Chrome with an MS skin.\n\nIt incorporated updates at a different cycle than Google though. And I'm sure they have custom flags of their own.\n\nJust need to wait another decade for it to be in all the browsers :‚Äô)\n\nAs the article says: \n\n&gt;&gt; Supported since:\n&gt;&gt; Chrome: 123 | Firefox: 125 | Safari: 17.4\n\nreminder of why I left webdesign behind a decade ago\n\nSo, what have people been doing to centre content before this feature was formally adopted?\n\nYou are in luck, the article linked actually answers your question. They show all the ways it‚Äôs ever been done\n\nAll the things.\n\nGoing insane while trying different workarounds, that's what.\n\nCouldn't you just get the viewport width, divide it by two, stick it into a variable called \"centre\", and refer to that? Sorry, I really don't know anything about CSS.\n\nOk, now resize the window which changes the size and overall proportion of the viewport.\n\nOh, well, just let me hook up this javascript over here to make that work with events that reposition according to the sizing.  \n\nOk, now try to print your window and realize it's still not right.  \n\n(1 week later).  OK, got that fixed.\n\nOk, now test it with Safari and realize it's completely messed up again.  \n\n(1 week later)  Ok, that's fixed!\n\nOk, now add a new column to your layout that puts your formerly centered content all the way over in the right hand side column.\n\n::shoots self::\n\nI mean... none of it is impossible by itself.  But it's just this maddening continual process of tweaking it, adjusting it, retesting it.  It's awesome if all you do is want to fiddle with CSS all day, but if you want to just complete the work and not have to worry about it down the road... yeah, that's generally not going to happen.\n\nDoesn't `vh` with `calc()` provide a means to vertically center?\n\n`calc()` is the absolute last resort\n\nReasoning? I've used `calc()` with `vh`, `vw`, `top` and `left` for years to  precisely align content.\n\nAbsolute classic webdev-hivemind on display here where you‚Äôll get downvote bombed for saying you use a method that has been proven to work for decades, with no elaboration of how what you‚Äôre doing is wrong\n\nBecause flexbox exists. It's like using an abacus instead of a calculator. Sure you _can_...\n\ncalc is not even any older than flexbox really so it's quite perplexing.\n\nOk so flexbox can do it too. Why does that mean that calc is an absolute last resort? I‚Äôve used the calc method before and it works great. It gets the job done in a very easy manner, and everyone who‚Äôs actually competent can understand it. It‚Äôs just nonsense cargo culting that‚Äôs unfortunately super prevalent in the programming space these days.\n\nTo use calc() to center things you need to know the height of the element.\n\nYou can't use calc to center most elements because the browser calculates their height from their contents and this calculation is not available inside calc().\n\nCentering an element with a known height was possible since forever using relative positioning or negative margins.\n\nEven then, sometimes an element with a \"known\" height can become one with an unknown height if the text wraps for instance. Even if you're sure that it will never wrap in English, are you sure it won't wrap when localized to another language? So it's good practice to treat all elements as having unknown height.\n\n&gt; To use calc() to center things you need to know the height of the element\n\nOften this is the case, and you know to the height\n\n&gt; Even if you‚Äôre sure it won‚Äôt wrap in English, it may wrap in other languages\n\nThis is true, but also the vast majority of software and websites are never localized beyond English, so for most people this is not a worry they need to have\n\nGood point. Why is a more complicated, less declarative and less readable approach worse? That's a real stumper. Must just be a hive mind at work.\n\nThat is not what I asked, and you know it. You‚Äôre being intentionally disingenuous\n\nI think you're being intentionally obtuse to act like there aren't obvious reasons why most devs would flag unnecessary uses of calc() in a review, and consequently why they would downvote a comment blindly declaring it to be preferable.\n\nGood thing I don't give a damn about \"up\" or \"down\" votes on social media boards. Especially not in the slums of social media, Reddit.\n\nYou're willingly hanging out in the slums my guy.\n\nI am from the slums, my guy. I AM the slums. I'm pretty sure I can be **far** more grimy than the vast majority of dullards on Reddit.\n\nThese boards are child's play.\n\nYou have to love the irony that the people who express the most vocal disdain of their strawman version of redditors are so often themselves the very epitome of that strawman\n\nReddit is generally garbage. Here and there people actually post helpful articles and answers questions directly.\n\nHowever, like your comment, many are on some would-be satire and comedian bullshit.\n\nIt makes absolutely no sense to cast worthless \"downvotes\" for `calc()` when that has been used for aligning content exactly since CSS introduced `calc()`, `vh`, `vw`.\n\nIf you are looking for sense on Reddit though, you have none.\n\nAin't no strawman here. I'm going to notify you directly your useless \"down\" votes (and \"up\" votes) are worthless.\n\nI didn't get the memo that I was supposed to care about some votes on social media. Or maybe I burned the memo and just don't give a fuck what you think.\n\nYou are 5% as edgy as you think you are, lol\n\nwhen having neither up nor down makes it vertically centered üëÄ\n\nVoting is overrated. \n\nSomebody said in a comment recently something like Redditors are the dumbest creatures on this planet. \n\nI can't contest that observation.\n\nI hate posting on developer forums because nobody loves to crow from atop a hill of s*** that you're doing something wrong without ever offering a solution like developers. Given the choice between teaching and tearing down, nine times out of 10 they'll choose to tear down.\n\n\"Up\" and \"down\" votes on these boards has no inherent value.\n\nPeople arbitrarily decide if a \"vote\" count is true and correct, or not, individually. A whole bunch of people still think the late O.J. Simpson was \"guilty\" of the charges the D.A. laid against him. Nevermind a jury acquitted him.\n\nWhy the hell would I care about Reddit's fake ass \"karma\"?\n\nI have been on these boards for decades now and have *never* cast a single \"down\" vote for any post or comment.\n\nI read the content. And decide for myself what works and what doesn't work.\n\nI don't rely on another human to make decisions for me.\n\nIf people are looking for truth to correspond with \"up\" or \"down\" votes on social media boards, or in politics in general, those people are fools.\n\nIn 2024 tens of millions of U.S. citizens will \"vote\" for complete strangers to be elected the President of the United States. But guess what? The Framers and Founding Fathers of the United States didn't trust each other and certainly didn't trust a bunch of illiterate European peasants that were indentured laborers who couldn't vote anyway if they didn't own property, so they designed the Electoral College to make sure the herd, the incompetent mob, could never really gain the balance of power. They formed the U.S. as a *representative republic*, decidedly *not* a democracy. Majority does not rule. Might makes right.\n\nHard to get right for different screen sizes (the example you showed in another comment chain fails when the screen is too small), and also it doesn't let you center in a container, only in a view\n\nWell, you have to test on different platforms and devices to get it right. The example I posted I spent a few minutes on. \n\nI don't have an issue with new additions to CSS. At one point in the not too distant past `calc()` was new, so was `vh`, `vw`, and so forth. \n\nDo whatever it takes. Use all of the tools in the toolbox.\n\nI don't roll around on mobile devices all day long, so I'm not that concerned with small screens, unless a client needs that precision for a certain requirement.\n\n&gt; `calc()` is the absolute last resort\n\nToo funny.\n\nAre you able to use calc() to vertically center content of arbitrary height inside a container? An obvious solution does not come to mind. I'm curious how you achieve it.\n\nYes, of course. That's one way it has been done since `calc()` was introduced into CSS. Make use of `vh`, `vw`, `left`, `top`, and take into account that browsers' margins and padding is different.\n\nThis was more challenging before there was `calc()`, `vh`, and `vw`.\n\nvh and vw let you vertically center in the view, not inside a container\n\nDepends on the `position`.\n\nNo, vw and vh refer to the entire viewport, no matter what the positioning of the container is\n\nWell, yes. You calculate where you want the element to be and put it there, by any means. Whether that be `calc()` with `vh`, `vw`, or any other means available. \n\nPer the article:\n\n&gt; CSS mastery takes effort!\n\nI think the sentiment people have here is that \"I want to vertically center an element within its parent element\" _shouldn't require mastery_.\n\n&gt; shouldn't require mastery.\n\nWell, what *shouldn't* is different from what is.\n\nYou you confess you are not even attempting to master CSS. Thus, you won't.\n\nOr, you'll get it and get it done with the tools you have.\n\n&gt; I want\n\nOh, join the club.\n\nMake it so Number 1, by any means.\n\nThat's what I did when I was hacking CSS and the CSSOM every day.\n\nMaybe I'm overlooking something obvious, but I don't see how vw or vh let you vertically center an element inside its parent. The only way I see this working is if the position of everything on the page is determined in advance and layout is fixed. Can you give an example?\n\nYou mean something like this https://guest271314.github.io/vits-web/?\n\nThat's without really refining and testing. Just an approximation. I could take that a few steps further if I wanted.\n\nI used to be, some years ago, a CSS and CSSOM enthusiast to the Nth degree.\n\nIs this supposed to be vertically centered? Because it's not.\n\nNot OP, you'd need to change the:\n\n    top: 20vh;\n\nto:\n\n    top: calc(50vh - 20px);\n\nTo fix it, and this type of stuff is why I personally don't like things like `calc`. For it to be \"correct\" it needs information like the current height of the element in `px` so variable height boxes get complicated fast.\n\nAnother annoyance is just blindly relying on `vh` to be correct. I don't think `vh` works when you are styling an element to be vertically centered within its container since `vh` is a measure of the browser's viewport height.\n\nBoth the `50vh` and the `20px` are very fragile, when what you really want is to vertically center the center point of the current element within the height of its parent element.\n\nThat's why `calc` would be considered a \"last resort\".\n\nThis does not vertically center content of arbitrary height within a parent container. This vertically centers content of a known height within the viewport. Right?\n\nI did that in a few minutes. For a pre-exiting basic Web page that's about speech synthesis, not CSS. Not for exactly what you describe, but to give you an idea of the capabilities. You have to do some work. Calculate the parent pixel dimensions, and whatever other specific requirments you have. I have not actively hacked CSS in years. I used to every day. It's possible. Look at the calculations I passed to the `calc()` function. They are not arbitrary. Center your element accordingly.\n\n\n\nAll you folks can manage for using CSS `calc()` for rending vertical alignment of content is *14* meaningless \"down\" votes?\n\nI grind \"down\" votes with a mortar and pestle for breakfast. \n\nC'mon now...\n\nNeeds more \"down\" vote...\n\nListen.  We've easily been able to vertically center content using flexbox for the past 15 years now.  If you guys are still having trouble with that, then that's on you.\n\nI think you should read the article to see what it solves specifically\n\nYeah my comment wasn't in regards to the article.\n\nTypical\n\nHere's a fact.  If you still can't center a div in 2024 you shouldn't be a dev. Does that apply to you?\n\nAre you trying to start a fight in a programming sub Reddit?\n\nHaven‚Äôt there been ways to achieve the same thing by combining css tags, for many years?\n\nEdit:\nOh look, here is a thread on how to do it from 16 years ago!¬†\n\nhttps://stackoverflow.com/questions/79461/how-can-i-vertically-align-elements-in-a-div"
  },
  {
    "title": "In a leaked recording, Amazon cloud chief tells employees that most developers could stop coding soon as AI takes over",
    "body": "",
    "score": 1045,
    "url": "",
    "created_utc": 1724277507.0,
    "author": "totemp0le",
    "permalink": "/r/programming/comments/1ey2aai/in_a_leaked_recording_amazon_cloud_chief_tells/",
    "all_comment_text": "Always pay attention to who it is saying this stuff.\n\nNVIDIA, Amazon, Microsoft, all vested interests. They aren't getting rid of their own developers, they need those people to build new AI products -- but they'll tell you to get rid of yours in a completely transparent attempt to cripple your technical capability and make you entirely reliant on their products (which of course happen to run in their cloud infrastructure, managed by... their engineers.)\n\nI have so many clients already with insanely high cloud hosting fees and I look at their traffic.... \"You could run all this on 4 rasberry pis and 1 1g Ethernet trunk....\"\n\nIve seen clients in azure with a 64 thread dedicated windows vm for 20,000 users a month.... \n\nThese people have no idea what they're doing.\n\nLol! Do we work at the same place?\n\n Had a previous client come to us paying like 15k just for their SQL Azure bill. Some previous devop cranked them up to some ridiculous 32 vcore level of business critical load balanced cluster shit due to poor performance.\n\n6 weeks of our team cleaning things up to optimize and we we're able to scale them down to 16 vcore general purposes level for around 3k a month!\n\nDid get a bonus for basically saving them a hundred thousand a year?\n\nLol\n\n6 weeks of a team of engineers (presumably consultants charging consultant rates) to save $100k a year is not necessarily great ROI, tbh.\n\nAnd, this is why managers love overpriced, overpowered servers.  As long as it works, it‚Äôs cheaper than paying engineers to figure out how to make it work on cheaper machines.\n\nWhich is fine until your service that‚Äôs not really that intense stoops working on the most expensive hardware.\n\nYeah. The benefit of good hardware is not wasting time on trivial shit. The downside is allowing lazy behavior to become habit.\n\nExcept that it works just as well on a local overpowered setup most of the time.\n\nYes I know cloud has advantages. My thesis is that it‚Äôs not materially better in probably most cases.\n\nDo you wanna be modern and follow the trends or are we going to discuss how most of AI is not AI :D¬†\n\nListen friend, the marketing department already has its budget set for the rest of the fiscal year. We don‚Äôt need you correcting them and forcing them to have to justify their budgets for next year, ok?!\n\nThermal overhead, few understand how much of our real world performance is throttled by the thermal envelope.\n\nCloud makes sense if you need to scale but otherwise you are 100% correct it‚Äôs proven slower on an advertised clock for clock basis.  Often as much as a 30% difference in sustained CPU speed.\n\n6 weeks 3 engineers 5 days a week for $800 a day would be about $72000 which is approx the amount they now save per year. So first year zero ROI but pays off after.\n\nTheir CTO did!\n\nIt's so depressing that we're still in a situation where people are running cloud infrastructure the same stupid way they did on prem.\n\nCloud providers long ago ran out of enterprises requiring truly scalable solutions to drive growth and started pitching to every firm that has no business on the cloud.  So of course they follow the promise of taking their local setup and just uploading it to the magic cloud that solves all problems with a sprinkling of fairy dust and marketing lies.\n\nYeeah but what about ScAlAbIlItY (ok, scalability is not a great word to ironicize). \n\n\nBrother you're putting the cart before the horse.\n\nThere are two extreme ends. \n\nI‚Äôve seen a client who hosted his business in his home bedroom, because some random IT guy at a bar said that would be the most ‚Äúreasonable‚Äù option.\n\nThey couldn‚Äôt properly handle downtimes due to windows updates, home network issues, wife turning the machine off by accident during housekeeping, etc. \n\nSo yeah, I wouldn‚Äôt idealize raspberry pi in business context, and there‚Äôs a fine middle ground in cloud hosting.\n\nHow big was the business, and how crucial the services hosted?\n\nI ask because that‚Äôs honestly probably reasonable for some very small businesses, especially if they‚Äôre just barely starting out. It‚Äôs not great, and you can colocate a server cheaply enough, but if it‚Äôs just a one-man plumbing operation with very little profit or funds for example, then it‚Äôs not *that* unreasonable.\n\nBusiness not big at all, maybe bigger in the future. Regardless, his Wordpress site needed to be online 24/7. \n\nHe consulted with me (funny because I‚Äôm just another IT guy he came across randomly) as he was having aforementioned troubles, losing more money than he was saving with the bedroom server.\n\nI basically just copied his stuff over to a cheap VPS and he was happy with the fraction of additional cost.\n\nHis wife liked the idea that the mysterious untouchable object no longer exists in the bedroom. I think his older kid got the laptop but I don‚Äôt think he can play Fortnite with that. \n\nI asked for a minimum maintenance fee because I basically do nothing. I can get a free tattoo at his shop too, but unfortunately I‚Äôm not into that.\n\nThat definitely makes sense. If it‚Äôs just a Wordpress site, I‚Äôm almost willing to bet the saved electricity is worth more than the cost of the VM too, lol.\n\nRun Wordpress on the Pi and use an S3 static site plugin and host the public site from that. Will cost literal pennies to run, highly available and the admin part is fine to run on a Pi and go down whenever since he‚Äôll be its only user.\n\nnull\n\n&gt; sCaLaBiLiTy\n\nI used to work for a client on an Azure VM, it was development work so it was a pretty powerful one. The project is loooong finished but I still get alerts from their IT telling me to delete the VM if I don't use it anymore. But I don't have any credentials anymore, I always tell the product owner but they don't give a fuck. This VM probably costs a few hundred Euros a month, and I doubt that I am the only one. We are talking med tech company with 100k employees here. It's some crazily sloppy shit.\n\nThey can put policies in place for that kind of stuff and then reap all the vms are older than a specific date. Azure has had that for a really long time.\n\nI swear Azure is just a money pit¬†\n\nIt's actually a great tool and getting a server up and running in a couple of clicks is pretty amazing. But the roi is still way too low to justify the costs.\n\nBro, if you are clicking shit to set up a server, you are one of the people who is going to get replaced by AI.\n\nI am a developer, it will be a loooong time before AI is anywhere near replcing me.\n\nFor doing some basic boilerplate it's ok if you already know what the LLM is going to do and you don't like typing much. Everything else is just wasted time. Even asking for documentation is gambling because it may write inexistent stuff...\n\nSo when you start a fresh project you first setup automations before doing the PoC? Certainly possible, but seems weird.\n\nTypically I first evaluate the options manually, then put some simple business logic as PoC in there, and if it gets greenlit that stuff goes into terraform and gets replicated to all environments.\n\nThe giant irony is AWS and surrounding tooling companies spend billions to develop UIs while claiming it‚Äôs all going to get automated by AIs anyways meaning their billions are being spent idiotically. Or maybe they‚Äôre just lying.\n\nOh well. I guess we will never know.\n\nI think they're plainly delusional. My experience with AI coding is that it is hit or miss. Either the AI gets what you want and it is all right or it isn't. In any case changing anything about it, extending it in a specific way is next to impossible.\n\nIt's paint-yourself-into-a-corner in a box.\n\nThe cloud is fine if you design and architect your app for it. If you run your apps in the cloud the same way you ran them on prem it's going to cost you a fortune. \n\nThere are exceptions, if your app is running at the same load all the time, the cloud is kind of pointless, but generally if you know what you're doing it's not too bad. \n\nYou pay a premium compared to a colocate, but in exchange you don't have to worry about licensing, upgrades, backups, redundancy etc. Pricing is pretty competitive. \n\nUnless you buy a VM you don't need because VMs are the only way you know how to work.\n\nwe use several apps, where vendor claims its a cloud app, but what they mean, is they can run it on a VM in the cloud... thats not a cloud app. licencing is also bound to the number of CPU's it insane how expensive it is, but management doesnt care, because \"its what weve always used\".. yes, but now its costing you 8 times as much\n\nYeah, running always on VMs in the cloud is not particularly cost effective. You have to pay all the maintenance costs associated with the VM and dedicated compute is the most expensive thing in the cloud.\n\nIt can still be worth it if it's an exception and the rest of your infrastructure is properly cloud native, but that's only because setting up a once off colocate or on prem server with everything else in the cloud isn't worth it.\n\nIt's kind of sad though. 99 times out of 100 when someone complains about how expensive the cloud is they've bought some gigantic honking VM to run something that could be an app service that is active three hours a day.\n\nDepends on what you're running and if you set it up decently.\n\nLifting and shifting a ton of VM's doing much ado about nothing is going to suck.\n\nBut for example I run a B2B data service that serves billions of requests and hundreds of terabytes of egress a month. Basic stuff. Steady load. Web apps, SQL, blob storage, Redis, messaging. Roughly $10k/month Azure spend.\n\nWe would save money colocating our own hardware but with a bunch of added risk and administrative technical work. The money saved would be a substantial portion of the total, but in the context of the business's revenue it's hardly an amount to be very concerned about.\n\nRenting managed servers wouldn't even save much money and would come with plenty of admin work as well.\n\nJust like AWS and GCP.\n\nI see you've met my previous employer.\n\nThey would stand up an Azure Windows VM, an Azure SQL instance, a blob storage account, and probably a bunch of other infra ... for *each organization*.\n\nTheir cloud tenancy strategy was, to really put a fine point on it, to replicate their *entire* cloud footprint per customer. And like, yeah, it was dumb, and they *knew* it was dumb, and they kept saying how they needed to do something about it, but they wouldn't because the whole org was dysfunctional.\n\nAll the software was developed to run on-premises, and operations (which was totally cut off from engineering except where we found ways to build rapport individually) was given the edict to start running it in Azure, while the skeleton crew on the engineering side had a mile-long feature backlog full of our own edicts to follow.\n\nOne of the last things I did there was write up a 4-phase plan to get the spending under control, each phase of which would cut costs dramatically (the first of which operations could have done entirely on their own, in the UI, and reduced cloud spend by *40%*, which was likely hundreds of thousands a year by that point.)\n\nThey eventually fired pretty much everyone I knew there, but from what I've heard from people who were still there, they never implemented that or any other plan *and* are getting gutted by a private equity firm because they're not profitable enough.\n\nMy company got bought by private equity and while we do nothing in the cloud (government contracting) man does the rest of the story sound scary similar...\n\nThere are two advantages in this kind of multi tenancy:\n\n1. You can determine precisly which customer cost you how much (on the ops site).\n\n2. Customer could even own their ressource groups, bringing some legal advantage.\n\nBut downside for 1 is the increased price and for 2 the either complicated or only-via-manual maintenance of customer installations.\n\nIt can certainly be worth it (large enterprise customers or state actors), but it also can be horribly inefficient (small customers).\n\n&gt; \"You could run all this on 4 rasberry pis and 1 1g Ethernet trunk....\"\n\nDo you really think their unoptimized garbage node application that makes 16 circular network requests could run on 4 rpis?\n\nIt was a joke, but to answer you seriously, no, absolutely not.\n\nWell, yes, the exaggeration was obvious. Even with the current application that im working I sometimes ponder whether the entire cloud stack could be run on a single box at all.\n\nI thought Nodes minimum requirements were an Intel atom processor and 64gb of ram or more.\n\nSo I‚Äôm thinking 8 pi‚Äôs might work in a cluster?\n\n[deleted]\n\nFor these people, yeah.  But I have seen on premise done right that got moved to the cloud because \"CLOUD!!\"\n\nI'm absolutely not worried I'll lose my job to AI. In order to turn requirements into software with the use of AI, the requirements have to be static and abundantly clear. None of which has _ever_ happened in my professional career of nearly twenty years.\n\nAI is going to kill us all after 3 weeks working with my clients. It'll decide the best solution for project creep is thermonuclear war.\n\nLet's be honest, that's probably a totally reasonable response too.\n\nIt has crossed my mind once or twice, yeh.\n\n&gt;I'm absolutely not worried I'll lose my job to AI\n\nI keep seeing this and even though we ultimately agree that the threat AI poses is overhyped, I think it misses the concern some have.\n\nI am pretty sure AI will not be doing my job anytime soon either. My work requires solutions to novel problems, many of which occur at the interfaces between systems. There is a lot of context to understand and there are no google-able answers. \n\nHowever, just because AI isn't going to be a one-to-one replacement for me does not mean I am safe. Every \"highly skilled\" industry is a pyramid. At the top are the elite few. They're the lawyers arguing before the Supreme Court, the doctors curing cancer, or the developer at Microsoft who notices SSH logins are taking a half second longer and stops a global cyberattack. On the bottom are the people doing more repetitive work. They're not necessarily less intelligent and their work isn't necessarily less important, but for whatever reason they're doing more monotonous tasks that require less creativity. There are many more people at the base of the pyramid than at the top.\n\nIf AI replaces even a small fraction of the workers at the bottom or automates their workload essentially overnight, that will mean a lot of new entrants to the workforce all vying for fewer open positions. That will absolutely put downward pressure on everyone's salaries, whether or not our skills are still in demand. Not to mention that corporate executives are going to turn every department and every problem into a nail once they get hold of an AI hammer. Even if they eventually come to realize that it has limitations, it won't be until after a painful and disruptive period of high unemployment.\n\nThe one unknown is will companies replace people with AI or just grow the requirements given the increased productivity. So far at least, every productivity boost for programmers (and increases in developers) has been absorbed by companies wanting to do more. Software is eating the world and still appears endless. \n\nHumans have a knack for using every resource available to get ahead. A company that can plug AI into it's existing workforce and make their product better/faster will do that, and will continue to do so until we reach some steady state in software - if that ever happens.\n\nMatt Garman is a product manager, not an engineer. He literally has no clue about software development.\n\n[removed]\n\n&gt; he'll likely get replaced by AI first\n\nYup. We have a bunch of eVanGelisTs at our company always posting the latest AI blog spam hype in Teams. Just your everyday, average, overpaid middle manager types desperately clinging to any shred of relevance since our IT departments went 100% remote. \n\nTo me it reeks of ‚Äúenemy collaborator‚Äù. They‚Äôre the snakes who rat out the resistance to the invaders and talk about how great things are going to be under the new regime only to be the first against the wall when they‚Äôre no longer useful.\n\nIt's ok, Peter DeSantis is the real CEO of AWS. That dude is awesome.\n\nAnd companies will readily rationalize it by saying that it wasn't part of their core business model anyway.\n\nAlternative point is that they have hit an AI plateau and want this overblown hype to continue.\n\nThis is probably what has happened, but seeing as how a good portion of programmers don‚Äôt seem to see that, I‚Äôm certain this statement comes from a place of astounding stupidity and not strategy.\n\nI just want to buy 50 computers and say, ‚ÄúChatGPT,  make me a clone of AWS! I expect 50 installers and a one page sheet describing how to set it up.‚Äù\n\nGod damn it, get this man a Manager's position s... no, I think he's Vice President material.\n\n/thread\n\nAny company that has competent leads outside the ones you mentioned that are worth their salt will not move 100% to AI, AI feeds of code, and code produced with AI is shit, that code goes directly back to the AI through git and it now has a worse codebase to generate, it as good as it is now, and any try to use it will give a dev ten times more work to debug the shitty code that they're generating, not worth it.\n\nThis is verified too\n\nVery well put. What‚Äôs more disturbing is that they‚Äôre using ‚Äúleaks‚Äù to do this. So fuckin‚Äô slimy\n\nAlso pay attention to what the person was actually saying rather than reading the headline.\n\nIt was an informal Q&amp;A where people leadership sat down with engineers. He was proposing a future, where IF AI is sufficsufficientient enough coding become a commodity and coders are working on much higher level problems. No where did he imply that everyone would get fired in favor of fully auto systems.\n\nI been part of those you will focus on higher level stuff meetings, usually means people get fired in the following months.\n\n\n\nAs a personal anecdote, long time ago I was part of a big , old entity that had shit loads of information in lots of ways, physical, xls, csv, old databases.\n\n\nThe team i was with got everything in a SQL database.\n\n\n\nWhile we were building the system one of the big wigs came to our department,  asked for some info outside of the normal reports, we did a quick SQL query and gave him the results.\n\n\n\nWe became wizards in 2 minutes, suddenly we were at all the important meetings,  got bonuses,  promotions,  budget, perks and lots of power within the organization.\n\n\n\nWhile we were riding the gravy train, one of the guys on the team hated going to those meetings and made a tool so the big wigs could easily get the info they wanted themselves.\n\n\n\nHis rationale was that we could focus on bigger things if we weren't wasting time on the big wigs meetings.\n\n\nThe day he presented the tool the guys from legal looked at us like wtf are you doing idiots!\n\n\n\n\nIn less than a month no longer went to meetings, bonuses and perks stopped, budget went down and we got downsized in less than 6 months.\n\n\n\nLesson dont automate yourself.\n\nBusinesses love when you automate away the work, they‚Äôre just too fucking stupid to let you keep doing it.\n\nThe big wigs appear to often be the thing that the company is succeeding in spite of, not because of. It‚Äôs wild really.\n\nMy personal lesson, is dont automate away your connection to power.\n\n\nBig wigs will always exist( unless AI replaces them), the close you are to the source of power the better conditions you will get.\n\n\nIn our case this guy cut our connection to big wigs, that ironically was allowing us to take bigger problems and have an input in the business decisions.\n\n\nA guy of legal later told me that we fucked up doing that, instead of making ourselves indispensable, we gave up our big boy seat willingly.\n\n\nSince then, whenever i have to automate stuff, i make sure we are kept in the loop somewhere.\n\nYes, exactly. The only people worth listening to are devs actually working with a tool, or scientists publishing papers or research in peer reviewed, reputable journals.\n\nOnce those developers build their AI, the AI will build the new AI\n\nai isnt good enough to do your job, but its just good enough to convince your boss it can\n\nI work at a software company. Our CEO has been convinced by his CEO friends that tools like copilot should deliver a 20:1 productivity improvement. \nLots of people close but not close enough to development seem to think similar. Fortunately even our board know that it's nonsense\n\n20:1!!¬† Is he high??\n\nShit it's not even 1:1.\n\nMight be close to 1:1 or even sometimes 2:1 at producing similar code that you'd get from a whole offshored team in a coding sweatshop out of somewhere like bangalore, kolkata, or hangzhou though.\n\nIt's useful if you're an absolute beginner at a language and have no guidance. It does bullshit a lot, so it's good to have some generic experience to catch that, but I found it superior to google or stack overflow for basic stuff. Stack overflow often just not answering complicated questions, and google having a lot of chaff.\n\nThat said, if you have any experience it is way worse than reading the docs/source of the problem yourself.\n\nAgreed. My favourite thing about it is just offloading the \"grunt\" work of coding. Once it sees what I'm trying to do it can quickly generate the structure of what I want but fuck up the insides real bad.\n\n[deleted]\n\nIf wager it‚Äôs partially AI tools but also delivery pressure.\n\nI swear every place seems to be both firing and understaffed and has record backlog sizes.\n\nIt makes no sense.\n\nThat problem will obviously only get worse as it continues to get trained on the bad code it created itself.\n\nIt also gets trained on my regular bad code!\n\nI think it‚Äôs 10-15%. Seriously. I equate it with somebody using an IDE really well. \n\nWe are pushing it hard and I‚Äôm seeing no substantial difference in people‚Äôs productivity.\n\nSkipped right past the 10x programmer.\n\nIt‚Äôs not even a meme at this point.\n\nThere we see the actual industry threatened by AI; the Bullshit As A Service chunk of the consulting industry (operating model; weasel your way into an org, while charging so much that it's politically impossible for the people who brought you in to admit that you suck, as that'd mean they were rubes who got duped).\n\nThis is precisely how it works and it drives me insane that the people who get duped somehow evade detection as rubes usually indefinitely.\n\nHowever stupid they are their management is truly rebar through the head levels of brain damaged.\n\nIt's turtles all the way down; the people who appointed the rubes can't come down on them for being idiots for fear of branding themselves as the exec that appoints morons. \n\nWhich means there's a narrow window after anew CEO is appointed where this sort of dumb shit can be dealt with, but that's about it ?and the CEO needs to be aware of the issue while all the rubes are dancing their hearts out to keep the CEO's attention anywhere else.\n\nAnd we can stop walking as soon as we grow wings.\n\n[If my Grandmother had wheels she would have been a bike](https://www.youtube.com/watch?v=A-RfHC91Ewc)\n\nThe hardest thing about software is not writing it, that's easy, it's about correctly understanding the problem and context around it that you're trying to solve. Often that means understanding the humans involved, what their desires are, what they need.\n\nThis is not an easy thing to solve with AI.\n\nMy former boss always told me \"coding is more than hacking keys\". The essence of software development isn't putting out code, it's understanding the problem.\n\nI'm happiest when I'm writing code because it means the hard part is over.\n\nIsn't that what he was saying? That authoring the code is not the important part?\n\nahahahahahahaha‚Ä¶\n\nsigned,\nevery dev forced to use AI to help them write code today\n\nHe doesn‚Äôt even realize we are likely already near the top of the S curve with this stuff. I remember when ChatGPT made its public debut almost 2 years ago so many people waving off its problems with the ‚Äúit‚Äôs getting exponentially better!‚Äù excuse. 2 years later and it‚Äôs a little better, not a lot, and in some cases even sliding backwards. Unless this dude is privy to some sort of super secret AWS advancement we don‚Äôt know about I‚Äôd say the era of exponential growth, the kind of growth we would need to get where this guy says we will be in 2 years, is over.\n\nAWS is trying to sell us Claude usage currently. If they have anything super secret it‚Äôs like the best kept secret ever.\n\nTheir CodeWhisperer stuff isn't as good as Copilot. And Copilot isn't that good.\n\nAs a 15 year software engineering veteran who constantly tries to use AI to help me with my job...\n\nHe is incorrect.\n\nHe is so incorrect that he should lose his job.\n\nNot because it's an awful thing to say, although it is, but because nobody who has this little understanding of technology should be in such a high position in a software company.\n\nThis right here.\n\nIt is understandable, yet lamentable, that as you walk up the management chain you often get those who have less and less deep understanding of intricate technical issues.  Furthermore, it's also common that the higher you go the greater folk are so wrapped up in the marketing propaganda that they believe it too much.\n\nBut this would appear to be very disturbing.  To the point, I wouldn't be surprised Amazon's stock takes a hit immediately.\n\nFar too many companies depend upon AWS.  I'd be a tad less comfortable about such dependence given nonsense like this.  It implies that AWS is likely going to degrade in quality as their management chases such fancies.\n\nAI demos in particular are often custom tuned, if not downright fabricated, to appeal to the audience that doesn‚Äôt understand the technology. Makes it look *way* more capable than it actually is.\n\nMaybe he could be replaced with AI\n\nHe absolutely knows its bullshit.  He's saying it because companies following this advice now suddenly have need for amazon services.\n\nIn fact, AI is on a far better trajectory to replace \"jobs\" like his than to replace engineers of any type\n\n[deleted]\n\nWhatever do you mean?!?! HE \"built\" EC2! Just read his bio.\n\n/s\n\nI've found it helpful on occasion, but for small tasks. Most of the time it gets things entirely wrong or not at all what I was asking for despite being very specific to my needs. Sometimes it makes things that I can rework a little bit to be helpful.\n\nMostly it's been helpful for filling out unit tests (which, for Copilot at least, seems to mostly base on previously written unit tests, which might not be related)\n\nI'm such a dork that I love TDD and writing tests.¬† I know, I know, I'll see myself out\n\nI find ChatGPT somewhat helpful as a better search engine when my actual googling skills fail me. Usually it's when I'm working in an unfamiliar domain or tech stack. It's pretty good at providing pointers to the truth even if it's not always correct by itself.\n\nI have to agree. I‚Äôve actually fallen into a bad habit of spending more time going back and forth with chat gpt trying to get it to correctly write shell scripts for me than I would‚Äôve if I just wrote it myself.\n\nExactly this. It only highlights how inept most business leadership is. Just nepotism/cronyism and then they wonder why they're so inefficient and losing money.\n\nThe title is written ambiguously. It really means \"developers will stop coding (as) soon as AI takes over\", not \"developers will stop coding soon, as AI takes over\". In short, it's a tautology. He elaborates by saying this will happen \"in 24 months, or later\" ie, it'll happen when it happens\n\nOccam's Razor says they leaked the recording to excite investors and re-instill waning trust that they will develop a competitive AI solution. The sentiment in the headline is absurd, and I find it's inexperienced developers that tend to promulgate it (i.e. the kinds of developers who think the entire field can be distilled down into \"Googling stuff\", which is such a tired joke that when told belies the massive rift between skilled engineers and dime-a-dozen React Andys and GitHub influencers).\n\nSaying AI will replace software engineers is like saying airplanes are going to drive birds extinct because they fly faster.\n\nI'm not ready to scavenge for stray seeds though. Really, it's a very strange analogy. Birds were never used for aerial transportation and they do not compete with airplanes.\n\nCoding is like 10% of a senior dev responsibilities, so even though they stop doing it, it doesn't mean you can run a company on your own with just an LLM prompt.\n\nAlthough I think this sub generally downplays the affect AI has and will have, I tend to agree with this. I'm a Staff dev, and I haven't finished a PR in weeks.\n\nWriting the code isn't the hard part as you get more senior, especially in a world where hardware is so incredibly cheap and there's increasing diminishing returns on holding back product value just to write hyper efficient code. The real challenge becomes aligning product excellence with technical excellence, which is so contextual that I don't see AI mastering that the same way that it can reliably generate me test suites that are ~60% passable.\n\nWhich is exactly what he's saying.  Seriously, did anyone read the damn article?\n\nCongrats, you are the first other person I've seen who read the article. \n\nYou are correct, he's literally saying that even if developers no longer needed to write code, they would still be needed to translate unclear business requirements to application logic.\n\nBut at that point aren't you a business analyst or product manager and not a developer?\n\nHow many lines of code (or serious/production-quality software products) did this guy write (build) in his career for me to take his words seriously? My wager based on what the title says here is probably meager/trivial.\n\nMy money is he wrote zero lines of code.\n\nI'm guessing he wrote a negative number of lines of code of value.\n\nThat is to say, when a hack writes bad code that doesn't work and then you send in a good programmer to \"fix it\" the diff often comes back removing hundreds of lines of code if not more and indeed fixes the problems.\n\nFrequently it feels like the worst programmer isn't one who gets stuck and can't write the code, but someone who just copies and pastes in voluminous lines of code from example code, vendor code or stack overflow.\n\nAnd don't forget, all that example code is what LLMs that are \"going to replace you\" were trained on!\n\nHe's a product manager apparently, so you would be right\n\nThe nice part is if AI can define and execute business processes enough to replace developers, it can also replace almost all of middle management.\n\nWhen co-pilot becomes more than a semi-smart autocomplete, I might be concerned. Until then, I think we're good\n\n[deleted]\n\n&gt; We could end up with fewer juniors \n\nI can imagine the alternate scenario too.  I've heard a few people say they've quit using copilot because they could feel it making them rustier and out of practice.  The work we can expect out of a junior and their average career skill development might actually be diminished.\n\nThat would require a different fundamental technology. LLM *is* semi-smart autocomplete technology.\n\nMost of the things I use AI for is boilerplate/template code. Sometimes it'll be smart enough to answer a question like, \"why am i getting this error\", but usually it's just a word for word copy from a stack overflow article somewhere.\n\nreplacing code with 'description of what you want' is a fool's gold. the latter is also coding. \n\nand in any case, once you try to eliminate ambiguity in your instructions, you'll end up with something closely resembling traditional code. i remember years ago my boss wanted requirements spec'd in pseudocode .. and everytime i tried to be precise i realised what i was writing was high-level Perl.\n\n[https://ludic.mataroa.blog/blog/i-will-fucking-piledrive-you-if-you-mention-ai-again/](https://ludic.mataroa.blog/blog/i-will-fucking-piledrive-you-if-you-mention-ai-again/)\n\nLool amazing \"try { thisBullshit(); } you are going to catch (theseHands)\"\n\nWhat a great post. Lol. \"Fix. Your. Shit\".\n\nThis is the \"line goes up\" of AI BS. There's not meaningful response to this in favour of AI that can't be shot down with either \"bigger, more effective problems can be solved more efficiently without AI\" and \"the environmental cost isn't worth it\"\n\nThis guy is awesome\n\nI'm pretty sure AI will be able to take over the Amazon cloud chief job way before it can take over a developers job.\n\nI once tried using ChatGPT to program me some smarthome code. \n\nThe first attempt looked promising, but I immediately spotted some problems. I told this to the LLM, and it corrected these. Then I found some logical errors, like \"if time &lt; 05:00 AND time &gt; 11:00 then...\". I told this to the LLM, and it corrected these. This repeated several times until the script worked.\n\nThen I realised that I basically was still programming and debugging myself, just with a secretary who did the typing.\n\nIsn‚Äôt this title a tautology? It‚Äôs basically saying that AI will take over coding when AI takes over coding.¬†\n\nAI can‚Äôt even say how many Rs in strawberry\n\n[removed]\n\nYeah, this is the hilarious part. People think they‚Äôre going to be able to tell AI to build their grand visions when they can‚Äôt even explain what they want to human beings. They want AI because they think the human engineers who have no fucking clue what they are being asked to build are the problem in that situation.\n\nThe day Amazon Q will give me the first even remotely correct or helpful answer... I will keep laughing. Our jobs are safe. Our tools will get smarter but our jobs are safe.\n\nThere's going to be hell to pay when this goes bust and companies want their developers back.\n\nTech industry left real growth to scams and financial hypes to fund their last days before being declares officially mature and no longer the growth companies that they were.\n\nlol hell will freeze over if I ever trust an Amazon bean counter.\n\nFor twenty years these assholes kept trying to drive down labor costs by saying there was a developer shortage and \"anyone can code\". Now they fire everyone and say AI will take over.\n\n[deleted]\n\n&gt; Coding is just kind of like the language that we talk to computers. It's not necessarily the skill in and of itself. The skill in and of itself is like, how do I innovate?\n\nThis person is a moron.\n\nI‚Äôve been trying to figure out how to put architectural principles around AI enough to let my team (in a regulated environment) use AI.\n\nI‚Äôve heard that steroid use only takes you one ‚Äúlevel‚Äù above what you would have naturally: I can take pills all day and never be as good at basketball as Steph Curry, or soccer as Renaldo or whatever. Best I could hope for - with drugs - is maybe a spot on a D4 college team, maayyybbeee. (I was low-average of ability in pretty much every sport)\n\nI‚Äôm starting to think LLMs are the steroids of development: throwing non coders at an LLM just gets you a 1/10 rated developer. (And throwing an AI at a 3/10 developer won‚Äôt get you a rockstar either, you‚Äôll just get a maaayyyyybbbe less sucky 4/10 developer.)\n\nHow many years have we had code generators? You still need people to specify, think through, debug and implement systems that work. AI won't eliminate development, it will automate some portions of it, but people will be needed for a long time to come.\n\nI had an Amazon director ask me to take on the project of building out an ai coding tool to replace programmers, by myself. This was when I was jobless. I asked what compensation I‚Äôd get and he said maybe he‚Äôd pay me but it‚Äôd mostly be a resume booster.\n\nThese people are delusional. The fact that they‚Äôre high in Amazon doesn‚Äôt mean as much as you‚Äôd think.\n\nThe CEO is a business weenie. He has no engineering or programing skills what-so-ever. In short, he's as smart as Elon Musk.\n\nElon Musk is not a business weenie. He‚Äôs a micromanager\n\nReminds me of that meme message where the guy is like \"i just used ai to build a website, you are so cooked. Want to see?\" And the programme replies \"sure\". Then op sends him a localhost link. Lol.\n\nAlternative Title : Amazon Cloud Chief found to be braindead but still talking.\n\nIf AI ever gets good enough to replace developers I‚Äôll have nothing to worry about because it will have already replaced 60% of corporate jobs and the world will be turmoil\n\n&gt;\"Coding is just kind of like the language that we talk to computers. It's not necessarily the skill in and of itself\"\n\nTell me you've never written a single line of code without telling me you've never written a single line of code.\n\nGolfing is just kind of like the language in which we tell the ball to go into the hole, it's not necessarily the skill in and of itself.\n\namazon cloud chief preparing their team to prioritze selling AWS services to unsuspecting small business clients\n\nAll my AI generated code has extra fingers in it.\n\nThe developers are gonna laugh and laugh at this. The delusion is real with people who have zero programming experience.\n\nMost managers could be replaced by a mail box and a copier machine.\n\nPeople have been saying that for at least 30 years.  Probably longer.\n\nThey're technically not wrong.  It's just...  No closer to reality now than it was when automation was in its infancy.\n\nWhat sets humans apart from machines is understanding.  When machines can understand what they're doing, then we can start to worry.\n\nA tale as old as time.\n\nTo use a calculator, you need to know math.\n\nTo use a spreadsheet you need to know math.\n\nTo use AI to write code, you need to be able to write code.\n\nOh God!  Time to start looking for another cloud provider then!\n\nNotice how executives never say their own job is in jeodardy of becoming obsolete.\n\nCoding with AI is the equivalent of coaching a second rate co-op student who you have to continuously prompt with additional information to get the job done properly while you could have done it yourself twice as fast with 2x the quality.\n\nI believe him. Might be 24 months, or 24000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000, but hes right.\n\nThis is dumb given that \"AI\" will still need to be coded to be run. Unless they found the magical recipe for those algorithms to predict outputs at a 0 marginal errors. I think these foos just try to scare developers - especially those that stay in their comfort zone of learning.\n\nYou just need to prompt harder my friend and you can get AI to do all the work for you with zero bugs. \n\n/s\n\nGood luck with any future catastrophes!\n\nSoftware engineers have a hard time understanding app requirements and when they do understand it, have a hard time designing it. Then SE or programmers have a harder time writing it.\n\nAnd we are to believe that AI can do everything with natural language input?\n\nGood luck doing close-loop n-case testing.\n\nI don't think AI will ever replace coders, but I could see an LLM that is trained on just law and court precedent could eventually replace lawyers. :)\n\n\"During Garman's talk, he told employees to find new ways to incorporate AI into their workflow.\"\n\nThat isn't possible because external LLMs are not allowed and the computer they give me to code on isn't powerful enough (mostly because of GPU) to run any good local models.\n\nThere is a on-prem LLM we can use but we aren't allowed to run any of our code through it either.\n\nü§£\n\nFeel like \"AI\" could more easily replace the cloud chief than the developers.\n\nCall me when ChatGPT correctly identifies the number of r‚Äôs in ‚Äústrawberry‚Äù\n\nSame MBA arse holes screaming that block chain would disrupt the world and look where that ended up. Granted AI has a greater practical use, but since the hype train started what has it really disrupted.\n\nI haven't liked coding for a better part of a decade at this point. If there was a single AI tool that even did 10% of my work I would be using it, but there isn't. GPT-4 isn't any more helpful than a Google search and GitHub Copilot is essentially useless: The suggestions are almost always wrong and when they are right, they are so obvious that 3 strokes and intellisense does the same task but quicker.\n\nI'm sure at some point some system will automate coding but we aren't going to get robot software engineers by fine tuning chat bots. That's just a fantasy.\n\nA management lobotomy case saying something nonsensical to people who know he's full of shit? say it ain't so!\n\nI think we will potentially see a bigger overlap in programming and business analyst responsibilities. The tough part of coding is obviously not the typing, but the breaking down of a business problem into terms a computer can understand, and all the edge cases that come with it. I think skilled business analyst are well positioned to be able to interface with an AI agent in a way to produce good results.\n\nThere is always more code to write.  AI may make some of the more tedious bits of coding easier ‚Äî boiler plate, etc.   If programmers get more productive with these tools then projects will just have more requirements.\n\nI haven't seen AI solve a single problem yet. So I'm not going to hold my breath.\n\nI'm 95% less afraid of AI taking my job than I was a year ago.\n\nMy experience with AI is that it is great for mundane tasks but if it gets something wrong, which it often does, it can't figure out how to fix the problem. I think it can speed up development considerably, but I can't think it will replace software devs. Then again, I'm not a neutral party.\n\nI deal with a lot of ai stuff and if it ever happens it will be along way off.  They are only mocking intelligence not really coming up with unique and most coder assistants or even the agent developers get it wrong 1/2 the time on anything that is not already been written by someone else\n\nHe is right. I wonder when we'll have an Artificial Intelligence proper, though.\n\nAutomation is most effective when repetitive tasks are involved. However, codebases vary widely across companies due to different technologies and the evolution of skills. What could be the common pattern to replace these tasks? It‚Äôs concerning to hear a cloud chief at such a large tech company making statements like that.\n\nlol. good luck."
  },
  {
    "title": "Software Engineer Titles Have (Almost) Lost All Their Meaning",
    "body": "",
    "score": 1024,
    "url": "",
    "created_utc": 1729440327.0,
    "author": "[deleted]",
    "permalink": "/r/programming/comments/1g823xn/software_engineer_titles_have_almost_lost_all/",
    "all_comment_text": "The problem I see sometimes is that HR sets pay scales for titles and engineering managers know what they have to pay someone to be competitive on the market; so good engineers who aren‚Äôt ready for the title but has the technical chops that the manager wants to keep is promoted so the manager can pay them enough to keep them.\n\nThis is the real problem.¬† Being on the other side and trying to keep the employee I've found myself running up against Hr paybands that are behind market trends and result in being forced to promo to keep the employee.¬†¬†\n\n\n¬†Hr takes too long, and seemingly also kinda tends to want to keep salaries low. Meanwhile the business wants to move increasingly faster.¬† Result is to get the sr eng talent I need at market rate means calling them staff or higher.¬† I'd much rather just pay them market rates, especially when that title confuses them and they think they are now responsible for more than a sr eng should be.¬†\n\nAs someone who has been at the staff+ level for a long time, I‚Äôve witnessed this exact thing, or a slight modification where the company is only willing to hire senior engineers due to some perceived speed advantage they would grant. So you find a mid level engineer who is solid AND teachable (most important) and hire them as senior. They burn themselves out trying to live up to the title when all I want to do is teach them and make them better. \n\nOR you get the mid level engineer you thought was solid, give them that senior title and it goes to their head. Suddenly they are trying to lead from a deficit in experience and it‚Äôs bad for the whole team‚Äôs morale‚Ä¶\n\nI was on the other side of this. Promoted to senior way before I should have been. I remember asking my manager directly what that means and he told me to just keep doing what I'm doing and if anything needs to be changed they would let me know. Having that kinda open feedback went a long way to me not feeling like I had to over preform in the role.\n\nI‚Äôve definitely explain that sort of thing, but because of the title outside expectations don‚Äôt align. Then I‚Äôm stuck trying to reset expectations externally and internally. It can be a total mess. I‚Äôm glad it worked for you though!\n\nYeah, it doesn't matter. They don't need a justification to prune you (if you live in the USA that is), since it's an At-Will Country.\n\nMy issue is the title often comes with zero support or authority.  I spend years as a lead where the product owners had more influence over how I did my job than I did (they‚Äôve since fixed this).  The job description had no explanation for responsibilities (and still doesn‚Äôt).  So I‚Äôd mostly be forced in to a corner by people who have no idea how to do my job or my teams job then blamed for the failure of the very things they forced me to do.\n\nI‚Äôm becoming increasingly convinced that the team lead position is just there so they have someone to blame when their decisions cause failure, because they sure as hell don‚Äôt listen to us.\n\nI dealt with this several times and it is INFURIATING!!! Eventually, the next time I changed jobs, I demanded the authority as part of my interview process. I told them what I needed to properly lead as a Staff/Principal Engineer, Tech Lead, whatever. \n\nGuess what? Because I set those expectations before being hired, I was (mostly üòÖ) given the authority I needed! Now whenever I‚Äôm put in a place where I don‚Äôt agree or think it‚Äôs a bad idea, I get it in writing. Then I can point back and say, ‚Äúlook, I didn‚Äôt want to do this, you did.‚Äù This has changed so much for me. I‚Äôm willing to say no, or at least that I can have the team do it, but I disagree and here‚Äôs my email saying so, and explaining why (very important to explain why).\n\nLastly, back up everything you say with evidence. Articles, blogs, podcasts, tech docs, well-regarded repos, whatever. This will give your arguments more weight.\n\nThe main problem I have is people really get impatient with detailed conversations.  It‚Äôs like they want to talk about it until that involves listening to your explanations for why you‚Äôre saying what you‚Äôre saying, but at the same time they dismiss what‚Äôs being said because you‚Äôve not explained.\n\nThey‚Äôre especially a fan of doing this with things like agile principles.  They‚Äôll make a (false) claim about agile and why you need to just do what they say, then when you try to explain the actual principles behind it they get frustrated and say you‚Äôre just stuck on the details and ideals and they don‚Äôt want to talk about it.  When it comes to the technical they just say that you can‚Äôt talk too technical but at the same time you need to do what they say even though they just told you they don‚Äôt understand the topic and don‚Äôt want it explained.\n\nBasically, they‚Äôre _really_ good at avoiding any discussion that would involve actual justification and explanation.\n\nFirst, you don‚Äôt have to explain the why entirely, send them the articles or whatever else. Paper trails are great when stuff goes sideways because you can point to your message/email history to back you up. If they chose not to read your reasoning, that‚Äôs on them. \n\nSecond, it sounds like you have a serious culture problem. Perhaps your engineering leadership and the other stakeholders‚Äô leadership needs to have a sit down and reset on expectations and responsibilities. Nip this garbage in the bud. \n\nIf leadership won‚Äôt help and you can make headway on your own, try getting a few more senior people together from the different stakeholder groups that are like minded and approach leadership together. This has worked well in the past and shows a desire for better cross-functional collaboration. Do it even if one group chooses to stay out. \n\nAt one company, product was always going to my engineers (I was the senior manager of mobile engineering) and asking them to do this or that for them. Sometimes these were huge tasks that dramatically affected the code base. I learned of this behavior a few weeks after starting, because the priorities I had set with the team weren‚Äôt getting finished. \n\nSo I went to the new VP of Product (she started around the same time as me) and we came up with a process to handle competing priorities. I held a weekly meeting with the product and mobile teams where we set priorities for the coming sprints. If you didn‚Äôt attend (or didn‚Äôt send someone in your stead), your work didn‚Äôt get prioritized. The VP was behind this fully. \n\nGuess what? The product people who showed up were happy and understood when we would get to their work. The ones that didn‚Äôt were super pissed that they were ‚Äúbeing ignored‚Äù and ‚Äúthat there was no way they were going to another meeting‚Äù. And when they went to the VP to complain, I be you can guess what she told them.\n\nWe‚Äôve actually been making headway on the issue and it‚Äôs in part because I‚Äôve gotten together with two other leads and we‚Äôve been going to leadership together.\n\nPart of the challenge is I was a lead on my own, then they promoted the other lead but he flat out refused to be a lead (he accepted the title but won‚Äôt do the job).  They since promoted one other (and I‚Äôm working on a promotion for another whom I‚Äôm mentoring and is awesome).  Those two new leads very much are leads (and imo are better than me because they don‚Äôt have the years of history) and we‚Äôve been making headway by working together.  There‚Äôs been some great progress recently but I‚Äôm still struggling with the lingering frustration.\n\nThat‚Äôs great news! Keep at it and expand your circle. The more people (especially from different stakeholders), the better!\n\nIf you had seen no change then you should be annoyed so take heart in the progress and if it continues that frustration will diminish in time.\n\nThank you for the advice and encouragement :)\n\n[deleted]\n\nSure, they should, and there was a time when I was much younger that I didn‚Äôt care about titles at all. Then I grew in my role and started interacting much more with other people inside the company and sometimes people outside as well. Those people rely on titles to understand who you are and what they can expect from you. And how much influence you may have. \n\nNow, I believe accurate titles are important, because they help set OTHER people‚Äôs expectations.\n\n[deleted]\n\nIn theory a company‚Äôs pay is always behind market trends, or intended to be kept there, otherwise they‚Äôre paying more money than they need.\n\nNot every company can physically pay ‚Äòat or above market‚Äô but literally every single company says that.\n\n&gt; Hr paybands that are behind market trends and result in being forced to promo to keep the employee.\n\nThat's why so many engineers would find another job sooner than they could get a promotion from their own company.\n\nSeen this in action myself - I was against it and was told they could \"grow into the role\". In hindsight it was the right decision, keeping good people motivated and paid fairly.\n\nThe companies all subscribe to salary comparison databases where they ignore titles and use standard numbers. Whatever they say your title is, somewhere in their system you are recorded as an Individual Contributor Level 4 or whatever. The levels roughly correspond to job duties but realistically it's just how much money you might get from another company so the company knows if their offer is competitive.\n\nI know companies use these services; and they decide where in the competitive pay scale they want to be. You can pick the types of companies you want to compete with or what percentile of salaries you want to be in. The problem is that HR is disconnected from the requirements of the work. They look at titles like \"Software Engineer\" when in reality there are many different skillsets you might want to hire against. A front end developer is a different pay scale than a backend developer than a full stack developer than a systems software engineer than a K8s software engineer and so on. \n\nIf you're building a really well defined set of software with a limited scope it's not so bad, but if you have a broad technology portfolio then you develop some real problems matching pay to skillsets for the more expensive skill sets; and the companies that have those broad technology scopes are the ones hiring a lot of engineers and those are driving the title inflation.\n\nAlso you have the money chasing grinders who seem to think a few years of intense targeted studying to check off all the boxes makes them a sr full stack developer.\n\nJust need to go get certified and then they‚Äôre good right?\n\nExactly this happened to me. I promoted someone earlier than the job description prescribed because it was the only way to retain them, and their contributions were well worth the money. What I was not anticipating was the intrateam competitiveness -- this promotion ended up causing resentment among my team, particularly among those who had this same title, simply because they viewed this person as not being ready for the title. We were all learning, and this person did actually grow into the role, but the resentment never seemed to go away.\n\nWhen someone on another team (that team works with my team) was promoted to a title they clearly were not performing at, it caused me to lose respect for their manager.\n\nAnd the other way around, consultancy places that set rates for people based on their title. The fresh from school people start out at senior so they can ask the customers for more money, the pay scale is as if the title was junior.\n\nTitles were never standardised anyway, or anything close it. There is huge variety in work culture over the whole developed world and job titles are a tiny part of it.\n\nYup.  Our team had really low compensation compared to a sister team.  I looked into it and discovered that the other team had higher compensation because they were hiring externally (gotta pay higher to kepp up with the market compared to people who stayed in the position), and to do that they would come in with really high titles to justify their pay.  It was so weird when we had joint projects and I (SWE Level 2) would be telling a SWE Level 4 how to do his job even though we had the same number of years of industry experience.\n\nTo compensate we literally had to hire someone external even though there was a better internal candidate.  But sure enough it worked.  Playing the game is so infuriating.\n\nSometimes (depending on the culture), it also _is_ about titles. The employee needs it to improve their CV and/or feel recognized.\n\nI agree.\nAlready the fact we are using the term ‚Äúengineer‚Äù instead of ‚Äúdeveloper‚Äù sais it all, I believe.\n\nWe're not PEs and don't pretend to be. I don't see the problem.\n\n&gt;and don't pretend to be\n\nWhat other reason could there be to transition from \"Software Developer\" to \"Software Engineer\" if not to borrow the prestige of an engineering title without the rigor, standards, or discipline?\n\nThis. 'Engineer' should describe education rather than being a job title (full disclosure: developer but not an engineer).\n\nI‚Äôve met a few people I would call software engineers but the vast majority of programmers I‚Äôve met shouldn‚Äôt qualify. As a group we (developers) should be advocating for stricter standards in our own industry but we seem to be allergic to collective action (at least in the US). If we had practice closer to actual engineers I think we would have better results. \n\nThere‚Äôs a problem that it would accelerate jobs offshoring however we could address this by having different liability standards along with an organization like UL for insuring against those liability claims. That org could set standards that would apply regardless of where the software is developed.\n\nIn my country there is an engineering degree in cs (informatics), so for those grads it is ok\n\nI see this all the time, I have almost 20 years of experience and we just hired someone with 5 years experience into a ‚Äúlead staff engineer‚Äù, which is a higher position than mine, I‚Äôm a ‚Äúsenior engineer‚Äù. I could program this person under the table, he‚Äôs not a bad programmer but he‚Äôs just past junior level and got to skip past senior level entirely. They did this because his last job called him a ‚Äúsenior‚Äù and they wanted him to accept the role. Not sure why they went this route though, there are plenty of programmers looking for jobs right now.\n\nIf I want to look for a job as Analyst Programer, it is listed under Software Engineer.   \nThe job description is exactly the same. and so are the salaries. Analyst Programer is getting scrubbed off most job site. If you search for programer, you get CNC operator job.  \n  \nSo now you have SE getting AP pay and nobody can say anything because the market is flooded by the school system who are banking on selling education by promising dream career. On the other end, that dream is used to exploit and underpay the clueless new generation replacing the retiring vet.   \n  \nOh, you want the title and some fancy business card? Sure, those are business expense, but your salary stay the same, Ok? You better be ok because the other guy behind is nodding at me that he's ok with it.\n\nWithin a job title salaries can vary by $100k a year. Titles are meaningless\n\nOften the salary won't extend that much at a single company. Until recently my company had much more narrow pay bands, especially through Senior titles. At the same time going into Senior, Principal or Staff titles the engineers are expected to perform different duties where you're taking on more of a leadership role within your group or within the company. \n\nThese sorts of titles used to have a ton of meaning and took years to attain. A senior took at least 5 years but often 7 or 8; principal titles took 15+ years to attain. Each of those levels required not only technical skill and experience but leadership, mentorship, added design and architecture duties and so on. \n\nNow I have engineers with two or three years experience expecting senior titles simply because they are really good at the job they have but without having developed those extra skills; and they expect it not simply because they are entitled but because they are looking at their peers and their job opportunities and they can go elsewhere and get it. \n\nHell, the number of chiefs we have at our company is out of control; given you'd expect only one.\n\nI got an email once that was meant for someone else with the same name who was a hiring manager that listen salary ranges for titles and one was like $75k to $175.  And the different  had a huge degree of overlap in salaries .\n\nIt really depends on the company and their HR philosophy. We recently expanded ours so we don't have to inflate titles and now they have those kinds of ranges but before then they absolutely did not. \n\nSide note: I've heard that companies which operate in jurisdictions which require salary transparency in job postings to have higher ranges. I'm not sure what the logic is there but it's something I've observed.\n\nThis coupled with the culture of no raises. Management or HR thinks employees do one amount/quality of work the entire time they hold a specific title, so they don‚Äôt deserve an increase in pay. \n\nI was a professional developer for 2.5 years before I was promoted to SE3. It wasn‚Äôt because I was ready, it was because my bosses knew I was gonna go somewhere else if I didn‚Äôt get paid more and this was the only way. My promotion made like 3 other good developers leave because I got the only SE3 spot available. So my company lost a lot of talent by holding on to me. It‚Äôs cool we‚Äôll go through this again in a couple years when our junior developers reach the wall and leave for more money.\n\nThis is the exact thing that has happened to me. I am the senior analyst at my company. But I'm also the only one sooo either it's a comment on how old I am or pay band issue.\n\nWe used to work with another (larger) company, where half of the people I have interacted with were vice presidents doing run-of-the-mill work.\n\nyeah in finance everybody and their mother is a \"vice president\" lol\n\naccording to wikipedia, a VP (in finance) is:\n\n&gt; junior non-management positions with four to 10 years of experience\n\nI was told by a vice president (i.e. sr. software engineer) that it's about finance and company rules. You have to be a VP to do &lt;insert long list of mundane stuff here&gt;. Everyone thinks it's stupid, but plays along with it.\n\nI wish they would inflate my title to VP. I was asked to travel to the India office so I reviewed the travel policy. VP+ can book the lie-flat seats. I'm going to be wasted when I get there after 20 hours in my lowly upright seat.\n\nThe worst companies are the ones that set T&amp;E rules based on title.\n\nMy favorite travel policy:  Anything over 6 hours can be booked as business/1st (cheapest of whichever is available).  If you can take a redeye business/1st and skip a hotel day/not take a travel day, then do that.\n\n\nIt didn't matter what your title was, this applied across the board.\n\nthat's basically any finance company. it's because only VPs can \"act as officers of the company\" to grant loans, sign stuff, etc.\n\nThe *real* movers and shakers are directors, in general.\n\n[deleted]\n\nHey, Paul! ü™ì\n\nThis was almost certainly a banking institution, where even the janitors are the \"VP of sanitation\".\n\nOh I know which company this is.\n\n\nWe can't even trust half of our \"VP Software Engineers\" to write a unit test.\n\nMy official title is \"Senior Manager, Software and Engineering, Sr.\"\n\nI am not a manager.\n\nare you in software and/or engineering?\n\nA few years ago there was this bank in Brazil that came with the \"genius\" idea to make everyone in their IT department a CTO...\n\nSo they had CTO of Testing, CTO of web development, CTO junior of iOS development, etc. It was the dumbest thing I have ever seen.\n\nTitle inflation isn't the problem, but the result of a really unhealthy, trend-seeking job market.\n\n\nAt the end of the day ~~its another day over~~ being a senior engineer is the only way to receive a fair compesation for our work. This shouldn't be the case.\n\nAdding senior to my current job title on my resume when applying for new jobs made the processes a lot easier (I get less challenging interviews, I guess they assume I know things) and also made it easier to negotiate pay. It's the way it is.\n\nDude...this can't be real...\n\nSome of my recent technical interviews have been a nightmare because they make the most obtuse questions about something no one gives a rat's ass for a mid position...\n\nGuess I need to adopt this strategy\n\nHate to be that guy, but if you're sitting in an interview they start throwing you stupid pinhead gotcha questions, call them out and ask them to explain the relevance of the question to your expected day to day work for the position. \n\nAre you going to throw the interview, yup, but we as an industry need call out the BS games. \n\nI do a couple technical interviews a month for my company. Every question I ask is relevant to the actual work you will do, no stupid question about how many elephants fit in a bus, no demanding someone whiteboard a qucksort algo, etc\n\nI've actually talked with a colleague about this BS lately and I came to the conclusion that, apart from small exercises that usually takes some days and that show your way of thinking, use of standards, thought process, \"why use this function instead of any other\", etc., I will purposely get a zero as a way of showing how stupid they are. Not a bad grade, but a big fat zero.\n\nHad a situation happen two times before, where the exercises or interviews are leet code shenanigans, some way of achieving the perfect algorithm, almost philosophical even. Had to study to remember less used concepts or specific definitions of things, so I was fully prepared. Then I got the job and the code is so chaotic, so full of pasta, I almost thought I was a cook for an Italian restaurant. So full of no standards, no patterns, no reason to what was done besides \"it needs to work\".\n\nSenior Interviews should be much more in depth IMO\n\nYes. But not a whiteboard \"dance code monkey dance\" interview. It should be in depth questions about their recent employment experience. How they discuss their previous projects and planning. A senior should be able to do the code. Yet why you are looking for a senior developer is really not because of the code. It's the ability to write good code. Develope and better the standards for good code. Take pull requests seriously. Not just for getting the task done but understanding the full roadmap and making sure that PR is moving towards that path. It takes the ability to speak up in meetings. Creating tasks to delegate to more junior developers. Then knowing the skills of those developers and who would be better at different tasks. \n\nI'm not some super coder. I'd argue that a team of mid engineers could match the result of a team of senior engineers on some one-off coding project. Extend that timeframe over 2 years with an evolving code base and requirements the senior engineers all day.\n\nI agree with the problem, but I don't think the solution is as easy as \"don't do it\". It's kind of like saying you shouldn't need to lock your doors in a safe neighborhood. Knowing all it takes is for one bad actor to ruin it for everyone inevitably means everyone is going to safeguard against it.\n\nTitle inflation is just that. To stay relevant in the ecosystem, you need to follow the trend, no matter how nonsensical it may become. You may see islands of stability develop, but it'll never return to the simplicity of yesteryear.\n\nDon‚Äôt get me started. No, someone is not a ‚Äúsenior software developer‚Äù two years out of a CS degree. They‚Äôre profoundly inexperienced.\n\nSenior just means they can leave you alone and they won't return to find you chewing on the power cables.\n\nI think that's actually a valuable distinction. If you want titles to reflect capabilities then maybe you should differentiate between \"stumbling around like a newborn deer\" and \"somewhat competent\". Maybe there's a better term for the first promotion, but the solution advocated by many title inflation complainers \"Thou shall not be promoteth til thou hath one score years of experience\" is pretty absurd. Reaching the terminal level after two years is silly and so is waiting 10+ years for the first title change.\n\nThat's why you have a junior level. Juniors chew on power cables, mid-levels should be competent, seniors should lead teams.\n\nWorks for me. I think generally the companies people complain about don't have the junior level so senior becomes mid-level.\n\nbut they taste so yummy and spicyyyy\n\nLikewise you are not a senior developer after 10 years of work. I have worked with far too many ‚Äòseniors‚Äô that had all the work experience but had less skills than the guys I had as classmates in university, and it‚Äôs really frustrating to be surrounded by such incompetence.\n\nWe need to start giving these titles based on skill and merit instead of work experience.\n\nYeah, years of experience != skill level. This always has been and always will be true. \n\nI remember early in my career being intimidated because I had to interview someone who had more than 20 years of experience. Turned out they knew almost nothing and it totally changed my perspective as an interviewer.\n\nI think work experience in this field is necessary but not sufficient. There‚Äôs so much stuff you can only pick up by seeing and doing.\n\nYou need to pick up by seeing and doing but each domain can be wildly different, yet everyone has one of two titles, developer or engineer. Ten years of experience between two people can look totally and completely different depending on what they worked on.\n\nWhat I really need is an SRE. My company doesn't even recognize this title so we are hiring \"senior software engineer\" and HR keeps giving me candidates that don't have the experience I need because they think we are all cookie cutters and so the same thing. I write the job description but they go through the applicants and the disconnect is infuriating.\n\nSource your own candidates? You could complain about it, or you could dedicate some time to finding candidates yourself and send them over to your recruiting department and say ‚Äúhere are 5 candidates whose experience is in line with what I‚Äôm looking for.‚Äù\n\nETA: don‚Äôt just write the job description; write a candidate spec. Sir down with recruiting and say ‚ÄúI‚Äôm looking for these technologies, or experience solving these kinds of problems.‚Äù Make it clear what‚Äôs a need, what‚Äôs a want, and what‚Äôs a nice-to-have, and what the tradeoffs are.\n\n&gt; Source your own candidates?\n\nSo now we gotta do HR's job for them?\n\nNo. Help them get better. Give them examples. Help them understand WHY those are good candidates. Or keep wasting your time and complaining. You do you.\n\nAgreed, but then you run into the major issue in the industry: management cannot gauge merit.\n\nIMO, senior means that you can give someone a task and trust that they'll get it done correctly without any kind of supervision or hand-holding.\n\nIt's the one reason I'm incredibly annoyed that someone was given a lead title on my team when he was damn-near fresh out of college, and is *constantly* bugging me for help whenever he hits a snag.  Motherfucker, look it up and figure shit out on your own... if its something super novel, then sure, I don't see an issue with asking for advice... but I'm just asking you to implement simple fucking web functionality.\n\nIts disgusting how high this dude's title is, and how incapable he is to finish even the most basic of tasks before giving up and seeking help after hitting even the tiniest of snags.\n\nYour first paragraph is getting there, but to me a senior means more than just ‚Äògetting a task done‚Äô. To me a senior is someone that actually knows how to program, and by this I mean:\n\n1. When tasked they know how to actually build a system (most modern programmers know how to add on to existing systems they maintain but get completely lost when starting from scratch)\n2. They posses working knowledge of the tools and technologies they use (the senior in my team with 15+ years work experience doesn‚Äôt know how to migrate from Python3.9 to 3.10; that is not a senior in my eyes).\n3. They actually understand how to write maintainable and efficient software based on real world experience instead of simply copying whatever bullshit they read on medium.com about ‚Äòclean code‚Äô or ‚ÄòDRY‚Äô or whatever. Solving tasks is not as helpful as it could be if your code is hot garbage. (It‚Äôs the fault of ‚Äòsenior developers‚Äô that most of our systems are spaghetti with 10+ levels of inheritance and other nonsense, because they wrote this shit at the beginning)\n\nSkill = experience \\* talent. You need both.\n\n&gt;No, someone is not a ‚Äúsenior software developer‚Äù two years out of a CS degree. They‚Äôre profoundly inexperienced.    \n     \nThis is garbage nonsense when you consider the wildly diverse labor market.   \nWe've got people who have been developing software since they were 12 years old, who have more experience by time they finish high school than most boot campers and many college grads have. We also have people graduating with degrees who have never actually developed a single thing of merit, because they mostly cheated their way through school.    \nWe've got people who are just wildly talented and hard working, and pick up a dozen new skills in just a few years, where at the same time, people who have been working in the industry for a decade have not gained any meaningful skills because they've never had a reason to push themselves, usually because they are adequate to their position and never had a job which demanded more of them.   \n    \nI think about my personal experience where two years after starting my first software engineering job after graduating with a Computer Engineering degree, I had been put in charge of a whole product line, and had three internal pieces of software to my name. I just happened to be perfectly suited to the work, not just in the software development side, but also to project management. If I had gone to a different company and worked on a different kind of project, then I wouldn't have progressed nearly as fast.     \nJust in terms of results, I did the job of a senior developer, and likely higher than that. Working software was released, revenue was made, clients were happy, and I can guarantee you that you have been personally impacted by my work, however indirectly.   \nIf I had gone to work at Amazon, then I likely would been a middle tier nobody in the same amount of time.    \n     \nThis is the largest problem in hiring across the whole industry: it's somewhere between difficult and impossible to know if a particular person is suitable for a specific position, and it's incredibly difficult to get an accurate assessment of their functional ability.   \nThe amount of years a person has been working often has very limited influence on how good they are. So many people hit a wall in their personal progression, and the job market has been such that they can job hop forward and look like they're more than they are. And again, some people have a heck of a lot of experience outside college/employment which just doesn't get any weight during hiring.    \n      \nSomeone can be perfectly capable in one area, and totally suck on another, but everything gets globbed together under \"software development\".  \nIt's a very difficult issue in hiring.\n\n&gt;We've got people who have been developing software since they were 12 years old, who have more experience by time they finish high school than most boot campers and many college grads have.\n\nI am one of those people. I disagree.\n\nIt's a different thing entirely to architect a major backend that scales to tens of thousands of requests per minute, processes petabytes of data, has major compliance or regulatory requirements, requires five nines of uptime, etc. Or to really, truly have to come up with novel solutions to extremely hard problems. Or to understand how best to grapple with \"legacy\" code, or how to safely refactor a codebase, how to release code reliably and safely, and probably a few dozen other skills I think I've picked up over the years.\n\nSomeone a few years out of a CS degree or bootcamp is rarely going to have a solid grasp on any of this.\n\nYou're sort of saying someone who's repaired their lawnmower as a teenager and maybe worked on a few cars is suddenly, obviously qualified to be an aerospace mechanic.\n\n&gt;This is garbage nonsense\n\nIt is not.\n\nI think you make good points and I never said it was a simple issue. But *generally speaking*, no: somebody is not a \"senior\" engineer two years out of college. They generally lack *experience*, even if they're otherwise a strong developer.\n\nedit: I've been a developer professionally for over two decades now. Coding for three. Comp Sci degree, top of my class. Currently a \"senior staff\" engineer, whatever that means.\n\nAlso one of those people and this is spot on. Experience is work experience, not time on keyboard. If your teenage experience is working at an actual company it may count for something. But writing some hobby apps is not the same thing. It may make you a better programmer, but there's much more to a career in software engineering.\n\n&gt; We've got people who have been developing software since they were 12 years old\n\nI've met plenty of these people who are atrocious programmers but since \"they have been doing it since they were 12\" they think they have some special magic. I've known programmers who didn't start until they were 30 become among the best engineers I've ever seen.\n\nSeems to me like you're both arguing the same point: it's impossible to assess ability by YoE alone\n\nSome of the most lamentable code I've had to deal with is from precisely this type of developer: young, inexperienced developers who are extremely fluent but not very pragmatic.\n\nI'd add that the issue isn't necessarily whether someone can hit the ground running and build functional or successful software, but whether they have the working experience to lean on in their decision making throughout the process. You don't know what you don't know and with only a few years of experience there is a functional limit to how much you *can* know. A wunderkind junior is still a junior.\n\nHonestly disagree with this. You can do all the dev you want but until you work on a professional work environment with code reviews, various code coverage metrics to hit, design docs to write, etc - you habent experienced what real dev is.\n\nI've been dicking around with programming since I was in school in the 90's.  Had some shitheaded kid start on my team a year or so ago that was for some reason given a senior title fresh out of college acting like he was hot shit, but didn't know how to work with a simple fucking array of data.\n\nI called him out (privately) on his inability to work independently - something that is absolutely a requirement of a senior-level engineer.  I put it in a fairly polite \"mentoring\" email where I gave him advice on ways to improve and things to study up on to help him in his career.... something that is - you know - expected of me as a DE at a very large company... and the fuck-head complained to HR about it.\n\nI fucking hate it... he wasn't the only \"senior\"-level idiot hired on to my team - a decision unilaterally made by an idiot manager that decided to handle all interviews herself, and not have technical interviews conducted.  It really bugs the shit out of me... it took me *fucking years* to get a senior title.. and these guys were just handed one for nothing - and instead of doing everything in their power to at least *try* and look competent... they just quarter-ass their job so that they're going to have fuck-all to show for it when they eventually get shit-canned.\n\nYou will use my formal title: Se√±or Software Developer.\n\nWhile I agree that titles lost the meaning, I also disagree with:\n\n&gt; Consider implementing a system similar to those used by larger tech companies, where levels (like L3, L4, L5) provide a more nuanced view of seniority without resorting to title inflation.\n\nIt changes absolutely nothing. You're just using different labels, nothing more. It's the same as using Principal, Staff, Senior Principal or Senior Staff as titles above a Senior. L3, L4, L5 - they also mean absolutely nothing. They are subject to the same \"inflation\".\n\nNot to mention that none of those are comparable between companies. There are companies where you can be a \"Senior Software Engineer\" with 3 years of experience, while in another company at 3 yoe you move from \"Graduate\" to \"Junior\".\n\nThis is why levels.fyi or Glassdoor exists and why big name companies is attractive.\n\nMy work lets me set me own title, so long as it's not misleading, and keeps my role as a \"Software Engineer\" separate.\n\nSometimes it causes problems: It was a little awkward to explain why I was the \"Chief Lizard Wrangling Officer\" on my employment verification letter to the mortgage broker\n\nIt‚Äôs all fun &amp; games till some sociology major in HR gets involved and tightly couples title to pay. We need a solid mid level tier and those guys need time to grow into their skin, but then some cheap bastard accounting consultant decided not to bump their pay commiserate with the market and rent, forced them to move to HCOL cities for some hair-brained RTO mandate and set up a system that encourages people to inflate their accomplishments to vye for a senior title in order to just stay afloat. \n\nWe also get wrapped around the axel over this idea that a senior is somehow faster at churning stuff out than a junior or mid when the real cause of the slowness is your rushed together codebase because some VC stuck a cattle prod up your ass and told you to go faster despite how we all know that ain‚Äôt how it works. In the first 6 months a mid level and a senior are barely distinguishable in terms of productivity.\n\nAlso can we stop saying silly shit like ‚Äúoh she‚Äôs senior so she gets the leetcode hard and he‚Äôs mid so we‚Äôll ask two leetcode easies‚Äù. Level and experience does not mean you just answer harder leetcode questions. Level and experience means you have more war stories so you should focus on explaining what the engineering org is trying to accomplish and see if they‚Äôve seen that shit before or better yet, led that shit before. If we keep over rotating on algorithms especially for mid+ we‚Äôre going to spend a long time being unproductive at best and hire incompetent jackasses who‚Äôs only technical skills involve solving puzzles that a theoretical PM has given perfect specifications for.\n\nThat‚Äôs how you end up with companies where every promotion announcement is accompanied by a bunch of ‚ÄúI thought you already were a level 3‚Äù messages. To keep salaries down they don‚Äôt promote anyone who isn‚Äôt doing 102% of the next title up.\n\nTitles are kinda stupid. One of the famous early software shops (I think it was bell labs?) just had the title ‚Äúmember of technical staff‚Äù for everyone. That was pretty cool and avoided these stupid distractions and dick waving.\n\nUntil you try to change jobs.  Netflix also had this (everyone was just Senior Software Engineer).  Which was great, until you went to get another job\n\nThey made you a Senior (or at best Staff) because \"you can't go from Senior to Principal\" even though most people there were operating at a Principal level already.  It took a long time for the industry to catch on, and then that's why Netflix started getting titles.\n\n&gt;¬†Remember when being a ‚ÄúSenior Software Engineer‚Äù actually meant something?\n\nNo, I do not. I‚Äôve been doing this for almost 20 years and ‚Äúsenior‚Äù was always a title earned in &lt;5 years. It‚Äôs never been all that lofty.\n\nIf you look at his LinkedIn, you can see that the author of the blog post apparently was a Senior Engineer with only 3 years experience.\n\n15 seconds into the article I was like \"this screams senior engineer who's mad other people are also senior engineers\"\n\nThat‚Äôs actually hilarious and re-contextualizes this article to be the author grappling with younger folk matching up to his skill level and blaming titles.\n\nRealizing there are those with less experience than you who are younger, but are getting paid more and/or are just plain smarter than you is a humbling experience that everyone must grapple with at some point. \n\nAge does not equal skill, but it brings experience which can factor into one aspect of skill.\n\nI got some serious blinders vibes. Author thinks they remember a reality where things were better, but it was never the way they think it was. Reminds me of when people talk about \"a simpler time before everyone stared at a screen and actually talked to people\" but the reality was everyone had their nose in a newspaper.\n\nI think the real title here is \"I realized job titles are arbitrary to the company setting them and I wish we had a universal standard\"\n\nTBH I don't actually disagree with the sentiment that \"Senior does not mean particularly experienced\". I've always thought it super weird that someone with 4 years experience would be considered \"senior\". I just don't think senior used to mean more.\n\nWhat has changed is that the amount of experience on teams is waaay larger. I joined the games industry in 2007. Around that time the average time someone spent in games was like 5 years. There were almost no devs in their 40s. People burned out fast and changed fields.\n\nOver the past 20 years the number of software engineers has **exploded**, and people are now staying in the field \"for life\". I feel like the generation ahead of me was the first significant \"lifer\" gen. When I joined my current team I was \\~35 and one of the youngest, least experienced!\n\nSo yeah, things didn't used to be better, but in 2024 \"senior\" is honestly pretty junior.\n\nI concur, and I've been working 35 years. There is nothing special about the words \"senior\" or \"engineer\".\n\nSame here. Likewise services companies billing juniors at higher skill levels than they have has been a thing since forever.\n\n[deleted]\n\nI ignore everyone who pulls their title as if it means being right or something.\n\nFavorite place I've worked so far, they decided to print us business cards because we were going to job fairs and needed something to hand out, and everyone had to go look up our job titles to put on the cards because nobody remembered what they were.\n\nAll I know is,¬† I was a programmer, and suddenly I was called a \"software engineer\". No engineering degree...¬†\n\nEngineering predates engineering degrees. Software engineering is as different from civil engineering is as different from chemical engineering is as different from electrical engineering, etc. \n\nOur discipline is far too recent to have codified standards and the stakes for most software are no where near as high or permanent. \n\nThis website wouldn‚Äôt exist if it had to coded to the standards of the space shuttle flight computers. Hell. The web wouldn‚Äôt even exist.\n\nThe things that we can codify we already build standards for. You can use a oauth compatible solution for login for instance. Or use an https server for secure communication. Use a database to safely store data. We don‚Äôt have a much of a need for degrees when we can write code that encapsulates that expertise.\n\nCanada actually has regulations about this: You can't have a title with \"Engineer\" without an Engineering degree. \n\nI'm a Canadian living near the US border. When I worked in the US, I was a Software Engineer. Now working in Canada (for the same company), I'm a Software Developer.\n\nFrom what I've seen, most software companies in Canada just don't use the title \"Software Engineer\", because although there are some people with Computer Engineering degrees, the more common degree is Computer Science, usually falling under Bachelor of Science or Bachelor of Mathematics.\n\n&gt; Canada actually has regulations about this: You can't have a title with \"Engineer\" without an Engineering degree. \n\nThere is something similar in Norway, where [_sivilingeni√∏r_](https://en.wikipedia.org/wiki/Sivilingeni%C3%B8r) is a protected title. Lots of us think it translates as \"civil engineer\" but it really translates as \"certified engineer\". Anyone can call themselves engineer, but to be a sivilingeni√∏r there are education requirements (more or less MSc, or cand. scient. if you're old).\n\nThat said, most people who study IT get a degree in informatics, and then get called a variety of job titles that I suspect nobody really cares about: To people outside IT we just say we work in IT, and to people inside IT we say what we actually work with. The job title is just something that exists in an HR system somewhere and is only relevant for those kinds of discussions.\n\nAm in Canada at Microsoft and we have many \"Software Engineer\"'s without degrees.\n\nMicrosoft (and other large companies) openly violate EGBC's  guidance on this in BC. Given the increasing enforcement of the provisions of the Professional Governance Act (legislation passed several years ago that gives EGBC the mandate to enforce this), I'm interested in seeing if that changes.\n\nMy understanding is that EGBC only really cares when local companies do this. Which is why HootSuite had to switch to using the title \"Software Developer\". As to how Mobify and D-Wave have been able to use \"engineer\" without EGBC lowering the boom on them, who knows...\n\nTo my knowledge, Canada does not have federal regulations about this. It comes down to provincial regulations. Alberta and Ontario in particular have strong regulations around the protected use of the Engineer title (i.e., you must be a professional engineer to use it). In BC that's not the case (or at least, wasn't until recently. There's recent case law that might change this). In BC the only protected titles are Professional Engineer and Engineer in Training. Engineer itself is not protected.\n\nCurrent BC law on protected engineering titles:\nhttps://www.bclaws.gov.bc.ca/civix/document/id/complete/statreg/14_2021#section4\n\nCase law from earlier this year that may protect engineer as a title:\nhttps://www.egbc.ca/News/Articles/Court-Ruling-Confirms-Title-Protection-Over-Engine\n\nAccording to that law you cite \"Engineer\" is not protected.  Only these 3 are:\n\n(a) \"professional engineer\";\n\n(b) \"professional licensee engineering\";\n\n(c) \"engineer in training\".\n\nI believe anyone who creates a runtime, programming language or game engine, for which other software can be built, is worthy of the software engineer title.\n\nThis is only for certain professions, I can find many photocopier engineer jobs advertised in Canada right now.\n\nLol, no idea why people make up nonsense like this when its so easy to check its bullshit.\n\nhttps://www.glassdoor.ca/Job/software-engineer-jobs-SRCH_KO0,17.htm\n\nLiterally thousands of Software engineer jobs advertised none of them asking for Engineering degrees. \n\n&gt; From what I've seen\n\nLiterally zero research done...jesus reddit.\n\nAs far as I can tell Software engineering at uni is just a CS degree where you have to do a module on project management and version control...that's literally all the difference is lol.\n\nAnd a developer, and a consultant, I've even been a researcher. \n\nThe work has always been programming.\n\nSadly I missed out on the era when \"Webmaster\" commanded the respect it should.\n\nYep. I feel horrible calling myself an engineer(because it‚Äôs my job title) knowing how long people go to school for this, while I did no school.\n\nwhen I did CS (many moons ago) I had a PhD professor who had worked at Los Alamos. He did nuclear explosion simulations on a Cray super computer (Cray invented what is now called a graphics card). He said programmers should never call themselves \"engineers\" because when an engineer says: \"that bridge is highly unlikely to fall down\" they can be quite confident that it is true because the the ground soil is a known type, the materials of the bridge are tried and true, the concrete type's properties are known and the design has been used before X times etc.\n\nWith large scale software, its so much more complicated and there are so many unknowns and foreign dependencies (FOSS rapid changes, API, DB), stupid \"just get it going quickly\" mentalities etc that you can never be confident it won't fall down. I am still surprised it's as reliable as it is.\n\nJust like version numbers.\n\nJust use the year as a version number. Though it might seem backwards from your traditional date based versioning scheme since older dates mean more senior. i.e. \"Software Engineer 2004\" vs \"Software Engineer 2022\".\n\nMm Software Engineer 2004 was a good year. You get those subtle notes of Perl and ASP from their formative years, but none of the bubble bursting turbulence and resulting bitterness of something like a '98. Pairs well with a meal from Emeril Live or Martha Stewart Living.\n\nJust a fun thing to note: I once worked in a company where they introduced a standard career development path for engineers. Initially they wanted to do something like \"Software Engineer v1\", \"Software Engineer v2\" and \"Software Engineer v3\" before you ever get to be \"Senior Enginer v1\".\n\nAfter my feedback that this would feel like a scam to engineers, they changed this to only \"Software Engineer I\", Software Engineer II\" and \"Senior Software Engineer I\" and so forth...\n\nSo they basically just removed a level and used roman numbers instead of \"versions\" (whoever came up with that, lol). When I pressed on the matter again so that they understood that is still kind of scammy, I was told that they need at least that many levels to properly negotiate salaries...And then they introduced this under the pretext that the engineers have been asking for clearer career paths, and everyone believed that and was happy, thinking that they now have a clear plan for their career development. A few years later (I'm not there anymore), ex-colleagues complain about being stuck at their level and salaries without any opportunities to advance.\n\nI've repeatedly seen management and HR fuck up on this one. Having a chain of titles to advance into is a nice first step. Having no clear criteria to get there and management that doesn't consider that a problem will lead to people leaving.\n\nI've seen that practice work really well - salary banding, levels, etc.\n\nBut it does need to come with regular pay band adjustments for inflation especially in competitive fields, just like anything else.\n\nIt is wrong to say titles have lost all meaning; it is more appropriate to state they're treated as royal titles of nobility by clueless HR personnel. Titles do not, and have never meant anything to engineers worth their salt.\n\nI'm sure some of them know we're not going to solve P vs. NP, but the titles are a great influence to clueless HR personnel who think words like `senior` and `principal` mean only those people can do \"this\" job which to them, sounds really challenging, complicated, and mind-bending levels of difficult.\n\nThese are the same people who struggle to open a PDF on their PC.\n\nEvery web developer after electron:\n\nIs this software engineering? üíÅ‚Äç‚ôÇÔ∏èü¶ã\n\nI disagree - I still call myself **The Ultimate Archduke of All Professions**. People like epic titles. I mean, some democratic countries still have royals after all ...\n\n[deleted]\n\nMaybe we all should be.\n\n[removed]\n\nSame, but today I'd prefer to be a Software Engineer.\n\nI was just looking at Staff &amp; Principle engineer job postings with descriptions that sound mid-level at best. Nothing about architectural decisions or crazy scaling/distributed issues or leading teams &amp; projects - just the typical meet w/stakeholders and build the things. 5yrs experience. \n\nJust applied to an ‚ÄúApplication Developer‚Äù job marked ‚Äúentry level‚Äù that wanted 2+ yrs experience and a *Masters* in CS. They‚Äôve reposted it at least twice now. I work in the same industry &amp; region doing the exact same thing at a mid/senior level &amp; probably won‚Äôt even get an interview w/only a BS. \n\nThe idiotic result of HR not knowing wtf they‚Äôre talking about plus companies refusing to hire or train Juniors is that everyone gets a flood of new grads through mid-levels applying for *everything* and the pipeline of actual ‚Äúseniors‚Äù is going to dry up.\n\nMany companies have pay bands for different titles.\n\nI was Senior Software Engineer at a big tech company then got laid off. My new employer needed to make me \"Senior Staff\" in order to match my previous pay. I do a lot less at this company than I did at my previous one.\n\nThe titles never really had much meaning. So many parts of a non-engineering org don't really even understand what we do. My first job was Systems Analyst/Programmer, but I was really an IT guy. I got promoted to System Programmer, which paid more but always seemed like a lesser title to me...not that it mattered.\n\n\nAfter decades as a software \"Engineer\" or \"Developer\" I long ago started calling myself a \"computer programmer\" and the only people who know my title are my boss and HR. The only thing that matters at work is whether I get the job done.\n\nAfter 20 years I still simply sign as \"software developer\". Even though I do *everything*, from project and employee management, high level architecture, backend and frontend code, database administration, cloud and kubernetes deployment, support and documentation. I don't really care about the title, do you?\n\nAbsolutely this. The only time I compromise is when job seeking because an levelled ‚Äúengineer‚Äù is often filtered out for any senior+ roles.\n\nMost companies I've witnessed as a consultant, working for them, or being close to existing employees were very poorly run. \n\nA few rare examples were just that, exemplars of excellence. \n\nThe poorly run ones were all variations on the same bad, and the great ones were also variations on the same greatness.\n\nWhat often kept them in business was various forms of inertia. They captured a regional market, or occupied a market niche. A combination of good marketing and sales (often sleazy) and stupid customers kept them in business despite their poor quality products.\n\nPoor management always made poor products; great management made great products.\n\nWhat was common among poor companies was the usual things people complained about; but they usually boiled down to a pile of examples of authority and responsibility being wildly out of balance. To nobody's shock at all, the great companies had authority and responsibility in near perfect balance.\n\nNearly everything bad had its black mirror opposite in good:\n\n* Micromanagement vs autonomy.\n* Burdensome scrutiny vs trust\n* Control information for power, distribute information for success\n* Seniority was prioritized over merit vs merit over seniority.\n* Zillion layers of hierarchy vs flattened structures.\n* Incentives for being a dick vs incentives for doing your job.\n* Not firing people causing problems vs aggressively firing people who cause problems.\n* HR which was there to protect the company vs not having HR at all.\n* A C-Suite vs no C-Suite.\n* Meetings vs seeing meetings as someone causing trouble and wasting time. (i.e firing people who try to have endless meetings).\n\nThe above rules aren't big companies vs smaller companies. Many of the great companies I've witnessed were fairly large. But, that is an interesting point. What seems to happen is they don't endlessly add people as they grow. Every hire is because there's a problem, not a hint of a problem, or someone making a mountain out of a molehill problem, but a genuine sense of relief when a position gets filled. I would argue that these things like no C-Suite is not something you can scoff at by saying, \"Well little startups can get away with that.\" but that having a C-Suite is a problem where nobody is asking why something is needed. A company not asking why is going to probably keep hiring as many people as their revenue can support. \n\nSo, inherently companies without an HR, a C-Suite, a pile of managers, and not having endless meetings is going to be smaller than the bloated mess which didn't avoid these stupidities. \n\nThen, when you have skipped these things, then other things like endless executives being blowhards about how great their company is, just doesn't happen.\n\nHere's a fun list: Warren Buffett, Ray Dalio, Carl Icahn, Bill Ackman, George Soros, Peter Thiel, Jim Simons. I suspect most people reading this recognize the first 7 names; but the last one is probably a mystery. Warren Buffett as an example endlessly plays himself as a quiet modest guy, but is always making public statements which are gobbled up by a large audience as do most of the rest. That last name, though is the most interesting. \n\n* Warren Buffett: ~20% annualized,\n* Ray Dalio: ~11% annualized,\n* Carl Icahn: ~15% annualized,\n* Bill Ackman: ~16% annualized,\n* George Soros: ~20% annualized,\n* Peter Thiel: Difficult to quantify (venture-based),\n* Cathie Wood: ~35% annualized (ARK Innovation ETF, shorter-term performance),\n* David Tepper: ~25% annualized,\n* Jim Simons: ~66% annualized (Medallion Fund)\n\n66% percent sustained for decades while managing many 10's of billions. Yet, he kept quiet, wasn't a blowhard, and had a tiny staff. \n\n* Warren Buffett (Berkshire Hathaway): ~$950 billion,\n* Ray Dalio (Bridgewater Associates): ~$140 billion,\n* Carl Icahn (Icahn Enterprises): ~$23 billion,\n* Bill Ackman (Pershing Square Capital): ~$18 billion,\n* George Soros (Soros Fund Management): ~$28 billion,\n* Peter Thiel (Founders Fund): ~$11 billion,\n* Cathie Wood (ARK Invest): ~$24 billion,\n* David Tepper (Appaloosa Management): ~$14 billion,\n* Jim Simons (Renaissance Technologies): ~$130 billion\n\n* Warren Buffett (Berkshire Hathaway): ~390,000 employees,\n* Ray Dalio (Bridgewater Associates): ~1,300 employees,\n* Carl Icahn (Icahn Enterprises): ~23 employees,\n* Bill Ackman (Pershing Square Capital): ~40 employees,\n* George Soros (Soros Fund Management): ~600 employees,\n* Peter Thiel (Founders Fund): ~50 employees,\n* Cathie Wood (ARK Invest): ~45 employees,\n* David Tepper (Appaloosa Management): ~30 employees,\n* Jim Simons (Renaissance Technologies): ~300 employees\n\n* Warren Buffett: 410.5 employees per billion\n* Ray Dalio: 9.3 employees per billion\n* Carl Icahn: 1.0 employee per billion\n* Bill Ackman: 2.2 employees per billion\n* George Soros: 21.4 employees per billion\n* Peter Thiel: 4.5 employees per billion\n* Cathie Wood: 1.9 employees per billion\n* David Tepper: 2.1 employees per billion\n* Jim Simons: 2.3 employees per billion\n\nI post these numbers to show that people trying to justify having micromanaging, shitty companies with bloated staffs, lots of manager, meetings, and other BS are somehow a requirement. They aren't. They only serve to make petty people feel better about themselves. But, I love the petty arguments petty people make to support their pathetically existences in  poorly run companies. Success can happen despite a bloated mess of a company, but it is not a requirement. \n\nTo circle back to the original point. Titles, are often part of a bloated mess. The great companies I saw had fairly vague titles which described what people did:\n\n* Programmer\n* Artist\n* Accounting\n* Sales\n* Engineer (doing engineering)\n\nWhat I didn't see in these companies were \"senior\" or even \"head of\" in those titles. Someone might say, \"I run the accounting department\" yet their title was \"Accountant\"; most certainly not CFO.\n\nIn the worst companies they used titles pretty much in lieu of pay. People would get promoted over and over and over and over; yet were mostly doing the same job. They might have a P-number for programmers. So you started as a P1 if you had a crappy degree from a community collage, and a P3 if you were a 4 year graduate. They would \"bless\" their most desired hires with a P4 or P5 and then remind them over and over that they didn't deserve the higher number. A P7 would be someone who had \"been there since the beginning\".\n\nYet, the person who was director of development was hired fairly fresh out of business school and their only qualification was an MBA and some good connections. Yet, this person is paid 3 times as much as a P7. Then there would be product managers, project managers, and in the worst of the worst of the absolute worst, scum masters. Or where satan had the pernicious, iniquitous, and the damned forge a company in the darkest bowels of hell; agile coaches.\n\nThese are the companies where they take a halfwit community college graduate and bless them with the title \"Software Engineer\".\n\n&gt; Unable to always match the salaries offered by tech giants, these companies resort to inflating titles as a form of non-monetary compensation. \n\nIs this just the IT variant of paying in exposure? It feels like getting into getting a shiny plastic medal territory. (Except of course when it's a \"we want to pay you a competitive wage but to do that we need to place you in this HR bucket\")\n\nReading the comments there seems to be less \n\n&gt; inflating titles as a form of non-monetary compensation  \n\nand more inflating titles because that's dictated by HR rules to be able to compensate them appropriately.\n\nIt's easier to use existing title frameworks to measure someone's worth than to come up with a better way to assess experience and competence.\n\n\nBack in the day, age alone was enough to command respect, but is age really a good measure of someone's value? \n\nI've met people with over 20 years of programming experience who had no business solving problems or writing code and I've met people with only 2 years of experience who were incredible problem solvers and programmers.\n\n\nSo how do you fairly pay/reward these people? \nHow do you create a system that rewards both talent and endurance in a way that‚Äôs truly fair?\"\n\nCan we just have the humility to say \"Software Engineer\". Yes that means you have to make your own judgement about which \"L\" my skillset is. \n\nMy apologies to managers, but that means you need to know what your people are capable of without someone bestowing a label upon you.\n\nYes, and?\n\nThis is what happens when the tech industry (which literally runs our entire world) has absolutely no governance authority, standardization within roles, Unions, etc. \n\nIt's \"throw it at the wall and see what sticks\" mentality. And this is what you get. \n\nYou want clear definitions and formality? Then you need structure. And that means you can't play as fast or loose. Which those in tech scream \"that doesn't work in a fast-paced industry\". Yeah, \"doing due diligence\" and \"playing it safe\" doesn't work...until you have a data breach every other day. \n\nMaybe the best thing right now is to *slow the fuck down*....just a smidge. A tad. A wee bit. You know, to refortify our foundational basics a little bit. Solidify our roles. Because if we keep flailing around as if we're wearing a chicken suit doused in gasoline and lit on fire, then more shit is going to burn the fuck down.\n\nWhen I started my career in the wonderful world of software development, the programmer was not yet an official role. My title was system engineer. Now, after more than forty years in the business, I feel that my original title still best describes what I do.\n\nI miss the \"Webmaster\" title.\n\nI'm an expert in so many random technologies that I have trouble even giving myself a title or explaining what I know when working with new teams. I used to be 1-stack of expertise, but now I'm crossing into so many areas.\n\nWhen I'm asked for my title, I sink a little because whatever I can possibly say won't be accurate.\n\nI push buttons for a living.\n\nThe last paragraph really sums up how I've found consistent work as a freelancer. I had never really received a formal title from anyone, even when working at my first company, I just called myself a full stack web dev. I also had experience leading a small team working on c# and node apis as well as mean/mern around 2 yoe.   \n\nA couple years ago, l had this client that kept saying, \"you're like a cto\", after a year or two of working together, and it kind of hit me since I was architect, engineer and developer of this site builder platform.  I've since added the fractional cto title to that role, which really helped me find similar clients and projects that fit what I was looking for.\n\nMy only interest is what are my obligations and what I will be paid for it. My only presentation to whomever interviews me is what I have done and what I can do.\n\nSo, I don't call myself anything. Well, maybe human. I say I grow software, but I don't identify myself with it. \n\nI do let people attach a title or whatever, since I do sign the contract and agree to abide by the company and whatever title it has for me. But that's about them, how others see me or see a use of me.\n\nYou have no fucking idea how incredibly god damn salty I was when I joined a company at a title I've been working towards for god damn near 20 fucking years.... only to have another dipshit manager come in and offer a close title to someone that was literally fresh out of school.\n\nThe best part are these dumb-fuck developers acting like the title they have is somehow \"deserved\", and will argue with me over implementations... and then be fucking shocked when they realize that I was right and they were wrong.\n\nThis is 100% another industry problem that stems from employers, management and hiring practices, not programmers.\n\nI've seen this argument before, the problem is in presuming they *ever* had meaning. They didn't. Some people really don't want to admit that though, people like to believe that when *they* got hired, it really *meant* something.\n\nI feel the same way about \"architect.\" Most employment notices have \"enterprise architect,\" for example, but from the job description, they want a developer. For \"data architecture,\" they want a DBA. They do not seem to know what a \"solutions architect\" is, either.    Also, some notices are completely ridiculous such as \"email architect\".  It seems that the word \"architect\" is another way of writing \"senior\".\n\nWe already have staff, principal and distinguished software enginners, but we still could have a couple of more, e.g. \n\n* prominent software engineer\n* venerable software engineer\n* magisterial software engineer\n* luminous software engineer\n\nand so on\n\nSoftware engineer titles never had any meaning. Programmers are not engineers; It's a self aggrandizing title that the software industry has adopted for itsself.\n\n99% of \"software engineers\" have literally never done a lick of engineering in their entire lives and simply spend their days cranking out some kind of application code via trial and error until it works/is good enough. Anyone is free to call themselves whatever they want, especially if it's their job title, but don't expect to be shown the same respect as actual engineers when the role requires none of the rigourous design, mathematical analysis, or other principal components of the engineering process.\n\nIf you want titles to have meaning then you first need to stop calling every single programmer/developer an \"Engineer\".\n\nI feel like I've experienced far more senior software engineers who were borderline incompetent that were the product of inertia, they got the title after working in the same role on the exact same thing for a long time. Or were given that title by interviewing well but can't really work outside of leetcode. Or by having a PhD in some specialization but can't code really at all. \n\nAt least a too soon promo probably got there by being technically strong.\n\nThey kind of stopped having any meaning when the term for most of the folks changed from \"programmer\" to \"engineer.\" Yeah, sure, there are some folks doing real architectural engineering, but most coders are simply doing coding.\n\nBut, hey, customer service engineer, field service engineer, sales engineer ‚Äì I get it, titles make us feel good.\n\nThis is why CVs hardly matter. ChatGPT will do that for you. I‚Äôve found live interviews and coding (where the hands are visible) the only reliable way to hire top talent. It‚Äôs shocking how many great CVs belong to useless candiates.\n\nI have done plenty of interviews on both sides. I have found live coding kinda useless. You don't have time to get into a real problem, so people just learn to spit out pre canned answers to known questions.\n\nI wish there was a substantive difference between programmer and engineer, like you had to pass certification with a board to be an engineer. Maybe it's a formality after your degree but it would give it some meaning imo\n\nMaybe it's a simple process, but if companies had to actually require that cert to post it as an engineer it wouldn't lose its meaning\n\nThat would probably cause a slew of other issues tho lmao\n\nIt's probably more of an issue of the title meaning nothing to me that I wish that in all honesty. What does the degree mean if anyone can call themselves an engineer? I believe it's different in Canada for \"engineers\"(?)\n\nIt should come with an ethics board that can strip the title too\n\nYes in Canada its a protected title, you cant just slap it on anything you like\n\n&gt;That would probably cause a slew of other issues tho lmao\n\nThis debate has raged for decades.  I remember being incensed in my college days (literally in the 1900s, lol) at the idea that being a programmer would require \"certification\" and how that could slow the continued evolution of the profession.\n\nNow I have a far more nuanced view, and I too think that some level of \"engineer\" distinction like the rest of the world is valuable.  Less about specific programming techniques and more about ethical considerations and general verification techniques. We've seen crypto, NFTs, we've seen LLMs, we've seen deceptive designs and skinner box-based incentives.  We've seen Boeing's MCAS kill people.\n\nEverything makes Therac-25 look like the good old days.\n\nMy last job didn‚Äôt have a staff engineer title. Basically a junior and senior principal engineer. But that‚Äôs a very different skill set and workload. So my about me section doesn‚Äôt agree with my recent work history.\n\nwhat meaning\n\nIf you're an engineer and you're not being used as a mechanical engineer you're doing pretty good. It seems like the only difference in the degrees is how many hats they'll want you to wear.\n\nalways have\n\nDid they have meaning? What was it?\n\nSomeone needs to tell the man that it's always been like this. I've been at a company that has pegged senior engineer to being between 4 and 10 years of experience for over 100 years now. The difference being that for the longest time after this point everyone would be expected to be promoted into management.\n\nIt's been this way for a long time.  Unless it's a known company (like Microsoft, for example), the titles do not mean very much.\n\nIt's so true‚Äîtitles like 'Senior' or 'Staff' often feel like they‚Äôre based more on salary bands than actual skill or impact. Has anyone here experienced burnout from being promoted too soon? How can companies balance titles with the reality of what engineers can actually deliver?\n\nIn an industry that historically from my experience hasn‚Äôt liked having peak bodies and standardization of what it means to be a developer, let alone the levels, we have someone who outlines a level that seems to have too much responsibility that reminds me of harking back to how companies worked historically where you just had less people and had to shoulder more responsibility - now decrying the evolution of the field.   Feels rich and out of touch.  Having more niche roles in big organizations that have large scale systems and responsibilities is a natural evolution.\nThere are some good points on misused title inflation due to competition and retention and the long term problems but solutions where you go hey try to standardise individually across an industry is just very unrealistic.\n\nIf you want standards you need a supported peak body everyone is a part of.  Otherwise what‚Äôs stopping people from doing their own thing and who‚Äôs validating that the level means x and not y.\n\nI hate that I train people to learn how to do what I‚Äôd consider trivial tasks who got hired with a title of sr software engineer ü§¶\n\n\nThat or my job is seriously hard\n\nJob titles have only ever been a rough guide to what someone does. \n\nI have been a sales director of a team of one (me), a general manager, a computer consultant, a development manager, and a solutions manager. \n\nI‚Äôve also been a developer, a senior developer, head of product management, software architect and more. \n\nQuite often I got given the swanky job title because they figured it was cheaper than paying me more. \n\nAll job titles are bs. What matters is what you do, and what they entrust you with.\n\nDid they ever have meaning outside of any organization? Or even inside most? I mean, I suppose they might identify roughly what responsibilities someone might have.\n\nWhat, you're telling me that *\"Amazeballs Commander in Chief of AI Vision Evangelism\"* doesn't actually mean anything?\n\nConsider me flabbergasted.\n\nTitle inflation is real, during some economic cycles managers have to give higher titles just to be competitive and this also created bad internal dynamic on the team\n\nI can almost guarantee you that these titles weren‚Äôt set by anyone on the engineering side.\n\nWdym?\n\nI am and will always be Se√±or Engineer!\n\nThere is no uniform definition of a senior. The YoE requirement ranges from 3 to 8 depending on who you ask, and the scope is between IC and team tech lead.\n\nThe effectiveness of people management and system design (Senior+ skills) is subjective enough to remain perpetually undecided, so senior+ can largely be made of bullshitting and politics.\n\nThe only universal agreement is that scope should increase as the title seniority increases, and the lower-level someone's title is, the more direct interaction with code they have, as higher levels focus on guidance, system design, and product direction.\n\nBut how can you expect consistency between companies? Software engineering is the least-rehulated engineering discipline. Joe writing HelloWorld in Python makes him a software engineer. We aren't licensed, regulated, certified, or tested beyond Leetcode. Without consistency in our profession, and no reasonable quantifiability of our skills, titles have been meaningless for a long time.\n\nI once tried to devise a scoring system based on the percent of the day a position spends on various IT tasks as an alternative to titles. It didn't catch on ... yet.\n\nThere are 4 types of dev:  \nJunior will need everything chewed.  \nSpecialist dev will get shit done as long as they follow a standard they are used to.  \nHacker dev will get anything done and fast.  \nIT department dev is the developer that doesn‚Äôt code most of the time, take whatever shit the other devs don‚Äôt want to do and is sociable enough to talk to the business in a way they feel good about it. Demos, meetings, unblocking the junior dev, keeping the hacker dev on the important work. Making sure the special dev isn‚Äôt isolated on a corner somewhere. The IT department dev spends most of his time dreading his next task, does it thinking he‚Äôs an absolute failure but people think he‚Äôs keeping things going somehow.\n\n100%. I had this conversation at work not long ago. I used to keep it simple and have SE 1-3, and Software Architect. Then came the need to add Senior SE. Then Associate SE for those who didn‚Äôt really fit as SE 1 yet. Then we added Staff and Principal and widened SE 1 and SE 2 and removed Associate, Architect and SE 3. We now can mod Staff and Principal with Senior or Distinguished. It‚Äôs really become quite crazy. I don‚Äôt really care for it. I like simple.\n\nIn my experience, title inflation is even worse in large corporations. In my team, 'staff engineer' is almost like an entry-level position. It all started when one person was promoted too easily.  \n  \nFrom the manager‚Äôs perspective, the team has one promotion quota each cycle. Even if the person might not fully qualify for the promotion, the manager doesn‚Äôt want to waste the quota."
  }
]